Conference	Year	Title                                                                                                                           	DOI                      	Link                                       	FirstPage	LastPage	PaperType	Abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	AuthorNames-Deduped                                                                                                                                                                                                       	AuthorNames                                                                                                                                                                                                               	AuthorAffiliation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	InternalReferences                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	AuthorKeywords                                                                                                                                                                      	AminerCitationCount_02-2020	AminerCitationCount_06-2020	XploreCitationCount - 2020-01	PubsCited	Award
SciVis    	2012	A Data-Driven Approach to Hue-Preserving Color-Blending                                                                         	10.1109/TVCG.2012.186    	http://dx.doi.org/10.1109/TVCG.2012.186    	2122     	2129    	J        	Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Lars Kuehne;Joachim Giesen;Zhiyuan Zhang;Sungsoo Ha;Klaus Mueller                                                                                                                                                         	Lars Kühne;Joachim Giesen;Zhiyuan Zhang;Sungsoo Ha;Klaus Mueller                                                                                                                                                          	Friedrich-Schiller-Universität Jena;Friedrich-Schiller-Universität Jena;Stony Brook University;Stony Brook University;Stony Brook University                                                                                                                                                                                                                                                                                                                                                                              	10.1109/TVCG.2009.150;10.1109/TVCG.2008.118;10.1109/TVCG.2007.70623;10.1109/TVCG.2012.234;10.1109/VISUAL.2003.1250362                                                                                                                                                                                                                                                                                                                                                                                                  	Color blending, hue preservation, knowledge-assisted visualization, volume rendering, parallel coordinates                                                                          	7                          	0                          	10                           	24
SciVis    	2012	A Novel Approach to Visualizing Dark Matter Simulations                                                                         	10.1109/TVCG.2012.187    	http://dx.doi.org/10.1109/TVCG.2012.187    	2078     	2087    	J        	In the last decades cosmological N-body dark matter simulations have enabled ab initio studies of the formation of structure in the Universe. Gravity amplified small density fluctuations generated shortly after the Big Bang, leading to the formation of galaxies in the cosmic web. These calculations have led to a growing demand for methods to analyze time-dependent particle based simulations. Rendering methods for such N-body simulation data usually employ some kind of splatting approach via point based rendering primitives and approximate the spatial distributions of physical quantities using kernel interpolation techniques, common in SPH (Smoothed Particle Hydrodynamics)-codes. This paper proposes three GPU-assisted rendering approaches, based on a new, more accurate method to compute the physical densities of dark matter simulation data. It uses full phase-space information to generate a tetrahedral tessellation of the computational domain, with mesh vertices defined by the simulation's dark matter particle positions. Over time the mesh is deformed by gravitational forces, causing the tetrahedral cells to warp and overlap. The new methods are well suited to visualize the cosmic web. In particular they preserve caustics, regions of high density that emerge, when several streams of dark matter particles share the same location in space, indicating the formation of structures like sheets, filaments and halos. We demonstrate the superior image quality of the new approaches in a comparison with three standard rendering techniques for N-body simulation data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Ralf Kähler;Oliver Hahn;Tom Abel                                                                                                                                                                                          	Ralf Kaehler;Oliver Hahn;Tom Abel                                                                                                                                                                                         	KIPAC;KIPAC;KIPAC                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	10.1109/TVCG.2010.148;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2004.85;10.1109/TVCG.2006.154;10.1109/VISUAL.2003.1250404;10.1109/TVCG.2011.216;10.1109/TVCG.2009.142;10.1109/VISUAL.2001.964512;10.1109/VISUAL.2003.1250404                                                                                                                                                                                                                                                                                          	Astrophysics, dark matter, n-body simulations, tetrahedral grids                                                                                                                    	19                         	20                         	15                           	35
SciVis    	2012	A Perceptual-Statistics Shading Model                                                                                           	10.1109/TVCG.2012.188    	http://dx.doi.org/10.1109/TVCG.2012.188    	2265     	2274    	J        	The process of surface perception is complex and based on several influencing factors, e.g., shading, silhouettes, occluding contours, and top down cognition. The accuracy of surface perception can be measured and the influencing factors can be modified in order to decrease the error in perception. This paper presents a novel concept of how a perceptual evaluation of a visualization technique can contribute to its redesign with the aim of improving the match between the distal and the proximal stimulus. During analysis of data from previous perceptual studies, we observed that the slant of 3D surfaces visualized on 2D screens is systematically underestimated. The visible trends in the error allowed us to create a statistical model of the perceived surface slant. Based on this statistical model we obtained from user experiments, we derived a new shading model that uses adjusted surface normals and aims to reduce the error in slant perception. The result is a shape-enhancement of visualization which is driven by an experimentally-founded statistical model. To assess the efficiency of the statistical shading model, we repeated the evaluation experiment and confirmed that the error in perception was decreased. Results of both user experiments are publicly-available datasets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	Veronika Soltészová;Cagatay Turkay;Mark C. Price;Ivan Viola                                                                                                                                                               	Veronika Šoltészová;Cagatay Turkay;Mark C. Price;Ivan Viola                                                                                                                                                               	Department of Informatics, University of Bergen;Department of Informatics, University of Bergen;Faculty of Psychology, University of Bergen;Department of Informatics, University of Bergen and Christian Michelsen Research, Norway                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2011.161                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Shading, perception, evaluation, surface slant, statistical analysis                                                                                                                	9                          	8                          	8                            	40
InfoVis   	2012	A User Study on Curved Edges in Graph Visualization                                                                             	10.1109/TVCG.2012.189    	http://dx.doi.org/10.1109/TVCG.2012.189    	2449     	2456    	J        	Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	Kai Xu 0003;Chris Rooney;Peter J. Passmore;Dong-Han Ham;Phong H. Nguyen                                                                                                                                                   	Kai Xu;Chris Rooney;Peter Passmore;Dong-Han Ham;Phong H. Nguyen                                                                                                                                                           	Middlesex University;Middlesex University;Middlesex University;Chonnam National University;Middlesex University                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2011.233;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.166                                                                                                                                                                                                                                                                                                                                      	Graph, visualization, curved edges, evaluation                                                                                                                                      	33                         	0                          	28                           	35
SciVis    	2012	A Visual Analysis Concept for the Validation of Geoscientific Simulation Models                                                 	10.1109/TVCG.2012.190    	http://dx.doi.org/10.1109/TVCG.2012.190    	2216     	2225    	J        	Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.                                                                                              	Andrea Unger;Sven Schulte;Volker Klemann;Doris Dransch                                                                                                                                                                    	Andrea Unger;Sven Schulte;Volker Klemann;Doris Dransch                                                                                                                                                                    	GFZ German Reserach Center For Geosciences, Potsdam, Germany;Magdeburg-Stendal University of Applied Sciences, Germany;National Oceanography Centre, Liverpool, UK;GFZ German Reserach Center For Geosciences, Potsdam, Germany                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2010.192;10.1109/VAST.2010.5652895;10.1109/TVCG.2011.248;10.1109/TVCG.2008.145;10.1109/TVCG.2011.225;10.1109/TVCG.2010.223;10.1109/TVCG.2010.171;10.1109/TVCG.2010.190;10.1109/VISUAL.1993.398859;10.1109/TVCG.2010.181;10.1109/TVCG.2008.139                                                                                                                                                                                                                                                             	Earth science visualization, model validation, coordinated multiple views, spatio-temporal visualization, sea level indicators                                                      	11                         	13                         	16                           	41
VAST      	2012	A Visual Analytics Approach to Multiscale Exploration of Environmental Time Series                                              	10.1109/TVCG.2012.191    	http://dx.doi.org/10.1109/TVCG.2012.191    	2899     	2907    	J        	We present a Visual Analytics approach that addresses the detection of interesting patterns in numerical time series, specifically from environmental sciences. Crucial for the detection of interesting temporal patterns are the time scale and the starting points one is looking at. Our approach makes no assumption about time scale and starting position of temporal patterns and consists of three main steps: an algorithm to compute statistical values for all possible time scales and starting positions of intervals, visual identification of potentially interesting patterns in a matrix visualization, and interactive exploration of detected patterns. We demonstrate the utility of this approach in two scientific scenarios and explain how it allowed scientists to gain new insight into the dynamics of environmental systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Mike Sips;Patrick Köthur;Andrea Unger;Hans-Christian Hege;Doris Dransch                                                                                                                                                   	Mike Sips;Patrick Köthur;Andrea Unger;Hans-Christian Hege;Doris Dransch                                                                                                                                                   	German Research Center for GeoSciences GFZ;German Research Center for GeoSciences GFZ;German Research Center for GeoSciences GFZ;Zuse Institute Berlin;German Research Center for GeoSciences GFZ                                                                                                                                                                                                                                                                                                                         	10.1109/INFVIS.2001.963273;10.1109/INFVIS.1995.528685                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Time series analysis, multiscale visualization, visual analytics                                                                                                                    	20                         	27                         	24                           	35
InfoVis   	2012	Adaptive Composite Map Projections                                                                                              	10.1109/TVCG.2012.192    	http://dx.doi.org/10.1109/TVCG.2012.192    	2575     	2582    	J        	All major web mapping services use the web Mercator projection. This is a poor choice for maps of the entire globe or areas of the size of continents or larger countries because the Mercator projection shows medium and higher latitudes with extreme areal distortion and provides an erroneous impression of distances and relative areas. The web Mercator projection is also not able to show the entire globe, as polar latitudes cannot be mapped. When selecting an alternative projection for information visualization, rivaling factors have to be taken into account, such as map scale, the geographic area shown, the map's height-to-width ratio, and the type of cartographic visualization. It is impossible for a single map projection to meet the requirements for all these factors. The proposed composite map projection combines several projections that are recommended in cartographic literature and seamlessly morphs map space as the user changes map scale or the geographic region displayed. The composite projection adapts the map's geometry to scale, to the map's height-to-width ratio, and to the central latitude of the displayed area by replacing projections and adjusting their parameters. The composite projection shows the entire globe including poles; it portrays continents or larger countries with less distortion (optionally without areal distortion); and it can morph to the web Mercator projection for maps showing small regions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	Bernhard Jenny                                                                                                                                                                                                            	Bernhard Jenny                                                                                                                                                                                                            	Oregon State University                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	10.1109/TVCG.2011.191;10.1109/TVCG.2010.191;10.1109/INFVIS.2000.885095                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Multi-scale map, web mapping, web cartography, web map projection, web Mercator, HTML5 Canvas                                                                                       	33                         	36                         	26                           	38
InfoVis   	2012	Algorithms for Labeling Focus Regions                                                                                           	10.1109/TVCG.2012.193    	http://dx.doi.org/10.1109/TVCG.2012.193    	2583     	2592    	J        	In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Martin Fink 0001;Jan-Henrik Haunert;André Schulz 0001;Joachim Spoerhase;Alexander Wolff 0001                                                                                                                              	Martin Fink;Jan-Henrik Haunert;André Schulz;Joachim Spoerhase;Alexander Wolff                                                                                                                                             	Universität Würzburg;Universität Würzburg;Universität Münster;Universität Würzburg;Universität Würzburg                                                                                                                                                                                                                                                                                                                                                                                                                   	10.1109/TVCG.2011.191;10.1109/TVCG.2010.180;10.1109/TVCG.2011.183;10.1109/INFVIS.2000.885087                                                                                                                                                                                                                                                                                                                                                                                                                           	Focus+context techniques, data clustering, mobile and ubiquitous visualization, geographic/geospatial visualization                                                                 	21                         	29                         	24                           	28
SciVis    	2012	An Adaptive Prediction-Based Approach to Lossless Compression of Floating-Point Volume Data                                     	10.1109/TVCG.2012.194    	http://dx.doi.org/10.1109/TVCG.2012.194    	2295     	2304    	J        	In this work, we address the problem of lossless compression of scientific and medical floating-point volume data. We propose two prediction-based compression methods that share a common framework, which consists of a switched prediction scheme wherein the best predictor out of a preset group of linear predictors is selected. Such a scheme is able to adapt to different datasets as well as to varying statistics within the data. The first method, called APE (Adaptive Polynomial Encoder), uses a family of structured interpolating polynomials for prediction, while the second method, which we refer to as ACE (Adaptive Combined Encoder), combines predictors from previous work with the polynomial predictors to yield a more flexible, powerful encoder that is able to effectively decorrelate a wide range of data. In addition, in order to facilitate efficient visualization of compressed data, our scheme provides an option to partition floating-point values in such a way as to provide a progressive representation. We compare our two compressors to existing state-of-the-art lossless floating-point compressors for scientific data, with our data suite including both computer simulations and observational measurements. The results demonstrate that our polynomial predictor, APE, is comparable to previous approaches in terms of speed but achieves better compression rates on average. ACE, our combined predictor, while somewhat slower, is able to achieve the best compression rate on all datasets, with significantly better rates on most of the datasets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Nathaniel Fout;Kwan-Liu Ma                                                                                                                                                                                                	Nathaniel Fout;Kwan-Liu Ma                                                                                                                                                                                                	University of California, Davis;University of California, Davis                                                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/VISUAL.1996.568138;10.1109/TVCG.2006.143;10.1109/VISUAL.1994.346332                                                                                                                                                                                                                                                                                                                                                                                                                                            	Volume compression, lossless compression, floating-point compression                                                                                                                	30                         	0                          	25                           	34
VAST      	2012	An Affordance-Based Framework for Human Computation and Human-Computer Collaboration                                            	10.1109/TVCG.2012.195    	http://dx.doi.org/10.1109/TVCG.2012.195    	2859     	2868    	J        	Visual Analytics is “the science of analytical reasoning facilitated by visual interactive interfaces” [70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	R. Jordan Crouser;Remco Chang                                                                                                                                                                                             	R. Jordon Crouser;Remco Chang                                                                                                                                                                                             	Tufts University;Tufts University                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	10.1109/VAST.2010.5652398;10.1109/VAST.2011.6102461;10.1109/TVCG.2009.199;10.1109/VAST.2010.5652910;10.1109/VAST.2010.5652484;10.1109/VAST.2009.5332584;10.1109/VAST.2010.5652885;10.1109/VAST.2009.5333564;10.1109/VAST.2010.5652392;10.1109/VAST.2009.5332586;10.1109/VAST.2011.6102451;10.1109/VAST.2009.5333023;10.1109/VAST.2009.5333020;10.1109/VAST.2009.5332628;10.1109/TVCG.2011.173;10.1109/TVCG.2011.218;10.1109/TVCG.2011.231;10.1109/VAST.2010.5652443;10.1109/VAST.2010.5653598;10.1109/VAST.2011.6102447	Human computation, human complexity, theory, framework                                                                                                                              	21                         	29                         	22                           	83
InfoVis   	2012	An Empirical Model of Slope Ratio Comparisons                                                                                   	10.1109/TVCG.2012.196    	http://dx.doi.org/10.1109/TVCG.2012.196    	2613     	2620    	J        	Comparing slopes is a fundamental graph reading task and the aspect ratio chosen for a plot influences how easy these comparisons are to make. According to Banking to 45°, a classic design guideline first proposed and studied by Cleveland et al., aspect ratios that center slopes around 45° minimize errors in visual judgments of slope ratios. This paper revisits this earlier work. Through exploratory pilot studies that expand Cleveland et al.'s experimental design, we develop an empirical model of slope ratio estimation that fits more extreme slope ratio judgments and two common slope ratio estimation strategies. We then run two experiments to validate our model. In the first, we show that our model fits more generally than the one proposed by Cleveland et al. and we find that, in general, slope ratio errors are not minimized around 45°. In the second experiment, we explore a novel hypothesis raised by our model: that visible baselines can substantially mitigate errors made in slope judgments. We conclude with an application of our model to aspect ratio selection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	Justin Talbot;John Gerth;Pat Hanrahan                                                                                                                                                                                     	Justin Talbot;John Gerth;Pat Hanrahan                                                                                                                                                                                     	Stanford University;Stanford University;Stanford University                                                                                                                                                                                                                                                                                                                                                                                                                                                               	10.1109/TVCG.2006.163;10.1109/TVCG.2011.167                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Banking to 45 degrees, slope perception, orientation resolution, aspect ratio selection                                                                                             	19                         	24                         	20                           	15
InfoVis   	2012	An Empirical Study on Using Visual Embellishments in Visualization                                                              	10.1109/TVCG.2012.197    	http://dx.doi.org/10.1109/TVCG.2012.197    	2759     	2768    	J        	In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces “divided attention”, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Rita Borgo;Alfie Abdul-Rahman;Farhan Mohamed;Phil W. Grant;Irene Reppa;Luciano Floridi;Min Chen 0001                                                                                                                      	Rita Borgo;Alfie Abdul-Rahman;Farhan Mohamed;Philip W. Grant;Irene Reppa;Luciano Floridi;Min Chen                                                                                                                         	Computer Science, Swansea University;Oxford e-Research Centre, Oxford University;Universiti Teknologi Malaysia;Computer Science, Swansea University;Psychology, Swansea University;Phylosophy, Oxford University;Oxford e-Research Centre, Oxford University                                                                                                                                                                                                                                                              	10.1109/TVCG.2010.132;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.171;10.1109/TVCG.2011.175                                                                                                                                                                                                                                                                                                                                                                                                                           	Visual embellishments, metaphors, icons, cognition, working memory, long-term memory, visual search, evaluation                                                                     	36                         	49                         	34                           	40
SciVis    	2012	Analysis of Streamline Separation at Infinity Using Time-Discrete Markov Chains                                                 	10.1109/TVCG.2012.198    	http://dx.doi.org/10.1109/TVCG.2012.198    	2140     	2148    	J        	Existing methods for analyzing separation of streamlines are often restricted to a finite time or a local area. In our paper we introduce a new method that complements them by allowing an infinite-time-evaluation of steady planar vector fields. Our algorithm unifies combinatorial and probabilistic methods and introduces the concept of separation in time-discrete Markov-Chains. We compute particle distributions instead of the streamlines of single particles. We encode the flow into a map and then into a transition matrix for each time direction. Finally, we compare the results of our grid-independent algorithm to the popular Finite-Time-Lyapunov-Exponents and discuss the discrepancies.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	Wieland Reich;Gerik Scheuermann                                                                                                                                                                                           	Wieland Reich;Gerik Scheuermann                                                                                                                                                                                           	University of Leipzig;University of Leipzig                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	10.1109/VISUAL.1999.809896                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	Vector field topology, flow visualization, feature extraction, uncertainty                                                                                                          	2                          	3                          	2                            	31
InfoVis   	2012	Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing                                              	10.1109/TVCG.2012.199    	http://dx.doi.org/10.1109/TVCG.2012.199    	2536     	2545    	J        	People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete                                                                                                                                                                       	Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete                                                                                                                                                                       	INRIA;INRIA;INRIA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	10.1109/TVCG.2010.210;10.1109/TVCG.2009.122                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Bayesian reasoning, base rate fallacy, probabilistic judgment, Euler diagrams, glyphs, crowdsourcing                                                                                	69                         	0                          	64                           	58       	HM
SciVis    	2012	Augmented Topological Descriptors of Pore Networks for Material Science                                                         	10.1109/TVCG.2012.200    	http://dx.doi.org/10.1109/TVCG.2012.200    	2041     	2050    	J        	One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO&lt;sub&gt;2&lt;/sub&gt; in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Daniela Ushizima;Dmitriy Morozov;Gunther H. Weber;Andrea G. C. Bianchi;James A. Sethian;E. Wes Bethel                                                                                                                     	Daniela Ushizima;Dmitriy Morozov;Gunther H. Weber;Andrea G.C. Bianchi;James A. Sethian;E. Wes Bethel                                                                                                                      	Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;University of California, Berkeley;Lawrence Berkeley National Laboratory                                                                                                                                                                                                                                                                                          	10.1109/TVCG.2010.218;10.1109/TVCG.2007.70603;10.1109/VISUAL.2005.1532795                                                                                                                                                                                                                                                                                                                                                                                                                                              	Reeb graph, persistent homology, topological data analysis, geometric algorithms, segmentation, microscopy                                                                          	19                         	24                         	25                           	25
SciVis    	2012	Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms                          	10.1109/TVCG.2012.202    	http://dx.doi.org/10.1109/TVCG.2012.202    	2178     	2187    	J        	Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Rocco Gasteiger;Dirk J. Lehmann;Roy van Pelt;Gábor Janiga;Oliver Beuing;Anna Vilanova;Holger Theisel;Bernhard Preim                                                                                                       	Rocco Gasteiger;Dirk J. Lehmann;Roy van Pelt;Gábor Janiga;Oliver Beuing;Anna Vilanova;Holger Theisel;Bernhard Preim                                                                                                       	University of Magdeburg, Germany;University of Magdeburg, Germany;Eindhoven University of Technology, Netherlands;University of Magdeburg, Germany;University Hospital Magdeburg, Germany;Eindhoven University of Technology, Netherlands;University of Magdeburg, Germany;University of Magdeburg, Germany                                                                                                                                                                                                               	10.1109/TVCG.2011.215;10.1109/TVCG.2011.159;10.1109/TVCG.2011.243;10.1109/TVCG.2009.138;10.1109/TVCG.2010.153;10.1109/TVCG.2010.173                                                                                                                                                                                                                                                                                                                                                                                    	Cerebral aneurysm, Hemodynamic, Inflow jet, Impingement zone, Visualization, Glyph                                                                                                  	20                         	21                         	17                           	37
SciVis    	2012	Automatic Tuning of Spatially Varying Transfer Functions for Blood Vessel Visualization                                         	10.1109/TVCG.2012.203    	http://dx.doi.org/10.1109/TVCG.2012.203    	2345     	2354    	J        	Computed Tomography Angiography (CTA) is commonly used in clinical routine for diagnosing vascular diseases. The procedure involves the injection of a contrast agent into the blood stream to increase the contrast between the blood vessels and the surrounding tissue in the image data. CTA is often visualized with Direct Volume Rendering (DVR) where the enhanced image contrast is important for the construction of Transfer Functions (TFs). For increased efficiency, clinical routine heavily relies on preset TFs to simplify the creation of such visualizations for a physician. In practice, however, TF presets often do not yield optimal images due to variations in mixture concentration of contrast agent in the blood stream. In this paper we propose an automatic, optimization-based method that shifts TF presets to account for general deviations and local variations of the intensity of contrast enhanced blood vessels. Some of the advantages of this method are the following. It computationally automates large parts of a process that is currently performed manually. It performs the TF shift locally and can thus optimize larger portions of the image than is possible with manual interaction. The method is based on a well known vesselness descriptor in the definition of the optimization criterion. The performance of the method is illustrated by clinically relevant CT angiography datasets displaying both improved structural overviews of vessel trees and improved adaption to local variations of contrast concentration.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	Gunnar Läthén;Stefan Lindholm;Reiner Lenz;Anders Persson;Magnus Borga                                                                                                                                                     	Gunnar Läthén;Stefan Lindholm;Reiner Lenz;Anders Persson;Magnus Borga                                                                                                                                                     	Linköping University;Linköping University;Linköping University;Linköping University;Linköping University                                                                                                                                                                                                                                                                                                                                                                                                                  	10.1109/VISUAL.2003.1250414;10.1109/TVCG.2009.120;10.1109/VISUAL.2001.964516;10.1109/VISUAL.1996.568113;10.1109/TVCG.2008.162;10.1109/TVCG.2010.195;10.1109/TVCG.2008.123                                                                                                                                                                                                                                                                                                                                              	Direct volume rendering, transfer functions, vessel visualization                                                                                                                   	9                          	12                         	9                            	34
InfoVis   	2012	Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions                           	10.1109/TVCG.2012.204    	http://dx.doi.org/10.1109/TVCG.2012.204    	2689     	2698    	J        	The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more “natural” interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more “natural,” interaction techniques for InfoVis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Bongshin Lee;Petra Isenberg;Nathalie Henry Riche;Sheelagh Carpendale                                                                                                                                                      	Bongshin Lee;Petra Isenberg;Nathalie Henry Riche;Sheelagh Carpendale                                                                                                                                                      	Microsoft Research;INRIA;Microsoft Research;University of Calgary                                                                                                                                                                                                                                                                                                                                                                                                                                                         	10.1109/TVCG.2010.164;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.121;10.1109/TVCG.2009.162;10.1109/TVCG.2010.206;10.1109/TVCG.2007.70582;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70568                                                                                                                                                                                                                                                                                                 	Design considerations, interaction, post-WIMP, NUI (Natural User Interface)                                                                                                         	98                         	116                        	71                           	82
InfoVis   	2012	Capturing the Design Space of Sequential Space-filling Layouts                                                                  	10.1109/TVCG.2012.205    	http://dx.doi.org/10.1109/TVCG.2012.205    	2593     	2602    	J        	We characterize the design space of the algorithms that sequentially tile a rectangular area with smaller, fixed-surface, rectangles. This space consist of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each of these dimensions describe a particular aspect of such layout tasks. This class of layouts is interesting, because, beyond encompassing simple grids, tables and trees, it also includes all kinds of treemaps involving the placement of rectangles. For instance, Slice and dice, Squarified, Strip and Pivot layouts are various points in this five dimensional space. Many classic statistics visualizations, such as 100% stacked bar charts, mosaic plots and dimensional stacking, are also instances of this class. A few new and potentially interesting points in this space are introduced, such as spiral treemaps and variations on the strip layout. The core algorithm is implemented as a JavaScript prototype that can be used as a layout component in a variety of InfoViz toolkits.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Thomas Baudel;Bertjan Broeksema                                                                                                                                                                                           	Thomas Baudel;Bertjan Broeksema                                                                                                                                                                                           	IBM;IBM                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	10.1109/VISUAL.1991.175815;10.1109/TVCG.2006.178;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.200;10.1109/TVCG.2011.227;10.1109/INFVIS.1998.729560;10.1109/TVCG.2010.186;10.1109/TVCG.2008.165;10.1109/TVCG.2009.128                                                                                                                                                                                                                                                                                                   	Layout, visualization models, tables & tree layouts, grids, treemaps, mosaic plots, dimensional stacking                                                                            	12                         	13                         	13                           	29
SciVis    	2012	Coherency-Based Curve Compression for High-Order finite Element Model Visualization                                             	10.1109/TVCG.2012.206    	http://dx.doi.org/10.1109/TVCG.2012.206    	2315     	2324    	J        	Finite element (FE) models are frequently used in engineering and life sciences within time-consuming simulations. In contrast with the regular grid structure facilitated by volumetric data sets, as used in medicine or geosciences, FE models are defined over a non-uniform grid. Elements can have curved faces and their interior can be defined through high-order basis functions, which pose additional challenges when visualizing these models. During ray-casting, the uniformly distributed sample points along each viewing ray must be transformed into the material space defined within each element. The computational complexity of this transformation makes a straightforward approach inadequate for interactive data exploration. In this paper, we introduce a novel coherency-based method which supports the interactive exploration of FE models by decoupling the expensive world-to-material space transformation from the rendering stage, thereby allowing it to be performed within a precomputation stage. Therefore, our approach computes view-independent proxy rays in material space, which are clustered to facilitate data reduction. During rendering, these proxy rays are accessed, and it becomes possible to visually analyze high-order FE models at interactive frame rates, even when they are time-varying or consist of multiple modalities. Within this paper, we provide the necessary background about the FE data, describe our decoupling method, and introduce our interactive rendering algorithm. Furthermore, we provide visual results and analyze the error introduced by the presented approach.                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Alexander Bock;Erik Sundén;Bingchen Liu;Burkhard Wünsche;Timo Ropinski                                                                                                                                                    	Alexander Bock;Erik Sundén;Bingchen Liu;Burkhard Wünsche;Timo Ropinski                                                                                                                                                    	Linköping University;Linköping University;University of Auckland;University of Auckland;Linköping University                                                                                                                                                                                                                                                                                                                                                                                                              	10.1109/VISUAL.1998.745310;10.1109/VISUAL.2004.91;10.1109/TVCG.2011.206;10.1109/TVCG.2006.110                                                                                                                                                                                                                                                                                                                                                                                                                          	finite element visualization, GPU-based ray-casting                                                                                                                                 	4                          	5                          	4                            	35
InfoVis   	2012	Comparing Clusterings Using Bertin's Idea                                                                                       	10.1109/TVCG.2012.207    	http://dx.doi.org/10.1109/TVCG.2012.207    	2506     	2515    	J        	Classifying a set of objects into clusters can be done in numerous ways, producing different results. They can be visually compared using contingency tables [27], mosaicplots [13], fluctuation diagrams [15], tableplots [20] , (modified) parallel coordinates plots [28], Parallel Sets plots [18] or circos diagrams [19]. Unfortunately the interpretability of all these graphical displays decreases rapidly with the numbers of categories and clusterings. In his famous book A Semiology of Graphics [5] Bertin writes “the discovery of an ordered concept appears as the ultimate point in logical simplification since it permits reducing to a single instant the assimilation of series which previously required many instants of study”. Or in more everyday language, if you use good orderings you can see results immediately that with other orderings might take a lot of effort. This is also related to the idea of effect ordering [12], that data should be organised to reflect the effect you want to observe. This paper presents an efficient algorithm based on Bertin's idea and concepts related to Kendall's t [17], which finds informative joint orders for two or more nominal classification variables. We also show how these orderings improve the various displays and how groups of corresponding categories can be detected using a top-down partitioning algorithm. Different clusterings based on data on the environmental performance of cars sold in Germany are used for illustration. All presented methods are available in the R package extracat which is used to compute the optimized orderings for the example dataset.                                                                                                                                                                                                                                                                                                                                                                                                                                  	Alexander Pilhofer;Alexander Gribov;Antony Unwin                                                                                                                                                                          	Alexander Pilhöfer;Alexander Gribov;Antony Unwin                                                                                                                                                                          	University of Augsburg;University of Augsburg;University of Augsburg                                                                                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2010.184;10.1109/TVCG.2010.138                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Order optimization, fluctuation diagrams, classification, seriation                                                                                                                 	15                         	18                         	14                           	37
InfoVis   	2012	Compressed Adjacency Matrices: Untangling Gene Regulatory Networks                                                              	10.1109/TVCG.2012.208    	http://dx.doi.org/10.1109/TVCG.2012.208    	2457     	2466    	J        	We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk                                                                                                                                                                      	Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk                                                                                                                                                                      	Eindhoven University of Technology;Eindhoven University of Technology;Eindhoven University of Technology                                                                                                                                                                                                                                                                                                                                                                                                                  	10.1109/TVCG.2011.187;10.1109/TVCG.2006.160;10.1109/TVCG.2007.70582;10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.147;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70556;10.1109/INFVIS.2004.5;10.1109/TVCG.2006.156;10.1109/TVCG.2010.159;10.1109/INFVIS.2003.1249030                                                                                                                                                                                                         	Network, gene regulation, scale-free, adjacency matrix                                                                                                                              	29                         	35                         	32                           	43
SciVis    	2012	Computing Morse-Smale Complexes with Accurate Geometry                                                                          	10.1109/TVCG.2012.209    	http://dx.doi.org/10.1109/TVCG.2012.209    	2014     	2022    	J        	Topological techniques have proven highly successful in analyzing and visualizing scientific data. As a result, significant efforts have been made to compute structures like the Morse-Smale complex as robustly and efficiently as possible. However, the resulting algorithms, while topologically consistent, often produce incorrect connectivity as well as poor geometry. These problems may compromise or even invalidate any subsequent analysis. Moreover, such techniques may fail to improve even when the resolution of the domain mesh is increased, thus producing potentially incorrect results even for highly resolved functions. To address these problems we introduce two new algorithms: (i) a randomized algorithm to compute the discrete gradient of a scalar field that converges under refinement; and (ii) a deterministic variant which directly computes accurate geometry and thus correct connectivity of the MS complex. The first algorithm converges in the sense that on average it produces the correct result and its standard deviation approaches zero with increasing mesh resolution. The second algorithm uses two ordered traversals of the function to integrate the probabilities of the first to extract correct (near optimal) geometry and connectivity. We present an extensive empirical study using both synthetic and real-world data and demonstrates the advantages of our algorithms in comparison with several popular approaches.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci                                                                                                                                                                         	Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci                                                                                                                                                                         	SCI Institute, University of Utah;Lawrence Livermore National Laboratory;SCI Institute, University of Utah                                                                                                                                                                                                                                                                                                                                                                                                                	10.1109/TVCG.2011.249;10.1109/TVCG.2008.110;10.1109/TVCG.2007.70603;10.1109/TVCG.2011.199;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2006.186                                                                                                                                                                                                                                                                                                                                                                            	Topology, topological methods, Morse-Smale complex                                                                                                                                  	19                         	26                         	23                           	30
SciVis    	2012	Cumulative Heat Diffusion Using Volume Gradient Operator for Volume Analysis                                                    	10.1109/TVCG.2012.210    	http://dx.doi.org/10.1109/TVCG.2012.210    	2069     	2077    	J        	We introduce a simple, yet powerful method called the Cumulative Heat Diffusion for shape-based volume analysis, while drastically reducing the computational cost compared to conventional heat diffusion. Unlike the conventional heat diffusion process, where the diffusion is carried out by considering each node separately as the source, we simultaneously consider all the voxels as sources and carry out the diffusion, hence the term cumulative heat diffusion. In addition, we introduce a new operator that is used in the evaluation of cumulative heat diffusion called the Volume Gradient Operator (VGO). VGO is a combination of the LBO and a data-driven operator which is a function of the half gradient. The half gradient is the absolute value of the difference between the voxel intensities. The VGO by its definition captures the local shape information and is used to assign the initial heat values. Furthermore, VGO is also used as the weighting parameter for the heat diffusion process. We demonstrate that our approach can robustly extract shape-based features and thus forms the basis for an improved classification and exploration of features based on shape.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Krishna Chaitanya Gurijala;Lei Wang 0024;Arie E. Kaufman                                                                                                                                                                  	Krishna Chaitanya Gurijala;Lei Wang;Arie Kaufman                                                                                                                                                                          	Stony Brook University;Stony Brook University;Stony Brook University                                                                                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2011.258;10.1109/VISUAL.2005.1532817                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Heat diffusion, volume gradient operator, shape-based volume analysis, classification, transfer function                                                                            	                           	0                          	3                            	31
SciVis    	2012	Derived Metric Tensors for Flow Surface Visualization                                                                           	10.1109/TVCG.2012.211    	http://dx.doi.org/10.1109/TVCG.2012.211    	2149     	2158    	J        	Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Harald Obermaier;Kenneth I. Joy                                                                                                                                                                                           	Harald Obermaier;Kenneth I. Joy                                                                                                                                                                                           	University of California, Davis;University of California, Davis                                                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2008.163;10.1109/TVCG.2010.173;10.1109/TVCG.2011.170;10.1109/TVCG.2006.134;10.1109/TVCG.2008.133;10.1109/VISUAL.1992.235211;10.1109/TVCG.2007.70551;10.1109/VISUAL.2004.80;10.1109/TVCG.2009.190;10.1109/TVCG.2010.166;10.1109/TVCG.2009.154;10.1109/TVCG.2007.70554                                                                                                                                                                                                                                      	Vector field, integral surfaces, metric tensor, deformation, velocity gradient, continuum mechanics                                                                                 	6                          	0                          	7                            	29
InfoVis   	2012	Design Considerations for Optimizing Storyline Visualizations                                                                   	10.1109/TVCG.2012.212    	http://dx.doi.org/10.1109/TVCG.2012.212    	2679     	2688    	J        	Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's “Movie Narrative Charts” [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Yuzuru Tanahashi;Kwan-Liu Ma                                                                                                                                                                                              	Yuzuru Tanahashi;Kwan-Liu Ma                                                                                                                                                                                              	University of California Davis;University of California Davis                                                                                                                                                                                                                                                                                                                                                                                                                                                             	10.1109/TVCG.2008.166;10.1109/TVCG.2008.135;10.1109/TVCG.2011.190;10.1109/TVCG.2011.239;10.1109/TVCG.2006.193;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2008.125;10.1109/INFVIS.2002.1173160                                                                                                                                                                                                                                                                                                    	Layout algorithm, timeline visualization, storyline visualization, design study                                                                                                     	78                         	0                          	72                           	36
InfoVis   	2012	Design Study Methodology: Reflections from the Trenches and the Stacks                                                          	10.1109/TVCG.2012.213    	http://dx.doi.org/10.1109/TVCG.2012.213    	2431     	2440    	J        	Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Michael Sedlmair;Miriah D. Meyer;Tamara Munzner                                                                                                                                                                           	Michael Sedlmair;Miriah Meyer;Tamara Munzner                                                                                                                                                                              	University of British Columbia;University of Utah;University of British Columbia                                                                                                                                                                                                                                                                                                                                                                                                                                          	10.1109/INFVIS.1999.801869;10.1109/INFVIS.1996.559226;10.1109/TVCG.2008.117;10.1109/TVCG.2009.152;10.1109/TVCG.2010.206;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.193;10.1109/VAST.2011.6102443;10.1109/TVCG.2011.174;10.1109/VAST.2007.4389008;10.1109/TVCG.2009.116;10.1109/TVCG.2011.192;10.1109/TVCG.2009.128;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.167;10.1109/TVCG.2009.111;10.1109/TVCG.2011.209                                                                                                    	Design study, methodology, visualization, framework                                                                                                                                 	193                        	267                        	216                          	95       	HM
InfoVis   	2012	Different Strokes for Different Folks: Visual Presentation Design between Disciplines                                           	10.1109/TVCG.2012.214    	http://dx.doi.org/10.1109/TVCG.2012.214    	2411     	2420    	J        	We present an ethnographic study of design differences in visual presentations between academic disciplines. Characterizing design conventions between users and data domains is an important step in developing hypotheses, tools, and design guidelines for information visualization. In this paper, disciplines are compared at a coarse scale between four groups of fields: social, natural, and formal sciences; and the humanities. Two commonplace presentation types were analyzed: electronic slideshows and whiteboard “chalk talks”. We found design differences in slideshows using two methods - coding and comparing manually-selected features, like charts and diagrams, and an image-based analysis using PCA called eigenslides. In whiteboard talks with controlled topics, we observed design behaviors, including using representations and formalisms from a participant's own discipline, that suggest authors might benefit from novel assistive tools for designing presentations. Based on these findings, we discuss opportunities for visualization ethnography and human-centered authoring tools for visual information.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Steven R. Gomez;Radu Jianu;Caroline Ziemkiewicz;Hua Guo;David H. Laidlaw                                                                                                                                                  	Steven R. Gomez;Radu Jianu;Caroline Ziemkiewicz;Hua Guo;David Laidlaw                                                                                                                                                     	Brown University;Brown University;Brown University;Brown University;Brown University                                                                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2011.251;10.1109/TVCG.2010.177;10.1109/TVCG.2010.179;10.1109/TVCG.2011.255                                                                                                                                                                                                                                                                                                                                                                                                                                	Presentations, information visualization, design, visual analysis                                                                                                                   	3                          	3                          	3                            	18
InfoVis   	2012	Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making       	10.1109/TVCG.2012.215    	http://dx.doi.org/10.1109/TVCG.2012.215    	2421     	2430    	J        	For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    	Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi                                                                                                                                                         	Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi                                                                                                                                                         	Purdue University;Purdue University;Purdue University;Purdue University;Purdue University                                                                                                                                                                                                                                                                                                                                                                                                                                 	10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.193;10.1109/VAST.2008.4677363;10.1109/TVCG.2010.149;10.1109/TVCG.2011.183;10.1109/VAST.2009.5333920                                                                                                                                                                                                                                                                                                                                                                       	Visualized decision making, eye tracking, crowdsourcing, quantitative empirical study, limitations, peripheral vision                                                               	23                         	31                         	22                           	55
SciVis    	2012	Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization                               	10.1109/TVCG.2012.216    	http://dx.doi.org/10.1109/TVCG.2012.216    	2130     	2139    	J        	We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Jian Chen;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw                                                                                                                                                                	Jian Chen;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw                                                                                                                                                                	University of Maryland Baltimore County;University of Southern Mississippi;University of Mississippi Medical Center;Brown University                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2009.126;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2009.111;10.1109/TVCG.2009.138;10.1109/TVCG.2006.183                                                                                                                                                                                                                                                                                                                                                                         	Display characteristics, diffusion tensor MRI, virtual environment                                                                                                                  	15                         	0                          	14                           	49
SciVis    	2012	Efficient Structure-Aware Selection Techniques for 3D Point Cloud Visualizations with 2DOF Input                                	10.1109/TVCG.2012.217    	http://dx.doi.org/10.1109/TVCG.2012.217    	2245     	2254    	J        	Data selection is a fundamental task in visualization because it serves as a pre-requisite to many follow-up interactions. Efficient spatial selection in 3D point cloud datasets consisting of thousands or millions of particles can be particularly challenging. We present two new techniques, TeddySelection and CloudLasso, that support the selection of subsets in large particle 3D datasets in an interactive and visually intuitive manner. Specifically, we describe how to spatially select a subset of a 3D particle cloud by simply encircling the target particles on screen using either the mouse or direct-touch input. Based on the drawn lasso, our techniques automatically determine a bounding selection surface around the encircled particles based on their density. This kind of selection technique can be applied to particle datasets in several application domains. TeddySelection and CloudLasso reduce, and in some cases even eliminate, the need for complex multi-step selection processes involving Boolean operations. This was confirmed in a formal, controlled user study in which we compared the more flexible CloudLasso technique to the standard cylinder-based selection technique. This study showed that the former is consistently more efficient than the latter - in several cases the CloudLasso selection time was half that of the corresponding cylinder-based selection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Lingyun Yu;Konstantinos Efstathiou 0001;Petra Isenberg;Tobias Isenberg 0001                                                                                                                                               	Lingyun Yu;Konstantinos Efstathiou;Petra Isenberg;Tobias Isenberg                                                                                                                                                         	University of Groningen;University of Groningen;INRIA;University of Groningen                                                                                                                                                                                                                                                                                                                                                                                                                                             	10.1109/TVCG.2010.157;10.1109/TVCG.2012.292;10.1109/TVCG.2008.153                                                                                                                                                                                                                                                                                                                                                                                                                                                      	3D interaction, spatial selection, direct-touch interaction                                                                                                                         	27                         	43                         	25                           	39       	HM
SciVis    	2012	ElVis: A System for the Accurate and Interactive Visualization of High-Order finite Element Solutions                           	10.1109/TVCG.2012.218    	http://dx.doi.org/10.1109/TVCG.2012.218    	2325     	2334    	J        	This paper presents the Element Visualizer (ElVis), a new, open-source scientific visualization system for use with high-order finite element solutions to PDEs in three dimensions. This system is designed to minimize visualization errors of these types of fields by querying the underlying finite element basis functions (e.g., high-order polynomials) directly, leading to pixel-exact representations of solutions and geometry. The system interacts with simulation data through runtime plugins, which only require users to implement a handful of operations fundamental to finite element solvers. The data in turn can be visualized through the use of cut surfaces, contours, isosurfaces, and volume rendering. These visualization algorithms are implemented using NVIDIA's OptiX GPU-based ray-tracing engine, which provides accelerated ray traversal of the high-order geometry, and CUDA, which allows for effective parallel evaluation of the visualization algorithms. The direct interface between ElVis and the underlying data differentiates it from existing visualization tools. Current tools assume the underlying data is composed of linear primitives; high-order data must be interpolated with linear functions as a result. In this work, examples drawn from aerodynamic simulations-high-order discontinuous Galerkin finite element solutions of aerodynamic flows in particular-will demonstrate the superiority of ElVis' pixel-exact approach when compared with traditional linear-interpolation methods. Such methods can introduce a number of inaccuracies in the resulting visualization, making it unclear if visual artifacts are genuine to the solution data or if these artifacts are the result of interpolation errors. Linear methods additionally cannot properly visualize curved geometries (elements or boundaries) which can greatly inhibit developers' debugging efforts. As we will show, pixel-exact visualization exhibits none of these issues, removing the visualization scheme as a source of uncertainty for engineers using ElVis.	Blake Nelson;Eric Liu;Robert Michael Kirby;Robert Haimes                                                                                                                                                                  	Blake Nelson;Eric Liu;Robert M. Kirby;Robert Haimes                                                                                                                                                                       	University of Utah;MIT;University of Utah;MIT                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	10.1109/VISUAL.2005.1532776;10.1109/VISUAL.1991.175837;10.1109/VISUAL.2004.91;10.1109/TVCG.2006.154;10.1109/TVCG.2011.206                                                                                                                                                                                                                                                                                                                                                                                              	High-order finite elements, spectral/hp elements, discontinuous Galerkin, fluid flow simulation, cut surface extraction, contours, isosurfaces                                      	16                         	20                         	18                           	37
VAST      	2012	Enterprise Data Analysis and Visualization: An Interview Study                                                                  	10.1109/TVCG.2012.219    	http://dx.doi.org/10.1109/TVCG.2012.219    	2917     	2926    	J        	Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer                                                                                                                                                            	Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer                                                                                                                                                            	Stanford University;Stanford University;University of California, Berkeley;Stanford University                                                                                                                                                                                                                                                                                                                                                                                                                            	10.1109/TVCG.2008.137;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5652880;10.1109/VAST.2009.5333878;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102435                                                                                                                                                                                                                                                                                                          	Data, analysis, visualization, enterprise                                                                                                                                           	138                        	185                        	105                          	37       	HM
InfoVis   	2012	Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty                                        	10.1109/TVCG.2012.220    	http://dx.doi.org/10.1109/TVCG.2012.220    	2769     	2778    	J        	We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Nadia Boukhelifa;Anastasia Bezerianos;Tobias Isenberg 0001;Jean-Daniel Fekete                                                                                                                                             	Nadia Boukhelifa;Anastasia Bezerianos;Tobias Isenberg;Jean-Daniel Fekete                                                                                                                                                  	INRIA;LRI;DIGITEO/CNRS/INRIA;INRIA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1992.235199;10.1109/TVCG.2007.70530;10.1109/TVCG.2009.114;10.1109/VAST.2009.5332611;10.1109/VAST.2006.261424;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70589;10.1109/VISUAL.2000.885679                                                                                                                                                                                                                                                                                       	Uncertainty visualization, qualitative evaluation, quantitative evaluation, perception                                                                                              	50                         	66                         	46                           	57
InfoVis   	2012	Evaluating the Effect of Style in Information Visualization                                                                     	10.1109/TVCG.2012.221    	http://dx.doi.org/10.1109/TVCG.2012.221    	2739     	2748    	J        	This paper reports on a between-subject, comparative online study of three information visualization demonstrators that each displayed the same dataset by way of an identical scatterplot technique, yet were different in style in terms of visual and interactive embellishment. We validated stylistic adherence and integrity through a separate experiment in which a small cohort of participants assigned our three demonstrators to predefined groups of stylistic examples, after which they described the styles with their own words. From the online study, we discovered significant differences in how participants execute specific interaction operations, and the types of insights that followed from them. However, in spite of significant differences in apparent usability, enjoyability and usefulness between the style demonstrators, no variation was found on the self-reported depth, expert-rated depth, confidence or difficulty of the resulting insights. Three different methods of insight analysis have been applied, revealing how style impacts the creation of insights, ranging from higher-level pattern seeking to a more reflective and interpretative engagement with content, which is what underlies the patterns. As this study only forms the first step in determining how the impact of style in information visualization could be best evaluated, we propose several guidelines and tips on how to gather, compare and categorize insights through an online evaluation study, particularly in terms of analyzing the concise, yet wide variety of insights and observations in a trustworthy and reproducable manner.                                                                                                                                                                                                                                                                                                                                                                                                                                        	Andrew Vande Moere;Martin Tomitsch;Christoph Wimmer;Christoph M. Bösch;Thomas Grechenig                                                                                                                                   	Andrew Vande Moere;Martin Tomitsch;Christoph Wimmer;Boesch Christoph;Thomas Grechenig                                                                                                                                     	KU Leuven;University of Sydney;TU Wien;TU Wien;TU Wien                                                                                                                                                                                                                                                                                                                                                                                                                                                                    	10.1109/TVCG.2007.70541;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.122                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Visualization, design, style, aesthetics, evaluation, online study, user experience                                                                                                 	31                         	41                         	28                           	33
SciVis    	2012	Evaluation of Fast-Forward Video Visualization                                                                                  	10.1109/TVCG.2012.222    	http://dx.doi.org/10.1109/TVCG.2012.222    	2095     	2103    	J        	We evaluate and compare video visualization techniques based on fast-forward. A controlled laboratory user study (n = 24) was conducted to determine the trade-off between support of object identification and motion perception, two properties that have to be considered when choosing a particular fast-forward visualization. We compare four different visualizations: two representing the state-of-the-art and two new variants of visualization introduced in this paper. The two state-of-the-art methods we consider are frame-skipping and temporal blending of successive frames. Our object trail visualization leverages a combination of frame-skipping and temporal blending, whereas predictive trajectory visualization supports motion perception by augmenting the video frames with an arrow that indicates the future object trajectory. Our hypothesis was that each of the state-of-the-art methods satisfies just one of the goals: support of object identification or motion perception. Thus, they represent both ends of the visualization design. The key findings of the evaluation are that object trail visualization supports object identification, whereas predictive trajectory visualization is most useful for motion perception. However, frame-skipping surprisingly exhibits reasonable performance for both tasks. Furthermore, we evaluate the subjective performance of three different playback speed visualizations for adaptive fast-forward, a subdomain of video fast-forward.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                	Markus Höferlin;Kuno Kurzhals;Benjamin Höferlin;Gunther Heidemann;Daniel Weiskopf                                                                                                                                         	Markus Höferlin;Kuno Kurzhals;Benjamin Höferlin;Gunther Heidemann;Daniel Weiskopf                                                                                                                                         	Visualization Research Center (VISUS), University of Stuttgart;Visualization Research Center (VISUS), University of Stuttgart;Computer Vision Group, Institute of Cognitive Science, University of Osnabrück;Computer Vision Group, Institute of Cognitive Science, University of Osnabrück;Visualization Research Center (VISUS), University of Stuttgart                                                                                                                                                                	10.1109/TVCG.2007.70542;10.1109/TVCG.2007.70617;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/TVCG.2006.194                                                                                                                                                                                                                                                                                                                                                                                                    	Video visualization, adaptive fast-forward, controlled laboratory user study                                                                                                        	8                          	13                         	11                           	38
SciVis    	2012	Evaluation of Multivariate Visualization on a Multivariate Task                                                                 	10.1109/TVCG.2012.223    	http://dx.doi.org/10.1109/TVCG.2012.223    	2114     	2121    	J        	Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Mark A. Livingston;Jonathan W. Decker;Zhuming Ai                                                                                                                                                                          	Mark A. Livingston;Jonathan W. Decker;Zhuming Ai                                                                                                                                                                          	Naval Research Laboratory;Naval Research Laboratory;Naval Research Laboratory                                                                                                                                                                                                                                                                                                                                                                                                                                             	10.1109/TVCG.2011.194;10.1109/TVCG.2009.126;10.1109/VISUAL.1998.745292;10.1109/VISUAL.1990.146387;10.1109/TVCG.2007.70623;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2003.1250362                                                                                                                                                                                                                                                                                 	Quantitative evaluation, multivariate visualization, visual task design, texture perception                                                                                         	10                         	11                         	8                            	23
VAST      	2012	Examining the Use of a Visual Analytics System for Sensemaking Tasks: Case Studies with Domain Experts                          	10.1109/TVCG.2012.224    	http://dx.doi.org/10.1109/TVCG.2012.224    	2869     	2878    	J        	While the formal evaluation of systems in visual analytics is still relatively uncommon, particularly rare are case studies of prolonged system use by domain analysts working with their own data. Conducting case studies can be challenging, but it can be a particularly effective way to examine whether visual analytics systems are truly helping expert users to accomplish their goals. We studied the use of a visual analytics system for sensemaking tasks on documents by six analysts from a variety of domains. We describe their application of the system along with the benefits, issues, and problems that we uncovered. Findings from the studies identify features that visual analytics systems should emphasize as well as missing capabilities that should be addressed. These findings inform design implications for future systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    	Youn ah Kang;John T. Stasko                                                                                                                                                                                               	Youn-ah Kang;John Stasko                                                                                                                                                                                                  	Google Inc.;Georgia Institute of Technology                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	10.1109/VAST.2008.4677362;10.1109/VAST.2006.261416;10.1109/INFVIS.2004.5;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333878                                                                                                                                                                                                                                                                                                                                       	Visual analytics, case study, qualitative evaluation                                                                                                                                	17                         	25                         	21                           	42
InfoVis   	2012	Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization                                	10.1109/TVCG.2012.225    	http://dx.doi.org/10.1109/TVCG.2012.225    	2659     	2668    	J        	Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Krist Wongsuphasawat;David Gotz                                                                                                                                                                                           	Krist Wongsuphasawat;David Gotz                                                                                                                                                                                           	University of Maryland;IBM                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                	10.1109/TVCG.2009.181;10.1109/VAST.2011.6102453;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532150;10.1109/VAST.2009.5332595;10.1109/TVCG.2009.117;10.1109/INFVIS.2005.1532152;10.1109/VAST.2006.261421                                                                                                                                                                                                                                                                                                                 	Outflow, information visualization, temporal event sequences, state diagram, state transition                                                                                       	89                         	121                        	98                           	35
InfoVis   	2012	Facilitating Discourse Analysis with Interactive Visualization                                                                  	10.1109/TVCG.2012.226    	http://dx.doi.org/10.1109/TVCG.2012.226    	2639     	2648    	J        	A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	Jian Zhao 0010;Fanny Chevalier;Christopher Collins 0001;Ravin Balakrishnan                                                                                                                                                	Jian Zhao;Fanny Chevalier;Christopher Collins;Ravin Balakrishnan                                                                                                                                                          	University of Toronto;University of Toronto;University of Ontario Institute of Technology;University of Toronto                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/VAST.2011.6102439;10.1109/TVCG.2007.70529;10.1109/TVCG.2009.122;10.1109/INFVIS.1999.801869;10.1109/INFVIS.2003.1249030                                                                                                                                                                                                                                                                                                                                                                                         	Discourse structure, tree comparison, computational linguisitics, visual analytics, interaction techniques                                                                          	19                         	24                         	16                           	30
SciVis    	2012	Fuzzy Volume Rendering                                                                                                          	10.1109/TVCG.2012.227    	http://dx.doi.org/10.1109/TVCG.2012.227    	2335     	2344    	J        	In order to assess the reliability of volume rendering, it is necessary to consider the uncertainty associated with the volume data and how it is propagated through the volume rendering algorithm, as well as the contribution to uncertainty from the rendering algorithm itself. In this work, we show how to apply concepts from the field of reliable computing in order to build a framework for management of uncertainty in volume rendering, with the result being a self-validating computational model to compute a posteriori uncertainty bounds. We begin by adopting a coherent, unifying possibility-based representation of uncertainty that is able to capture the various forms of uncertainty that appear in visualization, including variability, imprecision, and fuzziness. Next, we extend the concept of the fuzzy transform in order to derive rules for accumulation and propagation of uncertainty. This representation and propagation of uncertainty together constitute an automated framework for management of uncertainty in visualization, which we then apply to volume rendering. The result, which we call fuzzy volume rendering, is an uncertainty-aware rendering algorithm able to produce more complete depictions of the volume data, thereby allowing more reliable conclusions and informed decisions. Finally, we compare approaches for self-validated computation in volume rendering, demonstrating that our chosen method has the ability to handle complex uncertainty while maintaining efficiency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Nathaniel Fout;Kwan-Liu Ma                                                                                                                                                                                                	Nathaniel Fout;Kwan-Liu Ma                                                                                                                                                                                                	University of California, Davis;University of California, Davis                                                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2007.70518;10.1109/TVCG.2010.211;10.1109/VISUAL.2005.1532807;10.1109/VAST.2009.5332611                                                                                                                                                                                                                                                                                                                                                                                                                    	Uncertainty visualization, verifiable visualization, volume rendering                                                                                                               	11                         	0                          	11                           	39
SciVis    	2012	Generalized Topological Simplification of Scalar fields on Surfaces                                                             	10.1109/TVCG.2012.228    	http://dx.doi.org/10.1109/TVCG.2012.228    	2005     	2013    	J        	We present a combinatorial algorithm for the general topological simplification of scalar fields on surfaces. Given a scalar field f, our algorithm generates a simplified field g that provably admits only critical points from a constrained subset of the singularities of f, while guaranteeing a small distance ||f - g||<sub>∞</sub>for data-fitting purpose. In contrast to previous algorithms, our approach is oblivious to the strategy used for selecting features of interest and allows critical points to be removed arbitrarily. When topological persistence is used to select the features of interest, our algorithm produces a standard ϵ-simplification. Our approach is based on a new iterative algorithm for the constrained reconstruction of sub- and sur-level sets. Extensive experiments show that the number of iterations required for our algorithm to converge is rarely greater than 2 and never greater than 5, yielding O(n log(n)) practical time performances. The algorithm handles triangulated surfaces with or without boundary and is robust to the presence of multi-saddles in the input. It is simple to implement, fast in practice and more general than previous techniques. Practically, our approach allows a user to arbitrarily simplify the topology of an input function and robustly generate the corresponding simplified function. An appealing application area of our algorithm is in scalar field design since it enables, without any threshold parameter, the robust pruning of topological noise as selected by the user. This is needed for example to get rid of inaccuracies introduced by numerical solvers, thereby providing topological guarantees needed for certified geometry processing. Experiments show this ability to eliminate numerical noise as well as validate the time efficiency and accuracy of our algorithm. We provide a lightweight C++ implementation as supplemental material that can be used for topological cleaning on surface meshes.                                                                           	Julien Tierny;Valerio Pascucci                                                                                                                                                                                            	Julien Tierny;Valerio Pascucci                                                                                                                                                                                            	CNRS;SCI Institute                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	10.1109/TVCG.2008.110;10.1109/TVCG.2009.163;10.1109/VISUAL.2004.96;10.1109/TVCG.2011.244                                                                                                                                                                                                                                                                                                                                                                                                                               	Scalar field visualization, scalar field design, topological simplification                                                                                                         	12                         	18                         	19                           	23
InfoVis   	2012	Graphical Overlays: Using Layered Elements to Aid Chart Reading                                                                 	10.1109/TVCG.2012.229    	http://dx.doi.org/10.1109/TVCG.2012.229    	2631     	2638    	J        	Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	Nicholas Kong;Maneesh Agrawala                                                                                                                                                                                            	Nicholas Kong;Maneesh Agrawala                                                                                                                                                                                            	University of California, Berkeley;University of California, Berkeley                                                                                                                                                                                                                                                                                                                                                                                                                                                     	10.1109/TVCG.2011.242;10.1109/VISUAL.1991.175820;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183                                                                                                                                                                                                                                                                                                                                                                                                                           	Visualization, overlays, graphical perception, graph comprehension                                                                                                                  	29                         	38                         	21                           	38
InfoVis   	2012	Graphical Tests for Power Comparison of Competing Designs                                                                       	10.1109/TVCG.2012.230    	http://dx.doi.org/10.1109/TVCG.2012.230    	2441     	2448    	J        	Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook                                                                                                                                                                	Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook                                                                                                                                                                	Iowa State University;Iowa State University;Iowa State University;Iowa State University                                                                                                                                                                                                                                                                                                                                                                                                                                   	10.1109/TVCG.2009.111;10.1109/TVCG.2010.161                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Lineups, Visual inference, Power comparison, Efficiency of displays                                                                                                                 	20                         	24                         	17                           	28
SciVis    	2012	Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms                          	10.1109/TVCG.2012.231    	http://dx.doi.org/10.1109/TVCG.2012.231    	2355     	2363    	J        	Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	Cheuk Yiu Ip;Amitabh Varshney;Joseph JáJá                                                                                                                                                                                 	Cheuk Yiu Ip;Amitabh Varshney;Joseph JaJa                                                                                                                                                                                 	University of Maryland;University of Maryland;University of Maryland                                                                                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2010.132;10.1109/TVCG.2009.185;10.1109/VISUAL.1999.809932;10.1109/VISUAL.2005.1532795;10.1109/VISUAL.2003.1250370;10.1109/TVCG.2010.208;10.1109/TVCG.2008.162;10.1109/TVCG.2011.248;10.1109/TVCG.2011.173;10.1109/TVCG.2006.174;10.1109/TVCG.2011.231;10.1109/TVCG.2007.70590;10.1109/TVCG.2009.197;10.1109/TVCG.2006.148                                                                                                                                                                                 	Volume exploration, volume classification, normalized cut, Information-guided exploration                                                                                           	27                         	43                         	36                           	46       	BP
SciVis    	2012	Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping                          	10.1109/TVCG.2012.232    	http://dx.doi.org/10.1109/TVCG.2012.232    	2364     	2371    	J        	In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.                                                                                                                                                                                                                                                                                                                                                                             	Daniel Jönsson;Joel Kronander;Timo Ropinski;Anders Ynnerman                                                                                                                                                               	Daniel Jönsson;Joel Kronander;Timo Ropinski;Anders Ynnerman                                                                                                                                                               	C-Research, Linköping University;C-Research, Linköping University;C-Research, Linköping University;C-Research, Linköping University                                                                                                                                                                                                                                                                                                                                                                                       	10.1109/TVCG.2011.211                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Volume rendering, photon mapping, global illumination, participating media                                                                                                          	17                         	20                         	16                           	34
InfoVis   	2012	How Capacity Limits of Attention Influence Information Visualization Effectiveness                                              	10.1109/TVCG.2012.233    	http://dx.doi.org/10.1109/TVCG.2012.233    	2402     	2410    	J        	In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	Steve Haroz;David Whitney                                                                                                                                                                                                 	Steve Haroz;David Whitney                                                                                                                                                                                                 	University of California, Davis;University of California, Berkeley                                                                                                                                                                                                                                                                                                                                                                                                                                                        	10.1109/INFVIS.2001.963274;10.1109/VISUAL.1996.568118;10.1109/TVCG.2010.186;10.1109/VISUAL.2005.1532838                                                                                                                                                                                                                                                                                                                                                                                                                	Perception, attention, color, motion, user study, nominal axis, layout, goal-oriented design                                                                                        	41                         	47                         	34                           	35       	BP
SciVis    	2012	Human Computation in Visualization: Using Purpose Driven Games for Robust Evaluation of Visualization Algorithms                	10.1109/TVCG.2012.234    	http://dx.doi.org/10.1109/TVCG.2012.234    	2104     	2113    	J        	Due to the inherent characteristics of the visualization process, most of the problems in this field have strong ties with human cognition and perception. This makes the human brain and sensory system the only truly appropriate evaluation platform for evaluating and fine-tuning a new visualization method or paradigm. However, getting humans to volunteer for these purposes has always been a significant obstacle, and thus this phase of the development process has traditionally formed a bottleneck, slowing down progress in visualization research. We propose to take advantage of the newly emerging field of Human Computation (HC) to overcome these challenges. HC promotes the idea that rather than considering humans as users of the computational system, they can be made part of a hybrid computational loop consisting of traditional computation resources and the human brain and sensory system. This approach is particularly successful in cases where part of the computational problem is considered intractable using known computer algorithms but is trivial to common sense human knowledge. In this paper, we focus on HC from the perspective of solving visualization problems and also outline a framework by which humans can be easily seduced to volunteer their HC resources. We introduce a purpose-driven game titled “Disguise” which serves as a prototypical example for how the evaluation of visualization algorithms can be mapped into a fun and addicting activity, allowing this task to be accomplished in an extensive yet cost effective way. Finally, we sketch out a framework that transcends from the pure evaluation of existing visualization methods to the design of a new one.                                                                                                                                                                                                                                                                                                                                                           	Nafees Ahmed;Ziyi Zheng;Klaus Mueller                                                                                                                                                                                     	Nafees Ahmed;Ziyi Zheng;Klaus Mueller                                                                                                                                                                                     	Stony Brook University;Stony Brook University;Stony Brook University                                                                                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2009.172;10.1109/TVCG.2011.218;10.1109/TVCG.2009.189;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2012.186;10.1109/TVCG.2008.118;10.1109/TVCG.2009.150                                                                                                                                                                                                                                                                                                                                                        	Human computation, perception, evaluation, color blending                                                                                                                           	10                         	12                         	9                            	46
InfoVis   	2012	Intelligent Graph Layout Using Many Users' Input                                                                                	10.1109/TVCG.2012.236    	http://dx.doi.org/10.1109/TVCG.2012.236    	2699     	2708    	J        	In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang                                                                                                                                                                                  	Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang                                                                                                                                                                                  	Peking University;Peking University;AT&amp;T Labs Research;Peking University                                                                                                                                                                                                                                                                                                                                                                                                                                              	10.1109/TVCG.2008.155;10.1109/INFVIS.2005.1532130;10.1109/TVCG.2009.109;10.1109/TVCG.2007.70580                                                                                                                                                                                                                                                                                                                                                                                                                        	Graph layout, Laplacian matrix, force directed layout, stress model, merging, editing, crowd sourcing                                                                               	18                         	21                         	15                           	33
InfoVis   	2012	Interaction Support for Visual Comparison Inspired by Natural Behavior                                                          	10.1109/TVCG.2012.237    	http://dx.doi.org/10.1109/TVCG.2012.237    	2719     	2728    	J        	Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	Christian Tominski;Camilla Forsell;Jimmy Johansson                                                                                                                                                                        	Christian Tominski;Camilla Forsell;Jimmy Johansson                                                                                                                                                                        	University of Rostock;Link&#x00F6;ping University;Link&#x00F6;ping University                                                                                                                                                                                                                                                                                                                                                                                                                                             	10.1109/TVCG.2008.109;10.1109/TVCG.2007.70568;10.1109/TVCG.2011.201;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70623;10.1109/TVCG.2009.151;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2011.223;10.1109/TVCG.2007.70582;10.1109/TVCG.2008.153                                                                                                                                                                                                                                                                              	Interaction techniques, visual comparison, visualization, human-computer interaction, natural interaction                                                                           	26                         	33                         	26                           	51
InfoVis   	2012	Interactive Level-of-Detail Rendering of Large Graphs                                                                           	10.1109/TVCG.2012.238    	http://dx.doi.org/10.1109/TVCG.2012.238    	2486     	2495    	J        	We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt                                                                                                                                                           	Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt                                                                                                                                                           	Uni Konstanz;Uni Konstanz;Uni Konstanz;Uni Konstanz                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	10.1109/INFVIS.2005.1532150;10.1109/TVCG.2006.120;10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2006.187;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/INFVIS.2004.66                                                                                                                                                                                                                                                                                                                                 	Graph visualization, OpenGL, edge aggregation                                                                                                                                       	53                         	69                         	50                           	28
SciVis    	2012	Interactive Retro-Deformation of Terrain for Reconstructing 3D Fault Displacements                                              	10.1109/TVCG.2012.239    	http://dx.doi.org/10.1109/TVCG.2012.239    	2208     	2215    	J        	Planetary topography is the result of complex interactions between geological processes, of which faulting is a prominent component. Surface-rupturing earthquakes cut and move landforms which develop across active faults, producing characteristic surface displacements across the fault. Geometric models of faults and their associated surface displacements are commonly applied to reconstruct these offsets to enable interpretation of the observed topography. However, current 2D techniques are limited in their capability to convey both the three-dimensional kinematics of faulting and the incremental sequence of events required by a given reconstruction. Here we present a real-time system for interactive retro-deformation of faulted topography to enable reconstruction of fault displacement within a high-resolution (sub 1m/pixel) 3D terrain visualization. We employ geometry shaders on the GPU to intersect the surface mesh with fault-segments interactively specified by the user and transform the resulting surface blocks in realtime according to a kinematic model of fault motion. Our method facilitates a human-in-the-loop approach to reconstruction of fault displacements by providing instant visual feedback while exploring the parameter space. Thus, scientists can evaluate the validity of traditional point-to-point reconstructions by visually examining a smooth interpolation of the displacement in 3D. We show the efficacy of our approach by using it to reconstruct segments of the San Andreas fault, California as well as a graben structure in the Noctis Labyrinthus region on Mars.                                                                                                                                                                                                                                                                                                                                                                                                                                                    	Rolf Westerteiger;Tracy Compton;Tony Bernardin;Eric S. Cowgill;Klaus Gwinner;Bernd Hamann;Andreas Gerndt;Hans Hagen                                                                                                       	Rolf Westerteiger;Tracy Compton;Tony Bernadin;Eric Cowgill;Klaus Gwinner;Bernd Hamann;Andreas Gerndt;Hans Hagen                                                                                                           	German Aerospace Center (DLR);Department of Geology, University of California, Davis;Institute for Data Analysis and Visualization, Department of Computer Science, University of California, Davis;Department of Geology, University of California, Davis;Institute of Planetary Research, German Aerospace Center (DLR), Berlin;Institute for Data Analysis and Visualization, Department of Computer Science, University of California, Davis;German Aerospace Center (DLR);University of Kaiserslautern               	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	Terrain rendering, interactive, fault simulation, mesh deformation                                                                                                                  	2                          	2                          	2                            	20
SciVis    	2012	Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach        	10.1109/TVCG.2012.240    	http://dx.doi.org/10.1109/TVCG.2012.240    	2285     	2294    	J        	This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister                                                                                                                                                              	Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister                                                                                                                                                              	King Adbullah University of Science and Technology, Saudi Arabia;King Adbullah University of Science and Technology, Saudi Arabia;UNIST;Harvard University                                                                                                                                                                                                                                                                                                                                                                	10.1109/VISUAL.1999.809908;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.161                                                                                                                                                                                                                                                                                                                                                                                                                                           	Petascale volume exploration, high-resolution microscopy, high-throughput imaging, neuroscience                                                                                     	42                         	51                         	41                           	31       	HM
SciVis    	2012	KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves                                                    	10.1109/TVCG.2012.242    	http://dx.doi.org/10.1109/TVCG.2012.242    	2051     	2060    	J        	We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.                                                                                                                                                                                                                                                                                                                                                                                                 	Hui Zhang 0006;Jianguang Weng;Lin Jing;Yiwen Zhong                                                                                                                                                                        	Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong                                                                                                                                                                             	Indiana University;Zhejiang University of Media and Communications, China;Fujian Agriculture and Forestry University, Fuzhou, China;Fujian Agriculture and Forestry University, Fuzhou, China                                                                                                                                                                                                                                                                                                                             	10.1109/VISUAL.2005.1532804;10.1109/VISUAL.2005.1532843;10.1109/TVCG.2007.70593                                                                                                                                                                                                                                                                                                                                                                                                                                        	Knot Theory, Math Visualization                                                                                                                                                     	3                          	5                          	4                            	33
SciVis    	2012	Lagrangian Coherent Structures for Design Analysis of Revolving Doors                                                           	10.1109/TVCG.2012.243    	http://dx.doi.org/10.1109/TVCG.2012.243    	2159     	2168    	J        	Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Benjamin Schindler;Raphael Fuchs;Stefan Barp;Jürgen Waser;Armin Pobitzer;Robert Carnecky;Kresimir Matkovic;Ronald Peikert                                                                                                 	Benjamin Schindler;Raphael Fuchs;Stefan Barp;Jürgen Waser;Armin Pobitzer;Robert Carnecky;Krešimir Matković;Ronald Peikert                                                                                                 	ETH Zurich;ETH Zurich;Air Flow Consulting AG Zurich;VRVis Research Center, Austria;University of Bergen;ETH Zurich;VRVis Research Center, Austria;ETH Zurich                                                                                                                                                                                                                                                                                                                                                              	10.1109/TVCG.2007.70551;10.1109/TVCG.2010.223;10.1109/TVCG.2007.70554;10.1109/TVCG.2010.156;10.1109/VISUAL.2005.1532813                                                                                                                                                                                                                                                                                                                                                                                                	Visualization in physical sciences and engineering, topology-based techniques, vector field data                                                                                    	6                          	0                          	7                            	38
InfoVis   	2012	Living Liquid: Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors                                   	10.1109/TVCG.2012.244    	http://dx.doi.org/10.1109/TVCG.2012.244    	2799     	2808    	J        	Interactive visualizations can allow science museum visitors to explore new worlds by seeing and interacting with scientific data. However, designing interactive visualizations for informal learning environments, such as museums, presents several challenges. First, visualizations must engage visitors on a personal level. Second, visitors often lack the background to interpret visualizations of scientific data. Third, visitors have very limited time at individual exhibits in museums. This paper examines these design considerations through the iterative development and evaluation of an interactive exhibit as a visualization tool that gives museumgoers access to scientific data generated and used by researchers. The exhibit prototype, Living Liquid, encourages visitors to ask and answer their own questions while exploring the time-varying global distribution of simulated marine microbes using a touchscreen interface. Iterative development proceeded through three rounds of formative evaluations using think-aloud protocols and interviews, each round informing a key visualization design decision: (1) what to visualize to initiate inquiry, (2) how to link data at the microscopic scale to global patterns, and (3) how to include additional data that allows visitors to pursue their own questions. Data from visitor evaluations suggests that, when designing visualizations for public audiences, one should (1) avoid distracting visitors from data that they should explore, (2) incorporate background information into the visualization, (3) favor understandability over scientific accuracy, and (4) layer data accessibility to structure inquiry. Lessons learned from this case study add to our growing understanding of how to use visualizations to actively engage learners with scientific data.                                                                                                                                                                                                                                       	Joyce Ma;Isaac Liao;Kwan-Liu Ma;Jennifer Frazier                                                                                                                                                                          	Joyce Ma;Isaac Liao;Kwan-Liu Ma;Jennifer Frazier                                                                                                                                                                          	Exploratorium;University of California, Davis;University of California, Davis;Exploratorium                                                                                                                                                                                                                                                                                                                                                                                                                               	10.1109/TVCG.2008.127;10.1109/TVCG.2011.175;10.1109/INFVIS.2004.8                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Information visualization, user interaction, evaluation, user studies, science museums, informal learning environments                                                              	22                         	28                         	22                           	45
InfoVis   	2012	Memorability of Visual Features in Network Diagrams                                                                             	10.1109/TVCG.2012.245    	http://dx.doi.org/10.1109/TVCG.2012.245    	2477     	2485    	J        	We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	Kim Marriott;Helen C. Purchase;Michael Wybrow;Cagatay Goncu                                                                                                                                                               	Kim Marriott;Helen Purchase;Michael Wybrow;Cagatay Goncu                                                                                                                                                                  	Monash University;University of Glasgow;Monash University;Monash University                                                                                                                                                                                                                                                                                                                                                                                                                                               	10.1109/TVCG.2008.155;10.1109/TVCG.2009.109                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Network diagrams, graph layout, perceptual theories, visual features, diagram recall, experiment                                                                                    	26                         	39                         	29                           	48
SciVis    	2012	Multivariate Data Analysis Using Persistence-Based filtering and Topological Signatures                                         	10.1109/TVCG.2012.248    	http://dx.doi.org/10.1109/TVCG.2012.248    	2382     	2391    	J        	The extraction of significant structures in arbitrary high-dimensional data sets is a challenging task. Moreover, classifying data points as noise in order to reduce a data set bears special relevance for many application domains. Standard methods such as clustering serve to reduce problem complexity by providing the user with classes of similar entities. However, they usually do not highlight relations between different entities and require a stopping criterion, e.g. the number of clusters to be detected. In this paper, we present a visualization pipeline based on recent advancements in algebraic topology. More precisely, we employ methods from persistent homology that enable topological data analysis on high-dimensional data sets. Our pipeline inherently copes with noisy data and data sets of arbitrary dimensions. It extracts central structures of a data set in a hierarchical manner by using a persistence-based filtering algorithm that is theoretically well-founded. We furthermore introduce persistence rings, a novel visualization technique for a class of topological features-the persistence intervals-of large data sets. Persistence rings provide a unique topological signature of a data set, which helps in recognizing similarities. In addition, we provide interactive visualization techniques that assist the user in evaluating the parameter space of our method in order to extract relevant structures. We describe and evaluate our analysis pipeline by means of two very distinct classes of data sets: First, a class of synthetic data sets containing topological objects is employed to highlight the interaction capabilities of our method. Second, in order to affirm the utility of our technique, we analyse a class of high-dimensional real-world data sets arising from current research in cultural heritage.                                                                                                                                                                                                            	Bastian Rieck;Hubert Mara;Heike Leitte                                                                                                                                                                                    	Bastian Rieck;Hubert Mara;Heike Leitte                                                                                                                                                                                    	Interdisciplinary Center for Scientific Computing;Interdisciplinary Center for Scientific Computing;Interdisciplinary Center for Scientific Computing                                                                                                                                                                                                                                                                                                                                                                     	10.1109/VISUAL.1990.146373;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2007.70601;10.1109/VISUAL.2002.1183774                                                                                                                                                                                                                                                                                                                                                                                                             	Topological persistence, multivariate data, clustering                                                                                                                              	22                         	29                         	22                           	40
SciVis    	2012	On the Interpolation of Data with Normally Distributed Uncertainty for Visualization                                            	10.1109/TVCG.2012.249    	http://dx.doi.org/10.1109/TVCG.2012.249    	2305     	2314    	J        	In many fields of science or engineering, we are confronted with uncertain data. For that reason, the visualization of uncertainty received a lot of attention, especially in recent years. In the majority of cases, Gaussian distributions are used to describe uncertain behavior, because they are able to model many phenomena encountered in science. Therefore, in most applications uncertain data is (or is assumed to be) Gaussian distributed. If such uncertain data is given on fixed positions, the question of interpolation arises for many visualization approaches. In this paper, we analyze the effects of the usual linear interpolation schemes for visualization of Gaussian distributed data. In addition, we demonstrate that methods known in geostatistics and machine learning have favorable properties for visualization purposes in this case.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	Steven Schlegel;Nico Korn;Gerik Scheuermann                                                                                                                                                                               	Steven Schlegel;Nico Korn;Gerik Scheuermann                                                                                                                                                                               	University of Leipzig;Helmholtz-Centre Dresden-Rossendorf;University of Leipzig                                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2007.70530;10.1109/TVCG.2011.203;10.1109/VISUAL.2005.1532807                                                                                                                                                                                                                                                                                                                                                                                                                                              	Gaussian process, uncertainty, interpolation                                                                                                                                        	20                         	0                          	24                           	26
InfoVis   	2012	Organizing Search Results with a Reference Map                                                                                  	10.1109/TVCG.2012.250    	http://dx.doi.org/10.1109/TVCG.2012.250    	2546     	2555    	J        	We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Arlind Nocaj;Ulrik Brandes                                                                                                                                                                                                	Arlind Nocaj;Ulrik Brandes                                                                                                                                                                                                	University of Konstanz;University of Konstanz                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	10.1109/INFVIS.2005.1532128;10.1109/INFVIS.1997.636718;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/TVCG.2009.176                                                                                                                                                                                                                                                                                                                                                                                               	Search results, mental map, voronoi treemaps, dynamic graph layout, multidimensional scaling, edge bundling                                                                         	19                         	23                         	15                           	46
InfoVis   	2012	Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications                          	10.1109/TVCG.2012.251    	http://dx.doi.org/10.1109/TVCG.2012.251    	2516     	2525    	J        	We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Anastasia Bezerianos;Petra Isenberg                                                                                                                                                                                       	Anastasia Bezerianos;Petra Isenberg                                                                                                                                                                                       	Univ Paris-Sud;INRIA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2011.160;10.1109/TVCG.2006.184                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Information visualization, perception, wall-displays                                                                                                                                	48                         	55                         	37                           	41
InfoVis   	2012	PivotPaths: Strolling through Faceted Information Spaces                                                                        	10.1109/TVCG.2012.252    	http://dx.doi.org/10.1109/TVCG.2012.252    	2709     	2718    	J        	We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	Marian Dörk;Nathalie Henry Riche;Gonzalo A. Ramos;Susan T. Dumais                                                                                                                                                         	Marian Dörk;Nathalie Henry Riche;Gonzalo Ramos;Susan Dumais                                                                                                                                                               	University of Calgary;Microsoft;Microsoft;Microsoft                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	10.1109/VAST.2009.5333443;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/VAST.2007.4389006;10.1109/VAST.2008.4677370;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.175                                                                                                                                                                                                                                                                                                                                             	Information visualization, interactivity, node-link diagrams, animation, information seeking, exploratory search                                                                    	80                         	102                        	73                           	24
InfoVis   	2012	RankExplorer: Visualization of Ranking Changes in Large Time Series Data                                                        	10.1109/TVCG.2012.253    	http://dx.doi.org/10.1109/TVCG.2012.253    	2669     	2678    	J        	For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen 0001;Huamin Qu                                                                                                                                                       	Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen;Huamin Qu                                                                                                                                                            	Hong Kong University of Science and Technology;Microsoft Research Aisa;Microsoft Research Aisa;Hong Kong University of Science and Technology;Zhe Jiang University;Hong Kong University of Science and Technology                                                                                                                                                                                                                                                                                                         	10.1109/TVCG.2008.166;10.1109/VAST.2010.5652931;10.1109/TVCG.2010.193;10.1109/VAST.2010.5652530;10.1109/INFVIS.2000.885098;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.140;10.1109/TVCG.2010.129;10.1109/TVCG.2008.181;10.1109/TVCG.2009.187;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.194;10.1109/TVCG.2011.239;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195;10.1109/TVCG.2009.180                           	Time-series data, ranking change, Themeriver, interaction techniques                                                                                                                	38                         	48                         	33                           	38
VAST      	2012	Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data                                          	10.1109/TVCG.2012.254    	http://dx.doi.org/10.1109/TVCG.2012.254    	2849     	2858    	J        	Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson's residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;M. Eduard Gröller                                                                                                                                                           	Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;M. Eduard Gröller                                                                                                                                                           	Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/INFVIS.2005.1532139;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2002.1173157                                                                                                                                                                                                                                                                                                                                                                            	Large categorical data, contingency table analysis, information interfaces and representation, visual analytics                                                                     	16                         	19                         	13                           	42       	HM
InfoVis   	2012	RelEx: Visualization for Actively Changing Overlay Network Specifications                                                       	10.1109/TVCG.2012.255    	http://dx.doi.org/10.1109/TVCG.2012.255    	2729     	2738    	J        	We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Michael Sedlmair;Annika Frank;Tamara Munzner;Andreas Butz                                                                                                                                                                 	Michael Sedlmair;Annika Frank;Tamara Munzner;Andreas Butz                                                                                                                                                                 	University of British Columbia;Bertrand AG, Munich;University of British Columbia;University of Munich (LMU)                                                                                                                                                                                                                                                                                                                                                                                                              	10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102443;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.111;10.1109/TVCG.2009.116;10.1109/INFVIS.1999.801869;10.1109/TVCG.2008.141;10.1109/TVCG.2008.117;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/INFVIS.2003.1249030;10.1109/VAST.2006.261426                                                                                                                                                                                               	Network visualization, change management, traffic routing, traffic optimization, automotive, design study                                                                           	14                         	16                         	12                           	49
InfoVis   	2012	Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data                                   	10.1109/TVCG.2012.256    	http://dx.doi.org/10.1109/TVCG.2012.256    	2621     	2630    	J        	Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Cagatay Turkay;Arvid Lundervold;Astri J. Lundervold;Helwig Hauser                                                                                                                                                         	Cagatay Turkay;Arvid Lundervold;Astri Johansen Lundervold;Helwig Hauser                                                                                                                                                   	Department of Informatics, University of Bergen;Department of Biomedicine, University of Bergen;Department of Biological and Medical Psychology, University of Bergen;Department of Informatics, University of Bergen                                                                                                                                                                                                                                                                                                     	10.1109/TVCG.2009.199;10.1109/INFVIS.2005.1532142;10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.116;10.1109/TVCG.2011.178;10.1109/TVCG.2007.70569;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153                                                                                                                                                                                                                    	Interactive visual analysis, high-dimensional data analysis                                                                                                                         	35                         	41                         	34                           	46
VAST      	2012	Scatter/Gather Clustering: Flexibly Incorporating User Feedback to Steer Clustering Results                                     	10.1109/TVCG.2012.258    	http://dx.doi.org/10.1109/TVCG.2012.258    	2829     	2838    	J        	Significant effort has been devoted to designing clustering algorithms that are responsive to user feedback or that incorporate prior domain knowledge in the form of constraints. However, users desire more expressive forms of interaction to influence clustering outcomes. In our experiences working with diverse application scientists, we have identified an interaction style scatter/gather clustering that helps users iteratively restructure clustering results to meet their expectations. As the names indicate, scatter and gather are dual primitives that describe whether clusters in a current segmentation should be broken up further or, alternatively, brought back together. By combining scatter and gather operations in a single step, we support very expressive dynamic restructurings of data. Scatter/gather clustering is implemented using a nonlinear optimization framework that achieves both locality of clusters and satisfaction of user-supplied constraints. We illustrate the use of our scatter/gather clustering approach in a visual analytic application to study baffle shapes in the bat biosonar (ears and nose) system. We demonstrate how domain experts are adept at supplying scatter/gather constraints, and how our framework incorporates these constraints effectively without requiring numerous instance-level constraints.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Mahmud Shahriar Hossain;Praveen Kumar Reddy Ojili;Cindy Grimm;Rolf Mueller;Layne T. Watson;Naren Ramakrishnan                                                                                                             	M. Shahriar Hossain;Praveen Kumar Reddy Ojili;Cindy Grimm;Rolf Müller;Layne T. Watson;Naren Ramakrishnan                                                                                                                  	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	10.1109/VAST.2009.5332584;10.1109/VAST.2007.4388999;10.1109/VAST.2008.4677350;10.1109/INFVIS.1998.729559;10.1109/VAST.2009.5332629                                                                                                                                                                                                                                                                                                                                                                                     	Scatter/gather clustering, alternative clustering, constrained clustering                                                                                                           	12                         	14                         	13                           	64
SciVis    	2012	SeiVis: An Interactive Visual Subsurface Modeling Application                                                                   	10.1109/TVCG.2012.259    	http://dx.doi.org/10.1109/TVCG.2012.259    	2226     	2235    	J        	The most important resources to fulfill today's energy demands are fossil fuels, such as oil and natural gas. When exploiting hydrocarbon reservoirs, a detailed and credible model of the subsurface structures is crucial in order to minimize economic and ecological risks. Creating such a model is an inverse problem: reconstructing structures from measured reflection seismics. The major challenge here is twofold: First, the structures in highly ambiguous seismic data are interpreted in the time domain. Second, a velocity model has to be built from this interpretation to match the model to depth measurements from wells. If it is not possible to obtain a match at all positions, the interpretation has to be updated, going back to the first step. This results in a lengthy back and forth between the different steps, or in an unphysical velocity model in many cases. This paper presents a novel, integrated approach to interactively creating subsurface models from reflection seismics. It integrates the interpretation of the seismic data using an interactive horizon extraction technique based on piecewise global optimization with velocity modeling. Computing and visualizing the effects of changes to the interpretation and velocity model on the depth-converted model on the fly enables an integrated feedback loop that enables a completely new connection of the seismic data in time domain and well data in depth domain. Using a novel joint time/depth visualization, depicting side-by-side views of the original and the resulting depth-converted data, domain experts can directly fit their interpretation in time domain to spatial ground truth data. We have conducted a domain expert evaluation, which illustrates that the presented workflow enables the creation of exact subsurface models much more rapidly than previous approaches.                                                                                                                                                                                                 	Thomas Höllt;Wolfgang Freiler;Fritz Gschwantner;Helmut Doleisch;Gabor Heinemann;Markus Hadwiger                                                                                                                           	Thomas Höllt;Wolfgang Freiler;Fritz-M. Gschwantner;Helmut Doleisch;Gabor Heinemann;Markus Hadwiger                                                                                                                        	King Adbullah University of Science and Technology, Saudi Arabia;SimVis GmbH, Austria;VRVis Research Center, Austria;SimVis GmbH, Austria;Heinemann Oil GmbH, Austria;King Adbullah University of Science and Technology, Saudi Arabia                                                                                                                                                                                                                                                                                    	10.1109/TVCG.2009.136;10.1109/TVCG.2006.140;10.1109/VISUAL.2005.1532802;10.1109/VISUAL.2003.1250400                                                                                                                                                                                                                                                                                                                                                                                                                    	Seismic visualization, volume deformation, exploded views, seismic interpretation                                                                                                   	4                          	7                          	5                            	23
VAST      	2012	Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering                                         	10.1109/TVCG.2012.260    	http://dx.doi.org/10.1109/TVCG.2012.260    	2879     	2888    	J        	Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users' analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user's reasoning and intuition.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Alex Endert;Patrick Fiaux;Chris North                                                                                                                                                                                     	Alex Endert;Patrick Fiaux;Chris North                                                                                                                                                                                     	Virginia Polytechnic Institute and State University;Virginia Polytechnic Institute and State University;Virginia Polytechnic Institute and State University                                                                                                                                                                                                                                                                                                                                                               	10.1109/INFVIS.1995.528686;10.1109/VAST.2012.6400559;10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102438;10.1109/VAST.2007.4389006                                                                                                                                                                                                                                                                                                                                                                                     	User Interaction, visualization, sensemaking, analytic reasoning, visual analytics                                                                                                  	48                         	69                         	49                           	36
SciVis    	2012	Sketching Uncertainty into Simulations                                                                                          	10.1109/TVCG.2012.261    	http://dx.doi.org/10.1109/TVCG.2012.261    	2255     	2264    	J        	In a variety of application areas, the use of simulation steering in decision making is limited at best. Research focusing on this problem suggests that most user interfaces are too complex for the end user. Our goal is to let users create and investigate multiple, alternative scenarios without the need for special simulation expertise. To simplify the specification of parameters, we move from a traditional manipulation of numbers to a sketch-based input approach. Users steer both numeric parameters and parameters with a spatial correspondence by sketching a change onto the rendering. Special visualizations provide immediate visual feedback on how the sketches are transformed into boundary conditions of the simulation models. Since uncertainty with respect to many intertwined parameters plays an important role in planning, we also allow the user to intuitively setup complete value ranges, which are then automatically transformed into ensemble simulations. The interface and the underlying system were developed in collaboration with experts in the field of flood management. The real-world data they have provided has allowed us to construct scenarios used to evaluate the system. These were presented to a variety of flood response personnel, and their feedback is discussed in detail in the paper. The interface was found to be intuitive and relevant, although a certain amount of training might be necessary.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Hrvoje Ribicic;Jürgen Waser;Roman Gurbat;Bernhard Sadransky;M. Eduard Gröller                                                                                                                                             	Hrvoje Ribicic;Juergen Waser;Roman Gurbat;Bernhard Sadransky;M. Eduard Gröller                                                                                                                                            	VRVis Research Center, Austria;VRVis Research Center, Austria;TU Wien;VRVis Research Center, Austria;TU Wien                                                                                                                                                                                                                                                                                                                                                                                                              	10.1109/TVCG.2010.223;10.1109/TVCG.2011.225;10.1109/TVCG.2010.223;10.1109/TVCG.2010.202;10.1109/VAST.2011.6102457                                                                                                                                                                                                                                                                                                                                                                                                      	Emergency/disaster management, interaction design, uncertainty visualization, sketch-based steering, ensemble simulation steering, integrated visualization system, flood management	7                          	8                          	4                            	31
InfoVis   	2012	Sketchy Rendering for Information Visualization                                                                                 	10.1109/TVCG.2012.262    	http://dx.doi.org/10.1109/TVCG.2012.262    	2749     	2758    	J        	We present and evaluate a framework for constructing sketchy style information visualizations that mimic data graphics drawn by hand. We provide an alternative renderer for the Processing graphics environment that redefines core drawing primitives including line, polygon and ellipse rendering. These primitives allow higher-level graphical features such as bar charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy style with a specified degree of sketchiness. The framework is designed to be easily integrated into existing visualization implementations with minimal programming modification or design effort. We show examples of use for statistical graphics, conveying spatial imprecision and for enhancing aesthetic and narrative qualities of visualization. We evaluate user perception of sketchiness of areal features through a series of stimulus-response tests in order to assess users' ability to place sketchiness on a ratio scale, and to estimate area. Results suggest relative area judgment is compromised by sketchy rendering and that its influence is dependent on the shape being rendered. They show that degree of sketchiness may be judged on an ordinal scale but that its judgement varies strongly between individuals. We evaluate higher-level impacts of sketchiness through user testing of scenarios that encourage user engagement with data visualization and willingness to critique visualization design. Results suggest that where a visualization is clearly sketchy, engagement may be increased and that attitudes to participating in visualization annotation are more positive. The results of our work have implications for effective information visualization design that go beyond the traditional role of sketching as a tool for prototyping or its use for an indication of general uncertainty.                                                                                                                                                                                                        	Jo Wood;Petra Isenberg;Tobias Isenberg 0001;Jason Dykes;Nadia Boukhelifa;Aidan Slingsby                                                                                                                                   	Jo Wood;Petra Isenberg;Tobias Isenberg;Jason Dykes;Nadia Boukhelifa;Aidan Slingsby                                                                                                                                        	giCentre, City University London;INRIA, Paris;University of Groningen, Netherlands;giCentre, City University London;INRIA, Paris;giCentre, City University London                                                                                                                                                                                                                                                                                                                                                         	10.1109/TVCG.2010.186;10.1109/TVCG.2011.175;10.1109/TVCG.2012.220;10.1109/TVCG.2011.251;10.1109/TVCG.2011.209;10.1109/TVCG.2011.255                                                                                                                                                                                                                                                                                                                                                                                    	NPR, non-photorealistic rendering, sketch, hand-drawn, uncertainty, visualization                                                                                                   	31                         	0                          	27                           	47
InfoVis   	2012	SnapShot: Visualization to Propel Ice Hockey Analytics                                                                          	10.1109/TVCG.2012.263    	http://dx.doi.org/10.1109/TVCG.2012.263    	2819     	2828    	J        	Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Hannah Pileggi;Charles D. Stolper;J. Michael Boyle;John T. Stasko                                                                                                                                                         	Hannah Pileggi;Charles D. Stolper;J. Michael Boyle;John T. Stasko                                                                                                                                                         	Georgia Institute of Technology;Georgia Institute of Technology;Sports Analytics Institute, Inc.;Georgia Institute of Technology                                                                                                                                                                                                                                                                                                                                                                                          	10.1109/TVCG.2010.179;10.1109/TVCG.2007.70537;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.1996.559229                                                                                                                                                                                                                                                                                                                                                                      	Visual knowledge discovery, visual knowledge representation, hypothesis testing, visual evidence, human computer interaction                                                        	42                         	55                         	41                           	28
InfoVis   	2012	Spatial Text Visualization Using Automatic Typographic Maps                                                                     	10.1109/TVCG.2012.264    	http://dx.doi.org/10.1109/TVCG.2012.264    	2556     	2564    	J        	We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the OpenStreetMap project into typographic maps for any region.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Shehzad Afzal;Ross Maciejewski;Yun Jang;Niklas Elmqvist;David S. Ebert                                                                                                                                                    	Shehzad Afzal;Ross Maciejewski;Yun Jang;Niklas Elmqvist;David S. Ebert                                                                                                                                                    	Purdue University;Arizona State University;Sejong University;Purdue University;Purdue University                                                                                                                                                                                                                                                                                                                                                                                                                          	10.1109/VAST.2010.5652931;10.1109/TVCG.2010.191;10.1109/TVCG.2010.175;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1997.663912;10.1109/VISUAL.2000.885694;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2002.1173144;10.1109/TVCG.2008.165;10.1109/TVCG.2010.194;10.1109/TVCG.2009.171;10.1109/INFVIS.2000.885095                                                                                                                                                                                                            	Geovisualization, spatial data, text visualization, label placement                                                                                                                 	29                         	30                         	20                           	48
InfoVis   	2012	Stacking-Based Visualization of Trajectory Attribute Data                                                                       	10.1109/TVCG.2012.265    	http://dx.doi.org/10.1109/TVCG.2012.265    	2565     	2574    	J        	Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Christian Tominski;Heidrun Schumann;Gennady L. Andrienko;Natalia V. Andrienko                                                                                                                                             	Christian Tominski;Heidrun Schumann;Gennady Andrienko;Natalia Andrienko                                                                                                                                                   	University of Rostock;University of Rostock;Fraunhofer Institute IAIS;Fraunhofer Institute IAIS                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2010.197;10.1109/VAST.2011.6102455;10.1109/VAST.2009.5332593;10.1109/VISUAL.1995.480803;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532144;10.1109/VAST.2011.6102454                                                                                                                                                                                                                                                                                                                                      	Visualization, interaction, exploratory analysis, trajectory attribute data, spatio-temporal data                                                                                   	120                        	150                        	124                          	35
SciVis    	2012	Structure-Aware Lighting Design for Volume Visualization                                                                        	10.1109/TVCG.2012.267    	http://dx.doi.org/10.1109/TVCG.2012.267    	2372     	2381    	J        	Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information - the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                	Yubo Tao;Hai Lin 0003;Feng Dong;Chao Wang;Gordon Clapworthy;Hujun Bao                                                                                                                                                     	Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Gordon Clapworthy;Hujun Bao                                                                                                                                                          	State Key Lab of CAD&CG, Zhejiang University, P.R. China;State Key Lab of CAD&CG, Zhejiang University, P.R. China;University of Bedfordshire, UK;University of Bedfordshire, UK;University of Bedfordshire, UK;State Key Lab of CAD&CG, Zhejiang University, P.R. China                                                                                                                                                                                                                                                   	10.1109/TVCG.2006.137;10.1109/TVCG.2011.218;10.1109/VISUAL.2004.62;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2003.1250395;10.1109/VISUAL.2002.1183785                                                                                                                                                                                                                                                                                                                                     	Automatic lighting design, structural dissimilarity, lighting similarity, lighting stability, volume rendering                                                                      	10                         	0                          	10                           	29
SciVis    	2012	Surface-Based Structure Analysis and Visualization for Multifield Time-Varying Datasets                                         	10.1109/TVCG.2012.269    	http://dx.doi.org/10.1109/TVCG.2012.269    	2392     	2401    	J        	This paper introduces a new feature analysis and visualization method for multifield datasets. Our approach applies a surface-centric model to characterize salient features and form an effective, schematic representation of the data. We propose a simple, geometrically motivated, multifield feature definition. This definition relies on an iterative algorithm that applies existing theory of skeleton derivation to fuse the structures from the constitutive fields into a coherent data description, while addressing noise and spurious details. This paper also presents a new method for non-rigid surface registration between the surfaces of consecutive time steps. This matching is used in conjunction with clustering to discover the interaction patterns between the different fields and their evolution over time. We document the unified visual analysis achieved by our method in the context of several multifield problems from large-scale time-varying simulations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	Samer S. Barakat;Markus Rütten;Xavier Tricoche                                                                                                                                                                            	Samer S. Barakat;Markus Rütten;Xavier Tricoche                                                                                                                                                                            	Purdue University;DLR Göttingen;Purdue University                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	10.1109/TVCG.2007.70615;10.1109/TVCG.2007.70523;10.1109/TVCG.2006.165;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.116;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.140;10.1109/VISUAL.1995.485139;10.1109/TVCG.2009.177;10.1109/TVCG.2008.148                                                                                                                                                                                                                                                                               	Multifield, time-varying, surface structures                                                                                                                                        	1                          	1                          	1                            	36
InfoVis   	2012	Taxonomy-Based Glyph Design---with a Case Study on Visualizing Workflows of Biological Experiments                              	10.1109/TVCG.2012.271    	http://dx.doi.org/10.1109/TVCG.2012.271    	2603     	2612    	J        	Glyph-based visualization can offer elegant and concise presentation of multivariate information while enhancing speed and ease in visual search experienced by users. As with icon designs, glyphs are usually created based on the designers' experience and intuition, often in a spontaneous manner. Such a process does not scale well with the requirements of applications where a large number of concepts are to be encoded using glyphs. To alleviate such limitations, we propose a new systematic process for glyph design by exploring the parallel between the hierarchy of concept categorization and the ordering of discriminative capacity of visual channels. We examine the feasibility of this approach in an application where there is a pressing need for an efficient and effective means to visualize workflows of biological experiments. By processing thousands of workflow records in a public archive of biological experiments, we demonstrate that a cost-effective glyph design can be obtained by following a process of formulating a taxonomy with the aid of computation, identifying visual channels hierarchically, and defining application-specific abstraction and metaphors.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen 0001                                                                                                                                      	Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen                                                                                                                                           	University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford                                                                                                                                                                                                                                                                                                                                                                                                                  	10.1109/TVCG.2006.134;10.1109/TVCG.2012.197;10.1109/TVCG.2010.132;10.1109/VISUAL.1995.485141;10.1109/INFVIS.1998.729568                                                                                                                                                                                                                                                                                                                                                                                                	Glyph-based techniques, taxonomies, design methodologies, bioinformatics visualization                                                                                              	32                         	                           	29                           	63
InfoVis   	2012	The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning                                              	10.1109/TVCG.2012.272    	http://dx.doi.org/10.1109/TVCG.2012.272    	2789     	2798    	J        	In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Florian Block;Michael S. Horn;Brenda Caldwell Phillips;Judy Diamond;E. Margaret Evans;Chia Shen                                                                                                                           	Florian Block;Michael S. Horn;Brenda Caldwell Phillips;Judy Diamond;E. Margaret Evans;Chia Shen                                                                                                                           	Harvard University;Northwestern University;Harvard University;University of Nebraska State Museum;University of Michigan;Harvard University                                                                                                                                                                                                                                                                                                                                                                               	10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541                                                                                                                                                                                                                                                                                                              	Informal science education, collaborative learning, large tree visualizations, multi-touch interaction                                                                              	34                         	37                         	25                           	55
VAST      	2012	The User Puzzle---Explaining the Interaction with Visual Analytics Systems                                                      	10.1109/TVCG.2012.273    	http://dx.doi.org/10.1109/TVCG.2012.273    	2908     	2916    	J        	Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Margit Pohl;Michael Smuc;Eva Mayr                                                                                                                                                                                         	Margit Pohl;Michael Smuc;Eva Mayr                                                                                                                                                                                         	Vienna University of Technology;Danube University Krems;Danube University Krems                                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2008.121;10.1109/TVCG.2007.70515;10.1109/VAST.2010.5653598;10.1109/VAST.2008.4677361;10.1109/VAST.2011.6102445                                                                                                                                                                                                                                                                                                                                                                                            	Cognitive theory, visual knowledge discovery, interaction design, reasoning, problem solving                                                                                        	18                         	                           	18                           	65
SciVis    	2012	Turbulence Visualization at the Terascale on Desktop PCs                                                                        	10.1109/TVCG.2012.274    	http://dx.doi.org/10.1109/TVCG.2012.274    	2169     	2177    	J        	Despite the ongoing efforts in turbulence research, the universal properties of the turbulence small-scale structure and the relationships between small- and large-scale turbulent motions are not yet fully understood. The visually guided exploration of turbulence features, including the interactive selection and simultaneous visualization of multiple features, can further progress our understanding of turbulence. Accomplishing this task for flow fields in which the full turbulence spectrum is well resolved is challenging on desktop computers. This is due to the extreme resolution of such fields, requiring memory and bandwidth capacities going beyond what is currently available. To overcome these limitations, we present a GPU system for feature-based turbulence visualization that works on a compressed flow field representation. We use a wavelet-based compression scheme including run-length and entropy encoding, which can be decoded on the GPU and embedded into brick-based volume ray-casting. This enables a drastic reduction of the data to be streamed from disk to GPU memory. Our system derives turbulence properties directly from the velocity gradient tensor, and it either renders these properties in turn or generates and renders scalar feature volumes. The quality and efficiency of the system is demonstrated in the visualization of two unsteady turbulence simulations, each comprising a spatio-temporal resolution of 10244. On a desktop computer, the system can visualize each time step in 5 seconds, and it achieves about three times this rate for the visualization of a scalar feature volume.                                                                                                                                                                                                                                                                                                                                                                                                                                   	Marc Treib;Kai Bürger;Florian Reichl;Charles Meneveau;Alexander S. Szalay;Rüdiger Westermann                                                                                                                              	Marc Treib;Kai Bürger;Florian Reichl;Charles Meneveau;Alex Szalay;Rüdiger Westermann                                                                                                                                      	Technische Universität München;Technische Universität München;Technische Universität München;Johns Hopkins University;Johns Hopkins University;Technische Universität München                                                                                                                                                                                                                                                                                                                                             	10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2001.964520;10.1109/TVCG.2006.143;10.1109/VISUAL.2005.1532808;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964531;10.1109/VISUAL.2004.55;10.1109/VISUAL.2003.1250385                                                                                                                                                                                                                                                                                                     	Visualization system and toolkit design, vector fields, volume rendering, data streaming, data compression                                                                          	18                         	24                         	16                           	45
InfoVis   	2012	Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards                                         	10.1109/TVCG.2012.275    	http://dx.doi.org/10.1109/TVCG.2012.275    	2779     	2788    	J        	Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Jagoda Walny;Bongshin Lee;Paul Johns;Nathalie Henry Riche;Sheelagh Carpendale                                                                                                                                             	Jagoda Walny;Bongshin Lee;Paul Johns;Nathalie Henry Riche;Sheelagh Carpendale                                                                                                                                             	University of Calgary;Microsoft Research;Microsoft Research;Microsoft Research;University of Calgary                                                                                                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2012.262;10.1109/TVCG.2009.174;10.1109/TVCG.2011.251;10.1109/TVCG.2007.70568;10.1109/TVCG.2010.164                                                                                                                                                                                                                                                                                                                                                                                                        	Pen and touch, interaction, Wizard of Oz, whiteboard, data exploration                                                                                                              	52                         	0                          	31                           	47
VAST      	2012	Visual Analytics Methodology for Eye Movement Studies                                                                           	10.1109/TVCG.2012.276    	http://dx.doi.org/10.1109/TVCG.2012.276    	2889     	2898    	J        	Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	Gennady L. Andrienko;Natalia V. Andrienko;Michael Burch;Daniel Weiskopf                                                                                                                                                   	Gennady Andrienko;Natalia Andrienko;Michael Burch;Daniel Weiskopf                                                                                                                                                         	Fraunhofer Institute IAIS;Fraunhofer Institute IAIS;University of Stuttgart;University of Stuttgart                                                                                                                                                                                                                                                                                                                                                                                                                       	10.1109/VAST.2009.5332593;10.1109/TVCG.2011.193;10.1109/INFVIS.2005.1532150                                                                                                                                                                                                                                                                                                                                                                                                                                            	Visual analytics, eye tracking, movement data, trajectory analysis                                                                                                                  	93                         	115                        	80                           	33       	BP
VAST      	2012	Visual Classifier Training for Text Document Retrieval                                                                          	10.1109/TVCG.2012.277    	http://dx.doi.org/10.1109/TVCG.2012.277    	2839     	2848    	J        	Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.                                                                                                                                                                                                                                                                                                                                                	Florian Heimerl;Steffen Koch;Harald Bosch;Thomas Ertl                                                                                                                                                                     	Florian Heimerl;Steffen Koch;Harald Bosch;Thomas Ertl                                                                                                                                                                     	Universoty of Stuttgart;Universoty of Stuttgart;Universoty of Stuttgart;Universoty of Stuttgart                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492                                                                                                                                                                                                                                                                                                                                                                                                                	Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation                                                               	58                         	0                          	59                           	48
SciVis    	2012	Visual Data Analysis as an Integral Part of Environmental Management                                                            	10.1109/TVCG.2012.278    	http://dx.doi.org/10.1109/TVCG.2012.278    	2088     	2094    	J        	The U.S. Department of Energy's (DOE) Office of Environmental Management (DOE/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                	Joerg Meyer;E. Wes Bethel;Jennifer L. Horsman;Susan S. Hubbard;Harinarayan Krishnan;Alexandru Romosan;Elizabeth H. Keating;Laura Monroe;Richard Strelitz;Phil Moore;Glenn Taylor;Ben Torkian;Timothy C. Johnson;Ian Gorton	Joerg Meyer;Glenn Taylor;Ben Torkian;Timothy C. Johnson;Ian Gorton;E. Wes Bethel;Jennifer L. Horsman;Susan S. Hubbard;Harinarayan Krishnan;Alexandru Romosan;Elizabeth H. Keating;Laura Monroe;Richard Strelitz;Phil Moore	Lawrence Berkeley National Laboratory;Savannah River National Laboratory;Savannah River National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Los Alamos National Laboratory;Los Alamos National Laboratory;Los Alamos National Laboratory;Savannah River National Laboratory     	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	Visual analytics, high-performance computing, data management, parallel rendering, environmental management                                                                         	0                          	5                          	4                            	8
InfoVis   	2012	Visual Semiotics & Uncertainty Visualization: An Empirical Study                                                                	10.1109/TVCG.2012.279    	http://dx.doi.org/10.1109/TVCG.2012.279    	2496     	2505    	J        	This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	Alan M. MacEachren;Robert E. Roth;James O'Brien;Bonan Li;Derek Swingley;Mark Gahegan                                                                                                                                      	Alan M. MacEachren;Robert E. Roth;James O'Brien;Bonan Li;Derek Swingley;Mark Gahegan                                                                                                                                      	Penn State University;University of Wisconsin;Macquarie University;ZillionInfo;Penn State University;University of Auckland                                                                                                                                                                                                                                                                                                                                                                                               	10.1109/VISUAL.1992.235199;10.1109/TVCG.2011.197;10.1109/TVCG.2009.114                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Uncertainty visualization, uncertainty categories, visual variables, semiotics                                                                                                      	86                         	                           	83                           	34       	HM
SciVis    	2012	Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research                                	10.1109/TVCG.2012.280    	http://dx.doi.org/10.1109/TVCG.2012.280    	2275     	2284    	J        	The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony S. Wexler;Bernd Hamann;Hans Hagen                                                                                                                             	Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony Wexler;Bernd Hamann;Hans Hagen                                                                                                                                	University of Kaiserslautern, Germany;University of Kaiserslautern, Germany;University of Kaiserslautern, Germany;Air Quality Research Center (AQRC), University of California, Davis, CA, USA;Air Quality Research Center (AQRC), University of California, Davis, CA, USA;Institute for Data Analysis and Visualization (IDAV), University of California, Davis, CA, USA;University of Kaiserslautern, Germany                                                                                                          	10.1109/INFVIS.2004.68;10.1109/INFVIS.2004.15;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.116;10.1109/VISUAL.2000.885734;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2010.223;10.1109/VISUAL.2005.1532850;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2008.153                                                                                                                                                                                                                                                             	Dimension reduction, mass spectrometry data, matrix factorization, visual encodings of numerical error metrics, multi-dimensional data visualization                                	4                          	5                          	5                            	44
SciVis    	2012	Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography                                   	10.1109/TVCG.2012.281    	http://dx.doi.org/10.1109/TVCG.2012.281    	2188     	2197    	J        	The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Stephan Wenger;Marco Ament;Stefan Guthe;Dirk A. Lorenz;Andreas M. Tillmann;Daniel Weiskopf;Marcus A. Magnor                                                                                                               	Stephan Wenger;Marco Ament;Stefan Guthe;Dirk Lorenz;Andreas Tillmann;Daniel Weiskopf;Marcus Magnor                                                                                                                        	Institut für Computergraphik, TU Braunschweig, Germany;Visualization Research Center, Universität Stuttgart, Germany;Institut für Computergraphik, TU Braunschweig, Germany;Institute for Analysis and Algebra, TU Braunschweig, Germany;Research Group Optimization, TU Darmstadt, Germany;Visualization Research Center, Universität Stuttgart, Germany;Institut für Computergraphik, TU Braunschweig, Germany                                                                                                          	10.1109/VISUAL.2005.1532803;10.1109/VISUAL.2004.18;10.1109/VISUAL.1994.346331                                                                                                                                                                                                                                                                                                                                                                                                                                          	Astronomical visualization, distributed volume reconstruction, direct volume rendering                                                                                              	6                          	7                          	7                            	38
SciVis    	2012	Visualization of Electrostatic Dipoles in Molecular Dynamics of Metal Oxides                                                    	10.1109/TVCG.2012.282    	http://dx.doi.org/10.1109/TVCG.2012.282    	2061     	2068    	J        	Metal oxides are important for many technical applications. For example alumina (aluminum oxide) is the most commonly-used ceramic in microelectronic devices thanks to its excellent properties. Experimental studies of these materials are increasingly supplemented with computer simulations. Molecular dynamics (MD) simulations can reproduce the material behavior very well and are now reaching time scales relevant for interesting processes like crack propagation. In this work we focus on the visualization of induced electric dipole moments on oxygen atoms in crack propagation simulations. The straightforward visualization using glyphs for the individual atoms, simple shapes like spheres or arrows, is insufficient for providing information about the data set as a whole. As our contribution we show for the first time that fractional anisotropy values computed from the local neighborhood of individual atoms of MD simulation data depict important information about relevant properties of the field of induced electric dipole moments. Iso surfaces in the field of fractional anisotropy as well as adjustments of the glyph representation allow the user to identify regions of correlated orientation. We present novel and relevant findings for the application domain resulting from these visualizations, like the influence of mechanical forces on the electrostatic properties.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	Sebastian Grottel;Philipp Beck;Christoph Müller 0001;Guido Reina;Johannes Roth;Hans-Rainer Trebin;Thomas Ertl                                                                                                             	Sebastian Grottel;Philipp Beck;Christoph Müller;Guido Reina;Johannes Roth;Hans-Rainer Trebin;Thomas Ertl                                                                                                                  	Computer Graphics and Visualization, TU Dresden;Institute for Theoretical and Applied Physics of the University of Stuttgart (ITAP);Visualization Research Center of the University of Stuttgart (VISUS);Visualization Research Center of the University of Stuttgart (VISUS);Institute for Theoretical and Applied Physics of the University of Stuttgart (ITAP);Institute for Theoretical and Applied Physics of the University of Stuttgart (ITAP);Visualization Research Center of the University of Stuttgart (VISUS)	10.1109/TVCG.2006.186;10.1109/VISUAL.2005.1532781;10.1109/VISUAL.1999.809886                                                                                                                                                                                                                                                                                                                                                                                                                                           	Visualization in physical sciences and engineering, glyph-based techniques, time-varying data, point-based data                                                                     	12                         	15                         	12                           	42
SciVis    	2012	Visualization of Flow Behavior in Earth Mantle Convection                                                                       	10.1109/TVCG.2012.283    	http://dx.doi.org/10.1109/TVCG.2012.283    	2198     	2207    	J        	A fundamental characteristic of fluid flow is that it causes mixing: introduce a dye into a flow, and it will disperse. Mixing can be used as a method to visualize and characterize flow. Because mixing is a process that occurs over time, it is a 4D problem that presents a challenge for computation, visualization, and analysis. Motivated by a mixing problem in geophysics, we introduce a combination of methods to analyze, transform, and finally visualize mixing in simulations of convection in a self-gravitating 3D spherical shell representing convection in the Earth's mantle. Geophysicists use tools such as the finite element model CitcomS to simulate convection, and introduce massless, passive tracers to model mixing. The output of geophysical flow simulation is hard to analyze for domain experts because of overall data size and complexity. In addition, information overload and occlusion are problems when visualizing a whole-earth model. To address the large size of the data, we rearrange the simulation data using intelligent indexing for fast file access and efficient caching. To address information overload and interpret mixing, we compute tracer concentration statistics, which are used to characterize mixing in mantle convection models. Our visualization uses a specially tailored version of Direct Volume Rendering. The most important adjustment is the use of constant opacity. Because of this special area of application, i. e. the rendering of a spherical shell, many computations for volume rendering can be optimized. These optimizations are essential to a smooth animation of the time-dependent simulation data. Our results show how our system can be used to quickly assess the simulation output and test hypotheses regarding Earth's mantle convection. The integrated processing pipeline helps geoscientists to focus on their main task of analyzing mantle homogenization.                                                                                                                                       	Simon Schröder;John A. Peterson;Harald Obermaier;Louise H. Kellogg;Kenneth I. Joy;Hans Hagen                                                                                                                              	Simon Schröder;John A. Peterson;Harald Obermaier;Louise H. Kellogg;Kenneth I. Joy;Hans Hagen                                                                                                                              	Fraunhofer ITWM;Department of Geology, University of California, Davis;Institute for Data Analysis and Visualization, University of California, Davis;Department of Geology, University of California, Davis;Institute for Data Analysis and Visualization, University of California, Davis;Computer Graphics and HCI Group, University of Kaiserslautern                                                                                                                                                                 	10.1109/TVCG.2010.156                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Geophysics, flow visualization, tracer concentration, Earth mantle, convection, large data system                                                                                   	1                          	2                          	1                            	31
SciVis    	2012	Visualization of Temporal Similarity in field Data                                                                              	10.1109/TVCG.2012.284    	http://dx.doi.org/10.1109/TVCG.2012.284    	2023     	2032    	J        	This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	Steffen Frey;Filip Sadlo;Thomas Ertl                                                                                                                                                                                      	Steffen Frey;Filip Sadlo;Thomas Ertl                                                                                                                                                                                      	University of Stuttgart;University of Stuttgart;University of Stuttgart                                                                                                                                                                                                                                                                                                                                                                                                                                                   	10.1109/TVCG.2008.139;10.1109/TVCG.2006.199;10.1109/TVCG.2006.165;10.1109/TVCG.2010.213;10.1109/TVCG.2010.133;10.1109/TVCG.2010.223;10.1109/TVCG.2009.199;10.1109/TVCG.2008.140;10.1109/TVCG.2010.216;10.1109/TVCG.2009.200;10.1109/TVCG.2011.159;10.1109/TVCG.2009.197                                                                                                                                                                                                                                                	Time-dependent fields, similarity analysis, interactive recurrence analysis, comparative visualization                                                                              	15                         	18                         	15                           	42
InfoVis   	2012	Visualizing Flow of Uncertainty through Analytical Processes                                                                    	10.1109/TVCG.2012.285    	http://dx.doi.org/10.1109/TVCG.2012.285    	2526     	2535    	J        	Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma                                                                                                                                                                                       	Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma                                                                                                                                                                                       	University of California, Davis;University of California, Davis;University of California, Davis                                                                                                                                                                                                                                                                                                                                                                                                                           	10.1109/TVCG.2008.137;10.1109/TVCG.2011.178;10.1109/INFVIS.2004.2;10.1109/INFVIS.2002.1173145;10.1109/VISUAL.1993.398857;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/TVCG.2009.114;10.1109/TVCG.2011.197;10.1109/TVCG.2010.176                                                                                                                                                                                                                                                                             	Uncertainty visualization, uncertainty quantification, uncertainty propagation, error ellipsoids, uncertainty fusion                                                                	21                         	31                         	31                           	46
InfoVis   	2012	Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations                                     	10.1109/TVCG.2012.286    	http://dx.doi.org/10.1109/TVCG.2012.286    	2467     	2476    	J        	The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	Aaditya G. Landge;Joshua A. Levine;Abhinav Bhatele;Katherine E. Isaacs;Todd Gamblin;Martin Schulz 0001;Steve H. Langer;Peer-Timo Bremer;Valerio Pascucci                                                                  	Aaditya G. Landge;Joshua A. Levine;Abhinav Bhatele;Katherine E. Isaacs;Todd Gamblin;Martin Schulz;Steve H. Langer;Peer-Timo Bremer;Valerio Pascucci                                                                       	SCI Institute, University of Utah;SCI Institute, University of Utah;Lawrence Livermore National Laboratory;University of California, Davis;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;SCI Institute, University of Utah                                                                                                                                                                                  	10.1109/TVCG.2009.196;10.1109/INFVIS.2004.66                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	Performance analysis, network traffic visualization, projected graph layouts                                                                                                        	36                         	43                         	33                           	37
SciVis    	2012	Visualizing Nuclear Scission through a Multifield Extension of Topological Analysis                                             	10.1109/TVCG.2012.287    	http://dx.doi.org/10.1109/TVCG.2012.287    	2033     	2040    	J        	In nuclear science, density functional theory (DFT) is a powerful tool to model the complex interactions within the atomic nucleus, and is the primary theoretical approach used by physicists seeking a better understanding of fission. However DFT simulations result in complex multivariate datasets in which it is difficult to locate the crucial `scission' point at which one nucleus fragments into two, and to identify the precursors to scission. The Joint Contour Net (JCN) has recently been proposed as a new data structure for the topological analysis of multivariate scalar fields, analogous to the contour tree for univariate fields. This paper reports the analysis of DFT simulations using the JCN, the first application of the JCN technique to real data. It makes three contributions to visualization: (i) a set of practical methods for visualizing the JCN, (ii) new insight into the detection of nuclear scission, and (iii) an analysis of aesthetic criteria to drive further work on representing the JCN.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	David J. Duke;Hamish A. Carr;Aaron Knoll;Nicolas Schunck;Hai Ah Nam;Andrzej Staszczak                                                                                                                                     	David Duke;Hamish Carr;Aaron Knoll;Nicolas Schunck;Hai Ah Nam;Andrzej Staszczak                                                                                                                                           	University of Leeds, UK;University of Leeds, UK;Argonne National Lab, USA;Lawrence Livermore National Lab, USA;Oak Ridge National Lab, USA;University Marie Curie-Skłodowska, Poland                                                                                                                                                                                                                                                                                                                                      	10.1109/TVCG.2008.143                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Topology, scalar fields, multifields                                                                                                                                                	16                         	22                         	20                           	35
InfoVis   	2012	Visualizing Student Histories Using Clustering and Composition                                                                  	10.1109/TVCG.2012.288    	http://dx.doi.org/10.1109/TVCG.2012.288    	2809     	2818    	J        	While intuitive time-series visualizations exist for common datasets, student course history data is difficult to represent using traditional visualization techniques due its concurrent nature. A visual composition process is developed and applied to reveal trends across various groupings. By working closely with educators, analytic strategies and techniques are developed to leverage the visualization composition to reveal unknown trends in the data. Furthermore, clustering algorithms are developed to group common course-grade histories for further analysis. Lastly, variations of the composition process are implemented to reveal subtle differences in the underlying data. These analytic tools and techniques enabled educators to confirm expected trends and to discover new ones.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                	David Trimm;Penny Rheingans;Marie desJardins                                                                                                                                                                              	David Trimm;Penny Rheingans;Marie desJardins                                                                                                                                                                              	The University of Maryland, Baltimore County;The University of Maryland, Baltimore County;The University of Maryland, Baltimore County                                                                                                                                                                                                                                                                                                                                                                                    	10.1109/INFVIS.2005.1532140;10.1109/TVCG.2007.70623;10.1109/TVCG.2009.131                                                                                                                                                                                                                                                                                                                                                                                                                                              	Clustering, aggregate visualization, student performance analysis, visualization composition                                                                                        	10                         	10                         	9                            	17
InfoVis   	2012	Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time                                               	10.1109/TVCG.2012.291    	http://dx.doi.org/10.1109/TVCG.2012.291    	2649     	2658    	J        	When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, “Whisper”, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Nan Cao;Yu-Ru Lin;Xiaohua Sun;David Lazer;Shixia Liu;Huamin Qu                                                                                                                                                            	Nan Cao;Yu-Ru Lin;Xiaohua Sun;David Lazer;Shixia Liu;Huamin Qu                                                                                                                                                            	Hong Kong University of Science and Technology;Northeastern University;TongJi University;Northeastern University;Microsoft Research Asia;Hong Kong University of Science and Technology                                                                                                                                                                                                                                                                                                                                   	10.1109/TVCG.2009.171;10.1109/TVCG.2006.147;10.1109/INFVIS.2000.885098;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70535;10.1109/TVCG.2010.129;10.1109/TVCG.2008.125;10.1109/TVCG.2011.188                                                                                                                                                                                                                                                                                                                                 	Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns                                                                   	76                         	90                         	66                           	54
SciVis    	2012	WYSIWYP: What You See Is What You Pick                                                                                          	10.1109/TVCG.2012.292    	http://dx.doi.org/10.1109/TVCG.2012.292    	2236     	2244    	J        	Scientists, engineers and physicians are used to analyze 3D data with slice-based visualizations. Radiologists for example are trained to read slices of medical imaging data. Despite the numerous examples of sophisticated 3D rendering techniques, domain experts, who still prefer slice-based visualization do not consider these to be very useful. Since 3D renderings have the advantage of providing an overview at a glance, while 2D depictions better serve detailed analyses, it is of general interest to better combine these methods. Recently there have been attempts to bridge this gap between 2D and 3D renderings. These attempts include specialized techniques for volume picking in medical imaging data that result in repositioning slices. In this paper, we present a new volume picking technique called WYSIWYP (“what you see is what you pick”) that, in contrast to previous work, does not require pre-segmented data or metadata and thus is more generally applicable. The positions picked by our method are solely based on the data itself, the transfer function, and the way the volumetric rendering is perceived by the user. To demonstrate the utility of the proposed method, we apply it to automated positioning of slices in volumetric scalar fields from various application areas. Finally, we present results of a user study in which 3D locations selected by users are compared to those resulting from WYSIWYP. The user study confirms our claim that the resulting positions correlate well with those perceived by the user.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	Alexander Wiebel;Frans Vos;David Foerster;Hans-Christian Hege                                                                                                                                                             	Alexander Wiebel;Frans M. Vos;David Foerster;Hans-Christian Hege                                                                                                                                                          	Zuse Institute Berlin (ZIB);TU Delft;Zuse Institute Berlin (ZIB);Zuse Institute Berlin (ZIB)                                                                                                                                                                                                                                                                                                                                                                                                                              	10.1109/TVCG.2012.217;10.1109/VISUAL.1998.745337;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70576;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2009.121                                                                                                                                                                                                                                                                                                                                                                 	Picking, volume rendering, WYSIWYG                                                                                                                                                  	19                         	26                         	23                           	40
VAST      	2012	Relative N-gram signatures: Document visualization at the level of character N-grams                                            	10.1109/VAST.2012.6400484	http://dx.doi.org/10.1109/VAST.2012.6400484	103      	112     	C        	The Common N-Gram (CNG) classifier is a text classification algorithm based on the comparison of frequencies of character n-grams (strings of characters of length n) that are the most common in the considered documents and classes of documents. We present a text analytic visualization system that employs the CNG approach for text classification and uses the differences in frequency values of common n-grams in order to visually compare documents at the sub-word level. The visualization method provides both an insight into n-gram characteristics of documents or classes of documents and a visual interpretation of the workings of the CNG classifier.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	Magdalena Jankowska;Vlado Keselj;Evangelos E. Milios                                                                                                                                                                      	Magdalena Jankowska;Vlado Kešelj;Evangelos Milios                                                                                                                                                                         	Faculty of Computer Science, Dalhousie University;Faculty of Computer Science, Dalhousie University;Faculty of Computer Science, Dalhousie University                                                                                                                                                                                                                                                                                                                                                                     	10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389004                                                                                                                                                                                                                                                                                                                                                                                                                                                                    	Visual analytics, visual text analysis, text classification                                                                                                                         	7                          	8                          	5                            	36
VAST      	2012	LeadLine: Interactive visual analysis of text data through event identification and exploration                                 	10.1109/VAST.2012.6400485	http://dx.doi.org/10.1109/VAST.2012.6400485	93       	102     	C        	Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, LeadLine, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, LeadLine integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, LeadLine allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, LeadLine provides a concise summary of the corpora. LeadLine also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of LeadLine in identifying events and supporting exploration, two case studies were conducted using news and social media data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	Wenwen Dou;Xiaoyu Wang;Drew Skau;William Ribarsky;Michelle X. Zhou                                                                                                                                                        	Wenwen Dou;Xiaoyu Wang;Drew Skau;William Ribarsky;Michelle X. Zhou                                                                                                                                                        	University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;IBM Almaden Research Center                                                                                                                                                                                                                                                                                                                       	10.1109/VAST.2011.6102456;10.1109/VAST.2010.5652931;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/TVCG.2011.185;10.1109/TVCG.2010.179;10.1109/VAST.2007.4389006;10.1109/INFVIS.2000.885098                                                                                                                                                                                                                                                                                             	                                                                                                                                                                                    	87                         	117                        	76                           	43
VAST      	2012	Dis-function: Learning distance functions interactively                                                                         	10.1109/VAST.2012.6400486	http://dx.doi.org/10.1109/VAST.2012.6400486	83       	92      	C        	The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Eli T. Brown;Jingjing Liu;Carla E. Brodley;Remco Chang                                                                                                                                                                    	Eli T. Brown;Jingjing Liu;Carla E. Brodley;Remco Chang                                                                                                                                                                    	Department of Computer Science Tufts University;Department of Computer Science Tufts University;Department of Computer Science Tufts University;Department of Computer Science Tufts University                                                                                                                                                                                                                                                                                                                           	10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4388999;10.1109/VAST.2009.5332584;10.1109/VAST.2011.6102448;10.1109/VAST.2008.4677352;10.1109/VAST.2010.5652443                                                                                                                                                                                                                                                                                                                                 	                                                                                                                                                                                    	79                         	108                        	70                           	40
VAST      	2012	Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations                                    	10.1109/VAST.2012.6400487	http://dx.doi.org/10.1109/VAST.2012.6400487	73       	82      	C        	We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                	Eser Kandogan                                                                                                                                                                                                             	Eser Kandogan                                                                                                                                                                                                             	IBM Center for Advanced Visualization, IBM Research                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3;10.1109/TVCG.2011.220;10.1109/INFVIS.2004.15;10.1109/INFVIS.1998.729559;10.1109/VAST.2006.261423;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652885;10.1109/VAST.2009.5332628;10.1109/TVCG.2011.229                                                                                                                                                                                                                                         	Just-in-time descriptive analytics, feature identification and characterization, point-based visualizations                                                                         	35                         	42                         	25                           	41
VAST      	2012	Subspace search and visualization to make sense of alternative clusterings in high-dimensional data                             	10.1109/VAST.2012.6400488	http://dx.doi.org/10.1109/VAST.2012.6400488	63       	72      	C        	In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.                                                                                                                            	Andrada Tatu;Fabian Maass;Ines Färber;Enrico Bertini;Tobias Schreck;Thomas Seidl 0001;Daniel A. Keim                                                                                                                      	Andrada Tatu;Fabian Maaß;Ines Färber;Enrico Bertini;Tobias Schreck;Thomas Seidl;Daniel Keim                                                                                                                               	University of Konstanz, Germany;University of Konstanz, Germany;RWTH Aachen University Germany;University of Konstanz, Germany;University of Konstanz, Germany;RWTH Aachen University Germany;University of Konstanz Germany                                                                                                                                                                                                                                                                                              	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2010.138;10.1109/VAST.2010.5652392;10.1109/INFVIS.2004.71;10.1109/VAST.2010.5652450;10.1109/VAST.2011.6102439;10.1109/TVCG.2011.188;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153                                                                                                                                                                                                                                                                                               	                                                                                                                                                                                    	46                         	60                         	36                           	35
VAST      	2012	iLAMP: Exploring high-dimensional spacing through backward multidimensional projection                                          	10.1109/VAST.2012.6400489	http://dx.doi.org/10.1109/VAST.2012.6400489	53       	62      	C        	Ever improving computing power and technological advances are greatly augmenting data collection and scientific observation. This has directly contributed to increased data complexity and dimensionality, motivating research of exploration techniques for multidimensional data. Consequently, a recent influx of work dedicated to techniques and tools that aid in understanding multidimensional datasets can be observed in many research fields, including biology, engineering, physics and scientific computing. While the effectiveness of existing techniques to analyze the structure and relationships of multidimensional data varies greatly, few techniques provide flexible mechanisms to simultaneously visualize and actively explore high-dimensional spaces. In this paper, we present an inverse linear affine multidimensional projection, coined iLAMP, that enables a novel interactive exploration technique for multidimensional data. iLAMP operates in reverse to traditional projection methods by mapping low-dimensional information into a high-dimensional space. This allows users to extrapolate instances of a multidimensional dataset while exploring a projection of the data to the planar domain. We present experimental results that validate iLAMP, measuring the quality and coherence of the extrapolated data; as well as demonstrate the utility of iLAMP to hypothesize the unexplored regions of a high-dimensional space.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Elisa Portes dos Santos;Emilio Vital Brazil;Joel Daniels II;Paulo Joia;Luis Gustavo Nonato;Mario Costa Sousa                                                                                                              	Elisa Portes dos Santos Amorim;Emilio Vital Brazil;Joel Daniels;Paulo Joia;Luis Gustavo Nonato;Mario Costa Sousa                                                                                                          	University of Calgary;University of Calgary;NYU Polytechnic Institute;University of Sao Paulo;University of Sao Paulo;University of Calgary                                                                                                                                                                                                                                                                                                                                                                               	10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.116;10.1109/TVCG.2010.213;10.1109/TVCG.2009.140;10.1109/TVCG.2011.220;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1996.567787;10.1109/TVCG.2010.170;10.1109/TVCG.2007.70580;10.1109/TVCG.2010.207;10.1109/INFVIS.2002.1173161                                                             	                                                                                                                                                                                    	13                         	19                         	8                            	51
VAST      	2012	Visual pattern discovery using random projections                                                                               	10.1109/VAST.2012.6400490	http://dx.doi.org/10.1109/VAST.2012.6400490	43       	52      	C        	An essential element of exploratory data analysis is the use of revealing low-dimensional projections of high-dimensional data. Projection Pursuit has been an effective method for finding interesting low-dimensional projections of multidimensional spaces by optimizing a score function called a projection pursuit index. However, the technique is not scalable to high-dimensional spaces. Here, we introduce a novel method for discovering noteworthy views of high-dimensional data spaces by using binning and random projections. We define score functions, akin to projection pursuit indices, that characterize visual patterns of the low-dimensional projections that constitute feature subspaces. We also describe an analytic, multivariate visualization platform based on this algorithm that is scalable to extremely large problems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    	Anushka Anand;Leland Wilkinson;Tommy Dang                                                                                                                                                                                 	Anushka Anand;Leland Wilkinson;Tuan Nhon Dang                                                                                                                                                                             	Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, University of Illinois at Chicago                                                                                                                                                                                                                                                                                                                     	10.1109/VAST.2010.5652433;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/VAST.2009.5332629                                                                                                                                                                                                                                                                                                                                    	Random Projections, High-dimensional Data                                                                                                                                           	17                         	25                         	16                           	49
VAST      	2012	A correlative analysis process in a visual analytics environment                                                                	10.1109/VAST.2012.6400491	http://dx.doi.org/10.1109/VAST.2012.6400491	33       	42      	C        	Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson's product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	Abish Malik;Ross Maciejewski;Niklas Elmqvist;Yun Jang;David S. Ebert;Whitney Huang                                                                                                                                        	Abish Malik;Ross Maciejewski;Niklas Elmqvist;Yun Jang;David S. Ebert;Whitney Huang                                                                                                                                        	Purdue University, USA;Arizona State University, USA;Purdue University, USA;Sejong University, South Korea;Purdue University, USA;Purdue University, USA                                                                                                                                                                                                                                                                                                                                                                  	10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2010.193;10.1109/INFVIS.1999.801851;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195                                                                                                                                                                                                                                                                                            	Visual analytics, correlative analysis                                                                                                                                              	21                         	26                         	19                           	34
VAST      	2012	Inter-active learning of ad-hoc classifiers for video visual analytics                                                          	10.1109/VAST.2012.6400492	http://dx.doi.org/10.1109/VAST.2012.6400492	23       	32      	C        	Learning of classifiers to be used as filters within the analytical reasoning process leads to new and aggravates existing challenges. Such classifiers are typically trained ad-hoc, with tight time constraints that affect the amount and the quality of annotation data and, thus, also the users' trust in the classifier trained. We approach the challenges of ad-hoc training by inter-active learning, which extends active learning by integrating human experts' background knowledge to greater extent. In contrast to active learning, not only does inter-active learning include the users' expertise by posing queries of data instances for labeling, but it also supports the users in comprehending the classifier model by visualization. Besides the annotation of manually or automatically selected data instances, users are empowered to directly adjust complex classifier models. Therefore, our model visualization facilitates the detection and correction of inconsistencies between the classifier model trained by examples and the user's mental model of the class definition. Visual feedback of the training process helps the users assess the performance of the classifier and, thus, build up trust in the filter created. We demonstrate the capabilities of inter-active learning in the domain of video visual analytics and compare its performance with the results of random sampling and uncertainty sampling of training sets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Benjamin Höferlin;Rudolf Netzel;Markus Höferlin;Daniel Weiskopf;Gunther Heidemann                                                                                                                                         	Benjamin Höferlin;Rudolf Netzel;Markus Höferlin;Daniel Weiskopf;Gunther Heidemann                                                                                                                                         	Institute of Cognitive Science, University of Osnabrück;Visualization Research Center (VISUS), University of Stuttgart;Visualization Research Center (VISUS), University of Stuttgart;Visualization Research Center (VISUS), University of Stuttgart;Institute of Cognitive Science, University of Osnabrück                                                                                                                                                                                                              	10.1109/VAST.2010.5652398;10.1109/TVCG.2012.277                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	                                                                                                                                                                                    	22                         	33                         	14                           	43
VAST      	2012	An adaptive parameter space-filling algorithm for highly interactive cluster exploration                                        	10.1109/VAST.2012.6400493	http://dx.doi.org/10.1109/VAST.2012.6400493	13       	22      	C        	For a user to perceive continuous interactive response time in a visualization tool, the rule of thumb is that it must process, deliver, and display rendered results for any given interaction in under 100 milliseconds. In many visualization systems, successive interactions trigger independent queries and caching of results. Consequently, computationally expensive queries like multidimensional clustering cannot keep up with rapid sequences of interactions, precluding visual benefits such as motion parallax. In this paper, we describe a heuristic prefetching technique to improve the interactive response time of KMeans clustering in dynamic query visualizations of multidimensional data. We address the tradeoff between high interaction and intense query computation by observing how related interactions on overlapping data subsets produce similar clustering results, and characterizing these similarities within a parameter space of interaction. We focus on the two-dimensional parameter space defined by the minimum and maximum values of a time range manipulated by dragging and stretching a one-dimensional filtering lens over a plot of time series data. Using calculation of nearest neighbors of interaction points in parameter space, we reuse partial query results from prior interaction sequences to calculate both an immediate best-effort clustering result and to schedule calculation of an exact result. The method adapts to user interaction patterns in the parameter space by reprioritizing the interaction neighbors of visited points in the parameter space. A performance study on Mesonet meteorological data demonstrates that the method is a significant improvement over the baseline scheme in which interaction triggers on-demand, exact-range clustering with LRU caching. We also present initial evidence that approximate, temporary clustering results are sufficiently accurate (compared to exact results) to convey useful cluster structure during rapid and protracted interaction.                                   	Zafar Ahmed;Chris Weaver                                                                                                                                                                                                  	Zafar Ahmed;Chris Weaver                                                                                                                                                                                                  	School of Computer Science and Center for Spatial Analysis The University of Oklahoma;School of Computer Science and Center for Spatial Analysis The University of Oklahoma                                                                                                                                                                                                                                                                                                                                               	10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12;10.1109/VAST.2009.5332629;10.1109/VAST.2008.4677357;10.1109/TVCG.2011.188;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VAST.2007.4388999                                                                                                                                                                                                                                                                                                               	                                                                                                                                                                                    	5                          	7                          	4                            	31
VAST      	2012	Visual cluster exploration of web clickstream data                                                                              	10.1109/VAST.2012.6400494	http://dx.doi.org/10.1109/VAST.2012.6400494	3        	12      	C        	Web clickstream data are routinely collected to study how users browse the web or use a service. It is clear that the ability to recognize and summarize user behavior patterns from such data is valuable to e-commerce companies. In this paper, we introduce a visual analytics system to explore the various user behavior patterns reflected by distinct clickstream clusters. In a practical analysis scenario, the system first presents an overview of clickstream clusters using a Self-Organizing Map with Markov chain models. Then the analyst can interactively explore the clusters through an intuitive user interface. He can either obtain summarization of a selected group of data or further refine the clustering result. We evaluated our system using two different datasets from eBay. Analysts who were working on the same data have confirmed the system's effectiveness in extracting user behavior patterns from complex datasets and enhancing their ability to reason.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             	Jishang Wei;Zeqian Shen;Neel Sundaresan;Kwan-Liu Ma                                                                                                                                                                       	Jishang Wei;Zeqian Shen;Neel Sundaresan;Kwan-Liu Ma                                                                                                                                                                       	University of California, Davis;eBay Research Labs;eBay Research Labs;University of California, Davis                                                                                                                                                                                                                                                                                                                                                                                                                     	10.1109/INFVIS.2005.1532145;10.1109/VAST.2007.4389008;10.1109/VAST.2011.6102462;10.1109/VISUAL.1991.175815                                                                                                                                                                                                                                                                                                                                                                                                             	                                                                                                                                                                                    	44                         	56                         	33                           	28
VAST      	2012	LensingWikipedia: Parsing text for the interactive visualization of human history                                               	10.1109/VAST.2012.6400530	http://dx.doi.org/10.1109/VAST.2012.6400530	247      	248     	M        	Extracting information from text is challenging. Most current practices treat text as a bag of words or word clusters, ignoring valuable linguistic information. Leveraging this linguistic information, we propose a novel approach to visualize textual information. The novelty lies in using state-of-the-art Natural Language Processing (NLP) tools to automatically annotate text which provides a basis for new and powerful interactive visualizations. Using NLP tools, we built a web-based interactive visual browser for human history articles from Wikipedia.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Ravikiran Vadlapudi;Maryam Siahbani;Anoop Sarkar;John Dill                                                                                                                                                                	Ravikiran Vadlapudi;Maryam Siahbani;Anoop Sarkar;John Dill                                                                                                                                                                	Simon Fraser University;Simon Fraser University;Simon Fraser University;Simon Fraser University                                                                                                                                                                                                                                                                                                                                                                                                                           	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	1                          	1                          	1                            	4
VAST      	2012	VDQAM: A toolkit for database quality evaluation based on visual morphology                                                     	10.1109/VAST.2012.6400531	http://dx.doi.org/10.1109/VAST.2012.6400531	245      	246     	M        	Data quality evaluation is one of the most critical steps during the data mining processes. Data with poor quality often leads to poor performance in data mining, low efficiency in data analysis, wrong decision which bring great economic loss to users and organizations further. Although many researches have been carried out from various aspects of the extracting, transforming, and loading processes in data mining, most researches pay more attention to analysis automation than to data quality evaluation. To address the data quality evaluation issues, we propose an approach to combine human beings' powerful cognitive abilities in data quality evaluation with the high efficiency ability of computer, and develop a visual analysis method for data quality evaluation based on visual morphology.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    	Dongxing Teng;Haiyan Yang;CuiXia Ma;Hongan Wang                                                                                                                                                                           	Dongxing Teng;Haiyan Yang;Cuixia Ma;Hongan Wang                                                                                                                                                                           	Institute of Software, Chinese Academy of Sciences, Beijing, China;Institute of Software, Chinese Academy of Sciences, Beijing, China;Institute of Software, Chinese Academy of Sciences, Beijing, China;Institute of Software, Chinese Academy of Sciences, Beijing, China                                                                                                                                                                                                                                               	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	0                          	0                          	0                            	7
VAST      	2012	A case study: Tracking and visualizing the evolution of dark matter halos and groups of satellite halos in cosmology simulations	10.1109/VAST.2012.6400532	http://dx.doi.org/10.1109/VAST.2012.6400532	243      	244     	M        	In this poster, we track the evolution of cosmic structures and higher level host structures in cosmological simulation as they interact with each other. The structures found in these simulations are made up of groups of dark matter tracer particles called satellite halos and groups of satellite halos called host halos. We implement a multilevel tracking model to track dark matter tracer particles, satellite halos and host halos to understand their behaviour and show how the different structures are formed over time. We also represent the evolution of halos in the form of merger trees for detailed analysis by cosmologists.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Jay Takle;Deborah Silver;Katrin Heitmann                                                                                                                                                                                  	Jay Takle;Deborah Silver;Katrin Heitmann                                                                                                                                                                                  	Department of Electrical & Computer Engineering, Rutgers University;Department of Electrical & Computer Engineering, Rutgers University;High Energy Physics Division, Argonne National Laboratory                                                                                                                                                                                                                                                                                                                         	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	5                          	5                          	5                            	7
VAST      	2012	Infographics at the Congressional Budget Office                                                                                 	10.1109/VAST.2012.6400533	http://dx.doi.org/10.1109/VAST.2012.6400533	241      	242     	M        	The Congressional Budget Office (CBO) is an agency of the federal government with about 240 employees that provides the U.S. Congress with timely, nonpartisan analysis of important budgetary and economic issues. Recently, CBO began producing static infographics to present its headline stories and to provide information to the Congress in different ways.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Jonathan A. Schwabish                                                                                                                                                                                                     	Jonathan A. Schwabish                                                                                                                                                                                                     	Congressional Budget Office                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	0                          	0                          	0                            	2
VAST      	2012	Visual exploration of local interest points in sets of time series                                                              	10.1109/VAST.2012.6400534	http://dx.doi.org/10.1109/VAST.2012.6400534	239      	240     	M        	Visual analysis of time series data is an important, yet challenging task with many application examples in fields such as financial or news stream data analysis. Many visual time series analysis approaches consider a global perspective on the time series. Fewer approaches consider visual analysis of local patterns in time series, and often rely on interactive specification of the local area of interest. We present initial results of an approach that is based on automatic detection of local interest points. We follow an overview-first approach to find useful parameters for the interest point detection, and details-on-demand to relate the found patterns. We present initial results and detail possible extensions of the approach.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Tobias Schreck;Lyubka Sharalieva;Franz Wanner;Jürgen Bernard;Tobias Ruppert;Tatiana von Landesberger;Benjamin Bustos                                                                                                      	Tobias Schreck;Lyubka Sharalieva;Franz Wanner;Jürgen Bernard;Tobias Ruppert;Tatiana von Landesberger;Benjamin Bustos                                                                                                      	University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;Fraunhofer IGD Darmstadt, Germany;Fraunhofer IGD Darmstadt, Germany;TU Darmstadt Germany;Universidad de Chile Santiago de Chile                                                                                                                                                                                                                                                                                           	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	5                          	5                          	2                            	8
VAST      	2012	Priming Locus of Control to affect performance                                                                                  	10.1109/VAST.2012.6400535	http://dx.doi.org/10.1109/VAST.2012.6400535	237      	238     	M        	Recent research suggests that the personality trait Locus of Control (LOC) can be a reliable predictor of performance when learning a new visualization tool. While these results are compelling and have direct implications to visualization design, the relationship between a user's LOC measure and their performance is not well understood. We hypothesize that there is a dependent relationship between LOC and performance; specifically, a person's orientation on the LOC scale directly influences their performance when learning new visualizations. To test this hypothesis, we conduct an experiment with 300 subjects using Amazon's Mechanical Turk. We adapt techniques from personality psychology to manipulate a user's LOC so that users are either primed to be more internally or externally oriented on the LOC scale. Replicating previous studies investigating the effect of LOC on performance, we measure users' speed and accuracy as they use visualizations with varying visual metaphors. Our findings demonstrate that changing a user's LOC impacts their performance. We find that a change in users' LOC results in performance changes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  	Alvitta Ottley;R. Jordan Crouser;Caroline Ziemkiewicz;Remco Chang                                                                                                                                                         	Alvitta Ottley;R. Jordan Crouser;Caroline Ziemkiewicz;Remco Chang                                                                                                                                                         	Tufts University;Tufts University;Brown University;Tufts University                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	0                          	0                          	0                            	4
VAST      	2012	The spatiotemporal multivariate hypercube for discovery of patterns in event data                                               	10.1109/VAST.2012.6400536	http://dx.doi.org/10.1109/VAST.2012.6400536	235      	236     	M        	Event data can hold valuable decision making information, yet detecting interesting patterns in this type of data is not an easy task because the data is usually rich and contains spatial, temporal as well as multivariate dimensions. Research into visual analytics tools to support the discovery of patterns in event data often focuses on the spatiotemporal or spatiomultivariate dimension of the data only. Few research efforts focus on all three dimensions in one framework. An integral view on all three dimensions is, however, required to unlock the full potential of event datasets. In this poster, we present an event visualization, transition, and interaction framework that enables an integral view on all dimensions of spatiotemporal multivariate event data. The framework is built around the notion that the event data space can be considered a spatiotemporal multivariate hypercube. Results of a case study we performed suggest that a visual analytics tool based on the proposed framework is indeed capable to support users in the discovery of multidimensional spatiotemporal multivariate patterns in event data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Fred Olislagers;Marcel Worring                                                                                                                                                                                            	Fred Olislagers;Marcel Worring                                                                                                                                                                                            	Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands;Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands                                                                                                                                                                                                                                                                                                                                                                   	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	1                          	1                          	1                            	3
VAST      	2012	A generic model for the integration of interactive visualization and statistical computing using R                              	10.1109/VAST.2012.6400537	http://dx.doi.org/10.1109/VAST.2012.6400537	233      	234     	M        	This poster describes general concepts of integrating the statistical computation package R into a coordinated multiple views framework. The integration is based on a cyclic analysis workflow. In this model, interactive selections are a key aspect to trigger and control computations in R. Dynamic updates of data columns are a generic mechanism to transfer computational results back to the interactive visualization. Further aspects include the integration of the R console and an R object browser as views in our system. We illustrate our approach by means of an interactive modeling process.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Johannes Kehrer;Roland N. Boubela;Peter Filzmoser;Harald Piringer                                                                                                                                                         	Johannes Kehrer;Roland N. Boubela;Peter Filzmoser;Harald Piringer                                                                                                                                                         	VRVis Research Center, Vienna, Austria;Dept. of Statistics and Probability Theory, Vienna University of Technology, Austria;Dept. of Statistics and Probability Theory, Vienna University of Technology, Austria;VRVis Research Center, Vienna, Austria                                                                                                                                                                                                                                                                   	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	6                          	7                          	6                            	7
VAST      	2012	Using visual analytics to detect problems in datasets collected from photo-sharing services                                     	10.1109/VAST.2012.6400538	http://dx.doi.org/10.1109/VAST.2012.6400538	231      	232     	M        	Datasets that are collected for research often contain millions of records and may carry hidden pitfalls that are hard to detect. This work demonstrates how visual analytics can be used for identifying problems in the spatial distribution of crawled photographic data in different datasets: Picasa Web Albums, Panoramio, Flickr and Geograph, chosen to be potential data sources for ongoing doctoral research. This poster summary describes a number of problems found in the datasets using visual analytics and suggests that greater attention should be paid to assessing the quality of data gathered from user-generated photographic content. This work is the first part of a three-year PhD project aimed at producing a pedestrian-routing system that can suggest attractive pathways extracted from user-generated photographic content.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   	Alexander Kachkaev;Jo Wood                                                                                                                                                                                                	Alexander Kachkaev;Jo Wood                                                                                                                                                                                                	giCentre, City University London;giCentre, City University London                                                                                                                                                                                                                                                                                                                                                                                                                                                         	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	0                          	0                          	0                            	7
VAST      	2012	Visualizing flows of images in social media                                                                                     	10.1109/VAST.2012.6400539	http://dx.doi.org/10.1109/VAST.2012.6400539	229      	230     	M        	Mass and social media provide flows of images for real world events. It is sometimes difficult to represent realities and impressions of events using only text. However, even a single photo might remind us complex events. Along with events in the real world, there are representative images, such as design of products and commercial pictures. We can therefore recognize changes in trends of people's ideas, experiences, and interests through observing the flows of such representative images. This paper presents a novel 3D visualization system to explore temporal changes in trends using images associating with different topics, called Image Bricks. We show case studies using images extracted from our six-year blog archive. We first extract clusters of images as topics related to given keywords. We then visualize them on multiple timelines in a 3D space. Users can visually read stories of topics through exploring visualized images.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      	Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa                                                                                                                                                            	Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa                                                                                                                                                            	Institute of Industrial Science, University of Tokyo;Institute of Industrial Science, University of Tokyo;Rakuten, Inc.;Institute of Industrial Science, University of Tokyo                                                                                                                                                                                                                                                                                                                                              	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	1                          	1                          	1                            	6
VAST      	2012	Exploring the impact of emotion on visual judgement                                                                             	10.1109/VAST.2012.6400540	http://dx.doi.org/10.1109/VAST.2012.6400540	227      	228     	M        	Existing research suggests that individual personality differences can influence performance with visualizations. In addition to stable traits such as locus of control, research in psychology has found that temporary changes in affect (emotion) can significantly impact individual performance on cognitive tasks. We examine the relationship between fundamental visual judgement tasks and affect through a crowdsourced user study that combines affective-priming techniques from psychology with longstanding graphical perception experiments. Our results suggest that affective-priming can significantly influence accuracy in visual judgements, and that some chart types may be more affected than others.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	Lane Harrison;Remco Chang;Aidong Lu                                                                                                                                                                                       	Lane Harrison;Remco Chang;Aidong Lu                                                                                                                                                                                       	UNC-Charlotte;Tufts University;UNC-Charlotte                                                                                                                                                                                                                                                                                                                                                                                                                                                                              	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	5                          	5                          	1                            	8
VAST      	2012	Exploring cyber physical data streams using Radial Pixel Visualizations                                                         	10.1109/VAST.2012.6400541	http://dx.doi.org/10.1109/VAST.2012.6400541	225      	226     	M        	Cyber physical systems (CPS), such as smart buildings and data centers, are richly instrumented systems composed of tightly coupled computational and physical elements that generate large amounts of data. To explore CPS data and obtain actionable insights, we construct a Radial Pixel Visualization (RPV) system, which uses multiple concentric rings to show the data in a compact circular layout of small polygons (pixel cells), each of which represents an individual data value. RPV provides an effective visual representation of locality and periodicity of the high volume, multivariate data streams, and seamlessly combines them with the results of an automated analysis. In the outermost ring the results of correlation analysis and peak point detection are highlighted. Our explorations demonstrates how RPV can help administrators to identify periodic thermal hot spots, understand data center energy consumption, and optimize IT workload.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 	Ming C. Hao;Manish Marwah;Sebastian Mittelstädt;Halldór Janetzko;Daniel A. Keim;Umeshwar Dayal;Cullen Bash;Carlos J. Felix;Chandrakant D. Patel;Meichun Hsu;Yuan Chen 0001                                                	M. Hao;Y. Chen;M. Marwah;S. Mittelstadt;H. Janetzko;D. Keim;U. Dayal;C. Bash;C. Felix;C. Patel;M. Hsu                                                                                                                     	Hewlett-Packard Laboratories, Palo Alto, CA;Hewlett-Packard Laboratories, Palo Alto, CA;Hewlett-Packard Laboratories, Palo Alto, CA;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;Hewlett-Packard Laboratories, Palo Alto, CA;Hewlett-Packard Laboratories, Palo Alto, CA;Hewlett-Packard Laboratories, Palo Alto, CA;Hewlett-Packard Laboratories, Palo Alto, CA;Hewlett-Packard Laboratories, Palo Alto, CA                                                           	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	1                          	1                          	1                            	2
VAST      	2012	Incorporating GOMS analysis into the design of an EEG data visual analysis tool                                                 	10.1109/VAST.2012.6400542	http://dx.doi.org/10.1109/VAST.2012.6400542	223      	224     	M        	In this paper, we present a case study where we incorporate GOMS (Goals, Operators, Methods, and Selectors) [2] task analysis into the design process of a visual analysis tool. We performed GOMS analysis on an Electroencephalography (EEG) analyst's current data analysis strategy to identify important user tasks and unnecessary user actions in his current workflow. We then designed an EEG data visual analysis tool based on the GOMS analysis result. Evaluation results show that the tool we have developed, EEGVis, allows the user to analyze EEG data with reduced subjective cognitive load, faster speed and increased confidence in the analysis quality. The positive evaluation results suggest that our design process demonstrates an effective application of GOMS analysis to discover opportunities for designing better tools to support the user's visual analysis process.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	Hua Guo;Diem Tran;David H. Laidlaw                                                                                                                                                                                        	Hua Guo;Diem Tran;David H. Laidlaw                                                                                                                                                                                        	Department of Computer Science Brown University;Department of Computer Science Brown University;Department of Computer Science Brown University                                                                                                                                                                                                                                                                                                                                                                           	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	2                          	2                          	1                            	7
VAST      	2012	Using translational science in visual analytics                                                                                 	10.1109/VAST.2012.6400543	http://dx.doi.org/10.1109/VAST.2012.6400543	221      	222     	M        	We introduce translational science, a research discipline from medicine, and show how adapting it for visual analytics can improve the design and evaluation of visual analytics interfaces. Translational science “translates” knowledge from the lab to the real-world to “ground truth” by incorporating a 3 phase program of research. Phase 1 &amp; 2 include protocols for research in the lab and field and Phase 3 focuses on dissemination and documentation. We discuss these phases and how they may be applied to visual analytics research.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          	Tera Marie Green;Brian D. Fisher                                                                                                                                                                                          	Tera Marie Green;Brian Fisher                                                                                                                                                                                             	School of Interactive Arts + Science, Simon Fraser University;School of Interactive Arts + Science, Simon Fraser University                                                                                                                                                                                                                                                                                                                                                                                               	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	2                          	2                          	1                            	7
VAST      	2012	Optimizing an SPT-tree for visual analytics                                                                                     	10.1109/VAST.2012.6400544	http://dx.doi.org/10.1109/VAST.2012.6400544	219      	220     	M        	Despite the extensive work done in the scientific visualization community on the creation and optimization of spatial data structures, there has been little adaptation of these structures in visual analytics and information visualization. In this work we present how we modify a space-partioning time (SPT) tree - a structure normally used in direct-volume rendering - for geospatial-temporal visualizations. We also present optimization techniques to improve the traversal speed of our structure through locational codes and bitwise comparisons. Finally, we present the results of an experiment that quantitatively evaluates our modified SPT tree with and without our optimizations. Our results indicate that retrieval was nearly three times faster when using our optimizations, and are consistent across multiple trials. Our finding could have implications for performance in using our modified SPT tree in large-scale geospatial temporal visual analytics software.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           	Connor Gramazio;Remco Chang                                                                                                                                                                                               	Connor Gramazio;Remco Chang                                                                                                                                                                                               	Department of Computer Science Brown University &amp; Tufts University;Department of Computer Science, Tufts University                                                                                                                                                                                                                                                                                                                                                                                                   	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	1                          	1                          	0                            	6
VAST      	2012	Visualising variations in household energy consumption                                                                          	10.1109/VAST.2012.6400545	http://dx.doi.org/10.1109/VAST.2012.6400545	217      	218     	M        	There is limited understanding of the relationship between neighbourhoods, demographic characteristics and domestic energy consumption habits. We report upon research that combines datasets relating to household energy use with geodemographics to enable better understanding of UK energy user types. A novel interactive interface is planned to evaluate the performance of specifically created energy-based data classifications. The research aims to help local governments and the energy industry in targeting households and populations for new energy saving schemes and in improving efforts to promote sustainable energy consumption. The new classifications may also stimulate consumption awareness amongst domestic users. This poster reports on initial visual findings and describes the research methodology, data sources and future visualisation requirements.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	Sarah Goodwin;Jason Dykes                                                                                                                                                                                                 	Sarah Goodwin;Jason Dykes                                                                                                                                                                                                 	giCentre, City University London, UK;giCentre, City University London, UK                                                                                                                                                                                                                                                                                                                                                                                                                                                 	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	6                          	6                          	2                            	10
VAST      	2012	Time-oriented visualization and anticipation                                                                                    	10.1109/VAST.2012.6400546	http://dx.doi.org/10.1109/VAST.2012.6400546	215      	216     	M        	Temporal awareness is pivotal to successful real-time dynamic decision making in a wide range of command and control situations; particularly in safety-critical environments. However, little explicit support for operators' temporal awareness is provided by decision support systems (DSS) for time-critical decisions. In the context of functional simulations of naval anti-air warfare and emergency response management, the present study compares operator support provided by two display formats. In both environments, we contrast a baseline condition to a condition in which a temporal display was integrated to the original interface to support operators' temporal awareness. We also wish to establish whether the implementation of time-based DSSs may also come with drawbacks on cognitive functioning and performance.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               	Cindy Chamberland;François Vachon;Jean-François Gagnon;Simon P. Banbury;Sébastien Tremblay                                                                                                                                	Cindy Chamberland;François Vachon;Jean-François Gagnon;Simon Banbury;Sébastien Tremblay                                                                                                                                   	Université Laval;Université Laval;Université Laval;Looking Glass HF, Inc.;Université Laval                                                                                                                                                                                                                                                                                                                                                                                                                                	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	0                          	0                          	0                            	8
VAST      	2012	Augmenting visual representation of affectively charged information using sound graphs                                          	10.1109/VAST.2012.6400547	http://dx.doi.org/10.1109/VAST.2012.6400547	213      	214     	M        	Within the Visual Analytics research agenda there is an interest on studying the applicability of multimodal information representation and interaction techniques for the analytical reasoning process. The present study summarizes a pilot experiment conducted to understand the effects of augmenting visualizations of affectively-charged information using auditory graphs. We designed an audiovisual representation of social comments made to different news posted on a popular website, and their affective dimension using a sentiment analysis tool for short texts. Participants of the study were asked to create an assessment of the affective valence trend (positive or negative) of the news articles using for it, the visualizations and sonifications. The conditions were tested looking for speed/accuracy trade off comparing the visual representation with an audiovisual one. We discuss our preliminary findings regarding the design of augmented information-representation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    	Nadya A. Calderón;Bernhard E. Riecke;Brian D. Fisher                                                                                                                                                                      	Nadya A. Calderon;Bernhard E. Riecke;Brian Fisher                                                                                                                                                                         	School of Interactive Arts and Technology Simon Fraser University;School of Interactive Arts and Technology Simon Fraser University;School of Interactive Arts and Technology Simon Fraser University                                                                                                                                                                                                                                                                                                                     	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	0                          	0                          	0                            	9
VAST      	2012	Feature-similarity visualization of MRI cortical surface data                                                                   	10.1109/VAST.2012.6400548	http://dx.doi.org/10.1109/VAST.2012.6400548	211      	212     	M        	We present an analytics-based framework for simultaneous visualization of large surface data collections arising in clinical neuroimaging studies. Termed Informatics Visualization for Neuroimaging (INVIZIAN), this framework allows the visualization of both cortical surfaces characteristics and feature relatedness in unison. It also uses dimension reduction methods to derive new coordinate systems using a Jensen-Shannon divergence metric for positioning cortical surfaces in a metric space such that the proximity in location is proportional to neuroanatomical similarity. Feature data such as thickness and volume are colored on the cortical surfaces and used to display both subject-specific feature values and global trends within the population. Additionally, a query-based framework allows the neuroscience researcher to investigate probable correlations between neuroanatomical and subject patient attribute values such as age and diagnosis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            	Ian Bowman;Shantanu H. Joshi;Vaughan Greer;John D. Van Horn                                                                                                                                                               	Ian Bowman;Shantanu H. Joshi;Vaughan Greer;John Darrell Van Horn                                                                                                                                                          	Laboratory of Neuro Imaging, UCLA School of Medicine, Los Angeles 90095;Laboratory of Neuro Imaging, UCLA School of Medicine, Los Angeles 90095;Laboratory of Neuro Imaging, UCLA School of Medicine, Los Angeles 90095;Laboratory of Neuro Imaging, UCLA School of Medicine, Los Angeles 90095                                                                                                                                                                                                                           	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	1                          	1                          	1                            	2
VAST      	2012	Matrix-based visual correlation analysis on large timeseries data                                                               	10.1109/VAST.2012.6400549	http://dx.doi.org/10.1109/VAST.2012.6400549	209      	210     	M        	In recent years, the quantity of time series data generated in a wide variety of domains grown consistently. Thus, it is difficult for analysts to process and understand this overwhelming amount of data. In the specific case of time series data another problem arises: time series can be highly interrelated. This problem becomes even more challenging when a set of parameters influences the progression of a time series. However, while most visual analysis techniques support the analysis of short time periods, e.g. one day or one week, they fail to visualize large-scale time series, ranging over one year or more. In our approach we present a time series matrix visualization that tackles this problem. Its primary advantages are that it scales to a large number of time series with different start and end points and allows for the visual comparison / correlation analysis of a set of influencing factors. To evaluate our approach, we applied our technique to a real-world data set, showing the impact of local weather conditions on the efficiency of photovoltaic power plants.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	Michael Behrisch 0001;James Davey;Tobias Schreck;Daniel A. Keim;Jörn Kohlhammer                                                                                                                                           	Michael Behrisch;James Davey;Tobias Schreck;Daniel Keim;Jörn Kohlhammer                                                                                                                                                   	Universität Konstanz;Fraunhofer IGD;Universität Konstanz;Universität Konstanz;Fraunhofer IGD                                                                                                                                                                                                                                                                                                                                                                                                                              	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	1                          	3                          	3                            	7
VAST      	2012	A visual analytics approach to understanding cycling behaviour                                                                  	10.1109/VAST.2012.6400550	http://dx.doi.org/10.1109/VAST.2012.6400550	207      	208     	M        	Existing research into cycling behaviours has either relied on detailed ethnographic studies or larger public attitude surveys [1] [9]. Instead, following recent contributions from information visualization [13] and data mining [5] [7], this design study uses visual analytics techniques to identify, describe and explain cycling behaviours within a large and attribute rich transactional dataset. Using data from London's bike share scheme&lt;sup&gt;1&lt;/sup&gt;, customer level classifications will be created, which consider the regularity of scheme use, journey length and travel times. Monitoring customer usage over time, user classifications will attend to the dynamics of cycling behaviour, asking substantive questions about how behaviours change under varying conditions. The 3-year PhD project will contribute to academic and strategic discussions around sustainable travel policy. A programme of research is outlined, along with an early visual analytics prototype for rapidly querying customer journeys.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         	Roger Beecham;Jo Wood;Audrey Bowerman                                                                                                                                                                                     	Roger Beecham;Jo Wood;Audrey Bowerman                                                                                                                                                                                     	City University London;City University London;Transport for London                                                                                                                                                                                                                                                                                                                                                                                                                                                        	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       	                                                                                                                                                                                    	3                          	3                          	1                            	13
VAST      	2012	Information retrieval failure analysis: Visual analytics as a support for interactive "what-if" investigation	10.1109/VAST.2012.6400551	http://dx.doi.org/10.1109/VAST.2012.6400551	204	206	M	This poster provides an analytical model for examining performances of IR systems, based on the discounted cumulative gain family of metrics, and visualization for interacting and exploring the performances of the system under examination. Moreover, we propose machine learning approach to learn the ranking model of the examined system in order to be able to conduct a “what-if” analysis and visually explore what can happen if you adopt a given solution before having to actually implement it.	Marco Angelini;Nicola Ferro 0001;Guido Granato;Giuseppe Santucci;Gianmaria Silvello	Marco Angelini;Nicola Ferro;Guido Granato;Guiseppe Santucci;Gianmaria Silvello	Sapienza University of Roma, Italy;University of Padua, Italy;Sapienza University of Roma, Italy;Sapienza University of Roma, Italy;University of Padua, Italy			2	2	2	3
VAST	2012	Watch this: A taxonomy for dynamic data visualization	10.1109/VAST.2012.6400552	http://dx.doi.org/10.1109/VAST.2012.6400552	193	202	C	Visualizations embody design choices about data access, data transformation, visual representation, and interaction. To interpret a static visualization, a person must identify the correspondences between the visual representation and the underlying data. These correspondences become moving targets when a visualization is dynamic. Dynamics may be introduced in a visualization at any point in the analysis and visualization process. For example, the data itself may be streaming, shifting subsets may be selected, visual representations may be animated, and interaction may modify presentation. In this paper, we focus on the impact of dynamic data. We present a taxonomy and conceptual framework for understanding how data changes influence the interpretability of visual representations. Visualization techniques are organized into categories at various levels of abstraction. The salient characteristics of each category and task suitability are discussed through examples from the scientific literature and popular practices. Examining the implications of dynamically updating visualizations warrants attention because it directly impacts the interpretability (and thus utility) of visualizations. The taxonomy presented provides a reference point for further exploration of dynamic data visualization techniques.	Joseph A. Cottam;Andrew Lumsdaine;Chris Weaver	Joseph A. Cottam;Andrew Lumsdaine;Chris Weaver	Indiana University;Indiana University;University of Oklahoma	10.1109/TVCG.2009.123;10.1109/INFVIS.2004.65;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.125;10.1109/INFVIS.2000.885092	Dynamic Data, Interpretation	16	16	10	49	
VAST	2012	Visual analytics methods for categoric spatio-temporal data	10.1109/VAST.2012.6400553	http://dx.doi.org/10.1109/VAST.2012.6400553	183	192	C	We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained.	Tatiana von Landesberger;Sebastian Bremm;Natalia V. Andrienko;Gennady L. Andrienko;Maria Tekusova	T. von Landesberger;Sebastian Bremm;Natalia Andrienko;Gennady Andrienko;Mária Tekušová	TU Darmstadt Darmstadt, Germany;TU Darmstadt Darmstadt, Germany;Fraunhofer IAIS Bonn, Germany;Fraunhofer IAIS Bonn, Germany;SHMU Bratislava, Slovakia	10.1109/TVCG.2011.174;10.1109/TVCG.2009.117;10.1109/TVCG.2009.181;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.138;10.1109/VAST.2010.5652530;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2001.963281;10.1109/TVCG.2008.165;10.1109/TVCG.2009.153		33	37	22	43	
VAST	2012	Visual analytics for the big data era---A comparative review of state-of-the-art commercial systems	10.1109/VAST.2012.6400554	http://dx.doi.org/10.1109/VAST.2012.6400554	173	182	C	Visual analytics (VA) system development started in academic research institutions where novel visualization techniques and open source toolkits were developed. Simultaneously, small software companies, sometimes spin-offs from academic research institutions, built solutions for specific application domains. In recent years we observed the following trend: some small VA companies grew exponentially; at the same time some big software vendors such as IBM and SAP started to acquire successful VA companies and integrated the acquired VA components into their existing frameworks. Generally the application domains of VA systems have broadened substantially. This phenomenon is driven by the generation of more and more data of high volume and complexity, which leads to an increasing demand for VA solutions from many application domains. In this paper we survey a selection of state-of-the-art commercial VA frameworks, complementary to an existing survey on open source VA tools. From the survey results we identify several improvement opportunities as future research directions.	Leishi Zhang;Andreas Stoffel;Michael Behrisch 0001;Sebastian Mittelstädt;Tobias Schreck;René Pompl;Stefan Weber 0004;Holger Last;Daniel A. Keim	Leishi Zhang;Andreas Stoffel;Michael Behrisch;Sebastian Mittelstadt;Tobias Schreck;René Pompl;Stefan Weber;Holger Last;Daniel Keim	University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;Siemens AG;Siemens AG;Siemens AG;University of Konstanz, Germany	10.1109/INFVIS.2004.12;10.1109/INFVIS.2004.64;10.1109/INFVIS.2000.885098		60	76	51	29	
VAST	2012	Smart super views---A knowledge-assisted interface for medical visualization	10.1109/VAST.2012.6400555	http://dx.doi.org/10.1109/VAST.2012.6400555	163	172	C	Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.	Gabriel Mistelbauer;Hamed Bouzari;Rüdiger Schernthaner;Ivan Baclija;Arnold Köchl;Stefan Bruckner;Milos Srámek;M. Eduard Gröller	Gabriel Mistelbauer;Arnold Köchl;Rudiger Schernthaner;Ivan Baclija;Rüdiger Schernthaner;Stefan Bruckner;Milos Sramek;Meister Eduard Gröller	Vienna University of Technology, Austria;Kaiser-Franz-Josef Hospital Vienna, Austria;Austrian Academy of Sciences;Vienna University of Technology Austria;Medical University of Vienna, Austria;Austrian Academy of Sciences;Kaiser-Franz-Josef Hospital Vienna, Austria;Vienna University of Technology, Austria	10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2007.70576;10.1109/TVCG.2007.70591;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2011.183;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.148	Visualization, Fuzzy Logic, Interaction	4	5	4	40	
VAST	2012	AlVis: Situation awareness in the surveillance of road tunnels	10.1109/VAST.2012.6400556	http://dx.doi.org/10.1109/VAST.2012.6400556	153	162	C	In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios.	Harald Piringer;Matthias Buchetics;Rudolf Benedik	Harald Piringer;Matthias Buchetics;Rudolf Benedik	VRVis Research Center;VRVis Research Center;Kapsch TrafficCom AG	10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2005.1532134;10.1109/VAST.2011.6102456;10.1109/TVCG.2007.70544;10.1109/TVCG.2007.70521;10.1109/TVCG.2007.70621;10.1109/INFVIS.2004.27;10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.185;10.1109/VAST.2007.4388994;10.1109/VAST.2007.4388998;10.1109/VAST.2008.4677353		13	15	11	40	
VAST	2012	Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition	10.1109/VAST.2012.6400557	http://dx.doi.org/10.1109/VAST.2012.6400557	143	152	C	Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process.	Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl	Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl	Purdue University;University of Stuttgart;University of Stuttgart;Sejong University;Arizona State University;Purdue University;University of Stuttgart	10.1109/VAST.2011.6102456;10.1109/VAST.2011.6102461;10.1109/TVCG.2008.175		104	145	94	39	
VAST	2012	SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization	10.1109/VAST.2012.6400558	http://dx.doi.org/10.1109/VAST.2012.6400558	133	142	C	Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users' needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics.	Liang Gou;Xiaolong Zhang 0001;Airong Luo;Patricia F. Anderson	Liang Gou;Xiaolong Zhang;Airong Luo;Patricia F. Anderson	The Pennsylvania State University;The Pennsylvania State University;University of Michigan;University of Michigan	10.1109/INFVIS.1999.801853;10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532126;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.192;10.1109/VAST.2009.5333020;10.1109/VAST.2011.6102440;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.2;10.1109/TVCG.2008.137;10.1109/TVCG.2006.166;10.1109/TVCG.2006.160;10.1109/VAST.2008.4677365;10.1109/TVCG.2006.147;10.1109/VAST.2007.4389006	Social network, visualization, sensemaking, visual analytics, SocialNetSense	6	6	0	48	
VAST	2012	Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays	10.1109/VAST.2012.6400559	http://dx.doi.org/10.1109/VAST.2012.6400559	123	131	C	Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.	Christopher Andrews;Chris North	Christopher Andrews;Chris North	Virginia Tech;Virginia Tech	10.1109/TVCG.2008.121;10.1109/VAST.2008.4677362;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677358;10.1109/TVCG.2006.184;10.1109/VAST.2007.4388992;10.1109/VAST.2010.5652880;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878	Embodiment, distributed cognition, large and high-resolution display, sensemaking, space	30	37	26	52	
VAST	2012	The Deshredder: A visual analytic approach to reconstructing shredded documents	10.1109/VAST.2012.6400560	http://dx.doi.org/10.1109/VAST.2012.6400560	113	122	C	Reconstruction of shredded documents remains a significant challenge. Creating a better document reconstruction system enables not just recovery of information accidentally lost but also understanding our limitations against adversaries' attempts to gain access to information. Existing approaches to reconstructing shredded documents adopt either a predominantly manual (e.g., crowd-sourcing) or a near automatic approach. We describe Deshredder, a visual analytic approach that scales well and effectively incorporates user input to direct the reconstruction process. Deshredder represents shredded pieces as time series and uses nearest neighbor matching techniques that enable matching both the contours of shredded pieces as well as the content of shreds themselves. More importantly, Deshred-der's interface support visual analytics through user interaction with similarity matrices as well as higher level assembly through more complex stitching functions. We identify a functional task taxonomy leading to design considerations for constructing deshredding solutions, and describe how Deshredder applies to problems from the DARPA Shredder Challenge through expert evaluations.	Patrick Butler;Prithwish Chakraborty;Naren Ramakrishnan	Patrick Butler;Prithwish Chakraborty;Naren Ramakrishan	Department of Computer Science and Discovery Analytics Center, Virginia Tech, Blacksburg, VA 24061;Department of Computer Science and Discovery Analytics Center, Virginia Tech, Blacksburg, VA 24061;Department of Computer Science and Discovery Analytics Center, Virginia Tech, Blacksburg, VA 24061			15	18	15	37	
InfoVis	2013	A Deeper Understanding of Sequence in Narrative Visualization	10.1109/TVCG.2013.119	http://dx.doi.org/10.1109/TVCG.2013.119	2406	2415	J	Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.	Jessica Hullman;Steven Mark Drucker;Nathalie Henry Riche;Bongshin Lee;Danyel Fisher;Eytan Adar	Jessica Hullman;Steven Drucker;Nathalie Henry Riche;Bongshin Lee;Danyel Fisher;Eytan Adar	University of Michigan;Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research;University of Michigan	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/TVCG.2008.137;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70539;10.1109/INFVIS.2000.885086	Data storytelling, narrative visualization, narrative structure	39	58	42	37	
InfoVis	2013	A Design Space of Visualization Tasks	10.1109/TVCG.2013.120	http://dx.doi.org/10.1109/TVCG.2013.120	2366	2375	J	Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.	Hans-Jörg Schulz;Thomas Nocke;Magnus Heitzler;Heidrun Schumann	Hans-Jörg Schulz;Thomas Nocke;Magnus Heitzler;Heidrun Schumann	University of Rostock;Potsdam Institute for Climate Impact Research;Potsdam Institute for Climate Impact Research;University of Rostock	10.1109/INFVIS.1996.559213;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146372;10.1109/TVCG.2012.205;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/INFVIS.1996.559211;10.1109/INFVIS.2004.10;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2000.885093;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375	Task taxonomy, design space, climate impact research, visualization recommendation	68	81	69	64	
SciVis	2013	A Lightweight Tangible 3D Interface for Interactive Visualization of Thin fiber Structures	10.1109/TVCG.2013.121	http://dx.doi.org/10.1109/TVCG.2013.121	2802	2809	J	We present a prop-based, tangible interface for 3D interactive visualization of thin fiber structures. These data are commonly found in current bioimaging datasets, for example second-harmonic generation microscopy of collagen fibers in tissue. Our approach uses commodity visualization technologies such as a depth sensing camera and low-cost 3D display. Unlike most current uses of these emerging technologies in the games and graphics communities, we employ the depth sensing camera to create a fish-tank sterePoscopic virtual reality system at the scientist's desk that supports tracking of small-scale gestures with objects already found in the work space. We apply the new interface to the problem of interactive exploratory visualization of three-dimensional thin fiber data. A critical task for the visual analysis of these data is understanding patterns in fiber orientation throughout a volume.The interface enables a new, fluid style of data exploration and fiber orientation analysis by using props to provide needed passive-haptic feedback, making 3D interactions with these fiber structures more controlled. We also contribute a low-level algorithm for extracting fiber centerlines from volumetric imaging. The system was designed and evaluated with two biophotonic experts who currently use it in their lab. As compared to typical practice within their field, the new visualization system provides a more effective way to examine and understand the 3D bioimaging datasets they collect.	Bret Jackson;Tung Yuen Lau;David Schroeder;Kimani C. Toussaint;Daniel F. Keefe	Bret Jackson;Tung Yuen Lau;David Schroeder;Kimani C. Toussaint;Daniel F. Keefe	University of Minnesota;University of Illinois Urbana-Champaign;University of Minnesota;University of Illinois Urbana-Champaign;University of Minnesota	10.1109/TVCG.2009.138;10.1109/VISUAL.2005.1532846;10.1109/VISUAL.2002.1183753;10.1109/VISUAL.1997.663912	Scientific visualization, 3D interaction, tangible interaction, microscopy visualization	18	28	19	26	
InfoVis	2013	A Model for Structure-Based Comparison of Many Categories in Small-Multiple Displays	10.1109/TVCG.2013.122	http://dx.doi.org/10.1109/TVCG.2013.122	2287	2296	J	Many application domains deal with multi-variate data that consist of both categorical and numerical information. Small-multiple displays are a powerful concept for comparing such data by juxtaposition. For comparison by overlay or by explicit encoding of computed differences, however, a specification of references is necessary. In this paper, we present a formal model for defining semantically meaningful comparisons between many categories in a small-multiple display. Based on pivotized data that are hierarchically partitioned by the categories assigned to the x and y axis of the display, we propose two alternatives for structure-based comparison within this hierarchy. With an absolute reference specification, categories are compared to a fixed reference category. With a relative reference specification, in contrast, a semantic ordering of the categories is considered when comparing them either to the previous or subsequent category each. Both reference specifications can be defined at multiple levels of the hierarchy (including aggregated summaries), enabling a multitude of useful comparisons. We demonstrate the general applicability of our model in several application examples using different visualizations that compare data by overlay or explicit encoding of differences.	Johannes Kehrer;Harald Piringer;Wolfgang Berger;M. Eduard Gröller	Johannes Kehrer;Harald Piringer;Wolfgang Berger;M. Eduard Gröller	VRVis Research Center, Vienna, and the Institute of Computer Graphics and Algorithms, Vienna University of Technology;VRVis Research Center, Vienna;VRVis Research Center, Vienna;Institute of Computer Graphics and Algorithms, Vienna University of Technology	10.1109/TVCG.2010.138;10.1109/TVCG.2007.70594;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.125;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102439;10.1109/TVCG.2008.125;10.1109/INFVIS.2000.885086;10.1109/TVCG.2012.237;10.1109/TVCG.2007.70521	Comparative visualization, small-multiple displays, trellis displays, categorical data	18	22	19	33	
SciVis	2013	A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation	10.1109/TVCG.2013.123	http://dx.doi.org/10.1109/TVCG.2013.123	2792	2801	J	We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.	Wei-Hsien Hsu;Yubo Zhang;Kwan-Liu Ma	Wei-Hsien Hsu;Yubo Zhang;Kwan-Liu Ma	University of California, Davis;University of California, Davis;University of California, Davis	10.1109/TVCG.2006.152;10.1109/TVCG.2006.140;10.1109/TVCG.2009.189;10.1109/INFVIS.2003.1249004;10.1109/VISUAL.2005.1532834;10.1109/TVCG.2012.292;10.1109/VISUAL.2005.1532787;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2001.964517	Camera motion planning, volume rendering, visualization, animation	8	9	6	39	
InfoVis	2013	A Multi-Level Typology of Abstract Visualization Tasks	10.1109/TVCG.2013.124	http://dx.doi.org/10.1109/TVCG.2013.124	2376	2385	J	The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.	Matthew Brehmer;Tamara Munzner	Matthew Brehmer;Tamara Munzner	University of British Columbia;University of British Columbia	10.1109/TVCG.2007.70541;10.1109/TVCG.2012.219;10.1109/INFVIS.1996.559213;10.1109/TVCG.2012.213;10.1109/TVCG.2012.273;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.177;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2008.137;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/TVCG.2012.252;10.1109/VISUAL.1990.146375	Typology, visualization models, task and requirements analysis, qualitative evaluation	164	0	166	84	
VAST	2013	A Partition-Based Framework for Building and Validating Regression Models	10.1109/TVCG.2013.125	http://dx.doi.org/10.1109/TVCG.2013.125	1962	1971	J	Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.	Thomas Mühlbacher;Harald Piringer	Thomas Mühlbacher;Harald Piringer	VRVis Research Center;VRVis Research Center	10.1109/TVCG.2012.219;10.1109/TVCG.2009.128;10.1109/VISUAL.1993.398859;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102453;10.1109/VAST.2009.5333431;10.1109/TVCG.2010.213;10.1109/TVCG.2012.205;10.1109/VAST.2009.5332628;10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102450;10.1109/VAST.2008.4677368;10.1109/VAST.2010.5652460;10.1109/TVCG.2011.248;10.1109/INFVIS.2005.1532142;10.1109/VAST.2007.4388999;10.1109/INFVIS.2004.10;10.1109/TVCG.2009.110;10.1109/VAST.2011.6102448;10.1109/INFVIS.2004.3	Regression, model building, visual knowledge discovery, feature selection, data partitioning, guided visualization	48	67	50	50	BP
SciVis	2013	A Systematic Review on the Practice of Evaluating Visualization	10.1109/TVCG.2013.126	http://dx.doi.org/10.1109/TVCG.2013.126	2818	2827	J	We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.	Tobias Isenberg 0001;Petra Isenberg;Jian Chen;Michael Sedlmair;Torsten Möller	Tobias Isenberg;Petra Isenberg;Jian Chen;Michael Sedlmair;Torsten Möller	INRIA;INRIA;University of Maryland;University of Vienna;University of Vienna	10.1109/TVCG.2009.121;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.143;10.1109/TVCG.2011.224;10.1109/TVCG.2010.199;10.1109/TVCG.2010.223;10.1109/TVCG.2012.213;10.1109/TVCG.2010.134;10.1109/TVCG.2009.194;10.1109/TVCG.2011.174;10.1109/TVCG.2009.111;10.1109/TVCG.2011.206;10.1109/TVCG.2012.234;10.1109/TVCG.2012.292;10.1109/TVCG.2008.128;10.1109/TVCG.2009.167;10.1109/TVCG.2012.223	Evaluation, validation, systematic review, visualization, scientific visualization, information visualization	93	128	101	74	
SciVis	2013	Acuity-Driven Gigapixel Visualization	10.1109/TVCG.2013.127	http://dx.doi.org/10.1109/TVCG.2013.127	2886	2895	J	We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.	Charilaos Papadopoulos;Arie E. Kaufman	Charilaos Papadopoulos;Arie E. Kaufman	Stony Brook University;Stony Brook University	10.1109/TVCG.2011.231;10.1109/INFVIS.2004.66	Gigapixel visualization, visual acuity, focus and context, Reality Deck, gigapixel display	3	7	6	45	
SciVis	2013	Adaptive Refinement of the Flow Map Using Sparse Samples	10.1109/TVCG.2013.128	http://dx.doi.org/10.1109/TVCG.2013.128	2753	2762	J	We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.	Samer S. Barakat;Xavier Tricoche	Samer S. Barakat;Xavier Tricoche	Purdue University;Purdue University	10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2007.70554;10.1109/TVCG.2007.70551	Lagrangian flow visualization, flow map, edge features, scattered data interpolation, sparse sampling, adaptive refinement, parallel reconstruction	9	13	14	40	HM
SciVis	2013	Ambient Volume Scattering	10.1109/TVCG.2013.129	http://dx.doi.org/10.1109/TVCG.2013.129	2936	2945	J	We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.	Marco Ament;Filip Sadlo;Daniel Weiskopf	Marco Ament;Filip Sadlo;Daniel Weiskopf	VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart	10.1109/TVCG.2011.211;10.1109/TVCG.2007.70555;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2000.885683;10.1109/TVCG.2010.187;10.1109/VISUAL.2004.64;10.1109/VISUAL.2003.1250406;10.1109/TVCG.2010.145;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2005.1532803;10.1109/TVCG.2009.204	Direct volume rendering, volume illumination, ambient scattering, preintegrated light transport, gradient-free shading	22	0	19	50	HM
InfoVis	2013	An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization	10.1109/TVCG.2013.130	http://dx.doi.org/10.1109/TVCG.2013.130	2356	2365	J	Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, &amp; delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, &amp; prescribe) and interaction operands (space-alone, attributes-in-space, &amp; space-in-time; elementary &amp; general). The operator sort suggested five enabling operators (import, export, save, edit, &amp; annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, &amp; calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.	Robert E. Roth	Robert E. Roth	University of Wisconsin-Madison	10.1109/INFVIS.1996.559213;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5653599;10.1109/INFVIS.2000.885092	Science of interaction, interaction primitives, interactive maps, geovisualization, interaction techniques	53	66	53	79	
SciVis	2013	An Exploration Framework to Identify and Track Movement of Cloud Systems	10.1109/TVCG.2013.131	http://dx.doi.org/10.1109/TVCG.2013.131	2896	2905	J	We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.	Harish Doraiswamy;Vijay Natarajan;Ravi S. Nanjundiah	Harish Doraiswamy;Vijay Natarajan;Ravi S. Nanjundiah	Polytechnic Institute of New York University;Indian Institute of Science;Indian Institute of Science	10.1109/TVCG.2007.70519;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250383	Cloud clusters, tracking, computational topology, split tree, weather and climate simulations	12	18	19	50	
VAST	2013	An Extensible Framework for Provenance in Human Terrain Visual Analytics	10.1109/TVCG.2013.132	http://dx.doi.org/10.1109/TVCG.2013.132	2139	2148	J	We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.	Rick Walker;Aidan Slingsby;Jason Dykes;Kai Xu 0003;Jo Wood;Phong H. Nguyen;Derek Stephens;B. L. William Wong;Yongjun Zheng	Rick Walker;Aiden Slingsby;Jason Dykes;Kai Xu;Jo Wood;Phong H. Nguyen;Derek Stephens;B.L. William Wong;Yongjun Zheng	Middlesex University;City University;City University;Middlesex University;City University;Middlesex University;Loughborough University;Middlesex University;Middlesex University	10.1109/TVCG.2012.252;10.1109/TVCG.2010.191;10.1109/VAST.2007.4388992;10.1109/TVCG.2006.142;10.1109/VAST.2006.261431;10.1109/TVCG.2010.154;10.1109/TVCG.2012.213;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677366;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4388992;10.1109/TVCG.2009.128;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919;10.1109/TVCG.2011.209;10.1109/TVCG.2009.139;10.1109/TVCG.2008.175	Human terrain analysis, provenance, framework, bookmarks, narratives	18	23	18	59	
SciVis	2013	An Information-Aware Framework for Exploring Multivariate Data Sets	10.1109/TVCG.2013.133	http://dx.doi.org/10.1109/TVCG.2013.133	2683	2692	J	Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.	Ayan Biswas;Soumya Dutta;Han-Wei Shen;Jonathan Woodring	Ayan Biswas;Soumya Dutta;Han-Wei Shen;Jonathan Woodring	The Ohio State University;The Ohio State University;The Ohio State University;Los Alamos National Laboratory	10.1109/TVCG.2010.132;10.1109/TVCG.2009.120;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2008.116;10.1109/TVCG.2010.184;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.160;10.1109/TVCG.2008.140;10.1109/VAST.2007.4389000;10.1109/TVCG.2011.201;10.1109/VISUAL.1995.485139;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2010.182;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785	Information theory, framework, isosurface, multivariate uncertainty	28	39	36	46	
InfoVis	2013	An Interaction Model for Visualizations Beyond The Desktop	10.1109/TVCG.2013.134	http://dx.doi.org/10.1109/TVCG.2013.134	2396	2405	J	We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.	Yvonne Jansen;Pierre Dragicevic	Yvonne Jansen;Pierre Dragicevic	Inria and Universite Paris Sud;Inria	10.1109/TVCG.2010.177;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2006.178;10.1109/TVCG.2009.162;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.1998.729560;10.1109/VISUAL.1990.146375	Information visualization, interaction model, notational system, physical visualization	56	0	40	65	
SciVis	2013	Area-Preservation Mapping using Optimal Mass Transport	10.1109/TVCG.2013.135	http://dx.doi.org/10.1109/TVCG.2013.135	2838	2847	J	We present a novel area-preservation mapping/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n&lt;sup&gt;2&lt;/sup&gt;) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton's method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework.	Xin Zhao;Zhengyu Su;Xianfeng Gu;Arie E. Kaufman;Jian Sun;Jie Gao 0001;Feng Luo 0002	Xin Zhao;Zhengyu Su;Xianfeng David Gu;Arie Kaufman;Jian Sun;Jie Gao;Feng Luo	Stony Brook University;Stony Brook University;Stony Brook University;Stony Brook University;Tsinghua University;Stony Brook University;Rutgers University	10.1109/TVCG.2011.171	Area-preservation mapping, surface flattening, optimal transport map, Monge-Brenier theory, visualization and graphics applications	33	44	33	38	
InfoVis	2013	Automatic Layout of Structured Hierarchical Reports	10.1109/TVCG.2013.137	http://dx.doi.org/10.1109/TVCG.2013.137	2586	2595	J	Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets.	Eirik Bakke;David R. Karger;Rob Miller 0001	Eirik Bakke;David R. Karger;Robert C. Miller	MIT Computer Science and Artificial Intelligence Laboratory (CSAIL);MIT Computer Science and Artificial Intelligence Laboratory (CSAIL);MIT Computer Science and Artificial Intelligence Laboratory (CSAIL)	10.1109/VAST.2011.6102445;10.1109/INFVIS.2004.1;10.1109/INFVIS.1995.528693;10.1109/TVCG.2007.70594;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.1997.636761	Hierarchy data, tabular data, nested relations, layout management	7	7	1	31	
SciVis	2013	Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging	10.1109/TVCG.2013.138	http://dx.doi.org/10.1109/TVCG.2013.138	2703	2712	J	Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.	Luke J. Gosink;Kevin Bensema;Trenton Pulsipher;Harald Obermaier;Michael Henry;Hank Childs;Kenneth I. Joy	Luke Gosink;Kevin Bensema;Trenton Pulsipher;Harald Obermaier;Michael Henry;Hank Childs;Kenneth I. Joy	Pacific Northwest National Laboratory;University of California at Davis;Pacific Northwest National Laboratory;University of California at Davis;Pacific Northwest National Laboratory;University of Oregon;University of California at Davis	10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.208;10.1109/TVCG.2010.181	Uncertainty visualization, numerical ensembles, statistical visualization	12	16	16	49	
SciVis	2013	Colon Flattening Using Heat Diffusion Riemannian Metric	10.1109/TVCG.2013.139	http://dx.doi.org/10.1109/TVCG.2013.139	2848	2857	J	We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.	Krishna Chaitanya Gurijala;Rui Shi;Wei Zeng;Xianfeng Gu;Arie E. Kaufman	Krishna Chaitanya Gurijala;Rui Shi;Wei Zeng;Xianfeng Gu;Arie Kaufman	Stony Brook University;Stony Brook University;Florida International University;Stony Brook University;Stony Brook University	10.1109/VISUAL.2001.964540;10.1109/TVCG.2006.112;10.1109/VISUAL.2001.964540;10.1109/TVCG.2010.200	Colon flattening, heat diffusion, virtual colonoscopy, volume rendering, topological noise, shape-preserving mapping	6	9	10	46	
InfoVis	2013	Common Angle Plots as Perception-True Visualizations of Categorical Associations	10.1109/TVCG.2013.140	http://dx.doi.org/10.1109/TVCG.2013.140	2297	2305	J	Visualizations are great tools of communications-they summarize findings and quickly convey main messages to our audience. As designers of charts we have to make sure that information is shown with a minimum of distortion. We have to also consider illusions and other perceptual limitations of our audience. In this paper we discuss the effect and strength of the line width illusion, a Muller-Lyer type illusion, on designs related to displaying associations between categorical variables. Parallel sets and hammock plots are both affected by line width illusions. We introduce the common-angle plot as an alternative method for displaying categorical data in a manner that minimizes the effect from perceptual illusions. Results from user studies both highlight the need for addressing line-width illusions in displays and provide evidence that common angle charts successfully resolve this issue.	Heike Hofmann;Marie Vendettuoli	Heike Hofmann;Marie Vendettuoli	Iowa State University;Iowa State University	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532128;10.1109/TVCG.2010.186;10.1109/TVCG.2011.185;10.1109/TVCG.2009.128	Linewidth illusion, data visualization, high-dimensional displays, parallel sets, hammock plots, Muller-Lyer illusion	7	8	7	37	
SciVis	2013	Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles	10.1109/TVCG.2013.141	http://dx.doi.org/10.1109/TVCG.2013.141	2743	2752	J	Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.	Mathias Hummel;Harald Obermaier;Christoph Garth;Kenneth I. Joy	Mathias Hummel;Harald Obermaier;Christoph Garth;Kenneth I. Joy	University of Kaiserslautern;University of California, Davis;University of Kaiserslautern;University of California, Davis	10.1109/TVCG.2011.203;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2007.70551	Ensemble, flow field, time-varying, comparison, visualization, Lagrangian, variance, principal components analysis	25	34	32	34	BP
SciVis	2013	ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data	10.1109/TVCG.2013.142	http://dx.doi.org/10.1109/TVCG.2013.142	2868	2877	J	This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.	Johanna Beyer;Ali K. Al-Awami;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger	Johanna Beyer;Ali Al-Awami;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger	King Abdullah University of Science and Technology;King Abdullah University of Science and Technology;Center for Brain Science at Harvard University;Center for Brain Science at Harvard University;School of Engineering and Applied Sciences at Harvard University;King Abdullah University of Science and Technology	10.1109/INFVIS.2000.885086;10.1109/VISUAL.2005.1532792;10.1109/TVCG.2009.178;10.1109/TVCG.2012.240;10.1109/TVCG.2006.195;10.1109/VISUAL.1995.485139;10.1109/TVCG.2007.70560;10.1109/TVCG.2009.118;10.1109/TVCG.2009.121	Connectomics, neuroscience, query algebra, visual knowledge discovery, petascale volume analysis	27	34	31	45	
SciVis	2013	Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles	10.1109/TVCG.2013.143	http://dx.doi.org/10.1109/TVCG.2013.143	2713	2722	J	Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.	Ross T. Whitaker;Mahsa Mirzargar;Robert Michael Kirby	Ross T. Whitaker;Mahsa Mirzargar;Robert M. Kirby	SCI Institute, University of Utah;University of Florida;University of Utah	10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.181	Uncertainty visualization, boxplots, band depth, ensemble visualization, order statistics	66	92	86	38	
SciVis	2013	Coupled Ensemble Flow Line Advection and Analysis	10.1109/TVCG.2013.144	http://dx.doi.org/10.1109/TVCG.2013.144	2733	2742	J	Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations.	Hanqi Guo;Xiaoru Yuan;Jian Huang 0007;Xiaomin Zhu	Hanqi Guo;Xiaoru Yuan;Jian Huang;Xiaomin Zhu	Key Laboratory of Machine Perception (Ministry of Education), School of EECS, and Center for Computational Science and Engineering, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, and Center for Computational Science and Engineering, Peking University;University of Tennessee;National Super Computing Center in Jinan, Shandong, China	10.1109/VISUAL.2005.1532853;10.1109/TVCG.2011.219;10.1109/TVCG.2011.203;10.1109/TVCG.2006.116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/VISUAL.1996.568116;10.1109/TVCG.2007.70551	Ensemble analysis, parallel processing, field line advection	25	0	26	43	
InfoVis	2013	Creative User-Centered Visualization Design for Energy Analysts and Modelers	10.1109/TVCG.2013.145	http://dx.doi.org/10.1109/TVCG.2013.145	2516	2525	J	We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design.	Sarah Goodwin;Jason Dykes;Sara Jones 0001;Iain Dillingham;Graham Dove;Alison Duffy;Alexander Kachkaev;Aidan Slingsby;Jo Wood	Sarah Goodwin;Jason Dykes;Sara Jones;Iain Dillingham;Graham Dove;Alison Duffy;Alexander Kachkaev;Aidan Slingsby;Jo Wood	giCentre, City University London;giCentre, City University London;Centre for Creativity in Professional Practice, City University London;giCentre, City University London;Centre for Creativity in Professional Practice, City University London;Centre for Creativity in Professional Practice, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London	10.1109/TVCG.2010.191;10.1109/TVCG.2012.213;10.1109/TVCG.2011.196;10.1109/TVCG.2007.70539;10.1109/INFVIS.1999.801851;10.1109/TVCG.2011.209	Creativity techniques, user-centered design, data visualization, smart home, energy consumption	23	31	23	57	
VAST	2013	Decision Exploration Lab: A Visual Analytics Solution for Decision Management	10.1109/TVCG.2013.146	http://dx.doi.org/10.1109/TVCG.2013.146	1972	1981	J	We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.	Bertjan Broeksema;Thomas Baudel;Arthur G. Telea;Paolo Crisafulli	Bertjan Broeksema;Thomas Baudel;Alex Telea;Paolo Crisafulli	IBM France Center for Advanced Studies, Institute Johann Bernoulli, University of Groningen, The Netherlands andINRIA, University of Bordeaux, France;IBM France Center for Advanced Studies;Institute Johann Bernoulli, University of Groningen, The Netherlands;IBM France	10.1109/VISUAL.1991.175815;10.1109/VAST.2011.6102463;10.1109/VAST.2010.5652398;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677363;10.1109/TVCG.2011.185;10.1109/VAST.2011.6102457	Decision support systems, model validation and analysis, multivariate Statistics, program analysis	5	6	6	49	
SciVis	2013	Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles	10.1109/TVCG.2013.147	http://dx.doi.org/10.1109/TVCG.2013.147	2783	2791	J	We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.	Dane M. Coffey;Chi-Lun Lin;Arthur G. Erdman;Daniel F. Keefe	Dane Coffey;Chi-Lun Lin;Arthur G. Erdman;Daniel F. Keefe	University of Minnesota;University of Minnesota;University of Minnesota;University of Minnesota	10.1109/TVCG.2012.261;10.1109/TVCG.2010.223;10.1109/TVCG.2010.190;10.1109/TVCG.2011.248;10.1109/VISUAL.2000.885734;10.1109/TVCG.2010.171;10.1109/TVCG.2007.70581	Design, simulation, direct manipulation, multi-touch	21	36	32	27	HM
SciVis	2013	Detecting Symmetry in Scalar fields Using Augmented Extremum Graphs	10.1109/TVCG.2013.148	http://dx.doi.org/10.1109/TVCG.2013.148	2663	2672	J	Visualizing symmetric patterns in the data often helps the domain scientists make important observations and gain insights about the underlying experiment. Detecting symmetry in scalar fields is a nascent area of research and existing methods that detect symmetry are either not robust in the presence of noise or computationally costly. We propose a data structure called the augmented extremum graph and use it to design a novel symmetry detection method based on robust estimation of distances. The augmented extremum graph captures both topological and geometric information of the scalar field and enables robust and computationally efficient detection of symmetry. We apply the proposed method to detect symmetries in cryo-electron microscopy datasets and the experiments demonstrate that the algorithm is capable of detecting symmetry even in the presence of significant noise. We describe novel applications that use the detected symmetry to enhance visualization of scalar field data and facilitate their exploration.	Dilip Mathew Thomas;Vijay Natarajan	Dilip Mathew Thomas;Vijay Natarajan	Indian Institute of Science;Indian Institute of Science	10.1109/VISUAL.2004.68;10.1109/TVCG.2009.120;10.1109/TVCG.2011.236;10.1109/TVCG.2008.143;10.1109/TVCG.2011.244;10.1109/TVCG.2007.70603;10.1109/TVCG.2012.200;10.1109/TVCG.2006.186	Scalar field visualization, extremum graph, Morse decomposition, symmetry detection, data exploration	9	11	9	44	
InfoVis	2013	DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation	10.1109/TVCG.2013.149	http://dx.doi.org/10.1109/TVCG.2013.149	2556	2565	J	Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.	Sébastien Rufiange;Michael J. McGuffin	Sébastien Rufiange;Michael J. McGuffin	école de technologie supérieure;école de technologie supérieure	10.1109/VAST.2012.6400552;10.1109/TVCG.2011.169;10.1109/INFVIS.2005.1532151;10.1109/TVCG.2011.226;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.213;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70582;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2002.1173160;10.1109/TVCG.2007.70539	Dynamic networks, hybrid visualization, taxonomy, evolution, animation, difference map	36	44	32	43	
InfoVis	2013	Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data	10.1109/TVCG.2013.150	http://dx.doi.org/10.1109/TVCG.2013.150	2625	2633	J	For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.	Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo	Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo	Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VAST.2012.6400488;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.184;10.1109/TVCG.2009.128;10.1109/VAST.2006.261422;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2009.153;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173151	High dimensional data, hierarchical visualization, sub-dimensional space, user interaction, subspace, tree, matrix	42	55	46	43	
InfoVis	2013	Edge Compression Techniques for Visualization of Dense Directed Graphs	10.1109/TVCG.2013.151	http://dx.doi.org/10.1109/TVCG.2013.151	2596	2605	J	We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.	Tim Dwyer;Nathalie Henry Riche;Kim Marriott;Christopher Mears	Tim Dwyer;Nathalie Henry Riche;Kim Marriott;Christopher Mears	Monash University;Microsoft Research;Monash University;Monash University	10.1109/TVCG.2009.165;10.1109/TVCG.2011.233;10.1109/TVCG.2006.120;10.1109/INFVIS.2004.66	Directed graphs, networks, modular decomposition, power graph analysis	20	30	26	25	
SciVis	2013	Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform	10.1109/TVCG.2013.152	http://dx.doi.org/10.1109/TVCG.2013.152	2693	2702	J	Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance.	Teng-Yok Lee;Han-Wei Shen	Teng-Yok Lee;Han-Wei Shen	The Ohio State University;The Ohio State University	10.1109/VISUAL.1999.809910;10.1109/TVCG.2010.131;10.1109/TVCG.2011.246;10.1109/VISUAL.2001.964516;10.1109/TVCG.2011.198;10.1109/TVCG.2009.197	WaveletSAT, integral histograms, discrete wavelet transform	11	15	9	38	
InfoVis	2013	Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices	10.1109/TVCG.2013.153	http://dx.doi.org/10.1109/TVCG.2013.153	2634	2643	J	To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.	Michael Sedlmair;Tamara Munzner;Melanie Tory	Michael Sedlmair;Tamara Munzner;Melanie Tory	University of Vienna;University of British Columbia;University of Victoria	10.1109/TVCG.2009.127;10.1109/TVCG.2011.229;10.1109/TVCG.2007.70596;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1997.636793;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2008.109;10.1109/VAST.2009.5332628	Dimensionality reduction, scatterplots, quantitative study	53	76	60	0	
InfoVis	2013	Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets	10.1109/TVCG.2013.154	http://dx.doi.org/10.1109/TVCG.2013.154	2536	2545	J	Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.	Alexander Lex;Christian Partl;Denis Kalkofen;Marc Streit;Samuel Gratzl;Anne Mai Wassermann;Dieter Schmalstieg;Hanspeter Pfister	Alexander Lex;Christian Partl;Denis Kalkofen;Marc Streit;Samuel Gratzl;Anne Mai Wassermann;Dieter Schmalstieg;Hanspeter Pfister	Harvard University;Graz University of Technology;Graz University of Technology;Johannes Kepler University Linz;Johannes Kepler University Linz;Novartis Institutes for BioMedical Research;Graz University of Technology;Harvard University	10.1109/VAST.2009.5333443;10.1109/TVCG.2011.250;10.1109/TVCG.2011.213;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183;10.1109/INFVIS.2000.885087	Pathway visualization, biological networks, subsets, graphs, biomolecular data	26	34	26	33	
InfoVis	2013	Evaluation of filesystem Provenance Visualization Tools	10.1109/TVCG.2013.155	http://dx.doi.org/10.1109/TVCG.2013.155	2476	2485	J	Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.	Michelle Borkin;Chelsea S. Yeh;Madelaine Boyd;Peter Macko;Krzysztof Z. Gajos;Margo I. Seltzer;Hanspeter Pfister	Michelle A. Borkin;Chelsea S. Yeh;Madelaine Boyd;Peter Macko;Krzysztof Z. Gajos;Margo Seltzer;Hanspeter Pfister	Harvard University;Harvard University;Harvard University;Harvard University;Harvard University;Harvard University;Harvard University	10.1109/TVCG.2006.193;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2006.120;10.1109/TVCG.2009.167;10.1109/INFVIS.2004.66;10.1109/INFVIS.2004.1;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532134	Provenance data, graph/network data, hierarchy data, quantitative evaluation, gender differences	23	0	22	54	
SciVis	2013	Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities	10.1109/TVCG.2013.156	http://dx.doi.org/10.1109/TVCG.2013.156	2810	2817	J	Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants' abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit.	Maria-Elena Froese;Melanie Tory;Guy-Warwick Evans;Kedar Shrikhande	Maria-Elena Froese;Melanie Tory;Guy-Warwick Evans;Kedar Shrikhande	University of Victoria;University of Victoria;University of Victoria;University of Victoria	10.1109/VISUAL.2005.1532836;10.1109/VISUAL.2003.1250396	Spatial ability, 3D visualization, training, evaluation, orthographic projection, CAD	2	5	5	48	
VAST	2013	Explainers: Expert Explorations with Crafted Projections	10.1109/TVCG.2013.157	http://dx.doi.org/10.1109/TVCG.2013.157	2042	2051	J	This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.	Michael Gleicher	Michael Gleicher	Department of Computer Sciences, University of Wisconsin - Madison	10.1109/VAST.2012.6400487;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.71;10.1109/TVCG.2012.256;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2011.220;10.1109/INFVIS.1998.729559;10.1109/VAST.2011.6102448;10.1109/TVCG.2009.153	High-dimensional spaces, exploration, support vector machines	27	39	26	51	HM
SciVis	2013	Fast Blending Scheme for Molecular Surface Representation	10.1109/TVCG.2013.158	http://dx.doi.org/10.1109/TVCG.2013.158	2653	2662	J	Representation of molecular surfaces is a well established way to study the interaction of molecules. The state-of-theart molecular representation is the SES model, which provides a detailed surface visualization. Nevertheless, it is computationally expensive, so the less accurate Gaussian model is traditionally preferred. We introduce a novel surface representation that resembles the SES and approaches the rendering performance of the Gaussian model. Our technique is based on the iterative blending of implicit functions and avoids any pre-computation. Additionally, we propose a GPU-based ray-casting algorithm that efficiently visualize our molecular representation. A qualitative and quantitative comparison of our model with respect to the Gaussian and SES models is presented. As showcased in the paper, our technique is a valid and appealing alternative to the Gaussian representation. This is especially relevant in all the applications where the cost of the SES is prohibitive.	Július Parulek;Andrea Brambilla	Julius Parulek;Andrea Brambilla	University of Bergen;University of Bergen	10.1109/TVCG.2009.157;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2006.115	Molecular visualization, geometry-based techniques, implicit surfaces	7	8	7	44	
SciVis	2013	Fast Generation of Virtual X-ray Images for Reconstruction of 3D Anatomy	10.1109/TVCG.2013.159	http://dx.doi.org/10.1109/TVCG.2013.159	2673	2682	J	We propose a novel GPU-based approach to render virtual X-ray projections of deformable tetrahedral meshes. These meshes represent the shape and the internal density distribution of a particular anatomical structure and are derived from statistical shape and intensity models (SSIMs). We apply our method to improve the geometric reconstruction of 3D anatomy (e.g. pelvic bone) from 2D X-ray images. For that purpose, shape and density of a tetrahedral mesh are varied and virtual X-ray projections are generated within an optimization process until the similarity between the computed virtual X-ray and the respective anatomy depicted in a given clinical X-ray is maximized. The OpenGL implementation presented in this work deforms and projects tetrahedral meshes of high resolution (200.000+ tetrahedra) at interactive rates. It generates virtual X-rays that accurately depict the density distribution of an anatomy of interest. Compared to existing methods that accumulate X-ray attenuation in deformable meshes, our novel approach significantly boosts the deformation/projection performance. The proposed projection algorithm scales better with respect to mesh resolution and complexity of the density distribution, and the combined deformation and projection on the GPU scales better with respect to the number of deformation parameters. The gain in performance allows for a larger number of cycles in the optimization process. Consequently, it reduces the risk of being stuck in a local optimum. We believe that our approach will improve treatments in orthopedics, where 3D anatomical information is essential.	Moritz Ehlke;Heiko Ramm;Hans Lamecker;Hans-Christian Hege;Stefan Zachow	Moritz Ehlke;Heiko Ramm;Hans Lamecker;Hans-Christian Hege;Stefan Zachow	Zuse Institut Berlin (ZIB);Zuse Institut Berlin (ZIB);Zuse Institut Berlin (ZIB);Zuse Institut Berlin (ZIB);Zuse Institut Berlin (ZIB)	10.1109/VISUAL.2005.1532809;10.1109/VISUAL.2005.1532815;10.1109/TVCG.2006.110;10.1109/VISUAL.2003.1250384	Digitally reconstructed radiographs, volume rendering, mesh deformation, statistical shape and intensity models, image registration, GPU acceleration	28	39	30	24	
InfoVis	2013	GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data	10.1109/TVCG.2013.160	http://dx.doi.org/10.1109/TVCG.2013.160	2606	2614	J	Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.	Jean-François Im;Michael J. McGuffin;Rock Leung	Jean-François Im;Michael J. McGuffin;Rock Leung	école de technologie supérieure;école de technologie supérieure;SAP, Vancouver	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/TVCG.2007.70594;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2010.205;10.1109/TVCG.2011.183;10.1109/VISUAL.1993.398859;10.1109/TVCG.2011.201;10.1109/TVCG.2010.164;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70521;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/VISUAL.1991.175796	Multidimensional data, tabular data, relational data, mdmv, high-dimensional data, database visualization, database overview, parallel coordinates, scatterplot matrix, user interfaces, business intelligence	28	34	23	40	
SciVis	2013	GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data	10.1109/TVCG.2013.161	http://dx.doi.org/10.1109/TVCG.2013.161	2916	2925	J	We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.	Adrian Maries;Nathan Mays;MeganOlson Hunt;Kim F. Wong;William J. Layton;Robert Boudreau;Caterina Rosano;G. Elisabeta Marai	Adrian Maries;Nathan Mays;MeganOlson Hunt;Kim F. Wong;William Layton;Robert Boudreau;Caterina Rosano;G. Elisabeta Marai	University of Pittsburgh;Wheeling Jesuit University;University of Pittsburgh;University of Pittsburgh;University of Pittsburgh;University of Pittsburgh;University of Pittsburgh;University of Pittsburgh	10.1109/TVCG.2009.141;10.1109/VISUAL.2000.885739;10.1109/VAST.2006.261438;10.1109/TVCG.2009.111;10.1109/TVCG.2010.137;10.1109/TVCG.2009.114;10.1109/VISUAL.1991.175815;10.1109/TVCG.2010.162	Design studies, methodology design, task and requirements analysis, integrating spatial and non-spatial data visualization, visual comparison, high-dimensional data, applications of visualization	7	10	9	49	
VAST	2013	HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies	10.1109/TVCG.2013.162	http://dx.doi.org/10.1109/TVCG.2013.162	2002	2011	J	Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.	Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;William Ribarsky	Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;William Ribarsky	University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte	10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485	Hierarchical topic representation, topic modeling, visual analytics, rose tree	71	88	58	35	
InfoVis	2013	Hybrid-Image Visualization for Large Viewing Environments	10.1109/TVCG.2013.163	http://dx.doi.org/10.1109/TVCG.2013.163	2346	2355	J	We present a first investigation into hybrid-image visualization for data analysis in large-scale viewing environments. Hybrid-image visualizations blend two different visual representations into a single static view, such that each representation can be perceived at a different viewing distance. Our work is motivated by data analysis scenarios that incorporate one or more displays with sufficiently large size and resolution to be comfortably viewed by different people from various distances. Hybrid-image visualizations can be used, in particular, to enhance overview tasks from a distance and detail-in-context tasks when standing close to the display. By using a perception-based blending approach, hybrid-image visualizations make two full-screen visualizations accessible without tracking viewers in front of a display. We contribute a design space, discuss the perceptual rationale for our work, provide examples, and introduce a set of techniques and tools to aid the design of hybrid-image visualizations.	Petra Isenberg;Pierre Dragicevic;Wesley Willett;Anastasia Bezerianos;Jean-Daniel Fekete	Petra Isenberg;Pierre Dragicevic;Wesley Willett;Anastasia Bezerianos;Jean-Daniel Fekete	INRIA;INRIA;INRIA;LRI (Univ. Paris-Sud &amp; CNRS) &amp; INRIA;INRIA	10.1109/TVCG.2012.251;10.1109/TVCG.2012.264;10.1109/TVCG.2006.184;10.1109/TVCG.2007.70582;10.1109/INFVIS.2001.963288;10.1109/TVCG.2007.70583;10.1109/INFVIS.2005.1532131	Multi-scale, large displays, hybrid images, collaboration, visualization	18	21	14	47	
VAST	2013	Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis	10.1109/TVCG.2013.164	http://dx.doi.org/10.1109/TVCG.2013.164	2198	2206	J	We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.	Wesley Willett;Shiry Ginosar;Avital Steinitz;Björn Hartmann;Maneesh Agrawala	Wesley Willett;Shiry Ginosar;Avital Steinitz;Björn Hartmann;Maneesh Agrawala	INRIA;UC Berkeley;UC Berkeley;UC Berkeley;UC Berkeley	10.1109/TVCG.2007.70577	Crowdsourcing, social data analysis	13	21	12	23	
InfoVis	2013	Information Visualization and Proxemics: Design Opportunities and Empirical findings	10.1109/TVCG.2013.166	http://dx.doi.org/10.1109/TVCG.2013.166	2386	2395	J	People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users' position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user's physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.	Mikkel Rønne Jakobsen;Yonas Sahlemariam Haile;Søren Knudsen;Kasper Hornbæk	Mikkel R. Jakobsen;Yonas Sahlemariam Haile;Søren Knudsen;Kasper Hornbæk	University of Copenhagen;University of Copenhagen;University of Copenhagen;University of Copenhagen	10.1109/TVCG.2006.184;10.1109/TVCG.2012.204;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136	Proxemics, information visualization, user study, large displays, user tracking, movement, orientation, distance	22	27	22	56	
VAST	2013	Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets	10.1109/TVCG.2013.167	http://dx.doi.org/10.1109/TVCG.2013.167	2080	2089	J	Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.	Jian Zhao 0010;Christopher Collins 0001;Fanny Chevalier;Ravin Balakrishnan	Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan	University of Toronto;University of Ontario Institute of Technology;University of Toronto, Canada;University of Toronto, Canada	10.1109/TVCG.2008.137;10.1109/VAST.2011.6102440;10.1109/TVCG.2011.213;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.205;10.1109/TVCG.2012.252;10.1109/TVCG.2006.166;10.1109/INFVIS.2000.885086	Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics	34	49	35	39	
VAST	2013	Interactive Exploration of Surveillance Video through Action Shot Summarization and Trajectory Visualization	10.1109/TVCG.2013.168	http://dx.doi.org/10.1109/TVCG.2013.168	2119	2128	J	We propose a novel video visual analytics system for interactive exploration of surveillance video data. Our approach consists of providing analysts with various views of information related to moving objects in a video. To do this we first extract each object's movement path. We visualize each movement by (a) creating a single action shot image (a still image that coalesces multiple frames), (b) plotting its trajectory in a space-time cube and (c) displaying an overall timeline view of all the movements. The action shots provide a still view of the moving object while the path view presents movement properties such as speed and location. We also provide tools for spatial and temporal filtering based on regions of interest. This allows analysts to filter out large amounts of movement activities while the action shot representation summarizes the content of each movement. We incorporated this multi-part visual representation of moving objects in sViSIT, a tool to facilitate browsing through the video content by interactive querying and retrieval of data. Based on our interaction with security personnel who routinely interact with surveillance video data, we identified some of the most common tasks performed. This resulted in designing a user study to measure time-to-completion of the various tasks. These generally required searching for specific events of interest (targets) in videos. Fourteen different tasks were designed and a total of 120 min of surveillance video were recorded (indoor and outdoor locations recording movements of people and vehicles). The time-to-completion of these tasks were compared against a manual fast forward video browsing guided with movement detection. We demonstrate how our system can facilitate lengthy video exploration and significantly reduce browsing time to find events of interest. Reports from expert users identify positive aspects of our approach which we summarize in our recommendations for future video visual analytics systems.	Amir H. Meghdadi;Pourang Irani	Amir H. Meghdadi;Pourang Irani	Department of Computer Science, University of Manitoba;Department of Computer Science, University of Manitoba	10.1109/INFVIS.2004.27;10.1109/TVCG.2012.222;10.1109/VISUAL.2003.1250401	Video visual analytics, surveillance video, video visualization, video summarization, video browsing and exploration	24	36	27	33	
SciVis	2013	Interactive Patient-Specific Vascular Modeling with Sweep Surfaces	10.1109/TVCG.2013.169	http://dx.doi.org/10.1109/TVCG.2013.169	2828	2837	J	The precise modeling of vascular structures plays a key role in medical imaging applications, such as diagnosis, therapy planning and blood flow simulations. For the simulation of blood flow in particular, high-precision models are required to produce accurate results. It is thus common practice to perform extensive manual data polishing on vascular segmentations prior to simulation. This usually involves a complex tool chain which is highly impractical for clinical on-site application. To close this gap in current blood flow simulation pipelines, we present a novel technique for interactive vascular modeling which is based on implicit sweep surfaces. Our method is able to generate and correct smooth high-quality models based on geometric centerline descriptions on the fly. It supports complex vascular free-form contours and consequently allows for an accurate and fast modeling of pathological structures such as aneurysms or stenoses. We extend the concept of implicit sweep surfaces to achieve increased robustness and applicability as required in the medical field. We finally compare our method to existing techniques and provide case studies that confirm its contribution to current simulation pipelines.	Jan Kretschmer;Christian Godenschwager;Bernhard Preim;Marc Stamminger	Jan Kretschmer;Christian Godenschwager;Bernhard Preim;Marc Stamminger	Computer Science Department, FAU Erlangen, and Siemens Healthcare, Computed Tomography;Computer Science Department, FAU Erlangen, and Siemens Healthcare, Computed Tomography;University of Magdeburg;Department of Computer Graphics, FAU Erlangen	10.1109/VISUAL.2001.964538;10.1109/VISUAL.1994.346339	Surface modeling, vascular visualization, centerline-based modeling	12	18	14	52	
InfoVis	2013	Interactive Visualizations on Large and Small Displays: The Interrelation of Display Size, Information Space, and Scale	10.1109/TVCG.2013.170	http://dx.doi.org/10.1109/TVCG.2013.170	2336	2345	J	In controlled experiments on the relation of display size (i.e., the number of pixels) and the usability of visualizations, the size of the information space can either be kept constant or varied relative to display size. Both experimental approaches have limitations. If the information space is kept constant then the scale ratio between an overview of the entire information space and the lowest zoom level varies, which can impact performance; if the information space is varied then the scale ratio is kept constant, but performance cannot be directly compared. In other words, display size, information space, and scale ratio are interrelated variables. We investigate this relation in two experiments with interfaces that implement classic information visualization techniques-focus+context, overview+detail, and zooming-for multi-scale navigation in maps. Display size varied between 0.17, 1.5, and 13.8 megapixels. Information space varied relative to display size in one experiment and was constant in the other. Results suggest that for tasks where users navigate targets that are visible at all map scales the interfaces do not benefit from a large display: With a constant map size, a larger display does not improve performance with the interfaces; with map size varied relative to display size, participants found interfaces harder to use with a larger display and task completion times decrease only when they are normalized to compensate for the increase in map size. The two experimental approaches show different interaction effects between display size and interface. In particular, focus+context performs relatively worse at a large display size with variable map size, and relatively worse at a small display size with a fixed map size. Based on a theoretical analysis of the interaction with the visualization techniques, we examine individual task actions empirically so as to understand the relative impact of display size and scale ratio on the visualization techniques' performance and to discuss differences between the two experimental approaches.	Mikkel Rønne Jakobsen;Kasper Hornbæk	Mikkel R. Jakobsen;Kasper Hornbæk	University of Copenhagen;University of Copenhagen	10.1109/TVCG.2006.184;10.1109/TVCG.2006.187	Information visualization, multi-scale navigation, interaction techniques, experimental method, user studies	13	18	11	32	
SciVis	2013	Lighting Design for Globally Illuminated Volume Rendering	10.1109/TVCG.2013.172	http://dx.doi.org/10.1109/TVCG.2013.172	2946	2955	J	With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.	Yubo Zhang;Kwan-Liu Ma	Yubo Zhang;Kwan-Liu Ma	University of California, Davis;University of California, Davis	10.1109/VISUAL.2005.1532812;10.1109/VISUAL.2004.62;10.1109/TVCG.2011.198;10.1109/TVCG.2012.267;10.1109/VISUAL.2002.1183785	Global illumination, lighting design, volume rendering, tone mapping	16	21	16	33	
InfoVis	2013	LineUp: Visual Analysis of Multi-Attribute Rankings	10.1109/TVCG.2013.173	http://dx.doi.org/10.1109/TVCG.2013.173	2277	2286	J	Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.	Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit	Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit	Johannes Kepler University Linz;Johannes Kepler University Linz;Harvard University;Harvard University;Harvard Medical School	10.1109/TVCG.2012.253;10.1109/TVCG.2008.166;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.181;10.1109/TVCG.2007.70539	Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts	90	127	91	36	BP
SciVis	2013	ManyVis: Multiple Applications in an Integrated Visualization Environment	10.1109/TVCG.2013.174	http://dx.doi.org/10.1109/TVCG.2013.174	2878	2885	J	As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.	Atul Rungta;Brian Summa;Dogan Demir;Peer-Timo Bremer;Valerio Pascucci	Atul Rungta;Brian Summa;Dogan Demir;Peer-Timo Bremer;Valerio Pascucci	SCI Institute, University of Utah;SCI Institute, University of Utah;SCI Institute, University of Utah;Lawrence Livermore National Laboratory;SCI Institute, University of Utah	10.1109/TVCG.2007.70552	Visualization environments, integrated applications, macros, linked views	3	4	3	40	
SciVis	2013	MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data	10.1109/TVCG.2013.177	http://dx.doi.org/10.1109/TVCG.2013.177	2906	2915	J	This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.	Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl	Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl	University of Applied Sciences Upper Austria, Campus Wels;University of Applied Sciences Upper Austria, Campus Wels;University of Applied Sciences Upper Austria, Campus Wels;Vienna University of Technology;University of Applied Sciences Upper Austria, Campus Wels	10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809871;10.1109/TVCG.2009.121;10.1109/TVCG.2012.227;10.1109/TVCG.2011.248;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.190;10.1109/TVCG.2010.214;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1997.663875	3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects	15	22	16	29	
VAST	2013	MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation	10.1109/TVCG.2013.178	http://dx.doi.org/10.1109/TVCG.2013.178	2257	2266	J	We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.	Jürgen Bernard;Nils Wilhelm;Björn Krüger;Thorsten May;Tobias Schreck;Jörn Kohlhammer	Jürgen Bernard;Nils Wilhelm;Björn Krüger;Thorsten May;Tobias Schreck;Jörn Kohlhammer	Fraunhofer Institute for Computer Graphics Research Darmstadt;Fraunhofer Institute for Computer Graphics Research Darmstadt;Institute of Computer Science, Universität Bonn;Fraunhofer Institute for Computer Graphics Research Darmstadt;Data Analysis and Visualization Group, Universität Konstanz;Fraunhofer Institute for Computer Graphics Research Darmstadt	10.1109/VISUAL.1999.809865;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.120;10.1109/TVCG.2011.181;10.1109/TVCG.2011.188	Visual analytics, exploratory search, multivariate time series, motion capture data, data aggregation, cluster glyph	32	50	36	45	
InfoVis	2013	Nanocubes for Real-Time Exploration of Spatiotemporal Datasets	10.1109/TVCG.2013.179	http://dx.doi.org/10.1109/TVCG.2013.179	2456	2465	J	Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.	Lauro Didier Lins;James T. Klosowski;Carlos Scheidegger	Lauro Lins;James T. Klosowski;Carlos Scheidegger	AT&amp;T Research;AT&amp;T Research;AT&amp;T Research	10.1109/TVCG.2006.161;10.1109/INFVIS.2002.1173141;10.1109/TVCG.2009.191;10.1109/VAST.2008.4677357;10.1109/TVCG.2007.70594;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185	Data cube, Data structures, Interactive exploration	96	139	84	36	HM
SciVis	2013	Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data	10.1109/TVCG.2013.180	http://dx.doi.org/10.1109/TVCG.2013.180	2926	2935	J	Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.	Rostislav Khlebnikov;Bernhard Kainz;Markus Steinberger;Dieter Schmalstieg	Rostislav Khlebnikov;Bernhard Kainz;Markus Steinberger;Dieter Schmalstieg	Graz University of Technology;Imperial College London;Graz University of Technology;Graz University of Technology	10.1109/VISUAL.1990.146373;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2006.113;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2007.70623;10.1109/TVCG.2012.223;10.1109/VISUAL.2003.1250362	Volume rendering, multi-variate data visualization, multi-volume rendering, scientific visualization	6	8	7	29	
VAST	2013	Open-Box Spectral Clustering: Applications to Medical Image Analysis	10.1109/TVCG.2013.181	http://dx.doi.org/10.1109/TVCG.2013.181	2100	2108	J	Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.	Thomas Schultz 0001;Gordon L. Kindlmann	Thomas Schultz;Gordon L. Kindlmann	University of Bonn;University of Chicago	10.1109/VISUAL.2005.1532820;10.1109/VAST.2010.5652926;10.1109/VISUAL.2000.885740;10.1109/VAST.2012.6400488;10.1109/TVCG.2009.141;10.1109/TVCG.2009.112;10.1109/TVCG.2009.177;10.1109/TVCG.2010.199;10.1109/TVCG.2009.199;10.1109/TVCG.2011.248;10.1109/TVCG.2011.253	Image segmentation, spectral clustering, high-dimensional embeddings, linked views, programming with example	21	24	19	53	
InfoVis	2013	Orthographic Star Coordinates	10.1109/TVCG.2013.182	http://dx.doi.org/10.1109/TVCG.2013.182	2615	2624	J	Star coordinates is a popular projection technique from an nD data space to a 2D/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.	Dirk J. Lehmann;Holger Theisel	Dirk J. Lehmann;Holger Theisel	University of Magdeburg;University of Magdeburg	10.1109/VISUAL.1997.663916	Start plot, multivariate visualization, visual analytics	24	31	24	27	
InfoVis	2013	Perception of Average Value in Multiclass Scatterplots	10.1109/TVCG.2013.183	http://dx.doi.org/10.1109/TVCG.2013.183	2316	2325	J	The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots.	Michael Gleicher;Michael Correll;Christine Nothelfer;Steven Franconeri	Michael Gleicher;Michael Correll;Christine Nothelfer;Steven Franconeri	University of Wisconsin - Madison;University of Wisconsin - Madison;Northwestern University;Northwestern University	10.1109/TVCG.2012.233	Psychophysics, Information Visualization, Perceptual Study	30	40	26	59	
InfoVis	2013	Radial Sets: Interactive Visual Analysis of Large Overlapping Sets	10.1109/TVCG.2013.184	http://dx.doi.org/10.1109/TVCG.2013.184	2496	2505	J	In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.	Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;Helwig Hauser	Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;Helwig Hauser	Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;University of Bergen	10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157	Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability	34	38	25	50	
VAST	2013	ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering	10.1109/TVCG.2013.186	http://dx.doi.org/10.1109/TVCG.2013.186	2022	2031	J	The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.	Harald Bosch;Dennis Thom;Florian Heimerl;Edwin Puttmann;Steffen Koch;Robert Krüger;Michael Wörner 0001;Thomas Ertl	Harald Bosch;Dennis Thom;Florian Heimerl;Edwin Püttmann;Steffen Koch;Robert Krüger;Michael Wörner;Thomas Ertl	Visualization and Interactive Systems, University of Stuttgart;Visualization and Interactive Systems, University of Stuttgart;Visualization and Interactive Systems, University of Stuttgart;Visualization and Interactive Systems, University of Stuttgart;Visualization and Interactive Systems, University of Stuttgart;Visualization and Interactive Systems, University of Stuttgart;Visualization and Interactive Systems, University of Stuttgart;Visualization and Interactive Systems, University of Stuttgart	10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175	Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification	61	83	63	35	
InfoVis	2013	Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation	10.1109/TVCG.2013.187	http://dx.doi.org/10.1109/TVCG.2013.187	2326	2335	J	Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.	Martin Fink 0001;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff 0001	Martin Fink;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff	Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg;Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg;Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg;Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg	10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.167	Scatter plot, aspect ratio, Delaunay triangulation	17	0	18	28	
VAST	2013	Semantics of Directly Manipulating Spatializations	10.1109/TVCG.2013.188	http://dx.doi.org/10.1109/TVCG.2013.188	2052	2059	J	When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.	Xinran Hu;Lauren Bradel;Dipayan Maiti;Leanna House;Chris North;Scotland Leman	Xinran Hu;Lauren Bradel;Dipayan Maiti;Leanna House;Chris North;Scotland Leman	Virginia Tech;Virginia Tech;Virginia Tech;Virginia Tech;Virginia Tech;Virginia Tech	10.1109/VAST.2011.6102449;10.1109/INFVIS.1995.528686;10.1109/TVCG.2012.260;10.1109/VAST.2012.6400486;10.1109/VAST.2008.4677358	Visual to parametric interaction, visual analytics, statistical models	21	25	20	23	
SciVis	2013	Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates	10.1109/TVCG.2013.189	http://dx.doi.org/10.1109/TVCG.2013.189	2773	2782	J	Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.	Benjamin Köhler 0001;Rocco Gasteiger;Uta Preim;Holger Theisel;Matthias Gutberlet;Bernhard Preim	Benjamin Köhler;Rocco Gasteiger;Uta Preim;Holger Theisel;Matthias Gutberlet;Bernhard Preim	Visualization and Visual Computing, University of Magdeburg;Visualization and Visual Computing, University of Magdeburg;Herzzentrum in Leipzig;Visualization and Visual Computing, University of Magdeburg;Herzzentrum in Leipzig;Visualization and Visual Computing, University of Magdeburg	10.1109/TVCG.2011.260;10.1109/VISUAL.1999.809869;10.1109/TVCG.2010.153;10.1109/VISUAL.1999.809896;10.1109/TVCG.2011.243;10.1109/TVCG.2007.70545;10.1109/VISUAL.2004.99;10.1109/TVCG.2010.173	4D pc-mri, cardiac blood flow, hemodynamics, line predicates, vortex extraction	37	46	37	45	
VAST	2013	SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space	10.1109/TVCG.2013.190	http://dx.doi.org/10.1109/TVCG.2013.190	2060	2069	J	High-dimensional data visualization has been attracting much attention. To fully test related software and algorithms, researchers require a diverse pool of data with known and desired features. Test data do not always provide this, or only partially. Here we propose the paradigm WYDIWYGS (What You Draw Is What You Get). Its embodiment, SketchPad&lt;sup&gt;ND&lt;/sup&gt;, is a tool that allows users to generate high-dimensional data in the same interface they also use for visualization. This provides for an immersive and direct data generation activity, and furthermore it also enables users to interactively edit and clean existing high-dimensional data from possible artifacts. SketchPad&lt;sup&gt;ND&lt;/sup&gt; offers two visualization paradigms, one based on parallel coordinates and the other based on a relatively new framework using an N-D polygon to navigate in high-dimensional space. The first interface allows users to draw arbitrary profiles of probability density functions along each dimension axis and sketch shapes for data density and connections between adjacent dimensions. The second interface embraces the idea of sculpting. Users can carve data at arbitrary orientations and refine them wherever necessary. This guarantees that the data generated is truly high-dimensional. We demonstrate our tool's usefulness in real data visualization scenarios.	Bing Wang 0007;Puripant Ruchikachorn;Klaus Mueller	Bing Wang;Puripant Ruchikachorn;Klaus Mueller	Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University;Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University, and Chulalongkorn Business School, Chulalongkorn University;Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University, and SUNY Korea	10.1109/TVCG.2011.237;10.1109/VAST.2012.6400489	Synthetic data generation, data editing, data acquisition and management, multivariate data, high-dimensional data, interaction, user interface, parallel coordinates, scatterplot, N-D navigation, multiple views	12	1	9	25	
InfoVis	2013	SketchStory: Telling More Engaging Stories with Data through Freeform Sketching	10.1109/TVCG.2013.191	http://dx.doi.org/10.1109/TVCG.2013.191	2416	2425	J	Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.	Bongshin Lee;Rubaiat Habib Kazi;Greg Smith	Bongshin Lee;Rubaiat Habib Kazi;Greg Smith	Microsoft Research;National University of Singapore;Microsoft Research	10.1109/TVCG.2007.70577;10.1109/TVCG.2012.262;10.1109/TVCG.2010.179;10.1109/TVCG.2012.275;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992	Storytelling, data presentation, sketch, pen and touch, interaction, visualization	58	78	32	51	
InfoVis	2013	SoccerStories: A Kick-off for Visual Soccer Analysis	10.1109/TVCG.2013.192	http://dx.doi.org/10.1109/TVCG.2013.192	2506	2515	J	This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.	Charles Perin;Romain Vuillemot;Jean-Daniel Fekete	Charles Perin;Romain Vuillemot;Jean-Daniel Fekete	INRIA and Universite Paris-Sud;INRIA;INRIA	10.1109/TVCG.2007.70582;10.1109/TVCG.2011.169;10.1109/TVCG.2011.185;10.1109/TVCG.2012.263	Visual knowledge discovery, visual knowledge representation, sport analytics, visual aggregation	50	68	64	26	HM
VAST	2013	Space Transformation for Understanding Group Movement	10.1109/TVCG.2013.193	http://dx.doi.org/10.1109/TVCG.2013.193	2169	2178	J	We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.	Natalia V. Andrienko;Gennady L. Andrienko;Louise Barrett;Marcus Dostie;S. Peter Henzi	Natalia Andrienko;Gennady Andrienko;Louise Barrett;Marcus Dostie;Peter Henzi	Fraunhofer Institute IAIS;Fraunhofer Institute IAIS;University of Lethbridge and University of South Africa;University of Lethbridge and University of South Africa;University of Lethbridge and University of South Africa	10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.27	Visual analytics, movement data, collective movement	30	37	35	37	
VAST	2013	Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli	10.1109/TVCG.2013.194	http://dx.doi.org/10.1109/TVCG.2013.194	2129	2138	J	We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.	Kuno Kurzhals;Daniel Weiskopf	Kuno Kurzhals;Daniel Weiskopf	University of Stuttgart.;University of Stuttgart.	10.1109/TVCG.2010.149;10.1109/TVCG.2011.193;10.1109/TVCG.2012.276;10.1109/TVCG.2006.194	Eye-tracking, space-time cube, dynamic areas of interest, spatiotemporal clustering, motion-compensated heat map	40	0	32	47	
InfoVis	2013	StoryFlow: Tracking the Evolution of Stories	10.1109/TVCG.2013.196	http://dx.doi.org/10.1109/TVCG.2013.196	2436	2445	J	Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.	Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu 0014	Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu	Microsoft Research Asia;Microsoft Research Asia;Shanghai Jiao Tong University;Tsinghua University;Microsoft Research Asia	10.1109/TVCG.2012.253;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/TVCG.2011.226;10.1109/VAST.2008.4677364;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/VAST.2006.261421;10.1109/VAST.2009.5333437;10.1109/TVCG.2011.239	Storylines, story-telling visualization, user interactions, level-of-detail, optimization	69	90	67	47	
VAST	2013	Supporting Awareness through Collaborative Brushing and Linking of Tabular Data	10.1109/TVCG.2013.197	http://dx.doi.org/10.1109/TVCG.2013.197	2189	2197	J	Maintaining an awareness of collaborators' actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other's results. Can a person's brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator's actions: brushing &amp;amp; linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator's activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing &amp;amp; linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work.	Amir Hossein Hajizadeh;Melanie Tory;Rock Leung	Amir Hossein Hajizadeh;Melanie Tory;Rock Leung	University of Victoria;University of Victoria;SAP	10.1109/TVCG.2011.196;10.1109/TVCG.2007.70541;10.1109/TVCG.2011.185;10.1109/VAST.2010.5652880;10.1109/INFVIS.2003.1249020;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102447	Collaboration, awareness, attentionally ambient visualization, brushing and linking, linked views, user study	9	14	9	36	
VAST	2013	Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes	10.1109/TVCG.2013.198	http://dx.doi.org/10.1109/TVCG.2013.198	2267	2276	J	The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.	Steffen Hadlak;Heidrun Schumann;Clemens H. Cap;Till Wollenberg	Steffen Hadlak;Heidrun Schumann;Clemens H. Cap;Till Wollenberg	University of Rostock;University of Rostock;University of Rostock;University of Rostock	10.1109/INFVIS.2005.1532151;10.1109/VAST.2010.5652530;10.1109/INFVIS.2004.18;10.1109/TVCG.2011.226;10.1109/TVCG.2011.213;10.1109/TVCG.2006.193;10.1109/VAST.2012.6400493;10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70529;10.1109/INFVIS.2002.1173160	Dynamic networks, visualization, supergraph clustering	14	22	16	34	
VAST	2013	Temporal Event Sequence Simplification	10.1109/TVCG.2013.200	http://dx.doi.org/10.1109/TVCG.2013.200	2227	2236	J	Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.	Megan Monroe;Rongjian Lan;Hanseung Lee;Catherine Plaisant;Ben Shneiderman	Megan Monroe;Rongjian Lan;Hanseung Lee;Catherine Plaisant;Ben Shneiderman	Department of Computer Science &amp; Human-Computer Interaction Lab, University of Maryland;Department of Computer Science &amp; Human-Computer Interaction Lab, University of Maryland;Department of Computer Science &amp; Human-Computer Interaction Lab, University of Maryland;Department of Computer Science &amp; Human-Computer Interaction Lab, University of Maryland;Department of Computer Science &amp; Human-Computer Interaction Lab, University of Maryland	10.1109/TVCG.2009.117;10.1109/TVCG.2012.213;10.1109/VAST.2010.5652890	Event sequences, simplification, electronic heath records, temporal query	102	139	104	33	HM
VAST	2013	The Impact of Physical Navigation on Spatial Organization for Sensemaking	10.1109/TVCG.2013.205	http://dx.doi.org/10.1109/TVCG.2013.205	2207	2216	J	Spatial organization has been proposed as a compelling approach to externalizing the sensemaking process. However, there are two ways in which space can be provided to the user: by creating a physical workspace that the user can interact with directly, such as can be provided by a large, high-resolution display, or through the use of a virtual workspace that the user navigates using virtual navigation techniques such as zoom and pan. In this study we explicitly examined the use of spatial sensemaking techniques within these two environments. The results demonstrate that these two approaches to providing sensemaking space are not equivalent, and that the greater embodiment afforded by the physical workspace changes how the space is perceived and used, leading to increased externalization of the sensemaking process.	Christopher Andrews;Chris North	Christopher Andrews;Chris North	Middlebury College;Virginia Tech	10.1109/VAST.2012.6400559;10.1109/VAST.2008.4677358;10.1109/VAST.2009.5333878	Sensemaking, visual analytics, physical navigation, embodiment, large and high-resolution displays	9	13	8	32	
VAST	2013	TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data	10.1109/TVCG.2013.206	http://dx.doi.org/10.1109/TVCG.2013.206	2247	2256	J	Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.	Alexander Rind;Tim Lammarsch;Wolfgang Aigner;Bilal Alsallakh;Silvia Miksch	Alexander Rind;Tim Lammarsch;Wolfgang Aigner;Bilal Alsallakh;Silvia Miksch	Vienna University of Technology, Institute of Software Technology & Interactive Systems;Vienna University of Technology, Institute of Software Technology & Interactive Systems;Vienna University of Technology, Institute of Software Technology & Interactive Systems;Vienna University of Technology, Institute of Software Technology & Interactive Systems;Vienna University of Technology, Institute of Software Technology & Interactive Systems	10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102446;10.1109/VAST.2006.261428;10.1109/INFVIS.2000.885086;10.1109/TVCG.2010.144;10.1109/TVCG.2006.178;10.1109/INFVIS.2004.64;10.1109/TVCG.2013.222;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.185;10.1109/TVCG.2010.126;10.1109/INFVIS.1997.636792	Visual Analytics, information visualization, toolkits, software infrastructure, time, temporal data	13	16	13	52	
VAST	2013	Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop	10.1109/TVCG.2013.207	http://dx.doi.org/10.1109/TVCG.2013.207	2109	2118	J	Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.	Philip A. Legg;David H. S. Chung;Matthew L. Parry;Rhodri Bown;Mark W. Jones;Iwan W. Griffiths;Min Chen 0001	Philip A. Legg;David H.S. Chung;Matthew L. Parry;Rhodri Bown;Mark W. Jones;Iwan W. Griffiths;Min Chen	Department of Computer Science, Swansea University, University of Oxford;Department of Computer Science, Swansea University;Department of Computer Science, Swansea University;Welsh Rugby Union;Department of Computer Science, Swansea University;Department of Engineering, Swansea University;e-Research Centre, University of Oxford	10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208	Visual knowledge discovery, data clustering, machine learning, multimedia visualization	11	18	16	42	
SciVis	2013	Uncertainty Quantification in Linear Interpolation for Isosurface Extraction	10.1109/TVCG.2013.208	http://dx.doi.org/10.1109/TVCG.2013.208	2723	2732	J	We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.	Tushar M. Athawale;Alireza Entezari	Tushar Athawale;Alireza Entezari	University of Florida;University of Florida	10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70602;10.1109/VISUAL.1991.175782;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1996.568116;10.1109/TVCG.2009.194;10.1109/TVCG.2011.203	Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes	13	0	19	36	
InfoVis	2013	Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization	10.1109/TVCG.2013.209	http://dx.doi.org/10.1109/TVCG.2013.209	2526	2535	J	Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.	Rahul C. Basole;Trustin Clear;Mengdie Hu;Harshit Mehrotra;John T. Stasko	Rahul C. Basole;Trustin Clear;Mengdie Hu;Harshit Mehrotra;John Stasko	Georgia Tech;Georgia Tech;Georgia Tech;Georgia Tech;Georgia Tech	10.1109/TVCG.2006.160;10.1109/INFVIS.2005.1532134;10.1109/INFVIS.2003.1249027;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652530;10.1109/TVCG.2006.166	Business ecosystems, market research, strategic analysis, design study, interaction, network visualization	26	33	30	51	
InfoVis	2013	Using Concrete Scales: A Practical Framework for Effective Visual Depiction of Complex Measures	10.1109/TVCG.2013.210	http://dx.doi.org/10.1109/TVCG.2013.210	2426	2435	J	From financial statistics to nutritional values, we are frequently exposed to quantitative information expressed in measures of either extreme magnitudes or unfamiliar units, or both. A common practice used to comprehend such complex measures is to relate, re-express, and compare them through visual depictions using magnitudes and units that are easier to grasp. Through this practice, we create a new graphic composition that we refer to as a concrete scale. To the best of our knowledge, there are no design guidelines that exist for concrete scales despite their common use in communication, educational, and decision-making settings. We attempt to fill this void by introducing a novel framework that would serve as a practical guide for their analysis and design. Informed by a thorough analysis of graphic compositions involving complex measures and an extensive literature review of scale cognition mechanisms, our framework outlines the design space of various measure relations-specifically relations involving the re-expression of complex measures to more familiar concepts-and their visual representations as graphic compositions.	Fanny Chevalier;Romain Vuillemot;Guia Gali	Fanny Chevalier;Romain Vuillemot;Guia Gali	University of Toronto &amp; OCAD University;INRIA;independant graphic designer and researcher	10.1109/TVCG.2012.199	Concrete scale, scale cognition, visual comparison, graphic composition, visual notation	15	16	8	41	
VAST	2013	Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design	10.1109/TVCG.2013.211	http://dx.doi.org/10.1109/TVCG.2013.211	2217	2226	J	This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.	Neesha Kodagoda;Simon Attfield;B. L. William Wong;Chris Rooney;Sharmin (Tinni) Choudhury	Neesha Kodagoda;Simon Attfield;B.L. William Wong;Chris Rooney;Sharmin Choudhury	School of Science and Technology, Middlesex University;School of Science and Technology, Middlesex University;School of Science and Technology, Middlesex University;School of Science and Technology, Middlesex University;School of Science and Technology, Middlesex University	10.1109/VAST.2009.5333020;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.252	Visual analytics, sense-making, dataframe mode, evaluation, reasoning, analysis, interaction, interface design	11	14	8	36	
VAST	2013	UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization	10.1109/TVCG.2013.212	http://dx.doi.org/10.1109/TVCG.2013.212	1992	2001	J	Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.	Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park	Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park	Georgia Institute of Technology;Georgia Institute of Technology;Wayne State University;Georgia Institute of Technology	10.1109/TVCG.2012.258;10.1109/VAST.2009.5332629;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4388999;10.1109/VAST.2007.4389006;10.1109/TVCG.2008.138;10.1109/VAST.2010.5652443	Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics	91	126	87	36	
VAST	2013	VAICo: Visual Analysis for Image Comparison	10.1109/TVCG.2013.213	http://dx.doi.org/10.1109/TVCG.2013.213	2090	2099	J	Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.	Johanna Schmidt;M. Eduard Gröller;Stefan Bruckner	Johanna Schmidt;M. Eduard Gröller;Stefan Bruckner	Vienna University of Technology;Vienna University of Technology;University of Bergen	10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70623;10.1109/VAST.2012.6400555;10.1109/TVCG.2010.190;10.1109/VISUAL.1999.809871;10.1109/VISUAL.1999.809873;10.1109/TVCG.2011.248;10.1109/VISUAL.2002.1183790	Comparative visualization, focus+context visualization, image set comparison	16	23	23	41	
InfoVis	2013	Variant View: Visualizing Sequence Variants in their Gene Context	10.1109/TVCG.2013.214	http://dx.doi.org/10.1109/TVCG.2013.214	2546	2555	J	Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.	Joel A. Ferstay;Cydney B. Nielsen;Tamara Munzner	Joel A. Ferstay;Cydney B. Nielsen;Tamara Munzner	University of British Columbia;University of British Columbia;University of British Columbia	10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/TVCG.2012.213;10.1109/TVCG.2011.185;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.116;10.1109/TVCG.2009.167;10.1109/TVCG.2011.209	Information visualization, design study, bioinformatics, genetic variants	15	17	13	36	
SciVis	2013	Vessel Visualization using Curved Surface Reformation	10.1109/TVCG.2013.215	http://dx.doi.org/10.1109/TVCG.2013.215	2858	2867	J	Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.	Thomas Auzinger;Gabriel Mistelbauer;Ivan Baclija;Rüdiger Schernthaner;Arnold Köchl;Michael Wimmer;M. Eduard Gröller;Stefan Bruckner	Thomas Auzinger;Gabriel Mistelbauer;Ivan Baclija;Rüdiger Schernthaner;Arnold Köchl;Michael Wimmer;M. Eduard Gröller;Stefan Bruckner	Vienna University of Technology;Vienna University of Technology;Kaiser-Franz-Josef Hospital Vienna;Medical University of Vienna;Landesklinikum Tulln;Vienna University of Technology;Vienna University of Technology;University of Bergen	10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555	Reformation, volume rendering, surface approximation	13	12	7	40	
VAST	2013	Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations	10.1109/TVCG.2013.219	http://dx.doi.org/10.1109/TVCG.2013.219	1982	1991	J	For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.	Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;E. Yanli	Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;Yanli E.	School of Computer Software and Information Technology Research Center for Cultural Heritage Conservation and Promotion, Tianjin University;School of Computer Software, Tianjin University;School of Computer Software, Tianjin University;School of Computer Software, Tianjin University;School of Computer Software, Tianjin University	10.1109/TVCG.2011.239;10.1109/INFVIS.2004.1;10.1109/TVCG.2008.173;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147;10.1109/TVCG.2012.244;10.1109/VAST.2007.4389013;10.1109/TVCG.2008.153;10.1109/INFVIS.2000.885098	Cultural heritage, wall paintings, degradation, visual analytics	8	10	7	46	
VAST	2013	Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System	10.1109/TVCG.2013.220	http://dx.doi.org/10.1109/TVCG.2013.220	2070	2079	J	Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.	Rachel Shadoan;Chris Weaver	Rachel Shadoan;Chris Weaver	Akashic Labs LLC;School of Computer Science and the Center for Spatial Analysis at University of Oklahoma	10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102440;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652520	Graph search, graph query language, multidimensional data, attribute relationship graphs, multivariate data analysis, higher-order conjunctive queries, visual query language, digital humanities	4	9	8	30	
VAST	2013	Visual Analysis of Topic Competition on Social Media	10.1109/TVCG.2013.221	http://dx.doi.org/10.1109/TVCG.2013.221	2012	2021	J	How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.	Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J. H. Zhu;Huamin Qu	Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J.H. Zhu;Huamin Qu	Hong Kong University of Science and Technology;Microsoft Research Asia;Shanghai Jiao Tong University;Nanyang Technological University;Microsoft Research Asia;City University of Hong Kong;Hong Kong University of Science and Technology	10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2012.225;10.1109/VAST.2009.5333437;10.1109/TVCG.2010.194;10.1109/TVCG.2012.291;10.1109/VAST.2010.5652931;10.1109/TVCG.2013.196;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.212;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/INFVIS.1999.801851	Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting	61	78	53	50	
VAST	2013	Visual Analytics for Model Selection in Time Series Analysis	10.1109/TVCG.2013.222	http://dx.doi.org/10.1109/TVCG.2013.222	2237	2246	J	Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.	Markus Bögl;Wolfgang Aigner;Peter Filzmoser;Tim Lammarsch;Silvia Miksch;Alexander Rind	Markus Bögl;Wolfgang Aigner;Peter Filzmoser;Tim Lammarsch;Silvia Miksch;Alexander Rind	Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology	10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539	Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views	19	24	21	42	
VAST	2013	Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists	10.1109/TVCG.2013.223	http://dx.doi.org/10.1109/TVCG.2013.223	2032	2041	J	Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.	Sohaib Ghani;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Niklas Elmqvist	Sohaib Ghani;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Niklas Elmqvist	School of Electrical and Computer Engineering, Purdue University;School of Industrial Engineering, Purdue University;Brian Lamb School of Communication, Purdue University;School of Industrial Engineering, Purdue University;School of Electrical and Computer Engineering, Purdue University	10.1109/TVCG.2011.247;10.1109/VAST.2011.6102440;10.1109/TVCG.2012.213;10.1109/TVCG.2011.201;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70521;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70535;10.1109/INFVIS.2002.1173155;10.1109/VAST.2006.261430;10.1109/TVCG.2006.166;10.1109/TVCG.2011.209	Design study, user-centered design, node-link diagrams, multimodal graphs, interaction, qualitative evaluation	24	36	31	55	
VAST	2013	Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration	10.1109/TVCG.2013.224	http://dx.doi.org/10.1109/TVCG.2013.224	2179	2188	J	We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data.	Eli Packer;Peter Bak;Mikko Nikkilä;Valentin Polishchuk;Harold J. Ship	Eli Packer;Peter Bak;Mikko Nikkilä;Valentin Polishchuk;Harold J. Ship	IBM Research – Haifa / Israel, Smarter Decision Solutions Group;IBM Research – Haifa / Israel, Smarter Decision Solutions Group;Helsinki Institute for Information Technology, Computer Science Department, University of Helsinki, Finland;Helsinki Institute for Information Technology, Computer Science Department, University of Helsinki, Finland;IBM Research – Haifa / Israel, Smarter Decision Solutions Group	10.1109/VAST.2011.6102449;10.1109/INFVIS.2003.1249015;10.1109/VAST.2012.6400486;10.1109/TVCG.2009.122;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.186	Heuristic-based spatial clustering, interactive visual clustering, k-order a-(alpha)-shapes	6	9	6	38	
InfoVis	2013	Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs	10.1109/TVCG.2013.225	http://dx.doi.org/10.1109/TVCG.2013.225	2576	2585	J	This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.	Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen 0001	Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen	University of Oxford;University of Oxford;University of Oxford;University of Oxford;University of Oxford	10.1109/TVCG.2007.70584;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.147;10.1109/TVCG.2009.195;10.1109/TVCG.2012.271;10.1109/VISUAL.1996.567752;10.1109/TVCG.2008.174;10.1109/TVCG.2006.166	Workflow visualization, motif detection, glyph-based visualization, glyph generation, state-transition-based algorithm	17	21	17	42	
VAST	2013	Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips	10.1109/TVCG.2013.226	http://dx.doi.org/10.1109/TVCG.2013.226	2149	2158	J	As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.	Nivan Ferreira;Jorge Poco;Huy T. Vo;Juliana Freire;Cláudio T. Silva	Nivan Ferreira;Jorge Poco;Huy T. Vo;Juliana Freire;Cláudio T. Silva	NYU Poly;NYU Poly;NYU CUSP;NYU Poly;NYU Poly and NYU CUSP	10.1109/INFVIS.2004.12;10.1109/VAST.2008.4677356;10.1109/VAST.2011.6102454;10.1109/TVCG.2007.70535;10.1109/VAST.2010.5652467;10.1109/INFVIS.2005.1532150;10.1109/VAST.2008.4677370;10.1109/INFVIS.2000.885086	Spatio-temporal queries, urban data, taxi movement data, visual exploration	184	267	220	40	
InfoVis	2013	Visual Sedimentation	10.1109/TVCG.2013.227	http://dx.doi.org/10.1109/TVCG.2013.227	2446	2455	J	We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.	Samuel Huron;Romain Vuillemot;Jean-Daniel Fekete	Samuel Huron;Romain Vuillemot;Jean-Daniel Fekete	INRIA;INRIA;INRIA	10.1109/VAST.2012.6400552;10.1109/TVCG.2012.291;10.1109/TVCG.2011.179;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.185;10.1109/TVCG.2008.166;10.1109/TVCG.2008.171;10.1109/INFVIS.2004.65;10.1109/TVCG.2007.70539	Design, Information Visualization, Dynamic visualization, Dynamic data, Data stream, Real time, Metaphor	32	40	33	42	
VAST	2013	Visual Traffic Jam Analysis Based on Trajectory Data	10.1109/TVCG.2013.228	http://dx.doi.org/10.1109/TVCG.2013.228	2159	2168	J	In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.	Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering	Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering	Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, and Center for Computational Science and Engineering, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, and Center for Computational Science and Engineering, Peking University;Shanghai Key Laboratory of Intelligent Information Processing, and School of Computer Science, Fudan University;Department of Mathematics and Computer Science, Technische Universiteit Eindhoven	10.1109/VISUAL.1997.663866;10.1109/VAST.2011.6102454;10.1109/TVCG.2009.145;10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400553;10.1109/TVCG.2012.265;10.1109/TVCG.2011.181;10.1109/VAST.2009.5332593;10.1109/TVCG.2008.125;10.1109/VAST.2011.6102455	Traffic visualization, traffic jam propagation	121	0	138	54	
SciVis	2013	Visualization of Morse Connection Graphs for Topologically Rich 2D Vector fields	10.1109/TVCG.2013.229	http://dx.doi.org/10.1109/TVCG.2013.229	2763	2772	J	Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.	Andrzej Szymczak;Levente Sipeki	Andrzej Szymczak;Levente Sipeki	Colorado School of Mines;Colorado School of Mines	10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2012.209;10.1109/VISUAL.2000.885716	Morse connection graph, vector field topology	1	1	1	34	
InfoVis	2013	Visualization of Shape Motions in Shape Space	10.1109/TVCG.2013.230	http://dx.doi.org/10.1109/TVCG.2013.230	2644	2652	J	Analysis of dynamic object deformations such as cardiac motion is of great importance, especially when there is a necessity to visualize and compare the deformation behavior across subjects. However, there is a lack of effective techniques for comparative visualization and assessment of a collection of motion data due to its 4-dimensional nature, i.e., timely varying three-dimensional shapes. From the geometric point of view, the motion change can be considered as a function defined on the 2D manifold of the surface. This paper presents a novel classification and visualization method based on a medial surface shape space, in which two novel shape descriptors are defined, for discriminating normal and abnormal human heart deformations as well as localizing the abnormal motion regions. In our medial surface shape space, the geodesic distance connecting two points in the space measures the similarity between their corresponding medial surfaces, which can quantify the similarity and disparity of the 3D heart motions. Furthermore, the novel descriptors can effectively localize the inconsistently deforming myopathic regions on the left ventricle. An easy visualization of heart motion sequences on the projected space allows users to distinguish the deformation differences. Our experimental results on both synthetic and real imaging data show that this method can automatically classify the healthy and myopathic subjects and accurately detect myopathic regions on the left ventricle, which outperforms other conventional cardiac diagnostic methods.	Vahid Taimouri;Jing Hua	Vahid Taimouri;Jing Hua	Wayne State University and Children’s Hospital Boston, Harvard Medical School;Wayne State University	10.1109/TVCG.2006.137;10.1109/INFVIS.2003.1249025;10.1109/TVCG.2009.159;10.1109/INFVIS.2004.65	Medial surface, shape space, comparative visualization, left ventricle diagnosis	2	3	5	43	
InfoVis	2013	Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView	10.1109/TVCG.2013.231	http://dx.doi.org/10.1109/TVCG.2013.231	2566	2575	J	To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node's actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu.	John Alexis Guerra Gómez;Michael L. Pack;Catherine Plaisant;Ben Shneiderman	JohnAlexis Guerra-Gómez;Michael L. Pack;Catherine Plaisant;Ben Shneiderman	University of Maryland;University of Maryland;University of Maryland;University of Maryland	10.1109/VAST.2011.6102439;10.1109/TVCG.2006.147;10.1109/TVCG.2011.185;10.1109/VISUAL.1991.175815;10.1109/TVCG.2007.70556;10.1109/INFVIS.2002.1173150;10.1109/VAST.2006.261450;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2003.1249026;10.1109/TVCG.2007.70529	Information visualization, Tree comparison	19	24	15	45	
InfoVis	2013	Visualizing Fuzzy Overlapping Communities in Networks	10.1109/TVCG.2013.232	http://dx.doi.org/10.1109/TVCG.2013.232	2486	2495	J	An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.	Corinna Vehlow;Thomas Reinhardt;Daniel Weiskopf	Corinna Vehlow;Thomas Reinhardt;Daniel Weiskopf	VISUS, University of Stuttgart;University of Stuttgart;VISUS, University of Stuttgart	10.1109/VISUAL.1993.398872;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2004.43;10.1109/TVCG.2009.113	Overlapping community visualization, fuzzy clustering, graph visualization, uncertainty visualization	24	27	23	53	
InfoVis	2013	Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems	10.1109/TVCG.2013.233	http://dx.doi.org/10.1109/TVCG.2013.233	2466	2475	J	Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system's many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.	Raja R. Sambasivan;Ilari Shafer;Michelle L. Mazurek;Gregory R. Ganger	Raja R. Sambasivan;Ilari Shafer;Michelle L. Mazurek;Gregory R. Ganger	Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University	10.1109/VAST.2010.5652910;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/VAST.2011.6102442	Distributed systems, human factors, problem diagnosis, visualization	4	5	3	37	
InfoVis	2013	What Makes a Visualization Memorable?	10.1109/TVCG.2013.234	http://dx.doi.org/10.1109/TVCG.2013.234	2306	2315	J	An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.	Michelle Borkin;Azalea A. Vo;Zoya Bylinskii;Phillip Isola;Shashank Sunkavalli;Aude Oliva;Hanspeter Pfister	Michelle A. Borkin;Azalea A. Vo;Zoya Bylinskii;Phillip Isola;Shashank Sunkavalli;Aude Oliva;Hanspeter Pfister	Harvard University;Harvard University;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Harvard University;Massachusetts Institute of Technology;Harvard University	10.1109/TVCG.2012.221;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/TVCG.2012.245;10.1109/TVCG.2011.175	Visualization taxonomy, information visualization, memorability	126	0	122	39	
InfoVis	2014	UpSet: Visualization of Intersecting Sets	10.1109/TVCG.2014.2346248	http://dx.doi.org/10.1109/TVCG.2014.2346248	1983	1992	J	Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.	Alexander Lex;Nils Gehlenborg;Hendrik Strobelt;Romain Vuillemot;Hanspeter Pfister	Alexander Lex;Nils Gehlenborg;Hendrik Strobelt;Romain Vuillemot;Hanspeter Pfister	Hendrik Strobelt and Hanspeter Pfister are with Harvard University.;Harvard Medical School;Hendrik Strobelt and Hanspeter Pfister are with Harvard University.;Romain Vuillemot is with Harvard University;Hendrik Strobelt and Hanspeter Pfister are with Harvard University.	10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183	Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data	133	335	328	29	
InfoVis	2014	OnSet: A Visualization Technique for Large-scale Binary Set Data	10.1109/TVCG.2014.2346249	http://dx.doi.org/10.1109/TVCG.2014.2346249	1993	2002	J	Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task and event scheduling.	Ramik Sadana;Timothy Major;Alistair D. M. Dove;John T. Stasko	Ramik Sadana;Timothy Major;Alistair Dove;John Stasko	Georgia Tech.;Georgia Tech.;Georgia Aquarium;Georgia Tech.	10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/TVCG.2013.184	Set visualization, information visualization, direct manipulation, Euler diagrams, interaction, logical operations	24	27	26	23	
InfoVis	2014	DimpVis: Exploring Time-varying Information Visualizations by Direct Manipulation	10.1109/TVCG.2014.2346250	http://dx.doi.org/10.1109/TVCG.2014.2346250	2003	2012	J	We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks.	Brittany Kondo;Christopher Collins 0001	Brittany Kondo;Christopher Collins	University of Ontario Institute of Technology;University of Ontario Institute of Technology	10.1109/TVCG.2013.147;10.1109/TVCG.2012.204;10.1109/TVCG.2012.260;10.1109/TVCG.2008.175;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.265;10.1109/TVCG.2013.149;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.185;10.1109/TVCG.2008.125;10.1109/TVCG.2011.195	Time navigation, direct manipulation, information visualization	17	28	24	33	
InfoVis	2014	Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots	10.1109/TVCG.2014.2346258	http://dx.doi.org/10.1109/TVCG.2014.2346258	2013	2022	J	Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.	Manuel Rubio-Sánchez;Alberto Sánchez 0001	Manuel Rubio-Sánchez;Alberto Sanchez	URJC;URJC	10.1109/TVCG.2010.209;10.1109/TVCG.2013.182;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1997.663916	Star Coordinates, RadViz, Biplots, Axis calibration, Attribute value estimation, Data centering, Orthographic projection	11	12	9	25	
InfoVis	2014	Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets	10.1109/TVCG.2014.2346260	http://dx.doi.org/10.1109/TVCG.2014.2346260	2023	2032	J	Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.	Samuel Gratzl;Nils Gehlenborg;Alexander Lex;Hanspeter Pfister;Marc Streit	Samuel Gratzl;Nils Gehlenborg;Alexander Lex;Hanspeter Pfister;Marc Streit	Johannes Kepler University Linz;Harvard Medical School;Harvard University;Harvard University;Johannes Kepler University Linz	10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2012.207;10.1109/TVCG.2011.250;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.173;10.1109/TVCG.2011.183;10.1109/TVCG.2013.160;10.1109/TVCG.2011.201;10.1109/TVCG.2006.166;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2004.15;10.1109/TVCG.2007.70521	Multiple coordinated views, visual linking, relationships, heterogeneous data, categorical data	23	32	28	37	HM
InfoVis	2014	Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data	10.1109/TVCG.2014.2346265	http://dx.doi.org/10.1109/TVCG.2014.2346265	2033	2042	J	The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.	Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes	Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes	Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK;Department of Informatics at University of Bergen, Bergen, Norway;Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK	10.1109/TVCG.2013.173;10.1109/TVCG.2011.178;10.1109/TVCG.2013.226;10.1109/TVCG.2011.197;10.1109/TVCG.2007.70558;10.1109/TVCG.2008.149;10.1109/INFVIS.2004.12;10.1109/TVCG.2012.256;10.1109/TVCG.2007.70574;10.1109/VAST.2008.4677350;10.1109/TVCG.2008.125;10.1109/TVCG.2013.122	Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis	23	24	18	54	
InfoVis	2014	Origin-Destination Flow Data Smoothing and Mapping	10.1109/TVCG.2014.2346271	http://dx.doi.org/10.1109/TVCG.2014.2346271	2043	2052	J	This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.	Diansheng Guo;Xi Zhu 0002	Diansheng Guo;Xi Zhu	Department of Geography, University of South Carolina;Department of Geography, University of South Carolina	10.1109/TVCG.2009.143;10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2011.202;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2011.181;10.1109/VISUAL.2005.1532819	flow mapping, kernel smoothing, generalization, multi-resolution mapping, graph drawing, spatial data mining	45	58	57	45	
InfoVis	2014	Stenomaps: Shorthand for shapes	10.1109/TVCG.2014.2346274	http://dx.doi.org/10.1109/TVCG.2014.2346274	2053	2062	J	We address some of the challenges in representing spatial data with a novel form of geometric abstraction-the stenomap. The stenomap comprises a series of smoothly curving linear glyphs that each represent both the boundary and the area of a polygon. We present an efficient algorithm to automatically generate these open, C&lt;sup&gt;1&lt;/sup&gt;-continuous splines from a set of input polygons. Feature points of the input polygons are detected using the medial axis to maintain important shape properties. We use dynamic programming to compute a planar non-intersecting spline representing each polygon's base shape. The results are stylised glyphs whose appearance may be parameterised and that offer new possibilities in the 'cartographic design space'. We compare our glyphs with existing forms of geometric schematisation and discuss their relative merits and shortcomings. We describe several use cases including the depiction of uncertain model data in the form of hurricane track forecasting; minimal ink thematic mapping; and the depiction of continuous statistical data.	Arthur van Goethem;Andreas Reimer;Bettina Speckmann;Jo Wood	Arthur van Goethem;Andreas Reimer;Bettina Speckmann;Jo Wood	TU Eindhoven;Universität Heidelberg;TU Eindhoven;City University London	10.1109/INFVIS.2005.1532145	Schematisation, Maps, Algorithm, Design	0	0	0	40	
InfoVis	2014	Nmap: A Novel Neighborhood Preservation Space-filling Algorithm	10.1109/TVCG.2014.2346276	http://dx.doi.org/10.1109/TVCG.2014.2346276	2063	2071	J	Space-filling techniques seek to use as much as possible the visual space to represent a dataset, splitting it into regions that represent the data elements. Amongst those techniques, Treemaps have received wide attention due to its simplicity, reduced visual complexity, and compact use of the available space. Several different Treemap algorithms have been proposed, however the core idea is the same, to divide the visual space into rectangles with areas proportional to some data attribute or weight. Although pleasant layouts can be effectively produced by the existing techniques, most of them do not take into account relationships that might exist between different data elements when partitioning the visual space. This violates the distance-similarity metaphor, that is, close rectangles do not necessarily represent similar data elements. In this paper, we propose a novel approach, called Neighborhood Treemap (Nmap), that seeks to solve this limitation by employing a slice and scale strategy where the visual space is successively bisected on the horizontal or vertical directions and the bisections are scaled until one rectangle is defined per data element. Compared to the current techniques with the same similarity preservation goal, our approach presents the best results while being two to three orders of magnitude faster. The usefulness of Nmap is shown by two applications involving the organization of document collections and the construction of cartograms illustrating its effectiveness on different scenarios.	Felipe S. L. G. Duarte;Fabio Sikansi;Francisco M. Fatore;Samuel G. Fadel;Fernando Vieira Paulovich	Felipe S. L. G. Duarte;Fabio Sikansi;Francisco M. Fatore;Samuel G. Fadel;Fernando V. Paulovich	Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532145;10.1109/TVCG.2007.70522;10.1109/TVCG.2009.128;10.1109/TVCG.2007.70529;10.1109/VISUAL.1991.175815;10.1109/TVCG.2008.165	Space-filling techniques, treemaps, distance-similarity preservation	9	15	14	24	
InfoVis	2014	Tree Colors: Color Schemes for Tree-Structured Data	10.1109/TVCG.2014.2346277	http://dx.doi.org/10.1109/TVCG.2014.2346277	2072	2081	J	We present a method to map tree structures to colors from the Hue-Chroma-Luminance color model, which is known for its well balanced perceptual properties. The Tree Colors method can be tuned with several parameters, whose effect on the resulting color schemes is discussed in detail. We provide a free and open source implementation with sensible parameter defaults. Categorical data are very common in statistical graphics, and often these categories form a classification tree. We evaluate applying Tree Colors to tree structured data with a survey on a large group of users from a national statistical institute. Our user study suggests that Tree Colors are useful, not only for improving node-link diagrams, but also for unveiling tree structure in non-hierarchical visualizations.	Martijn Tennekes;Edwin de Jonge	Martijn Tennekes;Edwin de Jonge	Statistics Netherlands;Statistics Netherlands	10.1109/TVCG.2011.193;10.1109/INFVIS.2000.885091;10.1109/INFVIS.2002.1173151	Color schemes, statistical graphics, hierarchical data	18	31	24	34	
InfoVis	2014	Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations	10.1109/TVCG.2014.2346279	http://dx.doi.org/10.1109/TVCG.2014.2346279	2082	2091	J	We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to “simplify without destroying” by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER	Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete	Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete	INRIA;INRIA;INRIA	10.1109/TVCG.2006.160;10.1109/TVCG.2014.2346292;10.1109/TVCG.2014.2346426	Visualization, Interaction, Tabular Data, Bertin, Crossing, Crossets	41	56	41	60	
InfoVis	2014	iVisDesigner: Expressive Interactive Design of Information Visualizations	10.1109/TVCG.2014.2346291	http://dx.doi.org/10.1109/TVCG.2014.2346291	2092	2101	J	We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.	Donghao Ren;Tobias Höllerer;Xiaoru Yuan	Donghao Ren;Tobias Höllerer;Xiaoru Yuan	Department of Computer Science, University of California, Santa Barbara;Department of Computer Science, University of California, Santa Barbara;Key Laboratory of Machine Perception (Ministry of Education), School of EECS	10.1109/INFVIS.2004.12;10.1109/TVCG.2010.144;10.1109/TVCG.2009.179;10.1109/TVCG.2009.174;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2010.126;10.1109/TVCG.2013.191;10.1109/INFVIS.1997.636792;10.1109/TVCG.2011.201;10.1109/TVCG.2011.261;10.1109/TVCG.2012.275;10.1109/INFVIS.1997.636761	Visualization design, Interactive Design, Interaction, Expressiveness, Web-based visualization	31	48	34	40	
InfoVis	2014	Constructing Visual Representations: Investigating the Use of Tangible Tokens	10.1109/TVCG.2014.2346292	http://dx.doi.org/10.1109/TVCG.2014.2346292	2102	2111	J	The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants' actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring.	Samuel Huron;Yvonne Jansen;Sheelagh Carpendale	Samuel Huron;Yvonne Jansen;Sheelagh Carpendale	Inria and IRI;Inria and University of Copenhagen;University of Calgary	10.1109/TVCG.2009.176;10.1109/TVCG.2011.185;10.1109/TVCG.2013.227;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2011.251;10.1109/VISUAL.1997.663890;10.1109/TVCG.2012.275;10.1109/TVCG.2013.134;10.1109/TVCG.2010.164;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.199	Constructive visualization, Physical visualization, Dynamic visualization, Empirical study, Token, Visualization authoring, Information visualization, Visual mapping, Novices, Visualization construction, Visual analytics	29	42	26	57	
InfoVis	2014	PanoramicData: Data Analysis through Pen & Touch	10.1109/TVCG.2014.2346293	http://dx.doi.org/10.1109/TVCG.2014.2346293	2112	2121	J	Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.	Emanuel Zgraggen;Robert C. Zeleznik;Steven Mark Drucker	Emanuel Zgraggen;Robert Zeleznik;Steven M. Drucker	Brown University;Brown University;Microsoft Research	10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.162;10.1109/TVCG.2010.164;10.1109/TVCG.2011.251;10.1109/TVCG.2013.191;10.1109/TVCG.2012.275;10.1109/VAST.2007.4389013;10.1109/TVCG.2013.150;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.137;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70594;10.1109/TVCG.2012.204	Visual analytics, pen and touch, user interfaces, interaction design, coordinated and multiple views	11	21	10	38	
InfoVis	2014	Visualizing Statistical Mix Effects and Simpson's Paradox	10.1109/TVCG.2014.2346297	http://dx.doi.org/10.1109/TVCG.2014.2346297	2132	2141	J	We discuss how “mix effects” can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as “omitted variable bias” or, in extreme cases, as “Simpson's paradox”) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the “comet chart,” that is meant to ameliorate some of these issues.	Zan Armstrong;Martin Wattenberg	Zan Armstrong;Martin Wattenberg	Google at the time of research, currently unaffiliated;Google	10.1109/TVCG.2012.213;10.1109/TVCG.2007.70577	Mix effects, Omitted variable bias, Simpson's paradox, Statistics	3	6	4	34	
InfoVis	2014	Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error	10.1109/TVCG.2014.2346298	http://dx.doi.org/10.1109/TVCG.2014.2346298	2142	2151	J	When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars.	Michael Correll;Michael Gleicher	Michael Correll;Michael Gleicher	Department of Computer Sciences, University of Wisconsin-Madison;Department of Computer Sciences, University of Wisconsin-Madison	10.1109/TVCG.2012.220;10.1109/TVCG.2012.199;10.1109/TVCG.2012.262;10.1109/TVCG.2011.175;10.1109/TVCG.2012.279	Visual statistics, information visualization, crowd-sourcing, empirical evaluation	50	71	54	35	
InfoVis	2014	MovExp: A Versatile Visualization Tool for Human-Computer Interaction Studies with 3D Performance and Biomechanical Data	10.1109/TVCG.2014.2346311	http://dx.doi.org/10.1109/TVCG.2014.2346311	2359	2368	J	In Human-Computer Interaction (HCI), experts seek to evaluate and compare the performance and ergonomics of user interfaces. Recently, a novel cost-efficient method for estimating physical ergonomics and performance has been introduced to HCI. It is based on optical motion capture and biomechanical simulation. It provides a rich source for analyzing human movements summarized in a multidimensional data set. Existing visualization tools do not sufficiently support the HCI experts in analyzing this data. We identified two shortcomings. First, appropriate visual encodings are missing particularly for the biomechanical aspects of the data. Second, the physical setup of the user interface cannot be incorporated explicitly into existing tools. We present MovExp, a versatile visualization tool that supports the evaluation of user interfaces. In particular, it can be easily adapted by the HCI experts to include the physical setup that is being evaluated, and visualize the data on top of it. Furthermore, it provides a variety of visual encodings to communicate muscular loads, movement directions, and other specifics of HCI studies that employ motion capture and biomechanical simulation. In this design study, we follow a problem-driven research approach. Based on a formalization of the visualization needs and the data structure, we formulate technical requirements for the visualization tool and present novel solutions to the analysis needs of the HCI experts. We show the utility of our tool with four case studies from the daily work of our HCI experts.	Gregorio Palmas;Myroslav Bachynskyi;Antti Oulasvirta;Hans-Peter Seidel;Tino Weinkauf	Gregorio Palmas;Myroslav Bachynskyi;Antti Oulasvirta;Hans-Peter Seidel;Tina Weinkauf	Max Planck Institute for Informatics;Max Planck Institute for Informatics;Max Planck Institute for Informatics;Max Planck Institute for Informatics;Max Planck Institute for Informatics	10.1109/TVCG.2009.152;10.1109/TVCG.2012.213;10.1109/TVCG.2012.204;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2004.12	Information visualization, Design study, Human-Computer Interaction	10	10	11	64	
InfoVis	2014	NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity	10.1109/TVCG.2014.2346312	http://dx.doi.org/10.1109/TVCG.2014.2346312	2369	2378	J	We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.	Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger	Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger	King Abdullah University of Science and Technology (KAUST);School of Engineering and Applied Sciences at Harvard University;School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Center for Brain Science at Harvard University;School of Engineering and Applied Sciences at Harvard University;King Abdullah University of Science and Technology (KAUST)	10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2009.121;10.1109/VAST.2011.6102439;10.1109/TVCG.2009.108;10.1109/TVCG.2011.192;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2013.154	Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context	18	27	17	47	HM
SciVis	2014	Predicate-Based Focus-and-Context Visualization for 3D Ultrasound	10.1109/TVCG.2014.2346317	http://dx.doi.org/10.1109/TVCG.2014.2346317	2379	2387	J	Direct volume visualization techniques offer powerful insight into volumetric medical images and are part of the clinical routine for many applications. Up to now, however, their use is mostly limited to tomographic imaging modalities such as CT or MRI. With very few exceptions, such as fetal ultrasound, classic volume rendering using one-dimensional intensity-based transfer functions fails to yield satisfying results in case of ultrasound volumes. This is particularly due its gradient-like nature, a high amount of noise and speckle, and the fact that individual tissue types are rather characterized by a similar texture than by similar intensity values. Therefore, clinicians still prefer to look at 2D slices extracted from the ultrasound volume. In this work, we present an entirely novel approach to the classification and compositing stage of the volume rendering pipeline, specifically designed for use with ultrasonic images. We introduce point predicates as a generic formulation for integrating the evaluation of not only low-level information like local intensity or gradient, but also of high-level information, such as non-local image features or even anatomical models. Thus, we can successfully filter clinically relevant from non-relevant information. In order to effectively reduce the potentially high dimensionality of the predicate configuration space, we propose the predicate histogram as an intuitive user interface. This is augmented by a scribble technique to provide a comfortable metaphor for selecting predicates of interest. Assigning importance factors to the predicates allows for focus-and-context visualization that ensures to always show important (focus) regions of the data while maintaining as much context information as possible. Our method naturally integrates into standard ray casting algorithms and yields superior results in comparison to traditional methods in terms of visualizing a specific target anatomy in ultrasound volumes.	Christian Schulte zu Berge;Maximilian Baust;Ankur Kapoor;Nassir Navab	Christian Schulte zu Berge;Maximilian Baust;Ankur Kapoor;Nassir Navab	Chair for Computer Aided Medical Procedures, Technische Universität, München, Germany;Chair for Computer Aided Medical Procedures, Technische Universität, München, Germany;Imaging and Computer Vision, Siemens Corporation, Corporate Technology, Princeton, NJ, USA;Chair for Computer Aided Medical Procedures, Technische Universität, München, Germany	10.1109/TVCG.2006.148;10.1109/TVCG.2006.124;10.1109/TVCG.2013.189;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2001.964539	Direct Volume Rendering, Ultrasound, Classification, Predicate Function, User Interface	5	5	4	27	
SciVis	2014	ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization	10.1109/TVCG.2014.2346318	http://dx.doi.org/10.1109/TVCG.2014.2346318	2388	2396	J	Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.	Peter Rautek;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger	Peter Rautek;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger	KAUST;University of Bergen;Vienna University of Technology;KAUST	10.1109/VISUAL.2005.1532792;10.1109/VISUAL.1992.235219;10.1109/TVCG.2009.174;10.1109/TVCG.2014.2346322;10.1109/VISUAL.2004.95;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1992.235202;10.1109/TVCG.2008.184	Domain-specific languages, Volume visualization, Volume visualization framework	6	12	11	42	
SciVis	2014	Interactive Progressive Visualization with Space-Time Error Control	10.1109/TVCG.2014.2346319	http://dx.doi.org/10.1109/TVCG.2014.2346319	2397	2406	J	We present a novel scheme for progressive rendering in interactive visualization. Static settings with respect to a certain image quality or frame rate are inherently incapable of delivering both high frame rates for rapid changes and high image quality for detailed investigation. Our novel technique flexibly adapts by steering the visualization process in three major degrees of freedom: when to terminate the refinement of a frame in the background and start a new one, when to display a frame currently computed, and how much resources to consume. We base these decisions on the correlation of the errors due to insufficient sampling and response delay, which we estimate separately using fast yet expressive heuristics. To automate the configuration of the steering behavior, we employ offline video quality analysis. We provide an efficient implementation of our scheme for the application of volume raycasting, featuring integrated GPU-accelerated image reconstruction and error estimation. Our implementation performs an integral handling of the changes due to camera transforms, transfer function adaptations, as well as the progression of the data to in time. Finally, the overall technique is evaluated with an expert study.	Steffen Frey;Filip Sadlo;Kwan-Liu Ma;Thomas Ertl	Steffen Frey;Filip Sadlo;Kwan-Liu Ma;Thomas Ertl	University of Stuttgart;University of Stuttgart;UC Davis;University of Stuttgart	10.1109/VISUAL.1994.346321;10.1109/TVCG.2013.126;10.1109/VISUAL.2000.885702;10.1109/TVCG.2009.114	Progressive visualization, error-based frame control, interactive volume raycasting	17	18	15	36	
InfoVis	2014	Four Experiments on the Perception of Bar Charts	10.1109/TVCG.2014.2346320	http://dx.doi.org/10.1109/TVCG.2014.2346320	2152	2160	J	Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland &amp;amp; McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland &amp;amp; McGill's ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants' errors. We use our results to propose new hypotheses on the perception of bar charts.	Justin Talbot;Vidya Setlur;Anushka Anand	Justin Talbot;Vidya Setlur;Anushka Anand	Tableau Research;Tableau Research;Tableau Research	10.1109/TVCG.2012.237	Graphical perception, bar charts	19	34	23	12	
InfoVis	2014	Visual Parameter Space Analysis: A Conceptual Framework	10.1109/TVCG.2014.2346321	http://dx.doi.org/10.1109/TVCG.2014.2346321	2161	2170	J	Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.	Michael Sedlmair;Christoph Heinzl;Stefan Bruckner;Harald Piringer;Torsten Möller	Michael Sedlmair;Christoph Heinzl;Stefan Bruckner;Harald Piringer;Torsten Möller	University of Vienna;University of Applied Sciences Upper Austria;University of Bergen;VRVis;University of Vienna	10.1109/INFVIS.1995.528680;10.1109/TVCG.2010.177;10.1109/TVCG.2008.145;10.1109/TVCG.2012.219;10.1109/TVCG.2009.155;10.1109/TVCG.2010.223;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2010.190;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1993.398859;10.1109/VAST.2009.5333431;10.1109/TVCG.2007.70581;10.1109/TVCG.2013.142;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.130;10.1109/TVCG.2013.147;10.1109/TVCG.2013.124;10.1109/TVCG.2012.190;10.1109/TVCG.2009.111;10.1109/TVCG.2011.229;10.1109/TVCG.2013.157;10.1109/TVCG.2013.125;10.1109/VAST.2011.6102450;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.126;10.1109/TVCG.2011.248;10.1109/TVCG.2010.214;10.1109/TVCG.2009.170;10.1109/VAST.2011.6102457;10.1109/TVCG.2013.120;10.1109/TVCG.2011.253	Parameter space analysis, input-output model, simulation, task characterization, literature analysis	58	84	71	77	
SciVis	2014	Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems	10.1109/TVCG.2014.2346322	http://dx.doi.org/10.1109/TVCG.2014.2346322	2407	2416	J	As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.	Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;David G. C. Hildebrand;Hanspeter Pfister;Won-Ki Jeong	Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;David G. C. Hildebrand;Hanspeter Pfister;Won-Ki Jeong	Ulsan National Institute of Science and Technology (UNIST);Ulsan National Institute of Science and Technology (UNIST);Ulsan National Institute of Science and Technology (UNIST);Harvard University;Harvard University;Ulsan National Institute of Science and Technology (UNIST)	10.1109/VISUAL.2004.95	Domain-specific language, volume rendering, GPU computing, distributed heterogeneous systems	9	14	16	30	
InfoVis	2014	Moving beyond sequential design: Reflections on a rich multi-channel approach to data visualization	10.1109/TVCG.2014.2346323	http://dx.doi.org/10.1109/TVCG.2014.2346323	2171	2180	J	We reflect on a four-year engagement with transport authorities and others involving a large dataset describing the use of a public bicycle-sharing scheme. We describe the role visualization of these data played in fostering engagement with policy makers, transport operators, the transport research community, the museum and gallery sector and the general public. We identify each of these as `channels'-evolving relationships between producers and consumers of visualization-where traditional roles of the visualization expert and domain expert are blurred. In each case, we identify the different design decisions that were required to support each of these channels and the role played by the visualization process. Using chauffeured interaction with a flexible visual analytics system we demonstrate how insight was gained by policy makers into gendered spatio-temporal cycle behaviors, how this led to further insight into workplace commuting activity, group cycling behavior and explanations for street navigation choice. We demonstrate how this supported, and was supported by, the seemingly unrelated development of narrative-driven visualization via TEDx, of the creation and the setting of an art installation and the curating of digital and physical artefacts. We assert that existing models of visualization design, of tool/technique development and of insight generation do not adequately capture the richness of parallel engagement via these multiple channels of communication. We argue that developing multiple channels in parallel opens up opportunities for visualization design and analysis by building trust and authority and supporting creativity. This rich, non-sequential approach to visualization design is likely to foster serendipity, deepen insight and increase impact.	Jo Wood;Roger Beecham;Jason Dykes	Jo Wood;Roger Beecham;Jason Dykes	giCentre, City University London;giCentre, City University London;giCentre, City University London	10.1109/TVCG.2012.272;10.1109/TVCG.2012.262;10.1109/TVCG.2012.213;10.1109/TVCG.2011.175;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/TVCG.2013.132;10.1109/INFVIS.2004.59;10.1109/TVCG.2011.209;10.1109/TVCG.2013.145;10.1109/TVCG.2008.127	Movement visualization, visual analytics, bikeshare, impact, visualization models, design study	11	16	13	59	
SciVis	2014	Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering	10.1109/TVCG.2014.2346324	http://dx.doi.org/10.1109/TVCG.2014.2346324	2417	2426	J	This paper presents a new multi-resolution volume representation called sparse pdf volumes, which enables consistent multi-resolution volume rendering based on probability density functions (pdfs) of voxel neighborhoods. These pdfs are defined in the 4D domain jointly comprising the 3D volume and its 1D intensity range. Crucially, the computation of sparse pdf volumes exploits data coherence in 4D, resulting in a sparse representation with surprisingly low storage requirements. At run time, we dynamically apply transfer functions to the pdfs using simple and fast convolutions. Whereas standard low-pass filtering and down-sampling incur visible differences between resolution levels, the use of pdfs facilitates consistent results independent of the resolution level used. We describe the efficient out-of-core computation of large-scale sparse pdf volumes, using a novel iterative simplification procedure of a mixture of 4D Gaussians. Finally, our data structure is optimized to facilitate interactive multi-resolution volume rendering on GPUs.	Ronell Sicat;Jens H. Krüger;Torsten Möller;Markus Hadwiger	Ronell Sicat;Jens Krüger;Torsten Möller;Markus Hadwiger	King Abdullah University of Science and Technology (KAUST);University of Duisburg-Essen;University of Vienna;King Abdullah University of Science and Technology (KAUST)	10.1109/TVCG.2006.143;10.1109/TVCG.2012.240;10.1109/VISUAL.1999.809908	Multi-resolution representations, sparse approximation, pursuit algorithms, large-scale volume rendering	9	13	12	40	
InfoVis	2014	An Algebraic Process for Visualization Design	10.1109/TVCG.2014.2346325	http://dx.doi.org/10.1109/TVCG.2014.2346325	2181	2190	J	We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.	Gordon L. Kindlmann;Carlos Scheidegger	Gordon Kindlmann;Carlos Scheidegger	University of Chicago;University of Arizona	10.1109/TVCG.2013.173;10.1109/INFVIS.1999.801860;10.1109/TVCG.2010.132;10.1109/TVCG.2010.199;10.1109/VISUAL.1996.568118;10.1109/TVCG.2013.124;10.1109/TVCG.2009.125;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594;10.1109/TVCG.2013.119;10.1109/INFVIS.2003.1249005;10.1109/INFVIS.2004.59;10.1109/VISUAL.1996.567784;10.1109/TVCG.2013.126;10.1109/TVCG.2008.121;10.1109/TVCG.2012.230;10.1109/TVCG.2010.161	Visualization Design, Symmetries, Visualization Theory	26	45	30	63	HM
InfoVis	2014	Design Activity Framework for Visualization Design	10.1109/TVCG.2014.2346331	http://dx.doi.org/10.1109/TVCG.2014.2346331	2191	2200	J	An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research.	Sean McKenna;Dominika Mazur;James Agutter;Miriah D. Meyer	Sean McKenna;Dominika Mazur;James Agutter;Miriah Meyer	School of Computing, Salt Lake City, UT;Department of Psychology, University of Utah, Salt Lake City, UT;College of Architecture and Planning, University of Utah, Salt Lake City, UT;School of Computing, Salt Lake City, UT	10.1109/TVCG.2012.213;10.1109/TVCG.2011.209;10.1109/TVCG.2009.111;10.1109/TVCG.2013.126;10.1109/TVCG.2013.145	Design, frameworks, process, cybersecurity, nested model, decisions, models, evaluation, visualization	22	33	28	69	
SciVis	2014	Multiscale Symmetry Detection in Scalar Fields by Clustering Contours	10.1109/TVCG.2014.2346332	http://dx.doi.org/10.1109/TVCG.2014.2346332	2427	2436	J	The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.	Dilip Mathew Thomas;Vijay Natarajan	Dilip Mathew Thomas;Vijay Natarajan	Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation and Supercomputer Education Research Centre, Indian Institute of Science, Bangalore, India	10.1109/TVCG.2013.142;10.1109/VISUAL.1999.809869;10.1109/TVCG.2006.149;10.1109/TVCG.2011.236;10.1109/TVCG.2008.143;10.1109/TVCG.2011.258;10.1109/TVCG.2013.148	Scalar field visualization, symmetry detection, contour tree, data exploration	13	26	22	43	
SciVis	2014	Low-Pass Filtered Volumetric Shadows	10.1109/TVCG.2014.2346333	http://dx.doi.org/10.1109/TVCG.2014.2346333	2437	2446	J	We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.	Marco Ament;Filip Sadlo;Carsten Dachsbacher;Daniel Weiskopf	Marco Ament;Filip Sadlo;Carsten Dachsbacher;Daniel Weiskopf	Karlsruhe Institute of Technology, Germany;University of Stuttgart, Germany;Karlsruhe Institute of Technology, Germany;University of Stuttgart, Germany	10.1109/TVCG.2013.172;10.1109/TVCG.2013.129;10.1109/TVCG.2011.211;10.1109/VISUAL.2003.1250394;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764	Direct volume rendering, volume illumination, soft shadows, filtered shadows, summed area table	13	15	13	49	
SciVis	2014	Boundary Aware Reconstruction of Scalar Fields	10.1109/TVCG.2014.2346351	http://dx.doi.org/10.1109/TVCG.2014.2346351	2447	2455	J	In visualization, the combined role of data reconstruction and its classification plays a crucial role. In this paper we propose a novel approach that improves classification of different materials and their boundaries by combining information from the classifiers at the reconstruction stage. Our approach estimates the targeted materials' local support before performing multiple material-specific reconstructions that prevent much of the misclassification traditionally associated with transitional regions and transfer function (TF) design. With respect to previously published methods our approach offers a number of improvements and advantages. For one, it does not rely on TFs acting on derivative expressions, therefore it is less sensitive to noisy data and the classification of a single material does not depend on specialized TF widgets or specifying regions in a multidimensional TF. Additionally, improved classification is attained without increasing TF dimensionality, which promotes scalability to multivariate data. These aspects are also key in maintaining low interaction complexity. The results are simple-to-achieve visualizations that better comply with the user's understanding of discrete features within the studied object.	Stefan Lindholm;Daniel Jönsson;Charles D. Hansen;Anders Ynnerman	Stefan Lindholm;Daniel Jönsson;Charles Hansen;Anders Ynnerman	Department of Science and Technology, Linköping University;Department of Science and Technology, Linköping University;Scientific Computing and Imaging Institute, University of Utah;Department of Science and Technology, Linköping University	10.1109/TVCG.2007.70518;10.1109/TVCG.2008.186;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2003.1250387	Reconstruction, signal processing, kernel regression, volume rendering	4	6	6	27	
SciVis	2014	Attractive Flicker: Guiding Attention in Dynamic Narrative Visualizations	10.1109/TVCG.2014.2346352	http://dx.doi.org/10.1109/TVCG.2014.2346352	2456	2465	J	Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first “orientation stage” is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (“engagement stage”) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.	Manuela Waldner;Mathieu Le Muzic;Matthias Bernhard;Werner Purgathofer;Ivan Viola	Manuela Waldner;Mathieu Le Muzic;Matthias Bernhard;Werner Purgathofer;Ivan Viola	Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology	10.1109/TVCG.2009.185;10.1109/VISUAL.1995.480802;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2010.179;10.1109/TVCG.2011.183;10.1109/TVCG.2006.174	Visual attention, flicker, narrative visualization	7	13	11	48	
SciVis	2014	Design and Evaluation of Interactive Proofreading Tools for Connectomics	10.1109/TVCG.2014.2346371	http://dx.doi.org/10.1109/TVCG.2014.2346371	2466	2475	J	Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.	Daniel Haehn;Seymour Knowles-Barley;Mike Roberts;Johanna Beyer;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister	Daniel Haehn;Seymour Knowles-Barley;Mike Roberts;Johanna Beyer;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister	School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Computer Graphics Laboratory at Stanford University;School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Center for Brain Science at Harvard University;School of Engineering and Applied Sciences at Harvard University	10.1109/TVCG.2013.142;10.1109/TVCG.2012.240	Proofreading, Segmentation, Connectomics, Quantitative Evaluation	19	27	23	49	
SciVis	2014	Characterizing Molecular Interactions in Chemical Systems	10.1109/TVCG.2014.2346403	http://dx.doi.org/10.1109/TVCG.2014.2346403	2476	2485	J	Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.	David Günther;Roberto Álvarez Boto;Juila Contreras-Garcia;Jean-Philip Piquemal;Julien Tierny	David Günther;Roberto A. Boto;Juila Contreras-Garcia;Jean-Philip Piquemal;Julien Tierny	Institut-Mines-Télécom, Paris, France;Sorbonne Universités, Paris, France;Sorbonne Universités, Paris, France;Sorbonne Universités, Paris, France;CNRS LIP6, UPMC, Paris, France	10.1109/TVCG.2009.163;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250376;10.1109/TVCG.2008.110;10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2007.70578;10.1109/TVCG.2013.158	Molecular Chemistry, Topological Data Analysis, Morse-Smale Complex, Join Tree	18	32	25	58	
SciVis	2014	Ligand Excluded Surface: A New Type of Molecular Surface	10.1109/TVCG.2014.2346404	http://dx.doi.org/10.1109/TVCG.2014.2346404	2486	2495	J	The most popular molecular surface in molecular visualization is the solvent excluded surface (SES). It provides information about the accessibility of a biomolecule for a solvent molecule that is geometrically approximated by a sphere. During a period of almost four decades, the SES has served for many purposes - including visualization, analysis of molecular interactions and the study of cavities in molecular structures. However, if one is interested in the surface that is accessible to a molecule whose shape differs significantly from a sphere, a different concept is necessary. To address this problem, we generalize the definition of the SES by replacing the probe sphere with the full geometry of the ligand defined by the arrangement of its van der Waals spheres. We call the new surface ligand excluded surface (LES) and present an efficient, grid-based algorithm for its computation. Furthermore, we show that this algorithm can also be used to compute molecular cavities that could host the ligand molecule. We provide a detailed description of its implementation on CPU and GPU. Furthermore, we present a performance and convergence analysis and compare the LES for several molecules, using as ligands either water or small organic molecules.	Norbert Lindow;Daniel Baum;Hans-Christian Hege	Norbert Lindow;Daniel Baum;Hans-Christian Hege	Zuse Institute Berlin;Zuse Institute Berlin;Zuse Institute Berlin	10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2013.158	Molecular visualization, solvent excluded surface, ligand excluded surface, cavity analysis	13	14	10	48	
SciVis	2014	ADR - Anatomy-Driven Reformation	10.1109/TVCG.2014.2346405	http://dx.doi.org/10.1109/TVCG.2014.2346405	2496	2505	J	Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.	Jan Kretschmer;Grzegorz Soza;Christian Tietjen;Michael Sühling;Bernhard Preim;Marc Stamminger	Jan Kretschmer;Grzegorz Soza;Christian Tietjen;Michael Suehling;Bernhard Preim;Marc Stamminger	Department of Computer Graphics, FAU Erlangen, and Siemens Healthcare Computed Tomography, Forchheim, Germany;Siemens Healthcare Computed Tomography, Forchheim, Germany;Siemens Healthcare Computed Tomography, Forchheim, Germany;Siemens Healthcare Computed Tomography, Forchheim, Germany;Department of Simulation and Graphics, Otto-von-Guericke University of Magdeburg, Germany;Department of Computer Graphics, FAU Erlangen, Germany	10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351	Medical Visualization, Volume Reformation, Viewing Algorithms	6	6	4	47	
SciVis	2014	Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms	10.1109/TVCG.2014.2346406	http://dx.doi.org/10.1109/TVCG.2014.2346406	2506	2515	J	For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.	Sylvia Saalfeld;Kai Lawonn;Thomas Hoffmann;Martin Skalej;Bernhard Preim	Sylvia Glaßer;Kai Lawonn;Thomas Hoffmann;Martin Skalej;Bernhard Preim	Department for Simulation and Graphics, University of Magdeburg, Germany;Department for Simulation and Graphics, University of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Department for Simulation and Graphics, University of Magdeburg, Germany	10.1109/TVCG.2012.202;10.1109/TVCG.2007.70550;10.1109/VISUAL.1995.480795;10.1109/TVCG.2011.189	Aneurysm, IVUS, Wall Thickness, Wall Shear Stress, Brushing and Linking, Focus + Context	12	14	9	43	
SciVis	2014	Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields	10.1109/TVCG.2014.2346411	http://dx.doi.org/10.1109/TVCG.2014.2346411	2516	2525	J	Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.	Sujal Bista;Jiachen Zhuo;Rao P. Gullapalli;Amitabh Varshney	Sujal Bista;Jiachen Zhuo;Rao P. Gullapalli;Amitabh Varshney	University of Maryland, College Park;University of Maryland School of Medicine at Baltimore;University of Maryland School of Medicine at Baltimore;University of Maryland, College Park	10.1109/TVCG.2013.172;10.1109/TVCG.2007.70602;10.1109/TVCG.2010.199;10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/VISUAL.2004.64;10.1109/VISUAL.2004.5;10.1109/TVCG.2011.198;10.1109/TVCG.2008.148	Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields	6	11	10	51	BP
SciVis	2014	A Robust Parity Test for Extracting Parallel Vectors in 3D	10.1109/TVCG.2014.2346412	http://dx.doi.org/10.1109/TVCG.2014.2346412	2526	2534	J	Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions.	Tao Ju;Minxin Cheng;Xu Wang;Ye Duan	Tao Ju;Minxin Cheng;Xu Wang;Ye Duan	Washington University in St. Louis;University of Missouri at Columbia;University of Missouri at Columbia;University of Missouri at Columbia	10.1109/VISUAL.2002.1183786;10.1109/VISUAL.2005.1532851;10.1109/VISUAL.1999.809896	Parallel vectors, feature curve extraction, ridges and valleys, parity test	3	3	3	17	HM
SciVis	2014	Vortex Cores of Inertial Particles	10.1109/TVCG.2014.2346415	http://dx.doi.org/10.1109/TVCG.2014.2346415	2535	2544	J	The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.	Tobias Günther;Holger Theisel	Tobias Günther;Holger Theisel	Visual Computing Group at the University of Magdeburg;Visual Computing Group at the University of Magdeburg	10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296	Inertial particles, flow visualization, vortex cores	9	11	9	36	
SciVis	2014	FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis	10.1109/TVCG.2014.2346416	http://dx.doi.org/10.1109/TVCG.2014.2346416	2545	2554	J	In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach.	Fan Hong;Chufan Lai;Hanqi Guo;Enya Shen;Xiaoru Yuan;Sikun Li	Fan Hong;Chufan Lai;Hanqi Guo;Enya Shen;Xiaoru Yuan;Sikun Li	Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;School of Computer Science, National University of Defense Technology, Changsha, China;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;School of Computer Science, National University of Defense Technology, Changsha, China	10.1109/TVCG.2008.131;10.1109/TVCG.2010.131;10.1109/TVCG.2011.239;10.1109/TVCG.2006.165;10.1109/TVCG.2008.116;10.1109/TVCG.2006.164;10.1109/TVCG.2010.190;10.1109/TVCG.2011.246;10.1109/TVCG.2008.167;10.1109/TVCG.2009.112;10.1109/TVCG.2010.170;10.1109/TVCG.2013.133	Flow visualization, Topic model, Latent Dirichlet allocation (LDA)	4	7	9	47	
SciVis	2014	Advection-Based Sparse Data Management for Visualizing Unsteady Flow	10.1109/TVCG.2014.2346418	http://dx.doi.org/10.1109/TVCG.2014.2346418	2555	2564	J	When computing integral curves and integral surfaces for large-scale unsteady flow fields, a major bottleneck is the widening gap between data access demands and the available bandwidth (both I/O and in-memory). In this work, we explore a novel advection-based scheme to manage flow field data for both efficiency and scalability. The key is to first partition flow field into blocklets (e.g. cells or very fine-grained blocks of cells), and then (pre)fetch and manage blocklets on-demand using a parallel key-value store. The benefits are (1) greatly increasing the scale of local-range analysis (e.g. source-destination queries, streak surface generation) that can fit within any given limit of hardware resources; (2) improving memory and I/O bandwidth-efficiencies as well as the scalability of naive task-parallel particle advection. We demonstrate our method using a prototype system that works on workstation and also in supercomputing environments. Results show significantly reduced I/O overhead compared to accessing raw flow data, and also high scalability on a supercomputer for a variety of applications.	Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang 0007;Xiangfei Meng;Jingshan Pan	Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang;Xiangfei Meng;Jingshan Pan	Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville;National Supercomputer Center in Tianjin, Binhai, Tianjin, China;National Supercomputer Center in Jinan, Shandong, China	10.1109/TVCG.2009.154;10.1109/TVCG.2011.219;10.1109/VISUAL.1997.663898;10.1109/TVCG.2013.144;10.1109/TVCG.2013.128;10.1109/TVCG.2007.70551	Flow visualization, Data management, High performance visualization, Key-value store	9	14	12	37	
InfoVis	2014	The Persuasive Power of Data Visualization	10.1109/TVCG.2014.2346419	http://dx.doi.org/10.1109/TVCG.2014.2346419	2211	2220	J	Data visualization has been used extensively to inform users. However, little research has been done to examine the effects of data visualization in influencing users or in making a message more persuasive. In this study, we present experimental research to fill this gap and present an evidence-based analysis of persuasive visualization. We built on persuasion research from psychology and user interfaces literature in order to explore the persuasive effects of visualization. In this experimental study we define the circumstances under which data visualization can make a message more persuasive, propose hypotheses, and perform quantitative and qualitative analyses on studies conducted to test these hypotheses. We compare visual treatments with data presented through barcharts and linecharts on the one hand, treatments with data presented through tables on the other, and then evaluate their persuasiveness. The findings represent a first step in exploring the effectiveness of persuasive visualization.	Anshul Vikram Pandey;Anjali Manivannan;Oded Nov;Margaret Satterthwaite;Enrico Bertini	Anshul Vikram Pandey;Anjali Manivannan;Oded Nov;Margaret Satterthwaite;Enrico Bertini	New York University;New York University;New York University;New York University;New York University	10.1109/TVCG.2012.199;10.1109/TVCG.2012.221;10.1109/TVCG.2012.197;10.1109/TVCG.2011.192;10.1109/TVCG.2013.234	Persuasive visualization, elaboration likelihood model, evaluation	28	41	32	39	
InfoVis	2014	Comparative Eye Tracking Study on Node-Link Visualizations of Trajectories	10.1109/TVCG.2014.2346420	http://dx.doi.org/10.1109/TVCG.2014.2346420	2221	2230	J	We present the results of an eye tracking study that compares different visualization methods for long, dense, complex, and piecewise linear spatial trajectories. Typical sources of such data are from temporally discrete measurements of the positions of moving objects, for example, recorded GPS tracks of animals in movement ecology. In the repeated-measures within-subjects user study, four variants of node-link visualization techniques are compared, with the following representations of directed links: standard arrow, tapered, equidistant arrows, and equidistant comets. In addition, we investigate the effect of rendering order for the halo visualization of those links as well as the usefulness of node splatting. All combinations of link visualization techniques are tested for different trajectory density levels. We used three types of tasks: tracing of paths, identification of longest links, and estimation of the density of trajectory clusters. Results are presented in the form of the statistical evaluation of task completion time, task solution accuracy, and two eye tracking metrics. These objective results are complemented by a summary of subjective feedback from the participants. The main result of our study is that tapered links perform very well. However, we discuss that equidistant comets and equidistant arrows are a good option to perceive direction information independent of zoom-level of the display.	Rudolf Netzel;Michael Burch;Daniel Weiskopf	Juhee Bae;Benjamin Watson	VISUS;VISUS;VISUS	10.1109/INFVIS.2004.1;10.1109/TVCG.2011.193;10.1109/TVCG.2011.226	User study, eye tracking, evaluation, trajectory visualization, node-link visualization, direction encoding, node splatting, halo rendering	15	21	17	33	
InfoVis	2014	Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation	10.1109/TVCG.2014.2346422	http://dx.doi.org/10.1109/TVCG.2014.2346422	2231	2240	J	Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools.	Bahador Saket;Paolo Simonetto;Stephen G. Kobourov;Katy Börner	Bahador Saket;Paolo Simonetto;Stephen Kobourov;Katy Börner	University of Arizona;University of Arizona;University of Arizona;Indiana University	10.1109/INFVIS.2003.1249011;10.1109/TVCG.2011.186;10.1109/TVCG.2008.155;10.1109/INFVIS.1995.528686;10.1109/TVCG.2007.70596;10.1109/TVCG.2009.122;10.1109/TVCG.2013.187;10.1109/TVCG.2013.124	graphs, networks, maps, scatter plots	19	0	18	48	
SciVis	2014	Trajectory-Based Flow Feature Tracking in Joint Particle/Volume Datasets	10.1109/TVCG.2014.2346423	http://dx.doi.org/10.1109/TVCG.2014.2346423	2565	2574	J	Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy.	Franz Sauer;Hongfeng Yu;Kwan-Liu Ma	Franz Sauer;Hongfeng Yu;Kwan-Liu Ma	University of California, Davis;University of Nebraska, Lincoln;University of California, Davis	10.1109/VISUAL.1997.663930;10.1109/VISUAL.1996.567807;10.1109/TVCG.2007.70599;10.1109/VISUAL.2003.1250374;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1998.745288	Feature extraction and tracking, particle data, volume data, particle trajectories, flow visualization	7	10	12	26	
InfoVis	2014	The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking	10.1109/TVCG.2014.2346424	http://dx.doi.org/10.1109/TVCG.2014.2346424	2241	2250	J	Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research.	Fanny Chevalier;Pierre Dragicevic;Steven Franconeri	Fanny Chevalier;Pierre Dragicevic;Steven Franconeri	Inria;Inria;Northwestern University	10.1109/TVCG.2012.199;10.1109/INFVIS.1999.801854;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2008.153;10.1109/TVCG.2007.70539	Animated transitions, staggered animation, visual tracking	21	29	22	41	
SciVis	2014	Visualizing 2-dimensional Manifolds with Curve Handles in 4D	10.1109/TVCG.2014.2346425	http://dx.doi.org/10.1109/TVCG.2014.2346425	2575	2584	J	In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies.	Hui Zhang 0006;Jianguang Weng;Guangchen Ruan	Hui Zhang;Jianguang Weng;Guangchen Ruan	Pervasive Technology Institute, Indiana University;Zhejiang University of Media and Communication;School of Informatics and Computing, Indiana University	10.1109/TVCG.2012.242;10.1109/VISUAL.2005.1532804;10.1109/VISUAL.2005.1532843;10.1109/TVCG.2010.151;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2007.70593	math visualization, 4D, deformation, Reidemeister theorem	1	3	2	38	
InfoVis	2014	The Influence of Contour on Similarity Perception of Star Glyphs	10.1109/TVCG.2014.2346426	http://dx.doi.org/10.1109/TVCG.2014.2346426	2251	2260	J	We conducted three experiments to investigate the effects of contours on the detection of data similarity with star glyph variations. A star glyph is a small, compact, data graphic that represents a multi-dimensional data point. Star glyphs are often used in small-multiple settings, to represent data points in tables, on maps, or as overlays on other types of data graphics. In these settings, an important task is the visual comparison of the data points encoded in the star glyph, for example to find other similar data points or outliers. We hypothesized that for data comparisons, the overall shape of a star glyph-enhanced through contour lines-would aid the viewer in making accurate similarity judgments. To test this hypothesis, we conducted three experiments. In our first experiment, we explored how the use of contours influenced how visualization experts and trained novices chose glyphs with similar data values. Our results showed that glyphs without contours make the detection of data similarity easier. Given these results, we conducted a second study to understand intuitive notions of similarity. Star glyphs without contours most intuitively supported the detection of data similarity. In a third experiment, we tested the effect of star glyph reference structures (i.e., tickmarks and gridlines) on the detection of similarity. Surprisingly, our results show that adding reference structures does improve the correctness of similarity judgments for star glyphs with contours, but not for the standard star glyph. As a result of these experiments, we conclude that the simple star glyph without contours performs best under several criteria, reinforcing its practice and popularity in the literature. Contours seem to enhance the detection of other types of similarity, e. g., shape similarity and are distracting when data similarity has to be judged. Based on these findings we provide design considerations regarding the use of contours and reference structures on star glyphs.	Johannes Fuchs 0001;Petra Isenberg;Anastasia Bezerianos;Fabian Fischer 0001;Enrico Bertini	Johannes Fuchs;Petra Isenberg;Anastasia Bezerianos;Fabian Fischer;Enrico Bertini	University of Konstanz;Inria;CNRS & Inria, Université Paris-Sud;University of Konstanz;NYU Poly	10.1109/TVCG.2012.220;10.1109/TVCG.2008.136;10.1109/TVCG.2011.242;10.1109/INFVIS.2004.15	Glyphs, star glyphs, contours, perception, quantitative evaluation, similarity detection, visual comparison	20	27	23	35	
InfoVis	2014	Order of Magnitude Markers: An Empirical Study on Large Magnitude Number Detection	10.1109/TVCG.2014.2346428	http://dx.doi.org/10.1109/TVCG.2014.2346428	2261	2270	J	In this paper we introduce Order of Magnitude Markers (OOMMs) as a new technique for number representation. The motivation for this work is that many data sets require the depiction and comparison of numbers that have varying orders of magnitude. Existing techniques for representation use bar charts, plots and colour on linear or logarithmic scales. These all suffer from related problems. There is a limit to the dynamic range available for plotting numbers, and so the required dynamic range of the plot can exceed that of the depiction method. When that occurs, resolving, comparing and relating values across the display becomes problematical or even impossible for the user. With this in mind, we present an empirical study in which we compare logarithmic, linear, scale-stack bars and our new markers for 11 different stimuli grouped into 4 different tasks across all 8 marker types.	Rita Borgo;Joel Dearden;Mark W. Jones	Rita Borgo;Joel Dearden;Mark W. Jones	Swansea University;Swansea University;Swansea University	10.1109/TVCG.2013.187;10.1109/TVCG.2012.229;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.160;10.1109/TVCG.2010.130;10.1109/TVCG.2013.234	Orders of magnitude, bar charts, logarithmic scale	9	12	7	26	
InfoVis	2014	Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists	10.1109/TVCG.2014.2346431	http://dx.doi.org/10.1109/TVCG.2014.2346431	2271	2280	J	For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system “in the wild”, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of “exploring” a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.	Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner	Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner	University of British Columbia;University of British Columbia;Columbia Journalism School and the Associated Press;University of British Columbia	10.1109/TVCG.2009.127;10.1109/INFVIS.2004.19;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2012.260;10.1109/TVCG.2009.140;10.1109/TVCG.2013.162;10.1109/TVCG.2013.153;10.1109/TVCG.2009.148;10.1109/TVCG.2013.124;10.1109/TVCG.2011.239;10.1109/VAST.2010.5652940;10.1109/TVCG.2011.209	Design study, investigative journalism, task and requirements analysis, text and document data, text analysis	27	45	23	53	
SciVis	2014	Fast and Memory-Efficienty Topological Denoising of 2D and 3D Scalar Fields	10.1109/TVCG.2014.2346432	http://dx.doi.org/10.1109/TVCG.2014.2346432	2585	2594	J	Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.	David Günther;Alec Jacobson;Jan Reininghaus;Hans-Peter Seidel;Olga Sorkine-Hornung;Tino Weinkauf	David Günther;Alec Jacobson;Jan Reininghaus;Hans-Peter Seidel;Olga Sorkine-Hornung;Tino Weinkauf	Institut Mines-Télécom, Paris, France;Columbia University, New York, USA;IST Austria, Vienna, Austria;Max Planck Institute for Informatics, Saarbrücken, Germany;ETH Zürich, Zürich, Switzerland;Max Planck Institute for Informatics, Saarbrücken, Germany	10.1109/TVCG.2012.228;10.1109/VISUAL.2001.964507	Numerical optimization, topology, scalar fields	15		15	26	
InfoVis	2014	How Hierarchical Topics Evolve in Large Text Corpora	10.1109/TVCG.2014.2346433	http://dx.doi.org/10.1109/TVCG.2014.2346433	2281	2290	J	Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.	Weiwei Cui;Shixia Liu;Zhuofeng Wu 0002;Hao Wei	Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei	Microsoft Research;Microsoft Research;Nankai University;Zhejiang University	10.1109/TVCG.2013.196;10.1109/TVCG.2009.108;10.1109/VAST.2014.7042494;10.1109/TVCG.2009.111;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346920;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/TVCG.2013.162;10.1109/TVCG.2013.200	Hierarchical topic visualization, evolutionary tree clustering, data transformation	41	66	56	43	
SciVis	2014	Conforming Morse-Smale Complexes	10.1109/TVCG.2014.2346434	http://dx.doi.org/10.1109/TVCG.2014.2346434	2595	2603	J	Morse-Smale (MS) complexes have been gaining popularity as a tool for feature-driven data analysis and visualization. However, the quality of their geometric embedding and the sole dependence on the input scalar field data can limit their applicability when expressing application-dependent features. In this paper we introduce a new combinatorial technique to compute an MS complex that conforms to both an input scalar field and an additional, prior segmentation of the domain. The segmentation constrains the MS complex computation guaranteeing that boundaries in the segmentation are captured as separatrices of the MS complex. We demonstrate the utility and versatility of our approach with two applications. First, we use streamline integration to determine numerically computed basins/mountains and use the resulting segmentation as an input to our algorithm. This strategy enables the incorporation of prior flow path knowledge, effectively resulting in an MS complex that is as geometrically accurate as the employed numerical integration. Our second use case is motivated by the observation that often the data itself does not explicitly contain features known to be present by a domain expert. We introduce edit operations for MS complexes so that a user can directly modify their features while maintaining all the advantages of a robust topology-based representation.	Attila Gyulassy;David Günther;Joshua A. Levine;Julien Tierny;Valerio Pascucci	Attila Gyulassy;David Günther;Joshua A. Levine;Julien Tierny;Valerio Pascucci	SCI Institute;Institut Mines-Télécom, Télécom ParisTech, CNRS LTCI, Paris, France;School of Computing, Visual Computing Division, Clemson University, Clemson, SC, USA;Institut Mines-Télécom, Télécom ParisTech, CNRS LTCI, Paris, France;SCI Institute, University of Utah	10.1109/TVCG.2011.249;10.1109/TVCG.2008.110;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/TVCG.2012.228;10.1109/TVCG.2012.209;10.1109/VISUAL.2005.1532839	Computational Topology, Morse-Smale Complex, Data Analysis	10	19	13	52	
InfoVis	2014	Exploring the Placement and Design of Word-Scale Visualizations	10.1109/TVCG.2014.2346435	http://dx.doi.org/10.1109/TVCG.2014.2346435	2291	2300	J	We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines-small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte's definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations.	Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg	Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg	Inria;Inria;Inria;Inria	10.1109/TVCG.2013.192;10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70589;10.1109/TVCG.2011.183;10.1109/TVCG.2013.120;10.1109/TVCG.2010.194;10.1109/INFVIS.2005.1532144	Information visualization, text visualization, sparklines, glyphs, design space, word-scale visualizations	18	25	21	34	
InfoVis	2014	Effects of Presentation Mode and Pace Control on Performance in Image Classification	10.1109/TVCG.2014.2346437	http://dx.doi.org/10.1109/TVCG.2014.2346437	2301	2309	J	A common task in visualization is to quickly find interesting items in large sets. When appropriate metadata is missing, automatic queries are impossible and users have to inspect all elements visually. We compared two fundamentally different, but obvious display modes for this task and investigated the difference with respect to effectiveness, efficiency, and satisfaction. The static mode is based on the page metaphor and presents successive pages with a static grid of items. The moving mode is based on the conveyor belt metaphor and lets a grid of items slide though the screen in a continuous flow. In our evaluation, we applied both modes to the common task of browsing images. We performed two experiments where 18 participants had to search for certain target images in a large image collection. The number of shown images per second (pace) was predefined in the first experiment, and under user control in the second one. We conclude that at a fixed pace, the mode has no significant impact on the recall. The perceived pace is generally slower for moving mode, which causes users to systematically choose for a faster real pace than in static mode at the cost of recall, keeping the average number of target images found per second equal for both modes.	Paul van der Corput;Jarke J. van Wijk	Paul van der Corput;Jarke J. van Wijk	Eindhoven University of Technology;Eindhoven University of Technology		RSVP, image classification, image browsing, multimedia visualization	3	3	2	15	
InfoVis	2014	Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations	10.1109/TVCG.2014.2346441	http://dx.doi.org/10.1109/TVCG.2014.2346441	2310	2319	J	Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.	Stef van den Elzen;Jarke J. van Wijk	Stef van den Elzen;Jarke J. van Wijk	Department of Mathematic and Computer Science, Eindhoven University of Technology, The Netherlands;Department of Mathematic and Computer Science, Eindhoven University of Technology, The Netherlands	10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.122;10.1109/TVCG.2009.145;10.1109/TVCG.2013.223;10.1109/VAST.2007.4389013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.153;10.1109/TVCG.2009.108;10.1109/TVCG.2006.166;10.1109/TVCG.2006.147	Multivariate Networks, Selections of Interest, Interaction, Direct Manipulation	41	65	53	47	BP
SciVis	2014	Escape Maps	10.1109/TVCG.2014.2346442	http://dx.doi.org/10.1109/TVCG.2014.2346442	2604	2613	J	We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.	Gustavo Mello Machado;Filip Sadlo;Thomas Müller 0005;Thomas Ertl	Gustavo Machado;Filip Sadlo;Thomas Müller;Thomas Ertl	University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany	10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2003.1250376	Streamline behavior, vector field topology, isocline surfaces, coronal hole extraction			1	30	
InfoVis	2014	GLO-STIX: Graph-Level Operations for Specifying Techniques and Interactive eXploration	10.1109/TVCG.2014.2346444	http://dx.doi.org/10.1109/TVCG.2014.2346444	2320	2328	J	The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs.	Charles D. Stolper;Minsuk Kahng;Zhiyuan Lin 0001;Florian Foerster;Aakash Goel;John T. Stasko;Duen Horng Chau	Charles D. Stolper;Minsuk Kahng;Zhiyuan Lin;Florian Foerster;Aakash Goel;John Stasko;Duen Horng Chau	College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology	10.1109/TVCG.2008.137;10.1109/VAST.2011.6102441;10.1109/TVCG.2010.144;10.1109/TVCG.2008.135;10.1109/TVCG.2007.70582;10.1109/VAST.2011.6102440;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/TVCG.2010.205;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.233;10.1109/TVCG.2011.185;10.1109/TVCG.2006.166;10.1109/TVCG.2009.108;10.1109/TVCG.2013.192	Graph-level operations, graph visualization, visualization technique specification, graph analysis, information visualization	9	9	8	30	
InfoVis	2014	TenniVis: Visualization for Tennis Match Analysis	10.1109/TVCG.2014.2346445	http://dx.doi.org/10.1109/TVCG.2014.2346445	2339	2348	J	Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men's singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.	Tom Polk;Jing Yang;Yueqi Hu;Ye Zhao	Tom Polk;Jing Yang;Yueqi Hu;Ye Zhao	University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;Kent State University	10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/VISUAL.2001.964496;10.1109/INFVIS.1996.559229;10.1109/INFVIS.2002.1173148	Visual knowledge discovery, sports analytics, tennis visualization	19	30	26	28	
SciVis	2014	City Forensics: Using Visual Elements to Predict Non-Visual City Attributes	10.1109/TVCG.2014.2346446	http://dx.doi.org/10.1109/TVCG.2014.2346446	2624	2633	J	We present a method for automatically identifying and validating predictive relationships between the visual appearance of a city and its non-visual attributes (e.g. crime statistics, housing prices, population density etc.). Given a set of street-level images and (location, city-attribute-value) pairs of measurements, we first identify visual elements in the images that are discriminative of the attribute. We then train a predictor by learning a set of weights over these elements using non-linear Support Vector Regression. To perform these operations efficiently, we implement a scalable distributed processing framework that speeds up the main computational bottleneck (extracting visual elements) by an order of magnitude. This speedup allows us to investigate a variety of city attributes across 6 different American cities. We find that indeed there is a predictive relationship between visual elements and a number of city attributes including violent crime rates, theft rates, housing prices, population density, tree presence, graffiti presence, and the perception of danger. We also test human performance for predicting theft based on street-level images and show that our predictor outperforms this baseline with 33% higher accuracy on average. Finally, we present three prototype applications that use our system to (1) define the visual boundary of city neighborhoods, (2) generate walking directions that avoid or seek out exposure to city attributes, and (3) validate user-specified visual elements for prediction.	Sean M. Arietta;Alexei A. Efros;Ravi Ramamoorthi;Maneesh Agrawala	Sean M. Arietta;Alexei A. Efros;Ravi Ramamoorthi;Maneesh Agrawala	EECS Department, University of California, Berkeley;EECS Department, University of California, Berkeley;CSE Department, University of California, San Diego;EECS Department, University of California, Berkeley		Data mining, big data, computational geography, visual processing	30	60	42	49	HM
SciVis	2014	Decomposition and Simplification of Multivariate Data using Pareto Sets	10.1109/TVCG.2014.2346447	http://dx.doi.org/10.1109/TVCG.2014.2346447	2684	2693	J	Topological and structural analysis of multivariate data is aimed at improving the understanding and usage of such data through identification of intrinsic features and structural relationships among multiple variables. We present two novel methods for simplifying so-called Pareto sets that describe such structural relationships. Such simplification is a precondition for meaningful visualization of structurally rich or noisy data. As a framework for simplification operations, we introduce a decomposition of the data domain into regions of equivalent structural behavior and the reachability graph that describes global connectivity of Pareto extrema. Simplification is then performed as a sequence of edge collapses in this graph; to determine a suitable sequence of such operations, we describe and utilize a comparison measure that reflects the changes to the data that each operation represents. We demonstrate and evaluate our methods on synthetic and real-world examples.	Lars Huettenberger;Christian Heine 0002;Christoph Garth	Lars Huettenberger;Christian Heine;Christoph Garth	TU Kaiserslautern;ETH Zurich;TU Kaiserslautern	10.1109/TVCG.2012.228;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2009.120;10.1109/VISUAL.2002.1183774;10.1109/VISUAL.2000.885716;10.1109/TVCG.2008.110	Multivariate Topology, Pareto Set, Simplification, Decomposition	6	8	7	22	
SciVis	2014	Multi-Charts for Comparative 3D Ensemble Visualization	10.1109/TVCG.2014.2346448	http://dx.doi.org/10.1109/TVCG.2014.2346448	2694	2703	J	A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.	Ismail Demir;Christian Dick;Rüdiger Westermann	Ismail Demir;Christian Dick;Rüdiger Westermann	Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany;Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany;Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany	10.1109/TVCG.2013.143;10.1109/VISUAL.2000.885739;10.1109/TVCG.2006.159;10.1109/TVCG.2008.139;10.1109/TVCG.2007.70518;10.1109/TVCG.2010.181;10.1109/TVCG.2009.198;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809921	Ensemble visualization, brushing and linking, statistical analysis	18	36	32	57	
SciVis	2014	Using Topological Analysis to Support Event-Guided Exploration in Urban Data	10.1109/TVCG.2014.2346449	http://dx.doi.org/10.1109/TVCG.2014.2346449	2634	2643	J	The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies.	Harish Doraiswamy;Nivan Ferreira;Theodoros Damoulas;Juliana Freire;Cláudio T. Silva	Harish Doraiswamy;Nivan Ferreira;Theodoros Damoulas;Juliana Freire;Cláudio T. Silva	New York University;New York University;New York University;New York University;New York University	10.1109/TVCG.2013.130;10.1109/TVCG.2007.70574;10.1109/VAST.2008.4677356;10.1109/VISUAL.2004.96;10.1109/TVCG.2013.179;10.1109/TVCG.2006.186;10.1109/VAST.2008.4677354;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/VAST.2012.6400557;10.1109/VAST.2011.6102454;10.1109/TVCG.2013.131	Computational topology, event detection, spatio-temporal index, urban data, visual exploration	33	43	31	56	
SciVis	2014	Trend-Centric Motion Visualization: Designing and Applying a New Strategy for Analyzing Scientific Motion Collections	10.1109/TVCG.2014.2346451	http://dx.doi.org/10.1109/TVCG.2014.2346451	2644	2653	J	In biomechanics studies, researchers collect, via experiments or simulations, datasets with hundreds or thousands of trials, each describing the same type of motion (e.g., a neck flexion-extension exercise) but under different conditions (e.g., different patients, different disease states, pre- and post-treatment). Analyzing similarities and differences across all of the trials in these collections is a major challenge. Visualizing a single trial at a time does not work, and the typical alternative of juxtaposing multiple trials in a single visual display leads to complex, difficult-to-interpret visualizations. We address this problem via a new strategy that organizes the analysis around motion trends rather than trials. This new strategy matches the cognitive approach that scientists would like to take when analyzing motion collections. We introduce several technical innovations making trend-centric motion visualization possible. First, an algorithm detects a motion collection's trends via time-dependent clustering. Second, a 2D graphical technique visualizes how trials leave and join trends. Third, a 3D graphical technique, using a median 3D motion plus a visual variance indicator, visualizes the biomechanics of the set of trials within each trend. These innovations are combined to create an interactive exploratory visualization tool, which we designed through an iterative process in collaboration with both domain scientists and a traditionally-trained graphic designer. We report on insights generated during this design process and demonstrate the tool's effectiveness via a validation study with synthetic data and feedback from expert musculoskeletal biomechanics researchers who used the tool to analyze the effects of disc degeneration on human spinal kinematics.	David Schroeder;Fedor Korsakov;Carissa Mai-Ping Knipe;Lauren Thorson;Arin M. Ellingson;David J. Nuckley;John V. Carlis;Daniel F. Keefe	David Schroeder;Fedor Korsakov;Carissa Mai-Ping Knipe;Lauren Thorson;Arin M. Ellingson;David Nuckley;John Carlis;Daniel F Keefe	University of Minnesota;University of Minnesota;University of Minnesota;Minneapolis College of Art and Design;University of Minnesota;Zimmer Spine;University of Minnesota;University of Minnesota	10.1109/TVCG.2013.178;10.1109/TVCG.2009.152;10.1109/VAST.2011.6102454;10.1109/TVCG.2010.223;10.1109/VISUAL.2001.964496;10.1109/TVCG.2007.70518;10.1109/VAST.2009.5332593;10.1109/VISUAL.2005.1532857	Design studies, focus + context techniques, integrating spatial and non-spatial data visualization, visual design, biomedical and medical visualization	5	7	7	38	
InfoVis	2014	The Effects of Interactive Latency on Exploratory Visual Analysis	10.1109/TVCG.2014.2346452	http://dx.doi.org/10.1109/TVCG.2014.2346452	2122	2131	J	To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.	Zhicheng Liu;Jeffrey Heer	Zhicheng Liu;Jeffrey Heer	Adobe Research;University of Washington	10.1109/TVCG.2010.177	Interaction, latency, exploratory analysis, interactive visualization, scalability, user performance, verbal analysis	75	117	71	45	
InfoVis	2014	LiveGantt: Interactively Visualizing a Large Manufacturing Schedule	10.1109/TVCG.2014.2346454	http://dx.doi.org/10.1109/TVCG.2014.2346454	2329	2338	J	In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.	Jaemin Jo;Jaeseok Huh;Jonghun Park;Bo Hyoung Kim;Jinwook Seo	Jaemin Jo;Jaeseok Huh;Jonghun Park;Bohyoung Kim;Jinwook Seo	Seoul National University;Seoul National University;Seoul National University;Seoul National University Bundang Hospital;Seoul National University	10.1109/TVCG.2013.200;10.1109/TVCG.2012.213;10.1109/TVCG.2009.117;10.1109/TVCG.2012.225	Schedule visualization, event sequence visualization, simplification, exploratory interactions, simulation	11	18	16	42	
SciVis	2014	Curve Boxplot: Generalization of Boxplot for Ensembles of Curves	10.1109/TVCG.2014.2346455	http://dx.doi.org/10.1109/TVCG.2014.2346455	2654	2663	J	In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.	Mahsa Mirzargar;Ross T. Whitaker;Robert Michael Kirby	Mahsa Mirzargar;Ross T. Whitaker;Robert M. Kirby	Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT;Scientific Computing and Imaging Institute, Salt Lake City, UT;Scientific Computing and Imaging Institute, Salt Lake City, UT	10.1109/TVCG.2013.143;10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1996.568105;10.1109/TVCG.2013.141;10.1109/TVCG.2010.212;10.1109/TVCG.2013.126;10.1109/TVCG.2010.181	Uncertainty visualization, boxplots, ensemble visualization, order statistics, data depth, nonparametric statistic, functional data, parametric curves	42	65	56	62	
InfoVis	2014	Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time	10.1109/TVCG.2014.2346456	http://dx.doi.org/10.1109/TVCG.2014.2346456	2349	2358	J	With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.	Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz 0001;Bernd Hamann	Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz;Bernd Hamann	University of California, Davis;Lawrence Livermore National Laboratory;University of California, Davis;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;University of California, Davis	10.1109/TVCG.2012.286;10.1109/TVCG.2009.196;10.1109/TVCG.2011.199;10.1109/TVCG.2013.200	Information visualization, software visualization, timelines, traces, performance analysis	22	23	17	44	
SciVis	2014	Volume-Preserving Mapping and Registration for Collective Data Visualization	10.1109/TVCG.2014.2346457	http://dx.doi.org/10.1109/TVCG.2014.2346457	2664	2673	J	In order to visualize and analyze complex collective data, complicated geometric structure of each data is desired to be mapped onto a canonical domain to enable map-based visual exploration. This paper proposes a novel volume-preserving mapping and registration method which facilitates effective collective data visualization. Given two 3-manifolds with the same topology, there exists a mapping between them to preserve each local volume element. Starting from an initial mapping, a volume restoring diffeomorphic flow is constructed as a compressible flow based on the volume forms at the manifold. Such a flow yields equality of each local volume element between the original manifold and the target at its final state. Furthermore, the salient features can be used to register the manifold to a reference template by an incompressible flow guided by a divergence-free vector field within the manifold. The process can retain the equality of local volume elements while registering the manifold to a template at the same time. An efficient and practical algorithm is also presented to generate a volume-preserving mapping and a salient feature registration on discrete 3D volumes which are represented with tetrahedral meshes embedded in 3D space. This method can be applied to comparative analysis and visualization of volumetric medical imaging data across subjects. We demonstrate an example application in multimodal neuroimaging data analysis and collective data visualization.	Jiaxi Hu;Guangyu Zou;Jing Hua	Jiaxi Hu;Guangyu Jeff Zou;Jing Hua	Department of Computer Science, Wayne State University, Detroit, MI;Department of Computer Science, Wayne State University, Detroit, MI;Department of Computer Science, Wayne State University, Detroit, MI	10.1109/TVCG.2008.134;10.1109/VISUAL.2004.75;10.1109/VISUAL.2002.1183795;10.1109/TVCG.2011.171	Volume-preserving mapping, data regularization, data transformation	2	3	3	33	
SciVis	2014	Fixed-Rate Compressed Floating-Point Arrays	10.1109/TVCG.2014.2346458	http://dx.doi.org/10.1109/TVCG.2014.2346458	2674	2683	J	Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4&lt;sup&gt;d&lt;/sup&gt; values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation.	Peter Lindstrom	Peter Lindstrom	Center for Applied Scientific Computing, Lawrence Livermore National Laboratory	10.1109/TVCG.2006.143;10.1109/VISUAL.2001.964531;10.1109/TVCG.2006.186;10.1109/VISUAL.2001.964520;10.1109/VISUAL.2003.1250385;10.1109/TVCG.2012.209;10.1109/TVCG.2007.70516;10.1109/TVCG.2012.194;10.1109/VISUAL.1996.568138	Data compression, floating-point arrays, orthogonal block transform, embedded coding	47	98	95	50	
SciVis	2014	Stent Maps - Comparative Visualization for the Prediction of Adverse Events of Transcatheter Aortic Valve Implantations	10.1109/TVCG.2014.2346459	http://dx.doi.org/10.1109/TVCG.2014.2346459	2704	2713	J	Transcatheter aortic valve implantation (TAVI) is a minimally-invasive method for the treatment of aortic valve stenosis in patients with high surgical risk. Despite the success of TAVI, side effects such as paravalvular leakages can occur postoperatively. The goal of this project is to quantitatively analyze the co-occurrence of this complication and several potential risk factors such as stent shape after implantation, implantation height, amount and distribution of calcifications, and contact forces between stent and surrounding structure. In this paper, we present a two-dimensional visualization (stent maps), which allows (1) to comprehensively display all these aspects from CT data and mechanical simulation results and (2) to compare different datasets to identify patterns that are typical for adverse effects. The area of a stent map represents the surface area of the implanted stent - virtually straightened and uncoiled. Several properties of interest, like radial forces or stent compression, are displayed in this stent map in a heatmap-like fashion. Important anatomical landmarks and calcifications are plotted to show their spatial relation to the stent and possible correlations with the color-coded parameters. To provide comparability, the maps of different patient datasets are spatially adjusted according to a corresponding anatomical landmark. Also, stent maps summarizing the characteristics of different populations (e.g. with or without side effects) can be generated. Up to this point several interesting patterns have been observed with our technique, which remained hidden when examining the raw CT data or 3D visualizations of the same data. One example are obvious radial force maxima between the right and non-coronary valve leaflet occurring mainly in cases without leakages. These observations confirm the usefulness of our approach and give starting points for new hypotheses and further analyses. Because of its reduced dimensionality, the stent map data is an appropriate input for statistical group evaluation and machine learning methods.	Silvia Born;Simon H. Sündermann;Christoph Russ;Raoul Hopf;Carlos E. Ruiz;Volkmar Falk;Michael Gessat	Silvia Born;Simon H. Sündermann;Christoph Russ;Raoul Hopf;Carlos E. Ruiz;Volkmar Falk;Michael Gessat	University of Zurich, Switzerland;Division of Cardiovascular Surgery, University Hospital of Zurich, Switzerland;Swiss Federal Institute of Technology (ETH) Zurich, Switzerland;Swiss Federal Institute of Technology (ETH) Zurich, Switzerland;Structural and Congenital Heart Division, Lenox Hill Hospital;Division of Cardiovascular Surgery, University Hospital of Zurich, Switzerland;University of Zurich, Switzerland	10.1109/TVCG.2009.169;10.1109/TVCG.2007.70550;10.1109/VISUAL.2001.964540;10.1109/TVCG.2011.235;10.1109/TVCG.2013.139;10.1109/VISUAL.2003.1250353	Comparative visualization, medical visualization, vessel flattening, transcatheter aortic valve implantation (TAVI)	6	8	8	31	
VAST	2014	Knowledge Generation Model for Visual Analytics	10.1109/TVCG.2014.2346481	http://dx.doi.org/10.1109/TVCG.2014.2346481	1604	1613	J	Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on.	Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim	Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim	Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz	10.1109/VISUAL.2005.1532781;10.1109/TVCG.2013.124;10.1109/VAST.2009.5333023;10.1109/TVCG.2011.229;10.1109/TVCG.2008.109;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677365;10.1109/VAST.2010.5652879;10.1109/TVCG.2012.273;10.1109/VAST.2008.4677358;10.1109/TVCG.2008.121;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102435;10.1109/TVCG.2013.120	Visual Analytics, Knowledge Generation, Reasoning, Visualization Taxonomies and Models, Interaction	69	113	95	43	
VAST	2014	INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data	10.1109/TVCG.2014.2346482	http://dx.doi.org/10.1109/TVCG.2014.2346482	1614	1623	J	Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.	Josua Krause;Adam Perer;Enrico Bertini	Josua Krause;Adam Perer;Enrico Bertini	NYU Polytechnic School of Engineering;IBM T.J. Watson Research Center;NYU Polytechnic School of Engineering	10.1109/INFVIS.2004.71;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2011.229;10.1109/VAST.2011.6102448;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102453;10.1109/TVCG.2013.125;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652443	Predictive modeling, feature selection, classification, visual analytics, high-dimensional data	36	55	39	23	
VAST	2014	Transforming Scagnostics to Reveal Hidden Features	10.1109/TVCG.2014.2346572	http://dx.doi.org/10.1109/TVCG.2014.2346572	1624	1632	J	Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.	Tommy Dang;Leland Wilkinson	Tuan Nhon Dang;Leland Wilkinson	Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, Skytree Software Inc.	10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.187;10.1109/TVCG.2011.167;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006	Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics	6	12	11	44	
VAST	2014	Supporting Communication and Coordination in Collaborative Sensemaking	10.1109/TVCG.2014.2346573	http://dx.doi.org/10.1109/TVCG.2014.2346573	1633	1642	J	When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other's activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.	Narges Mahyar;Melanie Tory	Narges Mahyar;Melanie Tory	University of Victoria;University of Victoria	10.1109/VAST.2009.5333245;10.1109/VAST.2006.261439;10.1109/VAST.2008.4677358;10.1109/TVCG.2013.197;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878;10.1109/VAST.2006.261430;10.1109/VAST.2007.4389011;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102447	Sensemaking, Collaboration, Externalization, Linked common work, Collaborative thinking space	36	47	36	43	BP
VAST	2014	Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics	10.1109/TVCG.2014.2346574	http://dx.doi.org/10.1109/TVCG.2014.2346574	1653	1662	J	As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records.	Charles D. Stolper;Adam Perer;David Gotz	Charles D. Stolper;Adam Perer;David Gotz	School of Interactive Computing, Georgia Institute of Technology;IBM T.J. Watson Research Center;University of North Carolina at Chapel Hill	10.1109/VAST.2006.261421;10.1109/TVCG.2013.227;10.1109/TVCG.2009.187;10.1109/TVCG.2011.179;10.1109/INFVIS.2005.1532133;10.1109/TVCG.2012.225;10.1109/TVCG.2013.179;10.1109/INFVIS.2000.885097;10.1109/TVCG.2013.200	Progressive visual analytics, information visualization, interactive machine learning, electronic medical records	60	101	72	43	
VAST	2014	Finding Waldo: Learning about Users from their Interactions	10.1109/TVCG.2014.2346575	http://dx.doi.org/10.1109/TVCG.2014.2346575	1663	1672	J	Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.	Eli T. Brown;Alvitta Ottley;Helen Zhao;Quan Lin;Richard Souvenir;Alex Endert;Remco Chang	Eli T Brown;Alvitta Ottley;Helen Zhao;Quan Lin;Richard Souvenir;Alex Endert;Remco Chang	Tufts U;Tufts U;Tufts U;Tufts U;U.N.C. Charlotte;Pacific Northwest National Lab;Tufts U	10.1109/TVCG.2012.204;10.1109/VAST.2010.5653587;10.1109/VAST.2009.5333020;10.1109/VAST.2012.6400486;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.276;10.1109/VAST.2006.261436;10.1109/VAST.2008.4677352	User Interactions, Analytic Provenance, Visualization, Applied Machine Learning	32	46	37	47	
VAST	2014	Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations	10.1109/TVCG.2014.2346578	http://dx.doi.org/10.1109/TVCG.2014.2346578	1643	1652	J	An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.	Thomas Mühlbacher;Harald Piringer;Samuel Gratzl;Michael Sedlmair;Marc Streit	Thomas Mühlbacher;Harald Piringer;Samuel Gratzl;Michael Sedlmair;Marc Streit	VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Johannes Kepler University, Linz, Austria;University of Vienna, Austria;Johannes Kepler University, Linz, Austria	10.1109/VAST.2012.6400486;10.1109/VAST.2007.4388999;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.151;10.1109/TVCG.2014.2346321;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.171;10.1109/TVCG.2013.212;10.1109/TVCG.2013.125;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.110;10.1109/INFVIS.2004.60;10.1109/VAST.2011.6102453;10.1109/TVCG.2012.195;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.229	Visual analytics infrastructures, integration, interactive algorithms, user involvement, problem subdivision	45	61	51	52	
VAST	2014	Interactive Visual Analysis of Image-Centric Cohort Study Data	10.1109/TVCG.2014.2346591	http://dx.doi.org/10.1109/TVCG.2014.2346591	1673	1682	J	Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.	Paul Klemm;Steffen Oeltze-Jafra;Kai Lawonn;Katrin Hegenscheid;Henry Völzke;Bernhard Preim	Paul Klemm;Steffen Oeltze-Jafra;Kai Lawonn;Katrin Hegenscheid;Henry Völzke;Bernhard Preim	Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Otto-von-Guericke University Magdeburg, Germany	10.1109/TVCG.2013.160;10.1109/TVCG.2011.185;10.1109/VISUAL.2000.885739;10.1109/TVCG.2011.217;10.1109/TVCG.2007.70569	Interactive Visual Analysis, Epidemiology, Spine	14	19	16	44	
VAST	2014	Visual Abstraction and Exploration of Multi-class Scatterplots	10.1109/TVCG.2014.2346594	http://dx.doi.org/10.1109/TVCG.2014.2346594	1683	1692	J	Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.	Haidong Chen;Wei Chen 0001;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen 0002;Wentao Gu;Kwan-Liu Ma	Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma	State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;Zhejiang University of Finance & Economics;Zhejiang GongShang University;University of California at Davis	10.1109/TVCG.2013.150;10.1109/TVCG.2008.119;10.1109/VISUAL.1998.745301;10.1109/TVCG.2008.120;10.1109/TVCG.2010.197;10.1109/TVCG.2006.187;10.1109/TVCG.2007.70623;10.1109/TVCG.2013.180;10.1109/INFVIS.2004.52;10.1109/VAST.2010.5652460;10.1109/TVCG.2009.112;10.1109/TVCG.2009.122;10.1109/TVCG.2011.181;10.1109/TVCG.2012.238;10.1109/TVCG.2010.176;10.1109/TVCG.2013.212;10.1109/TVCG.2011.261;10.1109/TVCG.2008.153;10.1109/TVCG.2013.183	Scatterplot, overdraw reduction, sampling, visual abstraction	20	36	41	48	
VAST	2014	Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees	10.1109/TVCG.2014.2346626	http://dx.doi.org/10.1109/TVCG.2014.2346626	1693	1702	J	Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.	Michael Beham;Wolfgang Herzner;M. Eduard Gröller;Johannes Kehrer	Michael Beham;Wolfgang Herzner;M. Eduard Gröller;Johannes Kehrer	Vienna University of Technology;Austrian Institute of Technology;Vienna University of Technology;Vienna University of Technology	10.1109/TVCG.2013.147;10.1109/TVCG.2013.213;10.1109/TVCG.2010.138;10.1109/TVCG.2009.155;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2010.190;10.1109/TVCG.2006.147;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809866;10.1109/TVCG.2007.70581	Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis	15	20	16	43	
VAST	2014	Visual Methods for Analyzing Probabilistic Classification Data	10.1109/TVCG.2014.2346660	http://dx.doi.org/10.1109/TVCG.2014.2346660	1703	1712	J	Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.	Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber	Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber	Vienna University of Technology;Vienna University of Technology;University of Bergen;Vienna University of Technology;Vienna University of Technology	10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652398;10.1109/VAST.2009.5332628;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.184;10.1109/TVCG.2012.254;10.1109/VAST.2011.6102448;10.1109/VAST.2011.6102453;10.1109/VAST.2012.6400492;10.1109/VAST.2010.5652443	Probabilistic classification, confusion analysis, feature evaluation and selection, visual inspection	18	33	23	43	
VAST	2014	A Five-Level Design Framework for Bicluster Visualizations	10.1109/TVCG.2014.2346665	http://dx.doi.org/10.1109/TVCG.2014.2346665	1713	1722	J	Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.	Maoyuan Sun;Chris North;Naren Ramakrishnan	Maoyuan Sun;Chris North;Naren Ramakrishnan	Department of Computer Science, Discovery Analytics Center, Virginia Tech;Department of Computer Science, Discovery Analytics Center, Virginia Tech;Department of Computer Science, Discovery Analytics Center, Virginia Tech	10.1109/TVCG.2006.147;10.1109/TVCG.2009.153;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.250;10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/VISUAL.1999.809866;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.1;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.167;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70582	Biclusters, interactive visual analytics, coordinated relationships, design framework	15	21	18	93	
VAST	2014	VarifocalReader -- In-Depth Visual Analysis of Large Text Documents	10.1109/TVCG.2014.2346677	http://dx.doi.org/10.1109/TVCG.2014.2346677	1723	1732	J	Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.	Steffen Koch;Markus John;Michael Wörner 0001;Andreas Müller 0012;Thomas Ertl	Steffen Koch;Markus John;Michael Wörner;Andreas Müller;Thomas Ertl	Institute of Visualization and Interactive Systems (VIS);Institute of Visualization and Interactive Systems (VIS);Institute of Visualization and Interactive Systems (VIS);Institute for Natural Language Processing (IMS);Institute of Visualization and Interactive Systems (VIS)	10.1109/VAST.2010.5652926;10.1109/TVCG.2008.172;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.188;10.1109/TVCG.2007.70577;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/TVCG.2009.165;10.1109/TVCG.2013.162;10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5333248;10.1109/TVCG.2012.260;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333919;10.1109/VAST.2007.4389004	visual analytics, document analysis, literary analysis, natural language processing, text mining, machine learning, distant reading	25	33	22	48	
VAST	2014	DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data	10.1109/TVCG.2014.2346682	http://dx.doi.org/10.1109/TVCG.2014.2346682	1783	1792	J	Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.	David Gotz;Harry Stavropoulos	David Gotz;Harry Stavropoulos	University of North Carolina at Chapel Hill;IBM T.J. Watson Research Center	10.1109/TVCG.2013.206;10.1109/TVCG.2012.225;10.1109/TVCG.2011.179;10.1109/INFVIS.2000.885097;10.1109/VAST.2009.5332595;10.1109/VAST.2010.5652890;10.1109/TVCG.2009.117;10.1109/VAST.2006.261421;10.1109/TVCG.2013.200	Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics	45	67	62	34	
VAST	2014	Footprints: A Visual Search Tool that Supports Discovery and Coverage Tracking	10.1109/TVCG.2014.2346743	http://dx.doi.org/10.1109/TVCG.2014.2346743	1793	1802	J	Searching a large document collection to learn about a broad subject involves the iterative process of figuring out what to ask, filtering the results, identifying useful documents, and deciding when one has covered enough material to stop searching. We are calling this activity “discoverage,” discovery of relevant material and tracking coverage of that material. We built a visual analytic tool called Footprints that uses multiple coordinated visualizations to help users navigate through the discoverage process. To support discovery, Footprints displays topics extracted from documents that provide an overview of the search space and are used to construct searches visuospatially. Footprints allows users to triage their search results by assigning a status to each document (To Read, Read, Useful), and those status markings are shown on interactive histograms depicting the user's coverage through the documents across dates, sources, and topics. Coverage histograms help users notice biases in their search and fill any gaps in their analytic process. To create Footprints, we used a highly iterative, user-centered approach in which we conducted many evaluations during both the design and implementation stages and continually modified the design in response to feedback.	Ellen Isaacs;Kelly Domico;Shane Ahern;Eugene Bart;Mudita Singhal	Ellen Isaacs;Kelly Damico;Shane Ahern;Eugene Bart;Mudita Singhal	Palo Alto Research Center (PARC);Palo Alto Research Center (PARC);Palo Alto Research Center (PARC);Palo Alto Research Center (PARC);Palo Alto Research Center (PARC)	10.1109/VAST.2009.5333443;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4389006;10.1109/INFVIS.2001.963287;10.1109/TVCG.2007.70589;10.1109/VAST.2006.261426;10.1109/TVCG.2007.70577	discovery search visualization, visual cues, discoverage, coverage tracking, document triage, interactive histograms	3	5	4	35	
VAST	2014	Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles	10.1109/TVCG.2014.2346744	http://dx.doi.org/10.1109/TVCG.2014.2346744	1803	1812	J	In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a naïve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the “best” points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.	Kresimir Matkovic;Denis Gracanin;Rainer Splechtna;Mario Jelovic;Benedikt Stehno;Helwig Hauser;Werner Purgathofer	Kreŝimir Matković;Denis Gračanin;Rainer Splechtna;Mario Jelović;Benedikt Stehno;Helwig Hauser;Werner Purgathofer	VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria;AVL-AST Zagreb, Croatia;VRVis Research Center, Vienna, Austria;University of Bergen, Norway;Vienna University of Technology, Austria	10.1109/TVCG.2010.223;10.1109/TVCG.2012.280;10.1109/TVCG.2008.145;10.1109/TVCG.2009.110;10.1109/TVCG.2010.171	Interactive Visual Analysis, Integrated Design Environment, Simulation, Visual Steering, Automatic Optimization	11	18	15	42	
VAST	2014	Visual Exploration of Sparse Traffic Trajectory Data	10.1109/TVCG.2014.2346746	http://dx.doi.org/10.1109/TVCG.2014.2346746	1813	1822	J	In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.	Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu	Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu	Peking University;Peking University;Peking University;Peking University;Hong Kong University of Science and Technology;Nanjing Intelligent Transportation Systems Co., Ltd;Nanjing Intelligent Transportation Systems Co., Ltd	10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/INFVIS.2005.1532151;10.1109/VAST.2011.6102458;10.1109/TVCG.2011.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/VAST.2009.5332584;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102454;10.1109/VAST.2011.6102455;10.1109/TVCG.2009.182;10.1109/TVCG.2012.265	Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion	41	57	54	46	
VAST	2014	DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios	10.1109/TVCG.2014.2346747	http://dx.doi.org/10.1109/TVCG.2014.2346747	1823	1832	J	We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.	Krishna P. C. Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuet Ling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri	Krishna Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri	Purdue University;Purdue University;Purdue University;Purdue University;Purdue University;Microsoft Corporation;Microsoft Corporation;George Mason University	10.1109/TVCG.2007.70541;10.1109/TVCG.2011.174;10.1109/TVCG.2010.177;10.1109/TVCG.2012.255;10.1109/TVCG.2009.123;10.1109/TVCG.2013.223;10.1109/INFVIS.2001.963283;10.1109/TVCG.2012.213;10.1109/VAST.2008.4677361	visual analytics, portfolio mining, web-based visualization, casual visualization, design study	10	15	15	40	
VAST	2014	Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles	10.1109/TVCG.2014.2346751	http://dx.doi.org/10.1109/TVCG.2014.2346751	1893	1902	J	Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.	Patrick Köthur;Mike Sips;Henryk Dobslaw;Doris Dransch	Patrick Köthur;Mike Sips;Henryk Dobslaw;Doris Dransch	GFZ German Research Centre for Geosciences, Potsdam, Germany;GFZ German Research Centre for Geosciences, Potsdam, Germany;GFZ German Research Centre for Geosciences, Potsdam, Germany;GFZ German Research Centre for Geosciences, Potsdam, Germany	10.1109/TVCG.2012.190;10.1109/TVCG.2012.284;10.1109/TVCG.2008.139	Ocean modeling, model assessment, geospatial time series, cluster ensembles, visual comparison, visual analytics	10	17	17	43	
VAST	2014	ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery	10.1109/TVCG.2014.2346752	http://dx.doi.org/10.1109/TVCG.2014.2346752	1883	1892	J	Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms.	Christian Partl;Alexander Lex;Marc Streit;Hendrik Strobelt;Anne Mai Wassermann;Hanspeter Pfister;Dieter Schmalstieg	Christian Partl;Alexander Lex;Marc Streit;Hendrik Strobelt;Anne-Mai Wassermann;Hanspeter Pfister;Dieter Schmalstieg	Graz University of Technology;Harvard University;Johannes Kepler University Linz;Harvard University;Novartis Institutes for BicMedical Research;Harvard University;Graz University of Technology	10.1109/TVCG.2013.167;10.1109/TVCG.2012.213;10.1109/TVCG.2012.252;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/TVCG.2013.223	Multi-relational data, visual data analysis, drug discovery	9	12	14	30	
VAST	2014	Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks	10.1109/TVCG.2014.2346753	http://dx.doi.org/10.1109/TVCG.2014.2346753	1903	1912	J	Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).	Bowen Yu;Harish Doraiswamy;Xi Chen;Emily R. Miraldi;Mario Luis Arrieta-Ortiz;Christoph Hafemeister;Aviv Madar;Richard Bonneau;Cláudio T. Silva	Bowen Yu;Harish Doraiswamy;Xi Chen;Emily Miraldi;Mario Luis Arrieta-Ortiz;Christoph Hafemeister;Aviv Madar;Richard Bonneau;Cláudio T. Silva	NYU Polytechnic School of Engineering;NYU Polytechnic School of Engineering;NYU Center for Genomics and Systems Biology;NYU Center for Genomics and Systems Biology;NYU Center for Genomics and Systems Biology;NYU Center for Genomics and Systems Biology;Cornell University;NYU Center for Genomics and Systems Biology;NYU Polytechnic School of Engineering	10.1109/TVCG.2008.117;10.1109/TVCG.2009.146;10.1109/TVCG.2011.185;10.1109/TVCG.2009.167	Web-based visualization, gene regulatory network	5	8	8	32	
VAST	2014	The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals	10.1109/TVCG.2014.2346754	http://dx.doi.org/10.1109/TVCG.2014.2346754	1913	1922	J	Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the current workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.	Maria Luján Ganuza;Gabriela Ferracutti;Maria Florencia Gargiulo;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic	María Luján Ganuza;Gabriela Ferracutti;María Florencia Gargiulo;Silvia Mabel Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković	VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de GeologíaINGEOSUR CCT CONICET, Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de GeologíaINGEOSUR CCT CONICET, Universidad Nacional del Sur, Bahía Blanca, Argentina;Vienna University of Technology, Austria;VRVis Research Center, Vienna, Austria	10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.155;10.1109/VISUAL.1995.485139	Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies	5	6	5	29	
VAST	2014	Visual Reconciliation of Alternative Similarity Spaces in Climate Modeling	10.1109/TVCG.2014.2346755	http://dx.doi.org/10.1109/TVCG.2014.2346755	1923	1932	J	Visual data analysis often requires grouping of data objects based on their similarity. In many application domains researchers use algorithms and techniques like clustering and multidimensional scaling to extract groupings from data. While extracting these groups using a single similarity criteria is relatively straightforward, comparing alternative criteria poses additional challenges. In this paper we define visual reconciliation as the problem of reconciling multiple alternative similarity spaces through visualization and interaction. We derive this problem from our work on model comparison in climate science where climate modelers are faced with the challenge of making sense of alternative ways to describe their models: one through the output they generate, another through the large set of properties that describe them. Ideally, they want to understand whether groups of models with similar spatio-temporal behaviors share similar sets of criteria or, conversely, whether similar criteria lead to similar behaviors. We propose a visual analytics solution based on linked views, that addresses this problem by allowing the user to dynamically create, modify and observe the interaction among groupings, thereby making the potential explanations apparent. We present case studies that demonstrate the usefulness of our technique in the area of climate science.	Jorge Poco;Aritra Dasgupta;Yaxing Wei;William W. Hargrove;Christopher R. Schwalm;Deborah N. Huntzinger;Robert B. Cook;Enrico Bertini;Cláudio T. Silva	Jorge Poco;Aritra Dasgupta;Yaxing Wei;William Hargrove;Christopher R. Schwalm;Deborah N. Huntzinger;Robert Cook;Enrico Bertini;Claudio T. Silva	New York University;New York University and DataONE;Oak Ridge National Laboratory;USDA Forest Service;Northern Arizona University;Northern Arizona University;Oak Ridge National Laboratory;New York University;New York University	10.1109/TVCG.2008.139;10.1109/TVCG.2012.256;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.157;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.188;10.1109/TVCG.2013.224;10.1109/VAST.2008.4677350;10.1109/TVCG.2013.120	Similarity, clustering, matrix, optimization, climate model	7	13	12	42	
VAST	2014	Visualizing Mobility of Public Transportation System	10.1109/TVCG.2014.2346893	http://dx.doi.org/10.1109/TVCG.2014.2346893	1833	1842	J	Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.	Wei Zeng;Chi-Wing Fu;Stefan Müller Arisona;Alexander Erath;Huamin Qu	Wei Zeng;Chi-Wing Fu;Stefan Müller Arisona;Alexander Erath;Huamin Qu	Nanyang Technological University, Singapore;Nanyang Technological University, Singapore;University of Applied Sciences;ETH Zurich;Hong Kong University of Science and Technology	10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.202;10.1109/TVCG.2011.205;10.1109/TVCG.2009.143;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/INFVIS.2005.1532150	Mobility, public transportation, visual analytics	37	47	42	42	
VAST	2014	Visual Analysis of Public Utility Service Problems in a Metropolis	10.1109/TVCG.2014.2346898	http://dx.doi.org/10.1109/TVCG.2014.2346898	1843	1852	J	Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions.	Jiawan Zhang;E. Yanli;Jing Ma;Yahui Zhao;Binghan Xu;Liting Sun;Jinyan Chen;Xiaoru Yuan	Jiawan Zhang;E Yanli;Jing Ma;Yahui Zhao;Binghan Xu;Liting Sun;Jinyan Chen;Xiaoru Yuan	School of Computer Science and Technology;School of Computer Science and Technology;SCS, Tianjin University;SCS, Tianjin University;SCS, Tianjin University;SCS, Tianjin University;SCS, Tianjin University;School of EECS	10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400556;10.1109/TVCG.2013.228;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677356;10.1109/TVCG.2012.291;10.1109/TVCG.2013.132;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/VAST.2011.6102460;10.1109/TVCG.2009.122	utility services, evidence-based decision making, visual analytics, aggregate	13	18	14	43	
VAST	2014	VASA: Interactive Computational Steering of Large Asynchronous Simulation Pipelines for Societal Infrastructure	10.1109/TVCG.2014.2346911	http://dx.doi.org/10.1109/TVCG.2014.2346911	1853	1862	J	We present VASA, a visual analytics platform consisting of a desktop application, a component model, and a suite of distributed simulation components for modeling the impact of societal threats such as weather, food contamination, and traffic on critical infrastructure such as supply chains, road networks, and power grids. Each component encapsulates a high-fidelity simulation model that together form an asynchronous simulation pipeline: a system of systems of individual simulations with a common data and parameter exchange format. At the heart of VASA is the Workbench, a visual analytics application providing three distinct features: (1) low-fidelity approximations of the distributed simulation components using local simulation proxies to enable analysts to interactively configure a simulation run; (2) computational steering mechanisms to manage the execution of individual simulation components; and (3) spatiotemporal and interactive methods to explore the combined results of a simulation run. We showcase the utility of the platform using examples involving supply chains during a hurricane as well as food contamination in a fast food restaurant chain.	Sungahn Ko;Jieqiong Zhao;Jing Xia;Shehzad Afzal;Xiaoyu Wang;Greg Abram;Niklas Elmqvist;Len Kne;David Van Riper;Kelly P. Gaither;Shaun Kennedy;William J. Tolone;William Ribarsky;David S. Ebert	Sungahn Ko;Shaun Kennedy;William Tolone;William Ribarsky;David S. Ebert;Jieqiong Zhao;Jing Xia;Shehzad Afzal;Xiaoyu Wang;Greg Abram;Niklas Elmqvist;Len Kne;David Van Riper;Kelly Gaither	Purdue University in West Lafayette, IN, USA;University of Minnesota in Minneapolis, MN, USA;University of North Carolina at Charlotte in Charlotte, NC, USA;University of North Carolina at Charlotte in Charlotte, NC, USA;Purdue University in West Lafayette, IN, USA;Purdue University in West Lafayette, IN, USA;State Key Lab of CAD&CG, China;Purdue University in West Lafayette, IN, USA;University of North Carolina at Charlotte in Charlotte, NC, USA;University of Texas at Austin in Austin, TX, USA;Purdue University in West Lafayette, IN, USA;University of Minnesota in Minneapolis, MN, USA;University of Minnesota in Minneapolis, MN, USA;University of Texas at Austin in Austin, TX, USA	10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.225;10.1109/TVCG.2012.260;10.1109/TVCG.2007.70541;10.1109/TVCG.2010.223;10.1109/TVCG.2013.146;10.1109/TVCG.2010.171;10.1109/VAST.2011.6102460;10.1109/VAST.2011.6102457	Computational steering, visual analytics, critical infrastructure, homeland security	6	9	5	42	
VAST	2014	LoyalTracker: Visualizing Loyalty Dynamics in Search Engines	10.1109/TVCG.2014.2346912	http://dx.doi.org/10.1109/TVCG.2014.2346912	1733	1742	J	The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.	Conglei Shi;Yingcai Wu;Shixia Liu;Hong Zhou;Huamin Qu	Conglei Shi;Yingcai Wu;Shixia Liu;Hong Zhou;Huamin Qu	Hong Kong University of Science and Technology;Microsoft Research Asia;Microsoft Research Asia;Shenzhen University;Hong Kong University of Science and Technology	10.1109/VAST.2010.5652931;10.1109/TVCG.2009.171;10.1109/VAST.2007.4389008;10.1109/TVCG.2012.253;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.212;10.1109/TVCG.2010.129;10.1109/TVCG.2012.225;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400494;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.166	Time-series visualization, stacked graphs, log data visualization, text visualization	14	16	14	48	HM
VAST	2014	VAET: A Visual Analytics Approach for E-Transactions Time-Series	10.1109/TVCG.2014.2346913	http://dx.doi.org/10.1109/TVCG.2014.2346913	1743	1752	J	Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.	Cong Xie;Wei Chen 0001;Xinxin Huang;Yueqi Hu;Scott Barlowe;Jing Yang	Cong Xie;Wei Chen;Xinxin Huang;Yueqi Hu;Scott Barlowe;Jing Yang	State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Dept. of Computer Science, University of North Carolina, Charlotte;Western Carolina University;Dept. of Computer Science, University of North Carolina, Charlotte	10.1109/TVCG.2009.123;10.1109/VAST.2007.4389009;10.1109/TVCG.2012.212;10.1109/INFVIS.1995.528685;10.1109/VAST.2012.6400494;10.1109/TVCG.2010.162;10.1109/TVCG.2009.180	Time-Series, Visual Analytics, E-transaction	14	23	28	27	
VAST	2014	EvoRiver: Visual Analysis of Topic Coopetition on Social Media	10.1109/TVCG.2014.2346919	http://dx.doi.org/10.1109/TVCG.2014.2346919	1753	1762	J	Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).	Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang	Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang	Zhejiang University of Technology;Microsoft Research;Microsoft Research;Nanyang Technological University;City University of Hong Kong;Zhejiang University of Technology	10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162	Topic coopetition, information diffusion, information propagation, time-based visualization	40	56	55	46	
VAST	2014	OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media	10.1109/TVCG.2014.2346920	http://dx.doi.org/10.1109/TVCG.2014.2346920	1763	1772	J	It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.	Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu	Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu	Microsoft Research;Microsoft Research;Harbin Institute of Technology;Tsinghua University;Tsinghua University	10.1109/TVCG.2011.239;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2012.291;10.1109/VAST.2006.261431;10.1109/TVCG.2010.129;10.1109/TVCG.2013.196;10.1109/TVCG.2014.2346919;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919	Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail	58	82	70	48	
VAST	2014	#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media	10.1109/TVCG.2014.2346922	http://dx.doi.org/10.1109/TVCG.2014.2346922	1773	1782	J	We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.	Jian Zhao 0010;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Christopher Collins 0001	Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Christopher Collins	University of Toronto;MIT;MIT;IBM J. Watson Research Center;University of Pittsburgh;UOIT	10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/TVCG.2012.226;10.1109/TVCG.2013.227;10.1109/VAST.2012.6400485;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162	Retweeting threads, anomaly detection, social media, visual analytics, machine learning, information visualization	49	69	57	48	HM
VAST	2014	Proactive Spatiotemporal Resource Allocation and Predictive Visual Analytics for Community Policing and Law Enforcement	10.1109/TVCG.2014.2346926	http://dx.doi.org/10.1109/TVCG.2014.2346926	1863	1872	J	In this paper, we present a visual analytics approach that provides decision makers with a proactive and predictive environment in order to assist them in making effective resource allocation and deployment decisions. The challenges involved with such predictive analytics processes include end-users' understanding, and the application of the underlying statistical algorithms at the right spatiotemporal granularity levels so that good prediction estimates can be established. In our approach, we provide analysts with a suite of natural scale templates and methods that enable them to focus and drill down to appropriate geospatial and temporal resolution levels. Our forecasting technique is based on the Seasonal Trend decomposition based on Loess (STL) method, which we apply in a spatiotemporal visual analytics context to provide analysts with predicted levels of future activity. We also present a novel kernel density estimation technique we have developed, in which the prediction process is influenced by the spatial correlation of recent incidents at nearby locations. We demonstrate our techniques by applying our methodology to Criminal, Traffic and Civil (CTC) incident datasets.	Abish Malik;Ross Maciejewski;Sherry Towers;Sean McCullough;David S. Ebert	Abish Malik;Ross Maciejewski;Sherry Towers;Sean McCullough;David S. Ebert	Purdue University;Arizona State University;Arizona State University;Purdue University;Purdue University	10.1109/TVCG.2013.125;10.1109/TVCG.2013.206;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.200	Visual Analytics, Natural Scales, Seasonal Trend decomposition based on Loess (STL), Law Enforcement	28	39	29	45	
VAST	2014	Run Watchers: Automatic Simulation-Based Decision Support in Flood Management	10.1109/TVCG.2014.2346930	http://dx.doi.org/10.1109/TVCG.2014.2346930	1873	1882	J	In this paper, we introduce a simulation-based approach to design protection plans for flood events. Existing solutions require a lot of computation time for an exhaustive search, or demand for a time-consuming expert supervision and steering. We present a faster alternative based on the automated control of multiple parallel simulation runs. Run Watchers are dedicated system components authorized to monitor simulation runs, terminate them, and start new runs originating from existing ones according to domain-specific rules. This approach allows for a more efficient traversal of the search space and overall performance improvements due to a re-use of simulated states and early termination of failed runs. In the course of search, Run Watchers generate large and complex decision trees. We visualize the entire set of decisions made by Run Watchers using interactive, clustered timelines. In addition, we present visualizations to explain the resulting response plans. Run Watchers automatically generate storyboards to convey plan details and to justify the underlying decisions, including those which leave particular buildings unprotected. We evaluate our solution with domain experts.	Artem Konev;Jürgen Waser;Bernhard Sadransky;Daniel Cornel;Rui A. P. Perdigão;Zsolt Horváth;M. Eduard Gröller	Artem Konev;Jürgen Waser;Bernhard Sadransky;Daniel Cornel;Rui A.P. Perdigão;Zsolt Horváth;M. Eduard Gröller	VRVis Vienna;VRVis Vienna;VRVis Vienna;VRVis Vienna;TU Vienna;TU Vienna;TU Vienna	10.1109/INFVIS.2002.1173149;10.1109/VISUAL.2000.885727;10.1109/TVCG.2010.190;10.1109/TVCG.2011.248;10.1109/TVCG.2010.223;10.1109/TVCG.2008.145	Disaster management, simulation control, decision making, visual evidence, storytelling	6	7	5	36	
InfoVis	2014	Learning Perceptual Kernels for Visualization Design	10.1109/TVCG.2014.2346978	http://dx.doi.org/10.1109/TVCG.2014.2346978	1933	1942	J	Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.	Çagatay Demiralp;Michael S. Bernstein;Jeffrey Heer	Çağatay Demiralp;Michael S. Bernstein;Jeffrey Heer	Stanford University;Stanford University;University of Washington	10.1109/TVCG.2010.186;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.167;10.1109/TVCG.2007.70583;10.1109/TVCG.2008.125;10.1109/TVCG.2010.130;10.1109/TVCG.2007.70539	Visualization, design, encoding, perception, model, crowdsourcing, automated visualization, visual embedding	39	60	35	47	
InfoVis	2014	Ranking Visualizations of Correlation Using Weber's Law	10.1109/TVCG.2014.2346979	http://dx.doi.org/10.1109/TVCG.2014.2346979	1943	1952	J	Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n = 1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber's law. The results of this experiment contribute to our understanding of information visualization by establishing that: (1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber's law, (2) correlation judgment precision showed striking variation between negatively and positively correlated data, and (3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization.	Lane Harrison;Fumeng Yang;Steven Franconeri;Remco Chang	Lane Harrison;Fumeng Yang;Steven Franconeri;Remco Chang	Tufts University;Tufts University;Northwestern University;Tufts University	10.1109/TVCG.2013.187;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594	Perception, Visualization, Evaluation	38	67	49	24	
InfoVis	2014	The relation between visualization size, grouping, and user performance	10.1109/TVCG.2014.2346983	http://dx.doi.org/10.1109/TVCG.2014.2346983	1953	1962	J	In this paper we make the following contributions: (1) we describe how the grouping, quantity, and size of visual marks affects search time based on the results from two experiments; (2) we report how search performance relates to self-reported difficulty in finding the target for different display types; and (3) we present design guidelines based on our findings to facilitate the design of effective visualizations. Both Experiment 1 and 2 asked participants to search for a unique target in colored visualizations to test how the grouping, quantity, and size of marks affects user performance. In Experiment 1, the target square was embedded in a grid of squares and in Experiment 2 the target was a point in a scatterplot. Search performance was faster when colors were spatially grouped than when they were randomly arranged. The quantity of marks had little effect on search time for grouped displays (“pop-out”), but increasing the quantity of marks slowed reaction time for random displays. Regardless of color layout (grouped vs. random), response times were slowest for the smallest mark size and decreased as mark size increased to a point, after which response times plateaued. In addition to these two experiments we also include potential application areas, as well as results from a small case study where we report preliminary findings that size may affect how users infer how visualizations should be used. We conclude with a list of design guidelines that focus on how to best create visualizations based on grouping, quantity, and size of visual marks.	Connor Gramazio;Karen B. Schloss;David H. Laidlaw	Connor C. Gramazio;Karen B. Schloss;David H. Laidlaw	Department of Computer Science, Brown University;Department of Cognitive, Linguistic, Psychological Sciences at Brown University;Department of Computer Science, Brown University	10.1109/TVCG.2012.233;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/VAST.2007.4389009;10.1109/TVCG.2013.187;10.1109/TVCG.2011.175;10.1109/TVCG.2013.183;10.1109/TVCG.2006.184;10.1109/TVCG.2010.186;10.1109/VISUAL.1996.568118;10.1109/TVCG.2012.220;10.1109/TVCG.2013.170;10.1109/TVCG.2013.234	information visualization, graphical perception, size, layout	8	14	7	51	
InfoVis	2014	A Principled Way of Assessing Visualization Literacy	10.1109/TVCG.2014.2346984	http://dx.doi.org/10.1109/TVCG.2014.2346984	1963	1972	J	We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use.	Jeremy Boy;Ronald A. Rensink;Enrico Bertini;Jean-Daniel Fekete	Jeremy Boy;Ronald A. Rensink;Enrico Bertini;Jean-Daniel Fekete	Inria, Telecom ParisTech, EnsadLab;University of British Columbia;NYU Polytechnic School of Engineering;Inria	10.1109/TVCG.2011.160	Literacy, Visualization literacy, Rasch Model, Item Response Theory	35	60	39	52	
InfoVis	2014	Reinforcing Visual Grouping Cues to Communicate Complex Informational Structure	10.1109/TVCG.2014.2346998	http://dx.doi.org/10.1109/TVCG.2014.2346998	1973	1982	J	In his book Multimedia Learning [7], Richard Mayer asserts that viewers learn best from imagery that provides them with cues to help them organize new information into the correct knowledge structures. Designers have long been exploiting the Gestalt laws of visual grouping to deliver viewers those cues using visual hierarchy, often communicating structures much more complex than the simple organizations studied in psychological research. Unfortunately, designers are largely practical in their work, and have not paused to build a complex theory of structural communication. If we are to build a tool to help novices create effective and well structured visuals, we need a better understanding of how to create them. Our work takes a first step toward addressing this lack, studying how five of the many grouping cues (proximity, color similarity, common region, connectivity, and alignment) can be effectively combined to communicate structured text and imagery from real world examples. To measure the effectiveness of this structural communication, we applied a digital version of card sorting, a method widely used in anthropology and cognitive science to extract cognitive structures. We then used tree edit distance to measure the difference between perceived and communicated structures. Our most significant findings are: 1) with careful design, complex structure can be communicated clearly; 2) communicating complex structure is best done with multiple reinforcing grouping cues; 3) common region (use of containers such as boxes) is particularly effective at communicating structure; and 4) alignment is a weak structural communicator.	Juhee Bae;Benjamin Watson	Juhee Bae;Benjamin Watson	North Carolina State University;North Carolina State University	10.1109/TVCG.2010.174;10.1109/INFVIS.2003.1249005	Visual grouping, visual hierarchy, gestalt principles, perception, visual communication	4	6	5	18	
SciVis	2014	Visualization of Regular Maps: The Chase Continues	10.1109/TVCG.2014.2352952	http://dx.doi.org/10.1109/TVCG.2014.2352952	2614	2623	J	A regular map is a symmetric tiling of a closed surface, in the sense that all faces, vertices, and edges are topologically indistinguishable. Platonic solids are prime examples, but also for surfaces with higher genus such regular maps exist. We present a new method to visualize regular maps. Space models are produced by matching regular maps with target shapes in the hyperbolic plane. The approach is an extension of our earlier work. Here a wider variety of target shapes is considered, obtained by duplicating spherical and toroidal regular maps, merging triangles, punching holes, and gluing the edges. The method produces about 45 new examples, including the genus 7 Hurwitz surface.	Jarke J. van Wijk	Jarke J. van Wijk	Eindhoven University of Technology		regular maps, tiling, tessellation, surface topology, mathematical visualization	1	2	1	24	
InfoVis	2014	Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity	10.1109/TVCG.2014.2352953	http://dx.doi.org/10.1109/TVCG.2014.2352953	2201	2210	J	Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.	Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz	Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz	University of Munich (LMU);Université de Lyon & CNRS, France;University of Munich (LMU);Exertion Games Lab, RMIT University;University of Munich (LMU)	10.1109/TVCG.2007.70541;10.1109/INFVIS.2003.1249031;10.1109/TVCG.2013.134	Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change	35	43	23	41	
VAST	2014	Towards Interactive, Intelligent, and Integrated Multimedia Analytics	10.1109/VAST.2014.7042476	http://dx.doi.org/10.1109/VAST.2014.7042476	3	12	C	The size and importance of visual multimedia collections grew rapidly over the last years, creating a need for sophisticated multimedia analytics systems enabling large-scale, interactive, and insightful analysis. These systems need to integrate the human's natural expertise in analyzing multimedia with the machine's ability to process large-scale data. The paper starts off with a comprehensive overview of representation, learning, and interaction techniques from both the human's and the machine's point of view. To this end, hundreds of references from the related disciplines (visual analytics, information visualization, computer vision, multimedia information retrieval) have been surveyed. Based on the survey, a novel general multimedia analytics model is synthesized. In the model, the need for semantic navigation of the collection is emphasized and multimedia analytics tasks are placed on the exploration-search axis. The axis is composed of both exploration and search in a certain proportion which changes as the analyst progresses towards insight. Categorization is proposed as a suitable umbrella task realizing the exploration-search axis in the model. Finally, the pragmatic gap, defined as the difference between the tight machine categorization model and the flexible human categorization model is identified as a crucial multimedia analytics topic.	Jan Zahálka;Marcel Worring	Jan Zahálka;Marcel Worring	University of Amsterdam;University of Amsterdam	10.1109/VAST.2006.261425;10.1109/VAST.2007.4389003;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.136;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70541;10.1109/TVCG.2013.168	Multimedia (image/video/music) visualization, machine learning	9	16	8	100	
VAST	2014	Feature-Driven Visual Analytics of Soccer Data	10.1109/VAST.2014.7042477	http://dx.doi.org/10.1109/VAST.2014.7042477	13	22	C	Soccer is one the most popular sports today and also very interesting from an scientific point of view. We present a system for analyzing high-frequency position-based soccer data at various levels of detail, allowing to interactively explore and analyze for movement features and game events. Our Visual Analytics method covers single-player, multi-player and event-based analytical views. Depending on the task the most promising features are semi-automatically selected, processed, and visualized. Our aim is to help soccer analysts in finding the most important and interesting events in a match. We present a flexible, modular, and expandable layer-based system allowing in-depth analysis. The integration of Visual Analytics techniques into the analysis process enables the analyst to find interesting events based on classification and allows, by a set of custom views, to communicate the found results. The feedback loop in the Visual Analytics pipeline helps to further improve the classification results. We evaluate our approach by investigating real-world soccer matches and collecting additional expert feedback. Several use cases and findings illustrate the capabilities of our approach.	Halldór Janetzko;Dominik Sacha;Manuel Stein;Tobias Schreck;Daniel A. Keim;Oliver Deussen	Halld'or Janetzko;Dominik Sacha;Manuel Stein;Tobias Schreck;Daniel A. Keim;Oliver Deussen	University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz	10.1109/TVCG.2012.263;10.1109/VAST.2008.4677350;10.1109/TVCG.2007.70621;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/TVCG.2013.207;10.1109/TVCG.2013.186	Visual Analytics, Sport Analytics, Soccer Analysis	24	38	24	43	
VAST	2014	Baseball4D: A Tool for Baseball Game Reconstruction & Visualization	10.1109/VAST.2014.7042478	http://dx.doi.org/10.1109/VAST.2014.7042478	23	32	C	While many sports use statistics and video to analyze and improve game play, baseball has led the charge throughout its history. With the advent of new technologies that allow all players and the ball to be tracked across the entire field, it is now possible to bring this understanding to another level. From discrete positions across time, we present techniques to reconstruct entire baseball games and visually explore each play. This provides opportunities to not only derive new metrics for the game, but also allow us to investigate existing measures with targeted visualizations. In addition, our techniques allow users to filter on demand so specific situations can be analyzed both in general and according to those situations. We show that gameplay can be accurately reconstructed from the raw position data and discuss how visualization and statistical methods can combine to better inform baseball analyses.	Carlos A. Dietrich;David Koop;Huy T. Vo;Cláudio T. Silva	Carlos Dietrich;David Koop;Huy T. Vo;Cláudio T. Silva	NYU;NYU;NYU	10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/TVCG.2012.225;10.1109/VISUAL.2001.964496	sports visualization, sports analytics, baseball, game reconstruction, baseball metrics, event data	7	12	12	35	
VAST	2014	A System for Visual Analysis of Radio Signal Data	10.1109/VAST.2014.7042479	http://dx.doi.org/10.1109/VAST.2014.7042479	33	42	C	Analysis of radio transmissions is vital for military defense as it provides valuable information about enemy communication and infrastructure. One challenge to the data analysis task is that there are far too many signals for analysts to go through by hand. Even typical signal meta data (such as frequency band, duration, and geographic location) can be overwhelming. In this paper, we present a system for exploring and analyzing such radio signal meta-data. Our system incorporates several visual representations for signal data, designed for readability and ease of comparison, as well as novel algorithms for extracting and classifying consistent signal patterns. We demonstrate the effectiveness of our system using data collected from real missions with an airborne sensor platform.	Tarik Crnovrsanin;Chris Muelder;Kwan-Liu Ma	Tarik Crnovrsanin;Chris Muelder;Kwan-Liu Ma	VIDi @ U. C. Davis;VIDi @ U. C. Davis;VIDi @ U. C. Davis	10.1109/TVCG.2012.286;10.1109/VAST.2009.5332596;10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1998.745302;10.1109/VAST.2009.5332593	Intelligence Analysis, Coordinated and Multiple Views, Time-varying data, Geographic/Geospatial Visualization	1	2	2	29	
VAST	2014	Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier	10.1109/VAST.2014.7042480	http://dx.doi.org/10.1109/VAST.2014.7042480	43	52	C	The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user's preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.	Michael Behrisch 0001;Fatih Korkmaz;Lin Shao;Tobias Schreck	Michael Behrisch;Fatih Korkmaz;Lin Shao;Tobias Schreck	Universit&#x00E4;t Konstanz, Germany;Universit&#x00E4;t Konstanz, Germany;Universit&#x00E4;t Konstanz, Germany;Universit&#x00E4;t Konstanz, Germany	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2012.277;10.1109/TVCG.2010.184;10.1109/VAST.2012.6400486;10.1109/VAST.2007.4389001;10.1109/TVCG.2013.160;10.1109/VAST.2012.6400488	View Space Exploration Framework, Interesting View Problem, Relevance Feedback, User Preference Model	21	31	21	37	
VAST	2014	An Integrated Visual Analysis System for Fusing MR Spectroscopy and Multi-Modal Radiology Imaging	10.1109/VAST.2014.7042481	http://dx.doi.org/10.1109/VAST.2014.7042481	53	62	C	For cancers such as glioblastoma multiforme, there is an increasing interest in defining "biological target volumes" (BTV), high tumour-burden regions which may be targeted with dose boosts in radiotherapy. The definition of a BTV requires insight into tumour characteristics going beyond conventionally defined radiological abnormalities and anatomical features. Molecular and biochemical imaging techniques, like positron emission tomography, the use of Magnetic Resonance (MR) Imaging contrast agents or MR Spectroscopy deliver this information and support BTV delineation. MR Spectroscopy Imaging (MRSI) is the only non-invasive technique in this list. Studies with MRSI have shown that voxels with certain metabolic signatures are more susceptible to predict the site of relapse. Nevertheless, the discovery of complex relationships between a high number of different metabolites, anatomical, molecular and functional features is an ongoing topic of research - still lacking appropriate tools supporting a smooth workflow by providing data integration and fusion of MRSI data with other imaging modalities. We present a solution bridging this gap which gives fast and flexible access to all data at once. By integrating a customized visualization of the multi-modal and multi-variate image data with a highly flexible visual analytics (VA) framework, it is for the first time possible to interactively fuse, visualize and explore user defined metabolite relations derived from MRSI in combination with markers delivered by other imaging modalities. Real-world medical cases demonstrate the utility of our solution. By making MRSI data available both in a VA tool and in a multi-modal visualization renderer we can combine insights from each side to arrive at a superior BTV delineation. We also report feedback from domain experts indicating significant positive impact in how this work can improve the understanding of MRSI data and its integration into radiotherapy planning.	Miguel Nunes;Benjamin Rowland;Matthias Schlachter;Soléakhéna Ken;Kresimir Matkovic;Anne Laprie;Katja Bühler	Miguel Nunes;Benjamin Rowland;Matthias Schlachter;Soléakhéna Ken;Kresimir Matkovic;Anne Laprie;Katja Bühler	VRVis Research Center, Vienna, Austria;Institut Claudius Regaud, Toulouse, France;VRVis Research Center, Vienna, Austria;Institut Claudius Regaud, Toulouse, France;VRVis Research Center, Vienna, Austria;Institut Claudius Regaud, Toulouse, France;VRVis Research Center, Vienna, Austria	10.1109/TVCG.2007.70569;10.1109/TVCG.2013.180;10.1109/TVCG.2010.176	MR spectroscopy, cancer, brain, visualization, multi-modality data, radiotherapy planning, medical decision support systems	3	4	3	29	
VAST	2014	An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics	10.1109/VAST.2014.7042482	http://dx.doi.org/10.1109/VAST.2014.7042482	63	72	C	We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight- and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.	Steven R. Gomez;Hua Guo;Caroline Ziemkiewicz;David H. Laidlaw	Steven R. Gomez;Hua Guo;Caroline Ziemkiewicz;David H. Laidlaw	Brown University;Brown University;Aptima, Inc;Brown University	10.1109/TVCG.2012.233;10.1109/TVCG.2007.70617;10.1109/TVCG.2013.124;10.1109/TVCG.2010.154;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2009.128;10.1109/TVCG.2011.185;10.1109/TVCG.2010.163;10.1109/TVCG.2013.120	Evaluation methodology, insight-based evaluation, visual analytics, network visualization, information visualization	8	10	7	31	
VAST	2014	Weaving a Carpet from Log Entries: A Network Security Visualization Built with Co-Creation	10.1109/VAST.2014.7042483	http://dx.doi.org/10.1109/VAST.2014.7042483	73	82	C	We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the "Carpet"). Visualizations that immediately point to areas of suspicious activity without requiring extensive filtering, help network engineers investigating unknown computer security incidents. Most of them, however, have limited knowledge of advanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, following a co-creative process. We will show how we explored the scope of the engineers' tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log files quickly and to define areas of interest for closer inspection.	Johannes Landstorfer;Ivo Herrmann;Jan-Erik Stange;Marian Dörk;Reto Wettach	Johannes Landstorfer;Ivo Herrmann;Jan-Erik Stange;Marian Dörk;Reto Wettach	Department of Design at the University of Applied Sciences Potsdam, Germany;Department of Design at the University of Applied Sciences Potsdam, Germany;Department of Design at the University of Applied Sciences Potsdam, Germany;Department of Design at the University of Applied Sciences Potsdam, Germany;Department of Design at the University of Applied Sciences Potsdam, Germany	10.1109/TVCG.2006.160;10.1109/INFVIS.2005.1532134;10.1109/VISUAL.1991.175795;10.1109/VAST.2006.261436;10.1109/TVCG.2009.111;10.1109/INFVIS.1995.528685	Pixel-oriented techniques, task and requirements analysis, multidimensional data, network security and intrusion	6	9	8	35	
VAST	2014	Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration	10.1109/VAST.2014.7042484	http://dx.doi.org/10.1109/VAST.2014.7042484	83	92	C	This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study.	Sungahn Ko;Shehzad Afzal;Simon J. Walton;Yang Yang;Junghoon Chae;Abish Malik;Yun Jang;Min Chen 0001;David S. Ebert	Sungahnn Ko;Shehzad Afzal;Simon Walton;Yang Yang;Junghoon Chae;Abish Malik;Yun Jang;Min Chen;David Ebert	Purdue University;Purdue University;Oxford University;Purdue University;Purdue University;Purdue University;Sejong University;Oxford University;Purdue University	10.1109/VAST.2012.6400554;10.1109/TVCG.2010.150;10.1109/TVCG.2007.70582;10.1109/TVCG.2011.190;10.1109/VAST.2011.6102440;10.1109/TVCG.2009.143;10.1109/INFVIS.1999.801851;10.1109/TVCG.2006.166;10.1109/VAST.2007.4389013		7		8	47	
VAST	2014	Visual Analysis of Patterns in Multiple Amino Acid Mutation Graphs	10.1109/VAST.2014.7042485	http://dx.doi.org/10.1109/VAST.2014.7042485	93	102	C	Proteins are essential parts in all living organisms. They consist of sequences of amino acids. An interaction with reactive agent can stimulate a mutation at a specific position in the sequence. This mutation may set off a chain reaction, which effects other amino acids in the protein. Chain reactions need to be analyzed, as they may invoke unwanted side effects in drug treatment. A mutation chain is represented by a directed acyclic graph, where amino acids are connected by their mutation dependencies. As each amino acid may mutate individually, many mutation graphs exist. To determine important impacts of mutations, experts need to analyze and compare common patterns in these mutations graphs. Experts, however, lack suitable tools for this purpose. We present a new system for the search and the exploration of frequent patterns (i.e., motifs) in mutation graphs. We present a fast pattern search algorithm specifically developed for finding biologically relevant patterns in many mutation graphs (i.e., many labeled acyclic directed graphs). Our visualization system allows an interactive exploration and comparison of the found patterns. It enables locating the found patterns in the mutation graphs and in the 3D protein structures. In this way, potentially interesting patterns can be discovered. These patterns serve as starting point for a further biological analysis. In cooperation with biologists, we use our approach for analyzing a real world data set based on multiple HIV protease sequences.	Olav Lenz;Frank Keul;Sebastian Bremm;Kay Hamacher;Tatiana von Landesberger	Olav Lenz;Frank Keul;Sebastian Bremm;Kay Hamacher;Tatiana von Landesberger	GRIS, TU Darmstadt;Computational Biology, TU Darmstadt;GRIS, TU Darmstadt;Computational Biology, TU Darmstadt;GRIS, TU Darmstadt	10.1109/TVCG.2013.225;10.1109/VAST.2011.6102439;10.1109/VAST.2009.5333893;10.1109/TVCG.2009.167;10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70529	Biologic Visualization, Graph Visualization, Motif Search, Motif Visualization, Biology, Mutations, Pattern Visualization	5	8	6	51	
VAST	2014	A Visual Reasoning Approach for Data-driven Transport Assessment on Urban Roads	10.1109/VAST.2014.7042486	http://dx.doi.org/10.1109/VAST.2014.7042486	103	112	C	Transport assessment plays a vital role in urban planning and traffic control, which are influenced by multi-faceted traffic factors involving road infrastructure and traffic flow. Conventional solutions can hardly meet the requirements and expectations of domain experts. In this paper we present a data-driven solution by leveraging a visual analysis system to evaluate the real traffic situations based on taxi trajectory data. A sketch-based visual interface is designed to support dynamic query and visual reasoning of traffic situations within multiple coordinated views. In particular, we propose a novel road-based query model for analysts to interactively conduct evaluation tasks. This model is supported by a bi-directional hash structure, TripHash, which enables real-time responses to the data queries over a huge amount of trajectory data. Case studies with a real taxi GPS trajectory dataset (&amp;gt; 30GB) show that our system performs well for on-demand transport assessment and reasoning.	Fei Wang 0016;Wei Chen 0001;Feiran Wu;Ye Zhao;Han Hong;Tianyu Gu;Long Wang;Ronghua Liang;Hujun Bao	Fei Wang;Wei Chen;Feiran Wu;Ye Zhao;Han Hong;Tianyu Gu;Long Wang;Ronghua Liang;Hujun Bao	State Key Lab of CAD&amp;CG, Zhejiang University;State Key Lab of CAD&amp;CG, Zhejiang University;State Key Lab of CAD&amp;CG, Zhejiang University;Kent State University;State Key Lab of CAD&amp;CG, Zhejiang University;State Key Lab of CAD&amp;CG, Zhejiang University;State Key Lab of CAD&amp;CG, Zhejiang University;Zhejiang University of Technology;State Key Lab of CAD&amp;CG, Zhejiang University	10.1109/VAST.2011.6102458;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.179;10.1109/VAST.2011.6102455;10.1109/TVCG.2013.133	Road-based Query, Taxi Trajectory, Hash Index, Visual Analysis	13	20	20	48	
VAST	2014	Using Visualizations to Monitor Changes and Harvest Insights from a Global-Scale Logging Infrastructure at Twitter	10.1109/VAST.2014.7042487	http://dx.doi.org/10.1109/VAST.2014.7042487	113	122	C	Logging user activities is essential to data analysis for internet products and services. Twitter has built a unified logging infrastructure that captures user activities across all clients it owns, making it one of the largest datasets in the organization. This paper describes challenges and opportunities in applying information visualization to log analysis at this massive scale, and shows how various visualization techniques can be adapted to help data scientists extract insights. In particular, we focus on two scenarios: (1) monitoring and exploring a large collection of log events, and (2) performing visual funnel analysis on log data with tens of thousands of event types. Two interactive visualizations were developed for these purposes: we discuss design choices and the implementation of these systems, along with case studies of how they are being used in day-to-day operations at Twitter.	Krist Wongsuphasawat;Jimmy Lin	Krist Wongsuphasawat;Jimmy Lin	Twitter, Inc.;Twitter, Inc.	10.1109/INFVIS.2000.885091;10.1109/TVCG.2009.117;10.1109/INFVIS.1997.636718;10.1109/VAST.2007.4389008;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70529;10.1109/VAST.2012.6400494;10.1109/TVCG.2013.231;10.1109/INFVIS.2004.64;10.1109/VISUAL.1991.175815;10.1109/TVCG.2013.200;10.1109/VAST.2006.261421;10.1109/TVCG.2011.185	Information Visualization, Visual Analytics, Log Analysis, Log Visualization, Session Analysis, Funnel Analysis	11	20	13	45	
VAST	2014	HydroQual: Visual Analysis of River Water Quality	10.1109/VAST.2014.7042488	http://dx.doi.org/10.1109/VAST.2014.7042488	123	132	C	Economic development based on industrialization, intensive agriculture expansion and population growth places greater pressure on water resources through increased water abstraction and water quality degradation [40], River pollution is now a visible issue, with emblematic ecological disasters following industrial accidents such as the pollution of the Rhine river in 1986 [31]. River water quality is a pivotal public health and environmental issue that has prompted governments to plan initiatives for preserving or restoring aquatic ecosystems and water resources [56], Water managers require operational tools to help interpret the complex range of information available on river water quality functioning. Tools based on statistical approaches often fail to resolve some tasks due to the sparse nature of the data. Here we describe HydroQual, a tool to facilitate visual analysis of river water quality. This tool combines spatiotemporal data mining and visualization techniques to perform tasks defined by water experts. We illustrate the approach with a case study that illustrates how the tool helps experts analyze water quality. We also perform a qualitative evaluation with these experts.	Pierre Accorsi;Nathalie Lalande;Mickaël Fabrègue;Agnès Braud;Pascal Poncelet;Arnaud Sallaberry;Sandra Bringay;Maguelonne Teisseire;Flavie Cernesson;Florence Le Ber	Pierre Accorsi;Nathalie Lalande;Mickäel Fabrègue;Agnès Braud;Pascal Poncelet;Arnaud Sallaberry;Sandra Bringay;Maguelonne Teisseire;Flavie Cernesson;Florence Le Ber	LIRMM Univ. Montpellier 2;IRSTEA Montpellier;IRSTEA Montpellier Univ. Strasbourg/ENGEES;ICube Univ. Strasbourg;LIRMM Univ. Montpellier 2;LIRMM Univ. Montpellier 3;LIRMM Univ. Montpellier 3;IRSTEA Montpellier;AgroParisTech Montpellier;ICube Univ. Strasbourg/ENGEES	10.1109/VISUAL.1996.568146;10.1109/INFVIS.2000.885097	Visual Analytics, Spatiotemporal Data Mining and Visualization, Water Quality	3	6	4	60	
VAST	2014	Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes	10.1109/VAST.2014.7042489	http://dx.doi.org/10.1109/VAST.2014.7042489	133	142	C	We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.	Jie Li 0006;Kang Zhang;Zhaopeng Meng	Jie Li;Kang Zhang;Zhao-Peng Meng	School of Computer Science and Technology, Tianjin University, and National Ocean Technology Center, Tianjin, China;Department of Computer Science, The University of Texas at Dallas, USA;School of Computer Software, Tianjin University, China	10.1109/VAST.2012.6400491;10.1109/TVCG.2010.194;10.1109/INFVIS.2000.885098;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.199;10.1109/TVCG.2010.183;10.1109/VAST.2012.6400553;10.1109/TVCG.2010.180;10.1109/TVCG.2009.197	climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics	10	14	9	54	
VAST	2014	BoundarySeer: Visual Analysis of 2D Boundary Changes	10.1109/VAST.2014.7042490	http://dx.doi.org/10.1109/VAST.2014.7042490	143	152	C	Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system.	Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen 0001;M. Eduard Gröller;Lionel M. Ni	Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Eduard Gröller;Lionel M. Ni	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;State Key Lab of CAD&CG, Zhejiang University;Institute of Computer Graphics and Algorithms, Vienna University of Technology and VRVis Research Center, Austria;Hong Kong University of Science and Technology	10.1109/TVCG.2013.230;10.1109/INFVIS.2004.27;10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.239;10.1109/TVCG.2008.166;10.1109/INFVIS.2005.1532149;10.1109/TVCG.2013.213;10.1109/TVCG.2012.265;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70561	Boundary change, visual analytics, scatter plot, ThemeRiver, contour map, radial visualization	10	14	7	40	
VAST	2014	YMCA - Your Mesh Comparison Application	10.1109/VAST.2014.7042491	http://dx.doi.org/10.1109/VAST.2014.7042491	153	162	C	Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.	Johanna Schmidt;Reinhold Preiner;Thomas Auzinger;Michael Wimmer;M. Eduard Gröller;Stefan Bruckner	Johanna Schmidt;Reinhold Preiner;Thomas Auzinger;Michael Wimmer;M. Eduard Gröller;Stefan Bruckner	Vienna University of Technology, Austria;Vienna University of Technology, Austria;Vienna University of Technology, Austria;Vienna University of Technology, Austria;Vienna University of Technology, Vienna, Austria;University of Bergen, Norway	10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1990.146402;10.1109/TVCG.2013.213;10.1109/VISUAL.2002.1183790	Visual analysis, comparative visualization, 3D data exploration, focus+context, mesh comparison	11	14	10	33	
VAST	2014	Multi-Model Semantic Interaction for Text Analytics	10.1109/VAST.2014.7042492	http://dx.doi.org/10.1109/VAST.2014.7042492	163	172	C	Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection.	Lauren Bradel;Chris North;Leanna House;Scotland Leman	Lauren Bradel;Chris North;Leanna House;Scotland Leman	Virginia Tech.;Virginia Tech.;Virginia Tech.;Virginia Tech.	10.1109/VAST.2011.6102449;10.1109/TVCG.2013.188;10.1109/VAST.2012.6400559;10.1109/VAST.2012.6400486;10.1109/INFVIS.1995.528686;10.1109/VAST.2007.4389006	Visual analytics, Semantic Interaction, Sensemaking, Text Analytics	17	24	18	35	
VAST	2014	Serendip: Topic Model-Driven Visual Exploration of Text Corpora	10.1109/VAST.2014.7042493	http://dx.doi.org/10.1109/VAST.2014.7042493	173	182	C	Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.	Eric C. Alexander;Joe Kohlmann;Robin Valenza;Michael Witmore;Michael Gleicher	Eric Alexander;Joe Kohlmann;Robin Valenza;Michael Witmore;Michael Gleicher	Department of Computer Sciences at the University of Wisconsin-Madison;Department of Computer Sciences at the University of Wisconsin-Madison;Department of English at the University of Wisconsin-Madison;Folger Shakespeare Library in Washington, D. C.;Department of Computer Sciences at the University of Wisconsin-Madison.	10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1998.729568;10.1109/TVCG.2011.239;10.1109/TVCG.2011.220;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.157;10.1109/TVCG.2013.162;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4389004	Text visualization, topic modeling	39	51	36	38	
VAST	2014	TopicPanorama: A Full Picture of Relevant Topics	10.1109/VAST.2014.7042494	http://dx.doi.org/10.1109/VAST.2014.7042494	183	192	C	We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.	Shixia Liu;Xiting Wang;Jianfei Chen;Jim Zhu;Baining Guo	Shixia Liu;Xiting Wang;Jianfei Chen;Jim Zhu;Baining Guo	Microsoft Research Asia;Tsinghua University and Microsoft Research Asia;Dept. of Comp. Sei. &amp; Tech., TNList Lab, State Key Lab of lntell. Tech. &amp; Sys., Tsingua University;Dept. of Comp. Sei. &amp; Tech., TNList Lab, State Key Lab of Intell. Tech. &amp; Sys., Tsinghua University;Microsoft Research Asia	10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919	Topic graph, graph matching, graph visualization, user interactions, level-of-detail	10	22	29	61	
VAST	2014	Integrating Predictive Analytics and Social Media	10.1109/VAST.2014.7042495	http://dx.doi.org/10.1109/VAST.2014.7042495	193	202	C	A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success.	Yafeng Lu;Robert Krüger;Dennis Thom;Feng Wang 0012;Steffen Koch;Thomas Ertl;Ross Maciejewski	Yafeng Lu;Robert Krüger;Dennis Thom;Feng Wang;Steffen Koch;Thomas Ertl;Ross Maciejewski	Arizona State University;University of Stuttgart, Germany;University of Stuttgart, Germany;Arizona State University;University of Stuttgart, Germany;University of Stuttgart, Germany;Arizona State University	10.1109/VAST.2012.6400557;10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/TVCG.2013.125;10.1109/INFVIS.2004.10;10.1109/VAST.2011.6102448;10.1109/VAST.2010.5652443;10.1109/INFVIS.2004.3	Social Media, Predictive Analytics, Feature Selection	17	24	20	49	
VAST	2014	PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media	10.1109/VAST.2014.7042496	http://dx.doi.org/10.1109/VAST.2014.7042496	203	212	C	Hundreds of millions of people leave digital footprints on social media (e.g., Twitter and Facebook). Such data not only disclose a person's demographics and opinions, but also reveal one's emotional style. Emotional style captures a person's patterns of emotions over time, including his overall emotional volatility and resilience. Understanding one's emotional style can provide great benefits for both individuals and businesses alike, including the support of self-reflection and delivery of individualized customer care. We present PEARL, a timeline-based visual analytic tool that allows users to interactively discover and examine a person's emotional style derived from this person's social media text. Compared to other visual text analytic systems, our work offers three unique contributions. First, it supports multi-dimensional emotion analysis from social media text to automatically detect a person's expressed emotions at different time points and summarize those emotions to reveal the person's emotional style. Second, it effectively visualizes complex, multi-dimensional emotion analysis results to create a visual emotional profile of an individual, which helps users browse and interpret one's emotional style. Third, it supports rich visual interactions that allow users to interactively explore and validate emotion analysis results. We have evaluated our work extensively through a series of studies. The results demonstrate the effectiveness of our tool both in emotion analysis from social media and in support of interactive visualization of the emotion analysis results.	Jian Zhao 0010;Liang Gou;Fei Wang;Michelle X. Zhou	Jian Zhao;Liang Gou;Fei Wang;Michelle Zhou	University of Toronto;IBM Research Almad&#x00E9;n;IBM Research Almad&#x00E9;n;IBM Research Almad&#x00E9;n	10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2010.129;10.1109/TVCG.2011.185;10.1109/TVCG.2010.183	Personal emotion analytics, affective and mood modeling, social media text, Twitter, information visualization	16	29	19	34	
SciVis	2015	A Classification of User Tasks in Visual Analysis of Volume Data	10.1109/SciVis.2015.7429485	http://dx.doi.org/10.1109/SciVis.2015.7429485	1	8	C	Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets.	Bireswar Laha;Doug A. Bowman;David H. Laidlaw;John J. Socha	Bireswar Laha;Doug A. Bowman;David H. Laidlaw;John J. Socha	Stanford University;Virginia Tech;Brown University;Virginia Tech	10.1109/INFVIS.2004.10;10.1109/TVCG.2013.124;10.1109/TVCG.2012.216;10.1109/TVCG.2009.126;10.1109/TVCG.2013.130;10.1109/TVCG.2013.120;10.1109/TVCG.2014.2346321;10.1109/INFVIS.2004.59	Task Taxonomy, Empirical Evaluation, Volume Visualization, Scientific Visualization, Virtual Reality, 3D Interaction	4	5	5	35	
SciVis	2015	Using Maximum Topology Matching to Explore Differences in Species Distribution Models	10.1109/SciVis.2015.7429486	http://dx.doi.org/10.1109/SciVis.2015.7429486	9	16	C	Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.	Jorge Poco;Harish Doraiswamy;Marian Talbert;Jeffrey T. Morisette;Cláudio T. Silva	Jorge Poco;Harish Doraiswamy;Marian Talbert;Jeffrey Morisette;Cláudio T. Silva	New York University;New York University;U.S. Geological Survey;U.S. Geological Survey;New York University	10.1109/TVCG.2011.244;10.1109/TVCG.2010.213;10.1109/TVCG.2008.145;10.1109/TVCG.2009.155;10.1109/TVCG.2013.125;10.1109/TVCG.2008.143;10.1109/TVCG.2011.236;10.1109/TVCG.2013.148;10.1109/TVCG.2014.2346332;10.1109/TVCG.2011.248;10.1109/TVCG.2007.70601	Function similarity, computational topology, species distribution models, persistence, high dimensional visualization	1	0	0	44	
SciVis	2015	Visual Verification of Space Weather Ensemble Simulations	10.1109/SciVis.2015.7429487	http://dx.doi.org/10.1109/SciVis.2015.7429487	17	24	C	We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel.	Alexander Bock;Asher Pembroke;M. Leila Mays;Lutz Rastaetter;Timo Ropinski;Anders Ynnerman	Alexander Bock;Asher Pembroke;M. Leila Mays;Lutz Rastaetter;Timo Ropinski;Anders Ynnerman	Linkoping University;NASA Goddard Space Flight Center;NASA Goddard Space Flight Center;NASA Goddard Space Flight Center;Ulm University;Linköping University	10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143	Visual Verification, Space Weather, Coronal Mass Ejections, Ensemble	2	6	6	25	
SciVis	2015	A Visual Voting Framework for Weather Forecast Calibration	10.1109/SciVis.2015.7429488	http://dx.doi.org/10.1109/SciVis.2015.7429488	25	32	C	Numerical weather predictions have been widely used for weather forecasting. Many large meteorological centers are producing highly accurate ensemble forecasts routinely to provide effective weather forecast services. However, biases frequently exist in forecast products because of various reasons, such as the imperfection of the weather forecast models. Failure to identify and neutralize the biases would result in unreliable forecast products that might mislead analysts; consequently, unreliable weather predictions are produced. The analog method has been commonly used to overcome the biases. Nevertheless, this method has some serious limitations including the difficulties in finding effective similar past forecasts, the large search space for proper parameters and the lack of support for interactive, real-time analysis. In this study, we develop a visual analytics system based on a novel voting framework to circumvent the problems. The framework adopts the idea of majority voting to combine judiciously the different variants of analog methods towards effective retrieval of the proper analogs for calibration. The system seamlessly integrates the analog methods into an interactive visualization pipeline with a set of coordinated views that characterizes the different methods. Instant visual hints are provided in the views to guide users in finding and refining analogs. We have worked closely with the domain experts in the meteorological research to develop the system. The effectiveness of the system is demonstrated using two case studies. An informal evaluation with the experts proves the usability and usefulness of the system.	Hongsen Liao;Yingcai Wu;Li Chen;Thomas M. Hamill;Yunhai Wang;Kan Dai;Hui Zhang;Wei Chen 0001	Hongsen Liao;Yingcai Wu;Li Chen;Thomas M. Hamill;Yunhai Wang;Kan Dai;Hui Zhang;Wei Chen	School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University;State Key Lab of CAD & CG, Zhejiang University;School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University;NOAA Earth System Research Lab, Physical Sciences Division;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences;National Meteorological Center of CMA;School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University;State Key Lab of CAD & CG, Zhejiang University	10.1109/TVCG.2013.131;10.1109/TVCG.2013.138;10.1109/TVCG.2013.144;10.1109/TVCG.2009.197;10.1109/TVCG.2008.139;10.1109/TVCG.2014.2346755;10.1109/TVCG.2010.181;10.1109/VISUAL.1994.346298;10.1109/TVCG.2013.143	Weather forecast, analog method, calibration, majority voting, visual analytics	0	0	2	30	
SciVis	2015	Real-time Uncertainty Visualization for B-Mode Ultrasound	10.1109/SciVis.2015.7429489	http://dx.doi.org/10.1109/SciVis.2015.7429489	33	40	C	B-mode ultrasound is a very well established imaging modality and is widely used in many of today's clinical routines. However, acquiring good images and interpreting them correctly is a challenging task due to the complex ultrasound image formation process depending on a large number of parameters. To facilitate ultrasound acquisitions, we introduce a novel framework for real-time uncertainty visualization in B-mode images. We compute real-time per-pixel ultrasound Confidence Maps, which we fuse with the original ultrasound image in order to provide the user with an interactive feedback on the quality and credibility of the image. In addition to a standard color overlay mode, primarily intended for educational purposes, we propose two perceptional visualization schemes to be used in clinical practice. Our mapping of uncertainty to chroma uses the perceptionally uniform L*a*b* color space to ensure that the perceived brightness of B-mode ultrasound remains the same. The alternative mapping of uncertainty to fuzziness keeps the B-mode image in its original grayscale domain and locally blurs or sharpens the image based on the uncertainty distribution. An elaborate evaluation of our system and user studies on both medical students and expert sonographers demonstrate the usefulness of our proposed technique. In particular for ultrasound novices, such as medical students, our technique yields powerful visual cues to evaluate the image quality and thereby learn the ultrasound image formation process. Furthermore, seeing the distribution of uncertainty adjust to the transducer positioning in real-time, provides also expert clinicians with a strong visual feedback on their actions. This helps them to optimize the acoustic window and can improve the general clinical value of ultrasound.	Christian Schulte zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab	Christian Schulte Zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab		10.1109/VISUAL.2001.964550;10.1109/TVCG.2006.134;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.279;10.1109/TVCG.2009.114	Ultrasound, Uncertainty Visualization, Confidence Maps, Real-time	5	5	1	23	
SciVis	2015	Explicit Frequency Control for High-Quality Texture-Based Flow Visualization	10.1109/SciVis.2015.7429490	http://dx.doi.org/10.1109/SciVis.2015.7429490	41	48	C	In this work we propose an effective method for frequency-controlled dense flow visualization derived from a generalization of the Line Integral Convolution (LIC) technique. Our approach consists in considering the spectral properties of the dense flow visualization process as an integral operator defined in a local curvilinear coordinate system aligned with the flow. Exploring LIC from this point of view, we suggest a systematic way to design a flow visualization process with particular local spatial frequency properties of the resulting image. Our method is efficient, intuitive, and based on a long-standing model developed as a result of numerous perception studies. The method can be described as an iterative application of line integral convolution, followed by a one-dimensional Gabor filtering orthogonal to the flow. To demonstrate the utility of the technique, we generated novel adaptive multi-frequency flow visualizations, that according to our evaluation, feature a higher level of frequency control and higher quality scores than traditional approaches in texture-based flow visualization.	Victor Matvienko;Jens H. Krüger	Victor Matvienko;Jens Krüger	Saarland University;University Duisburg-Essen	10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70595;10.1109/TVCG.2006.161;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1996.567784;10.1109/VISUAL.2001.964505;10.1109/TVCG.2009.126;10.1109/VISUAL.1999.809892;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.2005.1532781	flow visualization, texture-based visualization, LIC, Gabor filter, spatial frequency, image contrast	0	1	1	49	
SciVis	2015	Feature-Based Tensor Field Visualization for Fiber Reinforced Polymers	10.1109/SciVis.2015.7429491	http://dx.doi.org/10.1109/SciVis.2015.7429491	49	56	C	Virtual testing is an integral part of modern product development in mechanical engineering. Numerical structure simulations allow the computation of local stresses which are given as tensor fields. For homogeneous materials, the tensor information is usually reduced to a scalar field like the von Mises stress. A material-dependent threshold defines the material failure answering the key question of engineers. This leads to a rather simple feature-based visualisation. For composite materials like short fiber reinforced polymers, the situation is much more complex. The material property is determined by the fiber distribution at every position, often described as fiber orientation tensor field. Essentially, the material's ability to cope with stress becomes anisotropic and inhomogeneous. We show how to combine the stress field and the fiber orientation field in such cases, leading to a feature-based visualization of tensor fields for composite materials. The resulting features inform the engineer about potential improvements in the product development.	Valentin Zobel;Markus Stommel;Gerik Scheuermann	Valentin Zobel;Markus Stommel;Gerik Scheuermann	Leipzig University;TU Dortmund University;Leipzig University	10.1109/VISUAL.1994.346326;10.1109/TVCG.2009.184;10.1109/VISUAL.1995.485141;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105	tensor visualization, feature-based visualisation, composite materials, structural mechanics	4	4	2	21	
SciVis	2015	CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees	10.1109/SciVis.2015.7429492	http://dx.doi.org/10.1109/SciVis.2015.7429492	57	64	C	We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.	Ingo Wald;Aaron Knoll;Gregory P. Johnson;William Usher;Valerio Pascucci;Michael E. Papka	Ingo Wald;Aaron Knoll;Gregory P. Johnson;Will Usher;Valerio Pascucci;Michael E. Papka	Intel Corporation;SCI Institute, University of Utah;Intel Corporation;SCI Institute, University of Utah;SCI Institute, University of Utah;Argonne National Laboratory, Northern Illinois University	10.1109/TVCG.2010.148;10.1109/TVCG.2009.142;10.1109/TVCG.2012.282	Ray tracing, Visualization, Particle Data, k-d Trees	7	12	11	27	
SciVis	2015	Auto-Calibration of Multi-Projector Displays with a Single Handheld Camera	10.1109/SciVis.2015.7429493	http://dx.doi.org/10.1109/SciVis.2015.7429493	65	72	C	We present a novel approach that utilizes a simple handheld camera to automatically calibrate multi-projector displays. Most existing studies adopt active structured light patterns to verify the relationship between the camera and the projectors. The utilized camera is typically expensive and requires an elaborate installation process depending on the scalability of its applications. Moreover, the observation of the entire area by the camera is almost impossible for a small space surrounded by walls as there is not enough distance for the camera to capture the entire scene. We tackle these issues by requiring only a portion of the walls to be visible to a handheld camera that is widely used these days. This becomes possible by the introduction of our new structured light pattern scheme based on a perfect submap and a geometric calibration that successfully utilizes the geometric information of multi-planar environments. We demonstrate that immersive display in a small space such as an ordinary room can be effectively created using images captured by a handheld camera.	Sanghun Park;Hyunggoog Seo;Seunghoon Cha;Jun-yong Noh	Sanghun Park;Hyunggoog Seo;Seunghoon Cha;Junyong Noh	KAIST;KAIST;KAIST;KAIST	10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.1999.809883		1	3	3	26	
SciVis	2015	Correlation analysis in multidimensional multivariate time-varying datasets	10.1109/SciVis.2015.7429502	http://dx.doi.org/10.1109/SciVis.2015.7429502	139	140	M	One of the most vital challenges for weather forecasters is the correlation between two geographical phenomena that are distributed continuously in multidimensional multivariate time-varying datasets. In this research, we have visualized the correlation between Pressure and Temperature in the climate datasets. Pearson correlation is used in this study to measure the major linear relationship between two variables in the dataset. Using glyphs in the spatial location, we highlighted the significant association between variables. Based on the positive or negative slope of correlation lines, we can conclude how much they are correlated. The principal of this research is visualizing the local trend of variables versus each other in multidimensional multivariate time-varying datasets, which needs to be visualized with their spatial locations in meteorological datasets. Using glyphs, not only can we visualize the correlation between two variables in the coordinate system, but we can also discern whether any of these variables is separately increasing or decreasing. Moreover, we can visualize the background color as another variable and see the correlation lines around of a particular zone such as storm area.	Najmeh Abedzadeh	Najmeh Abedzadeh	Mississippi State University			0	0	0	5	
SciVis	2015	OpenSpace: Public dissemination of space mission profiles	10.1109/SciVis.2015.7429503	http://dx.doi.org/10.1109/SciVis.2015.7429503	141	142	M	This work presents a visualization system and its application to space missions. The system allows the public to disseminate the scientific findings of space craft and gain a greater understanding thereof. Instruments' field-of-views and their measurements are embedded in an accurate 3 dimensional rendering of the solar system to provide context to past measurements or the planning of future events. We tested our system with NASA's New Horizons at the Pluto Pallooza event in New York and will expose it to the greater public on the upcoming July 14th Pluto flyby.	Alexander Bock;Michal Marcinkowski;Joakim Kilby;Carter Emmart;Anders Ynnerman	Alexander Bock;Michal Marcinkowski;Joakim Kilby;Carter Emmart;Anders Ynnerman	Linköping University;American Museum of Natural History, Linköping University;Linköping University;American Museum of Natural History;Linköping University			3	4	3	7	
SciVis	2015	3D superquadric glyphs for visualizing myocardial motion	10.1109/SciVis.2015.7429504	http://dx.doi.org/10.1109/SciVis.2015.7429504	143	144	M	Various cardiac diseases can be diagnosed by the analysis of myocardial motion. Relevant biomarkers are radial, longitudinal, and rotational velocities of the cardiac muscle computed locally from MR images. We designed a visual encoding that maps these three attributes to glyph shapes according to a barycentric space formed by 3D superquadric glyphs. The glyphs show aggregated myocardial motion information following the AHA model and are displayed in a respective 3D layout.	Teodora Chitiboi;Mathias Neugebauer;Susanne Schnell;Michael Markl;Lars Linsen	Teodora Chitiboi;Mathias Neugebauer;Susanne Schnell;Michael Markl;Lars Linsen	FraunhoferMEVIS, Jacobs University Bremen;Fraunhofer MEVIS;Northwestern University;Northwestern University;Jacobs University Bremen			2	4	2	8	
SciVis	2015	Real-time interactive time correction on the GPU	10.1109/SciVis.2015.7429505	http://dx.doi.org/10.1109/SciVis.2015.7429505	145	146	M	The study of physical phenomena and their dynamic evolution is supported by the analysis and visualization of time-enabled data. In many applications, available data are sparsely distributed in the space-time domain, which leads to incomprehensible visualizations. We present an interactive approach for the dynamic tracking and visualization of measured data particles through advection in a simulated flow. We introduce a fully GPU-based technique for efficient spatio-temporal interpolation, using a kd-tree forest for acceleration. As the user interacts with the system using a time slider, particle positions are reconstructed for the time selected by the user. Our results show that the proposed technique achieves highly accurate parallel tracking for thousands of particles. The rendering performance is mainly affected by the size of the query set.	Mai El-Shehaly;Denis Gracanin;Mohamed A. Gad;JunPeng Wang;Hicham G. Elmongui	Mai Elshehaly;Denis Gračanin;Mohamed Gad;Junpeng Wang;Hicham G. Elmongui	Virginia Tech;Virginia Tech;Ain Shams University;Virginia Tech;Alexandria University			0	0	0	3	
SciVis	2015	Visualizing crossing probabilistic tracts	10.1109/SciVis.2015.7429506	http://dx.doi.org/10.1109/SciVis.2015.7429506	147	148	M	Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain.	Mathias Goldau;André Reichenbach;Mario Hlawitschka	Mathias Goldau;André Reichenbach;Mario Hlawitschka	Leipzig University;Leipzig University;Leipzig University			0	0	0	10	
SciVis	2015	An evaluation of three methods for visualizing uncertainty in architecture and archaeology	10.1109/SciVis.2015.7429507	http://dx.doi.org/10.1109/SciVis.2015.7429507	149	150	M	This project explores the representation of uncertainty in visualizations for archaeological research and provides insights obtained from user feedback. Our 3D models brought together information from standing architecture and excavated remains, surveyed plans, ground penetrating radar (GPR) data from the Carthusian monastery of Bourgfontaine in northern France. We also included information from comparative Carthusian sites and a bird's eye representation of the site in an early modern painting. Each source was assigned a certainty value which was then mapped to a color or texture for the model. Certainty values between one and zero were assigned by one subject matter expert and should be considered qualitative. Students and faculty from the fields of architectural history and archaeology at two institutions interacted with the models and answered a short survey with four questions about each. We discovered equal preference for color and transparency and a strong dislike for the texture model. Discoveries during model building also led to changes of the excavation plans for summer 2015.	Scott Houde;Sheila Bonde;David H. Laidlaw	Scott Houde;Sheila Bonde;David H. Laidlaw	Brown University;Brown University;Brown University			0	0	0	5	
SciVis	2015	Multiresolution visualization of digital earth data via hexagonal box-spline wavelets	10.1109/SciVis.2015.7429508	http://dx.doi.org/10.1109/SciVis.2015.7429508	151	152	M	Multiresolution analysis is an important tool for exploring large-scale data sets. Such analysis provides facilities to visualize data at different levels of detail while providing the advantages of efficient data compression and transmission. In this work, an approach is presented to apply multiresolution analysis to digital Earth data where each resolution describes data at a specific level of detail. Geospatial data at a fine level is taken as the input and a hierarchy of approximation and detail coefficients is built by applying a hexagonal discrete wavelet transform. Multiresolution filters are designed for hexagonal cells based on the three directional linear box spline which is natively supported by modern GPUs.	Mohammad Imrul Jubair;Usman R. Alim;Niklas Röber;John P. Clyne;Ali Mahdavi-Amiri;Faramarz F. Samavati	Mohammad Imrul Jubair;Usman Alim;Niklas Roeber;John Clyne;Ali Mahdavi-Amiri;Faramarz Samavati	University of Calgary;University of Calgary;German Climate Computing Centre;University Corporation for Atmospheric Research;University of Calgary;University of Calgary			0	3	2	6	
SciVis	2015	Automated visualization workflow for simulation experiments	10.1109/SciVis.2015.7429509	http://dx.doi.org/10.1109/SciVis.2015.7429509	153	154	M	Modeling and simulation is often used to predict future events and plan accordingly. Experiments in this domain often produce thousands of results from individual simulations, based on slightly varying input parameters. Geo-spatial visualizations can be a powerful tool to help health researchers and decision-makers to take measures during catastrophic and epidemic events such as Ebola outbreaks. The work produced a web-based geo-visualization tool to visualize and compare the spread of Ebola in the West African countries Ivory Coast and Senegal based on multiple simulation results. The visualization is not Ebola specific and may visualize any time-varying frequencies for given geo-locations.	Jonathan Leidig;Santhosh Dharmapuri	Jonathan P. Leidig;Santhosh Dharmapuri	School of Computing and Information Systems, Grand Valley State University;School of Computing and Information Systems, Grand Valley State University			0	1	1	12	
SciVis	2015	A bottom-up scheme for user-defined feature exploration in vector field ensembles	10.1109/SciVis.2015.7429510	http://dx.doi.org/10.1109/SciVis.2015.7429510	155	156	M	Most of the existing approaches to visualize vector field ensembles are achieved by visualizing the uncertainty of individual variables from different simulation runs. However, the comparison of the derived feature or user-defined feature, such as the vortex in ensemble flow is also of vital significance since they often make more sense according to the domain knowledge. In this work, we present a framework to extract user-defined feature from different simulation runs. Specially, we use a bottom-up searching scheme to help to extract vortex with a user-defined shape, and further compute the geometry information including the size, and the geo-spatial location of the extracted vortex. Finally we design some linked views to compare the feature between different runs.	Richen Liu;Hanqi Guo;Xiaoru Yuan	Richen Liu;Hanqi Guo;Xiaoru Yuan	Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Argonne National Laboratory;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University			0	1	1	5	
SciVis	2015	A proposed multivariate visualization taxonomy from user data	10.1109/SciVis.2015.7429511	http://dx.doi.org/10.1109/SciVis.2015.7429511	157	158	M	We revisited past user study data on multivariate visualizations, looking at whether image processing measures offer any insight into user performance. While we find statistically significant correlations, some of the greatest insights into user performance came from variables that have strong ties to two key properties of multivariate representations. We discuss our analysis and propose a taxonomy of multivariate visualizations that arises.	Mark A. Livingston;Jonathan W. Decker;Zhuming Ai	Mark A. Livingston;Jonathan W. Decker;Zhuming Ai				0	0	0	8	
SciVis	2015	PathlinesExplorer ??? Image-based exploration of large-scale pathline fields	10.1109/SciVis.2015.7429512	http://dx.doi.org/10.1109/SciVis.2015.7429512	159	160	M	PathlinesExplorer is a novel image-based tool, which has been designed to visualize large scale pathline fields on a single computer [7]. PathlinesExplorer integrates explorable images (EI) technique [4] with order-independent transparency (OIT) method [2]. What makes this method different is that it allows users to handle large data on a single workstation. Although it is a view-dependent method, PathlinesExplorer combines both exploration and modification of visual aspects without re-accessing the original huge data. Our approach is based on constructing a per-pixel linked list data structure in which each pixel contains a list of pathline segments. With this view-dependent method, it is possible to filter, color-code, and explore large-scale flow data in real-time. In addition, optimization techniques such as early-ray termination and deferred shading are applied, which further improves the performance and scalability of our approach.	Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan	Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan	KAUST;KAUST;KAUST			0	0	0	7	
SciVis	2015	Visualizing 3D flow through cutting planes	10.1109/SciVis.2015.7429513	http://dx.doi.org/10.1109/SciVis.2015.7429513	161	162	M	Studies have found conflicting results regarding the effectiveness of tube-like structures for representing 3D flow data. This paper presents the findings of a small-scale pilot study contrasting static monoscopic depth cues to ascertain their importance in perceiving the orientation of a three-dimensional glyph with respect to a cutting plane. A simple striped texture and shading were found to reduce judgement errors when used with a 3D tube glyph as compared to plain or shaded line glyphs. A discussion of considerations for a full-scale study and possible future work follows.	Colin Ware;Andrew H. Stevens	Colin Ware;Andrew H. Stevens	University of New Hampshire;University of New Hampshire			0	0	0	6	
SciVis	2015	Inviwo ??? An extensible, multi-purpose visualization framework	10.1109/SciVis.2015.7429514	http://dx.doi.org/10.1109/SciVis.2015.7429514	163	164	M	To enable visualization research impacting other scientific domains, the availability of easy-to-use visualization frameworks is essential. Nevertheless, an easy-to-use system also has to be adapted to the capabilities of modern hardware architectures, as only this allows for realizing interactive visualizations. With this trade-off in mind, we have designed and realized the cross-platform Inviwo (Interactive Visualization Workshop) visualization framework, that supports both interactive visualization research as well as efficient visualization application development and deployment. In this poster we give an overview of the architecture behind Inviwo, and show how its design enables us and other researchers to realize their visualization ideas efficiently. Inviwo consists of a modern and lightweight, graphics independent core, which is extended by optional modules that encapsulate visualization algorithms, well-known utility libraries and commonly used parallel-processing APIs (such as OpenGL and OpenCL). The core enables a simplistic structure for creating bridges between the different modules regarding data transfer across architecture and devices with an easy-to-use screen graph and minimalistic programming. Making the base structures in a modern way while providing intuitive methods of extending the functionality and creating modules based on other modules, we hope that Inviwo can help the visualization community to perform research through a rapid-prototyping design and GUI, while at the same time allowing users to take advantage of the results implemented in the system in any way they desire later on. Inviwo is publicly available at www.inviwo.org, and can be used freely by anyone under a permissive free software license (Simplified BSD).	Erik Sundén;Peter Steneteg;Sathish Kottravel;Daniel Jönsson;Rickard Englund;Martin Falk;Timo Ropinski	Erik Sunden;Peter Steneteg;Sathish Kottravel;Daniel Jonsson;Rickard Englund;Martin Falk;Timo Ropinski	Linkoping University;Linkoping University;Linkoping University;Linkoping University;Linkoping University;Linkoping University;Ulm University			4	11	7	10	
SciVis	2015	High performance flow field visualization with high-order access dependencies	10.1109/SciVis.2015.7429515	http://dx.doi.org/10.1109/SciVis.2015.7429515	165	166	M	We present a novel model based on high-order access dependencies for high performance pathline computation in flow field. The high-order access dependencies are defined as transition probabilities from one data block to other blocks based on a few historical data accesses. Compared with existing methods which employed first-order access dependencies, our approach takes the advantages of high order access dependencies with higher accuracy and reliability in data access prediction. In our work, high-order access dependencies are calculated by tracing densely-seeded pathlines. The efficiency of our proposed approach is demonstrated through a parallel particle tracing framework with high-order data prefetching. Results show that our method can achieve higher data locality than the first-order access dependencies based method, thereby reducing the I/O requests and improving the efficiency of pathline computation in various applications.	Jiang Zhang;Hanqi Guo;Xiaoru Yuan	Jiang Zhang;Hanqi Guo;Xiaoru Yuan	Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Argonne National Laboratory;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University			0	0	0	4	
SciVis	2015	Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data	10.1109/TVCG.2015.2466838	http://dx.doi.org/10.1109/TVCG.2015.2466838	827	836	J	We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible.	Hanqi Guo;Carolyn L. Phillips;Tom Peterka;Dmitry A. Karpeyev;Andreas Glatz	Hanqi Guo;Carolyn L. Phillips;Tom Peterka;Dmitry Karpeyev;Andreas Glatz	Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA	10.1109/VISUAL.1994.346327;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2011.249;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1996.568137;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2004.3;10.1109/TVCG.2012.212;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545	Superconductor, Vortex extraction, Feature tracking, Unstructured grid	2	5	5	39	
InfoVis	2015	Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis	10.1109/TVCG.2015.2466971	http://dx.doi.org/10.1109/TVCG.2015.2466971	449	458	J	The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.	Matthew Brehmer;Jocelyn Ng;Kevin Tate;Tamara Munzner	Matthew Brehmer;Jocelyn Ng;Kevin Tate;Tamara Munzner	University of British Columbia;EnerNOC, Inc.;EnerNOC, Inc.;University of British Columbia	10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2008.166;10.1109/TVCG.2013.145;10.1109/TVCG.2013.173;10.1109/TVCG.2010.162;10.1109/TVCG.2007.70583;10.1109/TVCG.2011.209;10.1109/TVCG.2014.2346331;10.1109/TVCG.2014.2346578;10.1109/TVCG.2009.111;10.1109/TVCG.2011.196;10.1109/TVCG.2012.213;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122	Design study, design methodologies, time series data, task and requirements analysis, coordinated and multiple views	10	14	13	46	
InfoVis	2015	Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research	10.1109/TVCG.2015.2466992	http://dx.doi.org/10.1109/TVCG.2015.2466992	579	588	J	The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed.	Jimmy Johansson;Camilla Forsell	Jimmy Johansson;Camilla Forsell	Norrköping Visualization Center C/Linköping University, Sweden;Norrköping Visualization Center C/Linköping University, Sweden	10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.201;10.1109/VISUAL.1999.809866;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.15;10.1109/INFVIS.2004.5;10.1109/TVCG.2011.197;10.1109/VISUAL.1997.663867	Survey, evaluation, guidelines, parallel coordinates	25	41	34	50	
SciVis	2015	Visualizing Tensor Normal Distributions at Multiple Levels of Detail	10.1109/TVCG.2015.2467031	http://dx.doi.org/10.1109/TVCG.2015.2467031	975	984	J	Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.	Amin Abbasloo;Vitalis Wiens;Max Hermann;Thomas Schultz 0001	Amin Abbasloo;Vitalis Wiens;Max Hermann;Thomas Schultz	University of Bonn;University of Bonn;University of Bonn;University of Bonn	10.1109/TVCG.2009.170;10.1109/TVCG.2009.184;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2006.181;10.1109/TVCG.2006.134;10.1109/TVCG.2010.199;10.1109/TVCG.2008.128;10.1109/TVCG.2007.70602;10.1109/TVCG.2015.2467435	Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization	6	9	9	60	
InfoVis	2015	SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams	10.1109/TVCG.2015.2467035	http://dx.doi.org/10.1109/TVCG.2015.2467035	330	338	J	System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology.	Aurélie Cohé;Bastien Liutkus;Gilles Bailly;James R. Eagan;Eric Lecolinet	Aurélie Cohé;Bastien Liutkus;Gilles Bailly;James Eagan;Eric Lecolinet	Télécom ParisTech;Télécom ParisTech;CNRS LTCI & Télécom ParisTech;Télécom ParisTech;Télécom ParisTech	10.1109/INFVIS.2004.66;10.1109/TVCG.2012.245;10.1109/INFVIS.2003.1249008	Fisheye, vector-scaling, content-aware, network schematics, interactive zoom, navigation, information visualization	4	8	4	33	
InfoVis	2015	AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations	10.1109/TVCG.2015.2467051	http://dx.doi.org/10.1109/TVCG.2015.2467051	688	697	J	Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.	Mehmet Adil Yalçin;Niklas Elmqvist;Benjamin B. Bederson	M. Adil Yalçin;Niklas Elmqvist;Benjamin B. Bederson	University of Maryland, College Park;University of Maryland, College Park;University of Maryland, College Park	10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2011.185;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.144;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.141;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210;10.1109/TVCG.2014.2346249	Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability	6	9	6	36	
InfoVis	2015	Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization	10.1109/TVCG.2015.2467091	http://dx.doi.org/10.1109/TVCG.2015.2467091	659	668	J	We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.	Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer	Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer	Stanford University;University of Washington;University of Washington;University of Washington	10.1109/VISUAL.1995.480821;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2010.144;10.1109/TVCG.2014.2346250;10.1109/TVCG.2013.179;10.1109/TVCG.2010.177;10.1109/VISUAL.1996.567752;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12;10.1109/TVCG.2015.2467191;10.1109/TVCG.2007.70515	Information visualization, systems, toolkits, declarative specification, optimization, interaction, streaming data	32	62	42	41	
InfoVis	2015	Visualization, Selection, and Analysis of Traffic Flows	10.1109/TVCG.2015.2467112	http://dx.doi.org/10.1109/TVCG.2015.2467112	379	388	J	Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts.	Roeland Scheepens;Christophe Hurter;Huub van de Wetering;Jarke J. van Wijk	Roeland Scheepens;Christophe Hurter;Huub Van De Wetering;Jarke J. Van Wijk	Department of Mathematics and Computer Science, Eindhoven University of Technology, The Netherlands;Interactive Computing Laboratory (LII) of the French Civil Aviation University (ENAC) in Toulouse, France;Department of Mathematics and Computer Science, Eindhoven University of Technology, The Netherlands;Department of Mathematics and Computer Science, Eindhoven University of Technology, The Netherlands	10.1109/TVCG.2011.185;10.1109/TVCG.2011.261;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294	Moving Object Visualization, traffic flows, interaction	24	38	26	36	
InfoVis	2015	Optimal Sets of Projections of High-Dimensional Data	10.1109/TVCG.2015.2467132	http://dx.doi.org/10.1109/TVCG.2015.2467132	609	618	J	Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.	Dirk J. Lehmann;Holger Theisel	Dirk J. Lehmann;Holger Theisel	University of Magdeburg;University of Magdeburg	10.1109/VAST.2010.5652433;10.1109/VAST.2011.6102437;10.1109/TVCG.2011.229;10.1109/VISUAL.1997.663916;10.1109/TVCG.2011.220;10.1109/TVCG.2013.182;10.1109/TVCG.2010.207;10.1109/VAST.2006.261423;10.1109/INFVIS.2005.1532142	Multivariate Projections, Star Coordinates, Radial Visualization, High-dimensional Data	14	20	21	29	
SciVis	2015	Visualization-by-Sketching: An Artist's Interface for Creating Multivariate Time-Varying Data Visualizations	10.1109/TVCG.2015.2467153	http://dx.doi.org/10.1109/TVCG.2015.2467153	877	885	J	We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data “under” the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay “in the creative zone” as they work.	David Schroeder;Daniel F. Keefe	David Schroeder;Daniel F. Keefe	University of Minnesota;Department of Computer Science & Engineering, University of Minnesota	10.1109/VAST.2008.4677356;10.1109/TVCG.2009.181;10.1109/TVCG.2013.124;10.1109/TVCG.2011.202;10.1109/TVCG.2008.153;10.1109/TVCG.2013.226;10.1109/TVCG.2014.2346271;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2009.145;10.1109/TVCG.2010.162;10.1109/INFVIS.2001.963286;10.1109/TVCG.2011.181;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346441	Visualization design, multivariate, art, sketch, color map, glyph	6	12	11	31	BP
InfoVis	2015	Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations	10.1109/TVCG.2015.2467191	http://dx.doi.org/10.1109/TVCG.2015.2467191	649	658	J	General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.	Kanit Wongsuphasawat;Dominik Moritz;Anushka Anand;Jock D. Mackinlay;Bill Howe;Jeffrey Heer	Kanit Wongsuphasawat;Dominik Moritz;Anushka Anand;Jock Mackinlay;Bill Howe;Jeffrey Heer	University of Washington;Tableau Research;Tableau Research;Tableau Research;University of Washington;University of Washington	10.1109/TVCG.2014.2346297;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70594;10.1109/TVCG.2014.2346291;10.1109/INFVIS.2000.885086	User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems	69	143	84	48	
SciVis	2015	TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data	10.1109/TVCG.2015.2467194	http://dx.doi.org/10.1109/TVCG.2015.2467194	935	944	J	Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.	Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni	Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Noah's Ark Lab;Noah's Ark Lab;University of Macau	10.1109/VAST.2010.5652478;10.1109/TVCG.2013.193;10.1109/TVCG.2014.2346276;10.1109/TVCG.2013.226;10.1109/TVCG.2011.166;10.1109/TVCG.2013.173;10.1109/TVCG.2014.2346271;10.1109/VAST.2011.6102455;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346665;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/VAST.2014.7042490;10.1109/TVCG.2014.2346922	Co-occurrence, human mobility, telco data, bicluster, visual analytics	18	40	34	45	
InfoVis	2015	How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice's Information Visualization Sensemaking	10.1109/TVCG.2015.2467195	http://dx.doi.org/10.1109/TVCG.2015.2467195	499	508	J	In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations.	Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn ah Kang;Ji Soo Yi	Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn-Ah Kang;Ji Soo Yi	School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Department of Computer Science, University of British Columbia, Vancouver, BC, Canada;School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Google Inc., Mountain View, CA, USA;Techno-Art Division, Information and Interaction Design, Incheon, South Korea;School of Industrial Engineering, Purdue University, West Lafayette, IN, USA	10.1109/TVCG.2013.234;10.1109/TVCG.2014.2346984;10.1109/TVCG.2010.164;10.1109/VAST.2011.6102435;10.1109/TVCG.2014.2346452;10.1109/TVCG.2010.177;10.1109/TVCG.2014.2346481;10.1109/TVCG.2010.179;10.1109/TVCG.2007.70515	Sensemaking model, information visualization, novice users, grounded theory, qualitative study	20	32	25	48	
VAST	2015	TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems	10.1109/TVCG.2015.2467196	http://dx.doi.org/10.1109/TVCG.2015.2467196	280	289	J	Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.	Nan Cao;Conglei Shi;Wan-Yi Sabrina Lin;Jie Lu;Yu-Ru Lin;Ching-Yung Lin	Nan Cao;Conglei Shi;Sabrina Lin;Jie Lu;Yu-Ru Lin;Ching-Yung Lin	IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;University of Pissburg;IBM T. J. Watson Research Center	10.1109/TVCG.2012.291;10.1109/TVCG.2006.170;10.1109/VISUAL.2002.1183816;10.1109/TVCG.2014.2346922	Anomaly Detection, Social Media, Visual Analysis	28	47	39	45	
SciVis	2015	Accurate Interactive Visualization of Large Deformations and Variability in Biomedical Image Ensembles	10.1109/TVCG.2015.2467198	http://dx.doi.org/10.1109/TVCG.2015.2467198	708	717	J	Large image deformations pose a challenging problem for the visualization and statistical analysis of 3D image ensembles which have a multitude of applications in biology and medicine. Simple linear interpolation in the tangent space of the ensemble introduces artifactual anatomical structures that hamper the application of targeted visual shape analysis techniques. In this work we make use of the theory of stationary velocity fields to facilitate interactive non-linear image interpolation and plausible extrapolation for high quality rendering of large deformations and devise an efficient image warping method on the GPU. This does not only improve quality of existing visualization techniques, but opens up a field of novel interactive methods for shape ensemble analysis. Taking advantage of the efficient non-linear 3D image warping, we showcase four visualizations: 1) browsing on-the-fly computed group mean shapes to learn about shape differences between specific classes, 2) interactive reformation to investigate complex morphologies in a single view, 3) likelihood volumes to gain a concise overview of variability and 4) streamline visualization to show variation in detail, specifically uncovering its component tangential to a reference surface. Evaluation on a real world dataset shows that the presented method outperforms the state-of-the-art in terms of visual quality while retaining interactive frame rates. A case study with a domain expert was performed in which the novel analysis and visualization methods are applied on standard model structures, namely skull and mandible of different rodents, to investigate and compare influence of phylogeny, diet and geography on shape. The visualizations enable for instance to distinguish (population-)normal and pathological morphology, assist in uncovering correlation to extrinsic factors and potentially support assessment of model quality.	Max Hermann;Anja C. Schunke;Thomas Schultz 0001;Reinhard Klein	Max Hermann;Anja C. Schunke;Thomas Schultz;Reinhard Klein	Institut für Informatik II;Max Planck Institute for Evolutionary Biology, Pl&#x00F6;n;Institut für Informatik II;Institut für Informatik II	10.1109/TVCG.2006.140;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2014.2346591;10.1109/TVCG.2014.2346405;10.1109/TVCG.2006.123	Statistical deformation model, stationary velocity fields, image warping, interactive visual analysis	7	9	8	46	
InfoVis	2015	Visualizing Multiple Variables Across Scale and Geography	10.1109/TVCG.2015.2467199	http://dx.doi.org/10.1109/TVCG.2015.2467199	599	608	J	Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable.	Sarah Goodwin;Jason Dykes;Aidan Slingsby;Cagatay Turkay	Sarah Goodwin;Jason Dykes;Aidan Slingsby;Cagatay Turkay	Monash University;the giCentre, City University London;the giCentre, City University London;the giCentre, City University London	10.1109/TVCG.2007.70558;10.1109/TVCG.2013.145;10.1109/TVCG.2007.70539;10.1109/TVCG.2014.2346482;10.1109/VAST.2011.6102448;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321;10.1109/TVCG.2009.128;10.1109/TVCG.2011.197;10.1109/TVCG.2012.256;10.1109/TVCG.2014.2346265	Scale, Geography, Multivariate, Sensitivity Analysis, Variable Selection, Local Statistics, Geodemographics, Energy	20	25	20	51	
SciVis	2015	Rotation Invariant Vortices for Flow Visualization	10.1109/TVCG.2015.2467200	http://dx.doi.org/10.1109/TVCG.2015.2467200	817	826	J	We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts.	Tobias Günther;Maik Schulze;Holger Theisel	Tobias Günther;Maik Schulze;Holger Theisel	Visual Computing Group, University of Magdeburg;MAXON Computer;Visual Computing Group, University of Magdeburg	10.1109/TVCG.2014.2346415;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2014.2346412;10.1109/TVCG.2011.249;10.1109/TVCG.2013.189;10.1109/VISUAL.1999.809917;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198	Vortex cores, rotation invariance, Galilean invariance, scientific visualization, flow visualization, line fields	8	10	11	49	HM
InfoVis	2015	Suggested Interactivity: Seeking Perceived Affordances for Information Visualization	10.1109/TVCG.2015.2467201	http://dx.doi.org/10.1109/TVCG.2015.2467201	639	648	J	In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward.	Jeremy Boy;Louis Eveillard;Françoise Détienne;Jean-Daniel Fekete	Jeremy Boy;Louis Eveillard;Françoise Detienne;Jean-Daniel Fekete	INRIA;EnsadLab;Telecom ParisTech;INRIA	10.1109/TVCG.2014.2346984;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/INFVIS.2005.1532122	Suggested interactivity, perceived affordances, information visualization for the people, online visualization		23	16	55	
SciVis	2015	CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds	10.1109/TVCG.2015.2467202	http://dx.doi.org/10.1109/TVCG.2015.2467202	886	895	J	We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency.	Lingyun Yu;Konstantinos Efstathiou 0001;Petra Isenberg;Tobias Isenberg 0001	Lingyun Yu;Konstantinos Efstathiou;Petra Isenberg;Tobias Isenberg	Hangrhou Dianzi University, Zhejiang, China;University of Groningen, The Netherlands;Inria, France;Inria, France	10.1109/TVCG.2008.153;10.1109/VISUAL.1999.809932;10.1109/TVCG.2013.126;10.1109/TVCG.2012.292;10.1109/INFVIS.1996.559216;10.1109/TVCG.2012.217;10.1109/TVCG.2010.157	Selection, spatial selection, structure-aware selection, context-aware selection, exploratory data visualization and analysis, 3D interaction, user interaction	8	18	17	58	
SciVis	2015	Cluster Analysis of Vortical Flow in Simulations of Cerebral Aneurysm Hemodynamics	10.1109/TVCG.2015.2467203	http://dx.doi.org/10.1109/TVCG.2015.2467203	757	766	J	Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices.	Steffen Oeltze-Jafra;Juan R. Cebral;Gábor Janiga;Bernhard Preim	Steffen Oeltze-Jafra;Juan R. Cebral;Gábor Janiga;Bernhard Preim	Department of Simulation and Graphics, University of Magdeburg, Germany;Center for Computational Fluid Dynamics, George Mason University, Fairfax, Virginia, USA;Institute of Fluid Dynamics and Thermodynamics, Germany;Department of Simulation and Graphics, University of Magdeburg, Germany	10.1109/TVCG.2009.138;10.1109/TVCG.2012.202;10.1109/TVCG.2014.2346406;10.1109/TVCG.2006.201;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2013.189;10.1109/VISUAL.2004.59;10.1109/TVCG.2006.199;10.1109/VISUAL.2005.1532830;10.1109/VISUAL.2005.1532859	Blood Flow, Aneurysm, Clustering, Vortex Dynamics, Embedded Vortices	14	19	16	51	
SciVis	2015	Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles	10.1109/TVCG.2015.2467204	http://dx.doi.org/10.1109/TVCG.2015.2467204	767	776	J	We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.	Florian Ferstl;Kai Bürger;Rüdiger Westermann	Florian Ferstl;Kai Bürger;Rüdiger Westermann	Computer Graphics and Visualization Group;Computer Graphics and Visualization Group;Computer Graphics and Visualization Group	10.1109/TVCG.2007.70595;10.1109/VISUAL.2000.885715;10.1109/VISUAL.1999.809863;10.1109/TVCG.2013.141;10.1109/TVCG.2007.70518;10.1109/TVCG.2014.2346455;10.1109/VISUAL.2005.1532779;10.1109/TVCG.2010.181;10.1109/VISUAL.1999.809865;10.1109/TVCG.2013.143	Ensemble visualization, uncertainty visualization, flow visualization, streamlines, statistical modeling	22	44	42	50	
InfoVis	2015	High-Quality Ultra-Compact Grid Layout of Grouped Networks	10.1109/TVCG.2015.2467251	http://dx.doi.org/10.1109/TVCG.2015.2467251	339	348	J	Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks.	Vahan Yoghourdjian;Tim Dwyer;Graeme Gange;Steve Kieffer;Karsten Klein 0001;Kim Marriott	Vahan Yoghourdjian;Tim Dwyer;Graeme Gange;Steve Kieffer;Karsten Klein;Kim Marriott	Monash University;Monash University;The University of Melbourne;Monash University;Monash University;Monash University	10.1109/TVCG.2008.117;10.1109/TVCG.2013.151;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/INFVIS.2003.1249009;10.1109/TVCG.2015.2467451;10.1109/TVCG.2012.245	Network visualization, graph drawing, power graph, optimization, large-neighborhood search	9	13	12	50	
InfoVis	2015	Sketching Designs Using the Five Design-Sheet Methodology	10.1109/TVCG.2015.2467271	http://dx.doi.org/10.1109/TVCG.2015.2467271	419	428	J	Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lo-fidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching.	Jonathan C. Roberts;Christopher James Headleand;Panagiotis D. Ritsos	Jonathan C. Roberts;Chris Headleand;Panagiotis D. Ritsos	School of Computer Science, Bangor University;School of Computer Science, Bangor University;Department of Computer Science, University of Chester	10.1109/TVCG.2010.132;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.178;10.1109/VISUAL.1994.346304;10.1109/TVCG.2014.2346331;10.1109/TVCG.2009.111;10.1109/TVCG.2012.213;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.171	Lo-fidelity prototyping, User-centred design, Sketching for visualization, Ideation	11	22	20	58	
SciVis	2015	Reconstruction and Visualization of Coordinated 3D Cell Migration Based on Optical Flow	10.1109/TVCG.2015.2467291	http://dx.doi.org/10.1109/TVCG.2015.2467291	995	1004	J	Animal development is marked by the repeated reorganization of cells and cell populations, which ultimately determine form and shape of the growing organism. One of the central questions in developmental biology is to understand precisely how cells reorganize, as well as how and to what extent this reorganization is coordinated. While modern microscopes can record video data for every cell during animal development in 3D+t, analyzing these videos remains a major challenge: reconstruction of comprehensive cell tracks turned out to be very demanding especially with decreasing data quality and increasing cell densities. In this paper, we present an analysis pipeline for coordinated cellular motions in developing embryos based on the optical flow of a series of 3D images. We use numerical integration to reconstruct cellular long-term motions in the optical flow of the video, we take care of data validation, and we derive a LIC-based, dense flow visualization for the resulting pathlines. This approach allows us to handle low video quality such as noisy data or poorly separated cells, and it allows the biologists to get a comprehensive understanding of their data by capturing dynamic growth processes in stills. We validate our methods using three videos of growing fruit fly embryos.	Christopher P. Kappe;Lucas Schutz;Stefan Gunther;Lars Hufnagel;Steffen Lemke;Heike Leitte	Christopher P. Kappe;Lucas Schütz;Stefan Gunther;Lars Hufnagel;Steffen Lemke;Heike Leitte	IWR, Heidelberg University;COS, Heidelberg University;EMBL, Heidelberg, Germany;EMBL, Heidelberg, Germany;COS, Heidelberg University;IWR, Heidelberg University	10.1109/TVCG.2010.169;10.1109/VISUAL.1996.567784;10.1109/TVCG.2009.190;10.1109/VISUAL.2003.1250364;10.1109/VISUAL.1997.663898;10.1109/VISUAL.2003.1250363	Cell migration, vector field, 3D, timedependent,LIC, tracking, validation	2	4	5	56	
SciVis	2015	Multi-field Pattern Matching based on Sparse Feature Sampling	10.1109/TVCG.2015.2467292	http://dx.doi.org/10.1109/TVCG.2015.2467292	807	816	J	We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts.	Zhongjie Wang 0001;Hans-Peter Seidel;Tino Weinkauf	Zhongjie Wang;Hans-Peter Seidel;Tino Weinkauf	MPI for Informatics, Saarbr&#x00FC;cken, Germany;MPI for Informatics, Saarbr&#x00FC;cken, Germany;KTH Royal Institute of Technology, Stockholm, Sweden	10.1109/VISUAL.2003.1250372;10.1109/TVCG.2009.141;10.1109/TVCG.2006.165;10.1109/TVCG.2007.70579;10.1109/TVCG.2014.2346332;10.1109/TVCG.2011.236	Pattern matching, multi-field visualization	4	4	5	36	
SciVis	2015	Real-Time Molecular Visualization Supporting Diffuse Interreflections and Ambient Occlusion	10.1109/TVCG.2015.2467293	http://dx.doi.org/10.1109/TVCG.2015.2467293	718	727	J	Today molecular simulations produce complex data sets capturing the interactions of molecules in detail. Due to the complexity of this time-varying data, advanced visualization techniques are required to support its visual analysis. Current molecular visualization techniques utilize ambient occlusion as a global illumination approximation to improve spatial comprehension. Besides these shadow-like effects, interreflections are also known to improve the spatial comprehension of complex geometric structures. Unfortunately, the inherent computational complexity of interreflections would forbid interactive exploration, which is mandatory in many scenarios dealing with static and time-varying data. In this paper, we introduce a novel analytic approach for capturing interreflections of molecular structures in real-time. By exploiting the knowledge of the underlying space filling representations, we are able to reduce the required parameters and can thus apply symbolic regression to obtain an analytic expression for interreflections. We show how to obtain the data required for the symbolic regression analysis, and how to exploit our analytic solution to enhance interactive molecular visualizations.	Robin Skanberg;Pere-Pau Vázquez;Victor Guallar;Timo Ropinski	Robin Skånberg;Pere-Pau Vázquez;Victor Guallar;Timo Ropinski	Visual Computing Group;MOVING Group;Barcelona Supercomputing Center;Visual Computing Group	10.1109/TVCG.2007.70578;10.1109/TVCG.2009.168;10.1109/TVCG.2007.70517;10.1109/TVCG.2012.282;10.1109/TVCG.2009.157;10.1109/TVCG.2014.2346404;10.1109/TVCG.2006.115	Molecular visualization, diffuse interreflections, ambient occlusion	7	8	8	48	
SciVis	2015	Intuitive Exploration of Volumetric Data Using Dynamic Galleries	10.1109/TVCG.2015.2467294	http://dx.doi.org/10.1109/TVCG.2015.2467294	896	905	J	In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach.	Daniel Jönsson;Martin Falk;Anders Ynnerman	Daniel Jönsson;Martin Falk;Anders Ynnerman	Linköping University, Sweden;Linköping University, Sweden;Linköping University, Sweden	10.1109/TVCG.2008.162;10.1109/TVCG.2011.261;10.1109/VISUAL.1996.568113;10.1109/TVCG.2012.231;10.1109/TVCG.2010.195;10.1109/TVCG.2011.224;10.1109/TVCG.2006.148;10.1109/TVCG.2011.218	Transfer function, scalar fields, volume rendering, touch interaction, visualization, user interfaces	8	12	9	34	
InfoVis	2015	Acquired Codes of Meaning in Data Visualization and Infographics: Beyond Perceptual Primitives	10.1109/TVCG.2015.2467321	http://dx.doi.org/10.1109/TVCG.2015.2467321	509	518	J	While information visualization frameworks and heuristics have traditionally been reluctant to include acquired codes of meaning, designers are making use of them in a wide variety of ways. Acquired codes leverage a user's experience to understand the meaning of a visualization. They range from figurative visualizations which rely on the reader's recognition of shapes, to conventional arrangements of graphic elements which represent particular subjects. In this study, we used content analysis to codify acquired meaning in visualization. We applied the content analysis to a set of infographics and data visualizations which are exemplars of innovative and effective design. 88% of the infographics and 71% of data visualizations in the sample contain at least one use of figurative visualization. Conventions on the arrangement of graphics are also widespread in the sample. In particular, a comparison of representations of time and other quantitative data showed that conventions can be specific to a subject. These results suggest that there is a need for information visualization research to expand its scope beyond perceptual channels, to include social and culturally constructed meaning. Our paper demonstrates a viable method for identifying figurative techniques and graphic conventions and integrating them into heuristics for visualization design.	Lydia Byrne;Daniel Angus;Janet Wiles	Lydia Byrne;Daniel Angus;Janet Wiles	The University of Queensland;The University of Queensland;The University of Queensland	10.1109/TVCG.2013.234;10.1109/TVCG.2010.126;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.221;10.1109/TVCG.2008.171	Visual Design, Taxonomies, Illustrative Visualization, Design Methodologies	5	8	8	62	
InfoVis	2015	Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators	10.1109/TVCG.2015.2467322	http://dx.doi.org/10.1109/TVCG.2015.2467322	569	578	J	A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.	Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli	Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli	University of Haifa, Israel;University of Haifa, Israel;IBM Research Haifa Lab, Haifa, Israel;Sheizaf Rafaeli is with University of Haifa, Israel	10.1109/TVCG.2010.209;10.1109/TVCG.2008.125	Visualization evaluation, radial layout design, composite indicator visualization, experiment	17	24	19	35	
InfoVis	2015	Automatic Selection of Partitioning Variables for Small Multiple Displays	10.1109/TVCG.2015.2467323	http://dx.doi.org/10.1109/TVCG.2015.2467323	669	677	J	Effective small multiple displays are created by partitioning a visualization on variables that reveal interesting conditional structure in the data. We propose a method that automatically ranks partitioning variables, allowing analysts to focus on the most promising small multiple displays. Our approach is based on a randomized, non-parametric permutation test, which allows us to handle a wide range of quality measures for visual patterns defined on many different visualization types, while discounting spurious patterns. We demonstrate the effectiveness of our approach on scatterplots of real-world, multidimensional datasets.	Anushka Anand;Justin Talbot	Anushka Anand;Justin Talbot	Tableau Research;Tableau Research	10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/TVCG.2011.229;10.1109/TVCG.2006.161;10.1109/TVCG.2010.184;10.1109/TVCG.2009.153;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2007.70594;10.1109/VAST.2006.261423;10.1109/INFVIS.2000.885086;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.161;10.1109/INFVIS.2005.1532142	Small multiple displays, Visualization selection, Multidimensional data	7	10	6	49	
InfoVis	2015	A comparative study between RadViz and Star Coordinates	10.1109/TVCG.2015.2467324	http://dx.doi.org/10.1109/TVCG.2015.2467324	619	628	J	RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.	Manuel Rubio-Sánchez;Laura Raya;Francisco Diaz;Alberto Sánchez 0001	Manuel Rubio-Sánchez;Laura Raya;Francisco Díaz;Alberto Sanchez	URJC;U-tad;UPM;URJC and CCS	10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1997.663916;10.1109/TVCG.2013.182;10.1109/TVCG.2014.2346258;10.1109/TVCG.2008.173	RadViz, Star coordinates, Exploratory data analysis, Cluster analysis, Classification, Outlier detection	22	33	27	45	
InfoVis	2015	TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients	10.1109/TVCG.2015.2467325	http://dx.doi.org/10.1109/TVCG.2015.2467325	409	418	J	We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan.	Mona Hosseinkhani Loorak;Charles Perin;Noreen Kamal;Michael Hill;Sheelagh Carpendale	Mona Hosseinkhani Loorak;Charles Perin;Noreen Kamal;Michael Hill;Sheelagh Carpendale	Department of Computer Science, University of Calgary;Department of Computer Science, University of Calgary;Department of Clinical Neurosciences, University of Calgary;Department of Clinical Neurosciences, University of Calgary;Department of Computer Science, University of Calgary	10.1109/INFVIS.2005.1532136;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/TVCG.2013.200;10.1109/TVCG.2014.2346279;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2009.187;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70515	Multi-dimensional data, Temporal event sequences, Electronic health records	11	24	21	37	
SciVis	2015	JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure	10.1109/TVCG.2015.2467331	http://dx.doi.org/10.1109/TVCG.2015.2467331	1025	1034	J	Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.	Matthias Labschutz;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger;Peter Rautek	Matthias Labschütz;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger;Peter Rautek	KAUST;University of Bergen;TU Wien and VrVis Research Center;KAUST;KAUST	10.1109/TVCG.2012.240	Data Transformation and Representation, GPUs and Multi-core Architectures, Volume Rendering	6	10	10	30	
SciVis	2015	In Situ Eddy Analysis in a High-Resolution Ocean Climate Model	10.1109/TVCG.2015.2467411	http://dx.doi.org/10.1109/TVCG.2015.2467411	857	866	J	An eddy is a feature associated with a rotating body of fluid, surrounded by a ring of shearing fluid. In the ocean, eddies are 10 to 150 km in diameter, are spawned by boundary currents and baroclinic instabilities, may live for hundreds of days, and travel for hundreds of kilometers. Eddies are important in climate studies because they transport heat, salt, and nutrients through the world's oceans and are vessels of biological productivity. The study of eddies in global ocean-climate models requires large-scale, high-resolution simulations. This poses a problem for feasible (timely) eddy analysis, as ocean simulations generate massive amounts of data, causing a bottleneck for traditional analysis workflows. To enable eddy studies, we have developed an in situ workflow for the quantitative and qualitative analysis of MPAS-Ocean, a high-resolution ocean climate model, in collaboration with the ocean model research and development process. Planned eddy analysis at high spatial and temporal resolutions will not be possible with a postprocessing workflow due to various constraints, such as storage size and I/O time, but the in situ workflow enables it and scales well to ten-thousand processing elements.	Jonathan Woodring;Mark Petersen;Andre Schmeißer;John Patchett;James P. Ahrens;Hans Hagen	Jonathan Woodring;Mark Petersen;Andre Schmeiβer;John Patchett;James Ahrens;Hans Hagen	Los Alamos National Laboratory, USA;Los Alamos National Laboratory, USA;Computer Graphics and HCI Group, Germany;Los Alamos National Laboratory, USA;Los Alamos National Laboratory, USA;Computer Graphics and HCI Group, Germany	10.1109/TVCG.2008.143;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2010.215;10.1109/TVCG.2011.162	In situ analysis, online analysis, mesoscale eddies, ocean modeling, climate modeling, simulation, feature extraction,feature analysis, high performance computing, supercomputing, software engineering, collaborative development, revision control	12	28	27	54	
SciVis	2015	Adaptive Multilinear Tensor Product Wavelets	10.1109/TVCG.2015.2467412	http://dx.doi.org/10.1109/TVCG.2015.2467412	985	994	J	Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells.	Kenneth Weiss;Peter Lindstrom	Kenneth Weiss;Peter Lindstrom	Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory	10.1109/TVCG.2010.145;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2002.1183810;10.1109/TVCG.2011.252;10.1109/VISUAL.1996.568127;10.1109/TVCG.2009.186	Multilinear interpolation, adaptive wavelets, multiresolution models, octrees, continuous reconstruction	1	3	3	51	
SciVis	2015	Planar Visualization of Treelike Structures	10.1109/TVCG.2015.2467413	http://dx.doi.org/10.1109/TVCG.2015.2467413	906	915	J	We present a novel method to create planar visualizations of treelike structures (e.g., blood vessels and airway trees) where the shape of the object is well preserved, allowing for easy recognition by users familiar with the structures. Based on the extracted skeleton within the treelike object, a radial planar embedding is first obtained such that there are no self-intersections of the skeleton which would have resulted in occlusions in the final view. An optimization procedure which adjusts the angular positions of the skeleton nodes is then used to reconstruct the shape as closely as possible to the original, according to a specified view plane, which thus preserves the global geometric context of the object. Using this shape recovered embedded skeleton, the object surface is then flattened to the plane without occlusions using harmonic mapping. The boundary of the mesh is adjusted during the flattening step to account for regions where the mesh is stretched over concavities. This parameterized surface can then be used either as a map for guidance during endoluminal navigation or directly for interrogation and decision making. Depth cues are provided with a grayscale border to aid in shape understanding. Examples are presented using bronchial trees, cranial and lower limb blood vessels, and upper aorta datasets, and the results are evaluated quantitatively and with a user study.	Joseph Marino;Arie E. Kaufman	Joseph Marino;Arie Kaufman	Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University	10.1109/TVCG.2011.235;10.1109/VISUAL.2001.964540;10.1109/TVCG.2011.192;10.1109/TVCG.2014.2346406;10.1109/VISUAL.2001.964538;10.1109/VISUAL.2004.75;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2011.182;10.1109/TVCG.2006.172	Geometry-based techniques, view-dependent visualization, medical visualization, planar embedding	6	11	7	41	
SciVis	2015	Association Analysis for Visual Exploration of Multivariate Scientific Data Sets	10.1109/TVCG.2015.2467431	http://dx.doi.org/10.1109/TVCG.2015.2467431	955	964	J	The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data's multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets.	Xiaotong Liu;Han-Wei Shen	Xiaotong Liu;Han-Wei Shen	The Ohio State University;The Ohio State University	10.1109/TVCG.2013.133;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.116;10.1109/TVCG.2007.70615;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.165;10.1109/VAST.2012.6400488;10.1109/TVCG.2011.178;10.1109/VAST.2007.4389000	Multivariate data, association analysis, visual exploration, multiple views	16	24	22	34	
SciVis	2015	Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials	10.1109/TVCG.2015.2467432	http://dx.doi.org/10.1109/TVCG.2015.2467432	916	925	J	Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials.	Attila Gyulassy;Aaron Knoll;Kah Chun Lau;Bei Wang;Peer-Timo Bremer;Michael E. Papka;Larry A. Curtiss;Valerio Pascucci	Attila Gyulassy;Aaron Knoll;Kah Chun Lau;Bei Wang;Peer-Timo Bremer;Michael E. Papka;Larry A. Curtiss;Valerio Pascucci	SCI Institute;SCI Institute;Materials Science Division, Argonne National Laboratory;SCI Institute;Lawrence Livermore National Laboratory;Materials Science Division, Argonne National Laboratory;Materials Science Division, Argonne National Laboratory;SCI Institute	10.1109/VISUAL.2005.1532795;10.1109/TVCG.2011.244;10.1109/TVCG.2014.2346403;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2011.259	materials science, morse-smale, topology, Delaunay, computational geometry	7	18	6	56	
SciVis	2015	Interactive Visualization for Singular Fibers of Functions f : R3 -> R2	10.1109/TVCG.2015.2467433	http://dx.doi.org/10.1109/TVCG.2015.2467433	945	954	J	Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R<sup>3</sup>→R<sup>2</sup>. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians.	Daisuke Sakurai;Osamu Saeki;Hamish A. Carr;Hsiang-Yun Wu;Takahiro Yamamoto;David J. Duke;Shigeo Takahashi	Daisuke Sakurai;Osamu Saeki;Hamish Carr;Hsiang-Yun Wu;Takahiro Yamamoto;David Duke;Shigeo Takahashi	University of Tokyo, Kashiwa, Japan;Kyushu University, Fukuoka, Japan;University of Leeds, Leeds, UK;Keio University, Yokohama, Japan;Kyushu Sangyo University, Fukuoka, Japan;University of Leeds, Leeds, UK;University of Aizu, Aizu-Wakamatsu, Japan	10.1109/TVCG.2008.119;10.1109/VISUAL.1997.663875;10.1109/TVCG.2012.287;10.1109/TVCG.2010.213;10.1109/TVCG.2014.2346447;10.1109/TVCG.2010.146;10.1109/VISUAL.2002.1183774;10.1109/TVCG.2008.143;10.1109/TVCG.2009.119;10.1109/TVCG.2007.70601	Singular fibers, fiber topology, mathematical visualization, design study	1	1	1	36	
SciVis	2015	AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics	10.1109/TVCG.2015.2467434	http://dx.doi.org/10.1109/TVCG.2015.2467434	747	756	J	In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included.	Jan Byska;Mathieu Le Muzic;M. Eduard Gröller;Ivan Viola;Barbora Kozlíková	Jan Byška;Mathieu Le Muzic;M. Eduard Gröller;Ivan Viola;Barbora Kozlíková	Masaryk University, Czech Republic;TU Wien, Austria;TU Wien, Austria;TU Wien, Austria;Masaryk University, Czech Republic	10.1109/VISUAL.2002.1183754;10.1109/TVCG.2009.136;10.1109/TVCG.2011.259;10.1109/VISUAL.2001.964540	Protein, tunnel, molecular dynamics, aggregation, interaction	6	0	10	25	
SciVis	2015	Glyph-Based Comparative Visualization for Diffusion Tensor Fields	10.1109/TVCG.2015.2467435	http://dx.doi.org/10.1109/TVCG.2015.2467435	797	806	J	Diffusion Tensor Imaging (DTI) is a magnetic resonance imaging modality that enables the in-vivo reconstruction and visualization of fibrous structures. To inspect the local and individual diffusion tensors, glyph-based visualizations are commonly used since they are able to effectively convey full aspects of the diffusion tensor. For several applications it is necessary to compare tensor fields, e.g., to study the effects of acquisition parameters, or to investigate the influence of pathologies on white matter structures. This comparison is commonly done by extracting scalar information out of the tensor fields and then comparing these scalar fields, which leads to a loss of information. If the glyph representation is kept, simple juxtaposition or superposition can be used. However, neither facilitates the identification and interpretation of the differences between the tensor fields. Inspired by the checkerboard style visualization and the superquadric tensor glyph, we design a new glyph to locally visualize differences between two diffusion tensors by combining juxtaposition and explicit encoding. Because tensor scale, anisotropy type, and orientation are related to anatomical information relevant for DTI applications, we focus on visualizing tensor differences in these three aspects. As demonstrated in a user study, our new glyph design allows users to efficiently and effectively identify the tensor differences. We also apply our new glyphs to investigate the differences between DTI datasets of the human brain in two different contexts using different b-values, and to compare datasets from a healthy and HIV-infected subject.	Changgong Zhang;Thomas Schultz 0001;Kai Lawonn;Elmar Eisemann;Anna Vilanova	Changgong Zhang;Thomas Schultz;Kai Lawonn;Elmar Eisemann;Anna Vilanova	Computer Graphics and Visualization Group at Delft University of Technology;Visualization and Medical Image Analysis Group at University of Bonn;Visualization Group at University of Magdeburg;Computer Graphics and Visualization Group at Delft University of Technology;Computer Graphics and Visualization Group at Delft University of Technology	10.1109/TVCG.2015.2467031;10.1109/TVCG.2006.134;10.1109/TVCG.2010.134;10.1109/VISUAL.1998.745294;10.1109/VAST.2014.7042491;10.1109/TVCG.2010.199	Glyph Design, Comparative Visualization, Diffusion Tensor Field	15	20	19	43	
SciVis	2015	Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis	10.1109/TVCG.2015.2467436	http://dx.doi.org/10.1109/TVCG.2015.2467436	837	846	J	Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.	Soumya Dutta;Han-Wei Shen	Soumya Dutta;Han-Wei Shen	GRAVITY group;GRAVITY group	10.1109/TVCG.2007.70599;10.1109/VISUAL.1993.398877;10.1109/VISUAL.2004.107;10.1109/TVCG.2011.246;10.1109/TVCG.2007.70615;10.1109/VISUAL.2003.1250374;10.1109/TVCG.2013.152;10.1109/TVCG.2014.2346423;10.1109/TVCG.2007.70579;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1998.745288;10.1109/TVCG.2008.163;10.1109/TVCG.2008.140	Gaussian mixture model (GMM), Incremental learning, Feature extraction and tracking, Time-varying data analysis	12	16	15	45	
SciVis	2015	NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects	10.1109/TVCG.2015.2467441	http://dx.doi.org/10.1109/TVCG.2015.2467441	738	746	J	In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.	Ali K. Al-Awami;Johanna Beyer;Daniel Haehn;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger	Ali K. Ai-Awami;Johanna Beyer;Daniel Haehn;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger	King Abdullah University of Science and Technology (KAUST);School of Engineering and Applied Sciences;School of Engineering and Applied Sciences;School of Medicine;Center for Brain Science;School of Engineering and Applied Sciences;King Abdullah University of Science and Technology (KAUST)	10.1109/TVCG.2014.2346312;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.142;10.1109/TVCG.2009.121;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2013.174;10.1109/TVCG.2014.2346249;10.1109/TVCG.2007.70584	Neuroscience, Segmentation, Proofreading, Data and Provenance Tracking	10	18	15	40	
SciVis	2015	Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis	10.1109/TVCG.2015.2467449	http://dx.doi.org/10.1109/TVCG.2015.2467449	867	876	J	Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets.	Gordon L. Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John H. Reppy	Gordon Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John Reppy	Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago	10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2014.2346322;10.1109/TVCG.2012.240;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1999.809896;10.1109/TVCG.2007.70534;10.1109/TVCG.2014.2346318;10.1109/VISUAL.1998.745290;10.1109/TVCG.2008.148;10.1109/TVCG.2008.163	Domain specific language, portable parallel programming, scientific visualization, tensor fields	6	15	14	53	
InfoVis	2015	HOLA: Human-like Orthogonal Network Layout	10.1109/TVCG.2015.2467451	http://dx.doi.org/10.1109/TVCG.2015.2467451	349	358	J	Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new “human-centred” methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand.	Steve Kieffer;Tim Dwyer;Kim Marriott;Michael Wybrow	Steve Kieffer;Tim Dwyer;Kim Marriott;Michael Wybrow	Monash University and NICTA Victoria;Monash University;Monash University and NICTA Victoria;Monash University	10.1109/TVCG.2006.120;10.1109/TVCG.2012.208;10.1109/TVCG.2013.151;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/TVCG.2008.141;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/TVCG.2008.155	Graph layout, orthogonal layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics	22	31	27	36	BP
InfoVis	2015	Speculative Practices: Utilizing InfoVis to Explore Untapped Literary Collections	10.1109/TVCG.2015.2467452	http://dx.doi.org/10.1109/TVCG.2015.2467452	429	438	J	In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While InfoVis has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an InfoVis perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to InfoVis, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes.	Uta Hinrichs;Stefania Forlini;Bridget Moynihan	Uta Hinrichs;Stefania Forlini;Bridget Moynihan	SACHI Group, University of St Andrews, UK;Department of English, University of Calgary;Department of English, University of Calgary	10.1109/TVCG.2012.272;10.1109/TVCG.2014.2346431;10.1109/TVCG.2008.175;10.1109/TVCG.2008.127;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.171;10.1109/TVCG.2008.172;10.1109/VAST.2008.4677370	Digital Humanities, Interlinked Visualization, Literary Studies, Cultural Collections, Science Fiction	7	15	13	54	
InfoVis	2015	A Linguistic Approach to Categorical Color Assignment for Data Visualization	10.1109/TVCG.2015.2467471	http://dx.doi.org/10.1109/TVCG.2015.2467471	698	707	J	When data categories have strong color associations, it is useful to use these semantically meaningful concept-color associations in data visualizations. In this paper, we explore how linguistic information about the terms defining the data can be used to generate semantically meaningful colors. To do this effectively, we need first to establish that a term has a strong semantic color association, then discover which color or colors express it. Using co-occurrence measures of color name frequencies from Google n-grams, we define a measure for colorability that describes how strongly associated a given term is to any of a set of basic color terms. We then show how this colorability score can be used with additional semantic analysis to rank and retrieve a representative color from Google Images. Alternatively, we use symbolic relationships defined by WordNet to select identity colors for categories such as countries or brands. To create visually distinct color palettes, we use k-means clustering to create visually distinct sets, iteratively reassigning terms with multiple basic color associations as needed. This can be additionally constrained to use colors only in a predefined palette.	Vidya Setlur;Maureen C. Stone	Vidya Setlur;Maureen C. Stone	Tableau Research;Tableau Research		linguistics, natural language processing, semantics, color names, categorical color, Google n-grams, WordNet, XKCD	16	23	19	45	
VAST	2015	TimeLineCurator: Interactive Authoring of Visual Timelines from Unstructured Text	10.1109/TVCG.2015.2467531	http://dx.doi.org/10.1109/TVCG.2015.2467531	300	309	J	We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment.	Johanna Fulda;Matthew Brehmer;Tamara Munzner	Johanna Fulda;Matthew Brehmel;Tamara Munzner	University of Munich (LMU);University of British Columbia;University of British Columbia	10.1109/VAST.2014.7042493;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346431;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400557;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/TVCG.2013.214;10.1109/TVCG.2012.224;10.1109/TVCG.2014.2346291;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.212;10.1109/VAST.2012.6400530;10.1109/TVCG.2007.70577	System, timelines, authoring environment, time-oriented data, journalism	14	27	22	76	
VAST	2015	Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes	10.1109/TVCG.2015.2467551	http://dx.doi.org/10.1109/TVCG.2015.2467551	31	40	J	While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.	Eric D. Ragan;Alex Endert;Jibonananda Sanyal;Jian Chen	Eric D. Ragan;Alex Endert;Jibonananda Sanyal;Jian Chen	Texas A&M University;Georgia Tech;Oak Ridge National Laboratory;University of Maryland, Baltimore County	10.1109/INFVIS.2005.1532136;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.155;10.1109/VISUAL.1993.398857;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346575;10.1109/VAST.2010.5652932;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/TVCG.2013.126;10.1109/VAST.2009.5333020;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.271;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677366;10.1109/TVCG.2013.130;10.1109/TVCG.2010.181;10.1109/TVCG.2010.179;10.1109/VISUAL.1990.146375	Provenance, Analytic provenance, Visual analytics, Framework, Visualization, Conceptual model	34	69	52	97	
VAST	2015	The Data Context Map: Fusing Data and Attributes into a Unified Display	10.1109/TVCG.2015.2467552	http://dx.doi.org/10.1109/TVCG.2015.2467552	121	130	J	Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs.	Shenghui Cheng;Klaus Mueller	Shenghui Cheng;Klaus Mueller	Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University and SUNY, Korea;Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University and SUNY, Korea	10.1109/TVCG.2013.146;10.1109/VAST.2009.5332629;10.1109/VISUAL.1997.663916;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.220;10.1109/INFVIS.1997.636793;10.1109/TVCG.2010.207	High Dimensional Data, Low-Dimensional Embedding, Visual Analytics, Decision Make, Tradeoffs	14	28	28	37	
VAST	2015	Temporal MDS Plots for Analysis of Multivariate Data	10.1109/TVCG.2015.2467553	http://dx.doi.org/10.1109/TVCG.2015.2467553	141	150	J	Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.	Dominik Jäckle;Fabian Fischer 0001;Tobias Schreck;Daniel A. Keim	Dominik Jäckle;Fabian Fischer;Tobias Schreck;Daniel A. Keim	University of Konstanz, Germany;University of Konstanz, Germany;Graz University of Technology, Austria;University of Konstanz, Germany	10.1109/VAST.2009.5332593;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1990.146386;10.1109/TVCG.2007.70592;10.1109/VAST.2009.5332628	Multivariate Data, Time Series, Data Reduction, Multidimensional Scaling	22	32	26	41	
VAST	2015	An Uncertainty-Aware Approach for Exploratory Microblog Retrieval	10.1109/TVCG.2015.2467554	http://dx.doi.org/10.1109/TVCG.2015.2467554	250	259	J	Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data.	Mengchen Liu;Shixia Liu;Xizhou Zhu;Qinying Liao;Furu Wei;Shimei Pan	Mengchen Liu;Shixia Liu;Xizhou Zhu;Qinying Liao;Furu Wei;Shimei Pan	Tsinghua University;Tsinghua University;USTC;Microsoft;Microsoft;University of Maryland, Baltimore County	10.1109/TVCG.2013.186;10.1109/TVCG.2012.291;10.1109/VAST.2009.5332611;10.1109/TVCG.2013.223;10.1109/TVCG.2011.233;10.1109/VAST.2014.7042494;10.1109/VISUAL.1996.568116;10.1109/INFVIS.2005.1532150;10.1109/VAST.2010.5652931;10.1109/TVCG.2011.197;10.1109/TVCG.2014.2346919;10.1109/TVCG.2013.232;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346920;10.1109/TVCG.2010.183;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346922	microblog data, mutual reinforcement model, uncertainty modeling, uncertainty visualization, uncertainty propagation	11	0	18	55	
VAST	2015	VisOHC: Designing Visual Analytics for Online Health Communities	10.1109/TVCG.2015.2467555	http://dx.doi.org/10.1109/TVCG.2015.2467555	71	80	J	Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.	Bum Chul Kwon;Sung-Hee Kim;Sukwon Lee;Jaegul Choo;Jina Huh;Ji Soo Yi	Bum Chul Kwon;Sung-Hee Kim;Sukwon Lee;Jaegul Choo;Jina Huh;Ji Soo Yi	University of Konstanz;University of British Columbia;Purdue University;Korea University;Michigan State University;Purdue University	10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102441;10.1109/TVCG.2014.2346292;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2010.175;10.1109/VAST.2014.7042494;10.1109/TVCG.2014.2346331;10.1109/VAST.2009.5333919;10.1109/TVCG.2012.213;10.1109/TVCG.2009.171;10.1109/TVCG.2009.187;10.1109/TVCG.2013.221;10.1109/VAST.2012.6400554;10.1109/VAST.2014.7042496;10.1109/TVCG.2008.171	Online health communities, visual analytics, conversation analysis, thread visualization, healthcare, design study	19	22	15	44	
VAST	2015	The Role of Uncertainty, Awareness, and Trust in Visual Analytics	10.1109/TVCG.2015.2467591	http://dx.doi.org/10.1109/TVCG.2015.2467591	240	249	J	Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.	Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim	Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim	Data Analysis and Visualisation Group;Data Analysis and Visualisation Group;Data Analysis and Visualisation Group;Data Analysis and Visualisation Group;Data Analysis and Visualisation Group	10.1109/TVCG.2014.2346575;10.1109/VISUAL.2000.885679;10.1109/VAST.2008.4677385;10.1109/VAST.2009.5332611;10.1109/TVCG.2012.260;10.1109/VAST.2011.6102473;10.1109/VAST.2009.5333020;10.1109/VAST.2011.6102435;10.1109/TVCG.2012.279;10.1109/TVCG.2014.2346481;10.1109/VAST.2006.261416	Visual Analytics, Knowledge Generation, Uncertainty Measures and Propagation, Trust Building, Human Factors	36	68	50	83	
VAST	2015	Visually Exploring Transportation Schedules	10.1109/TVCG.2015.2467592	http://dx.doi.org/10.1109/TVCG.2015.2467592	170	179	J	Public transportation schedules are designed by agencies to optimize service quality under multiple constraints. However, real service usually deviates from the plan. Therefore, transportation analysts need to identify, compare and explain both eventual and systemic performance issues that must be addressed so that better timetables can be created. The purely statistical tools commonly used by analysts pose many difficulties due to the large number of attributes at tripand station-level for planned and real service. Also challenging is the need for models at multiple scales to search for patterns at different times and stations, since analysts do not know exactly where or when relevant patterns might emerge and need to compute statistical summaries for multiple attributes at different granularities. To aid in this analysis, we worked in close collaboration with a transportation expert to design TR-EX, a visual exploration tool developed to identify, inspect and compare spatio-temporal patterns for planned and real transportation service. TR-EX combines two new visual encodings inspired by Marey's Train Schedule: Trips Explorer for trip-level analysis of frequency, deviation and speed; and Stops Explorer for station-level study of delay, wait time, reliability and performance deficiencies such as bunching. To tackle overplotting and to provide a robust representation for a large numbers of trips and stops at multiple scales, the system supports variable kernel bandwidths to achieve the level of detail required by users for different tasks. We justify our design decisions based on specific analysis needs of transportation analysts. We provide anecdotal evidence of the efficacy of TR-EX through a series of case studies that explore NYC subway service, which illustrate how TR-EX can be used to confirm hypotheses and derive new insights through visual exploration.	Cesar Palomo;Zhan Guo;Cláudio T. Silva;Juliana Freire	Cesar Palomo;Zhan Guo;Cláudio T. Silva;Juliana Freire	New York University;New York University;New York University;New York University	10.1109/INFVIS.2004.68;10.1109/TVCG.2014.2346449;10.1109/TVCG.2007.70535;10.1109/TVCG.2011.176;10.1109/TVCG.2013.226;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.137;10.1109/TVCG.2009.131;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2011.179;10.1109/TVCG.2006.170;10.1109/INFVIS.2003.1249005	Transportation, schedules, kernel density estimation, visual exploration	10	13	14	44	
VAST	2015	SensePath: Understanding the Sensemaking Process Through Analytic Provenance	10.1109/TVCG.2015.2467611	http://dx.doi.org/10.1109/TVCG.2015.2467611	41	50	J	Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process.	Phong H. Nguyen;Kai Xu 0003;Ashley Wheat;B. L. William Wong;Simon Attfield;Bob Fields	Phong H. Nguyen;Kai Xu;Ashley Wheat;B.L. William Wong;Simon Attfield;Bob Fields	Middlesex University;Middlesex University;Middlesex University;Middlesex University;Middlesex University;Middlesex University	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346575;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333020;10.1109/TVCG.2013.132	Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization	11	18	13	42	
VAST	2015	Visual Analytics for Development and Evaluation of Order Selection Criteria for Autoregressive Processes	10.1109/TVCG.2015.2467612	http://dx.doi.org/10.1109/TVCG.2015.2467612	151	159	J	Order selection of autoregressive processes is an active research topic in time series analysis, and the development and evaluation of automatic order selection criteria remains a challenging task for domain experts. We propose a visual analytics approach, to guide the analysis and development of such criteria. A flexible synthetic model generator-combined with specialized responsive visualizations-allows comprehensive interactive evaluation. Our fast framework allows feedback-driven development and fine-tuning of new order selection criteria in real-time. We demonstrate the applicability of our approach in three use-cases for two general as well as a real-world example.	Thomas Löwe;Emmy-Charlotte Förster;Georgia Albuquerque;Jens-Peter Kreiss;Marcus A. Magnor	Thomas Löwe;Emmy-Charlotte Förster;Georgia Albuquerque;Jens-Peter Kreiss;Marcus Magnor	Computer Graphics Lab, Germany;Computer Graphics Lab, Germany;Computer Graphics Lab, Germany;Institut für Mathematische Stochastik, Germany;Computer Graphics Lab, Germany	10.1109/TVCG.2013.222	Visual analytics, time series analysis, order selection	4	5	5	44	
VAST	2015	A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights	10.1109/TVCG.2015.2467613	http://dx.doi.org/10.1109/TVCG.2015.2467613	51	60	J	We present results from an experiment aimed at using logs of interactions with a visual analytics application to better understand how interactions lead to insight generation. We performed an insight-based user study of a visual analytics application and ran post hoc quantitative analyses of participants' measured insight metrics and interaction logs. The quantitative analyses identified features of interaction that were correlated with insight characteristics, and we confirmed these findings using a qualitative analysis of video captured during the user study. Results of the experiment include design guidelines for the visual analytics application aimed at supporting insight generation. Furthermore, we demonstrated an analysis method using interaction logs that identified which interaction patterns led to insights, going beyond insight-based evaluations that only quantify insight characteristics. We also discuss choices and pitfalls encountered when applying this analysis method, such as the benefits and costs of applying an abstraction framework to application-specific actions before further analysis. Our method can be applied to evaluations of other visualization tools to inform the design of insight-promoting interactions and to better understand analyst behaviors.	Hua Guo;Steven R. Gomez;Caroline Ziemkiewicz;David H. Laidlaw	Hua Guo;Steven R. Gomez;Caroline Ziemkiewicz;David H. Laidlaw	Brown University;Brown University;Aptima Inc.;Brown University	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2014.2346575;10.1109/VAST.2014.7042482;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346452;10.1109/TVCG.2012.221;10.1109/TVCG.2007.70515	Evaluation, visual analytics, interaction, intelligence analysis, insight-based evaluation	19	31	21	34	HM
VAST	2015	InterAxis: Steering Scatterplot Axes via Observation-Level Interaction	10.1109/TVCG.2015.2467615	http://dx.doi.org/10.1109/TVCG.2015.2467615	131	140	J	Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios.	Hannah Kim;Jaegul Choo;Haesun Park;Alex Endert	Hannah Kim;Jaegul Choo;Haesun Park;Alex Endert	Georgia Institute of Technology;Korea University;Georgia Institute of Technology;Georgia Institute of Technology	10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.212;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.201;10.1109/TVCG.2008.153;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.157;10.1109/TVCG.2014.2346250;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.178;10.1109/TVCG.2013.167	Scatterplots, user interaction, model steering	27	44	35	50	
VAST	2015	Task-Driven Comparison of Topic Models	10.1109/TVCG.2015.2467618	http://dx.doi.org/10.1109/TVCG.2015.2467618	320	329	J	Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.	Eric C. Alexander;Michael Gleicher	Eric Alexander;Michael Gleicher	University of Wisconsin-Madison;University of Wisconsin-Madison	10.1109/TVCG.2011.232;10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/TVCG.2011.239;10.1109/TVCG.2012.260;10.1109/INFVIS.2000.885098;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.221	Text visualization, topic modeling	12	25	19	36	
VAST	2015	Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data	10.1109/TVCG.2015.2467619	http://dx.doi.org/10.1109/TVCG.2015.2467619	270	279	J	Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.	Siming Chen;Xiaoru Yuan;Zhenhuang Wang;Cong Guo;Jie Liang 0004;Zuchao Wang;Xiaolong Zhang 0001;Jiawan Zhang	Siming Chen;Xiaoru Yuan;Zhenhuang Wang;Cong Guo;Jie Liang;Zuchao Wang;Xiaolong Luke Zhang;Jiawan Zhang	Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;College of Information Sciences and Technology, Pennsylvania State University;School of Computer Science and Technology, and School of Computer Software, Tianjin University	10.1109/VAST.2009.5332584;10.1109/VAST.2008.4677356;10.1109/TVCG.2009.182;10.1109/TVCG.2011.185;10.1109/TVCG.2012.291;10.1109/TVCG.2009.143;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346746;10.1109/TVCG.2014.2346922	Spatial temporal visual analytics, Geo-tagged social media, Sparsely sampling, Uncertainty, Movement	33	53	52	47	
VAST	2015	Interactive Visual Profiling of Musicians	10.1109/TVCG.2015.2467620	http://dx.doi.org/10.1109/TVCG.2015.2467620	200	209	J	Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians' attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology.	Stefan Jänicke;Josef Focht;Gerik Scheuermann	Stefan Jänicke;Josef Focht;Gerik Scheuermann	Image and Signal Processing Group, Germany;Museum of Musical Instruments, Germany;Image and Signal Processing Group, Germany	10.1109/VAST.2011.6102454;10.1109/TVCG.2010.159;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/VAST.2009.5333443;10.1109/TVCG.2014.2346433;10.1109/TVCG.2008.175;10.1109/TVCG.2012.252;10.1109/VAST.2012.6400485;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2009.111;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333023;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333248;10.1109/VAST.2008.4677370;10.1109/VAST.2010.5652520	visual analytics, profiling system, musicians database visualization, digital humanities, musicology	5	10	10	54	
VAST	2015	CiteRivers: Visual Analytics of Citation Patterns	10.1109/TVCG.2015.2467621	http://dx.doi.org/10.1109/TVCG.2015.2467621	190	199	J	The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.	Florian Heimerl;Qi Han;Steffen Koch;Thomas Ertl	Florian Heimerl;Qi Han;Steffen Koch;Thomas Ertl	Institute for Visualization and Interactive Systems (VIS);Institute for Visualization and Interactive Systems (VIS);Institute for Visualization and Interactive Systems (VIS);Institute for Visualization and Interactive Systems (VIS)	10.1109/INFVIS.2004.77;10.1109/TVCG.2015.2467757;10.1109/TVCG.2008.166;10.1109/TVCG.2013.212;10.1109/VAST.2009.5333443;10.1109/TVCG.2011.239;10.1109/TVCG.2012.252;10.1109/TVCG.2013.162;10.1109/TVCG.2012.277;10.1109/INFVIS.2004.45;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2009.162;10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1995.528686;10.1109/TVCG.2014.2346920;10.1109/TVCG.2009.202	scientific literature, visual document analysis, visual citation analysis, streamgraph, clustering	21	38	34	53	
VAST	2015	Supporting Iterative Cohort Construction with Visual Temporal Queries	10.1109/TVCG.2015.2467622	http://dx.doi.org/10.1109/TVCG.2015.2467622	91	100	J	Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.	Josua Krause;Adam Perer;Harry Stavropoulos	Josua Krause;Adam Perer;Harry Stavropoulos	NYU;IBM T.J. Watson Research Center;IBM T.J. Watson Research Center	10.1109/TVCG.2011.185;10.1109/VAST.2007.4389013;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/VAST.2010.5652890;10.1109/TVCG.2014.2346482;10.1109/TVCG.2013.200;10.1109/TVCG.2013.206;10.1109/TVCG.2009.117;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.225;10.1109/TVCG.2013.167	Visual temporal queries, cohort definition, electronic medical records, information visualization	24	43	31	44	
InfoVis	2015	Beyond Weber's Law: A Second Look at Ranking Visualizations of Correlation	10.1109/TVCG.2015.2467671	http://dx.doi.org/10.1109/TVCG.2015.2467671	469	478	J	Models of human perception - including perceptual “laws” - can be valuable tools for deriving visualization design recommendations. However, it is important to assess the explanatory power of such models when using them to inform design. We present a secondary analysis of data previously used to rank the effectiveness of bivariate visualizations for assessing correlation (measured with Pearson's r) according to the well-known Weber-Fechner Law. Beginning with the model of Harrison et al. [1], we present a sequence of refinements including incorporation of individual differences, log transformation, censored regression, and adoption of Bayesian statistics. Our model incorporates all observations dropped from the original analysis, including data near ceilings caused by the data collection process and entire visualizations dropped due to large numbers of observations worse than chance. This model deviates from Weber's Law, but provides improved predictive accuracy and generalization. Using Bayesian credibility intervals, we derive a partial ranking that groups visualizations with similar performance, and we give precise estimates of the difference in performance between these groups. We find that compared to other visualizations, scatterplots are unique in combining low variance between individuals and high precision on both positively- and negatively correlated data. We conclude with a discussion of the value of data sharing and replication, and share implications for modeling similar experimental data.	Matthew Kay;Jeffrey Heer	Matthew Kay;Jeffrey Heer	University of Washington;University of Washington	10.1109/TVCG.2014.2346979	Weber's law, perception of correlation, log transformation, censored regression, Bayesian methods	25	39	32	21	HM
InfoVis	2015	AmbiguityVis: Visualization of Ambiguity in Graph Layouts	10.1109/TVCG.2015.2467691	http://dx.doi.org/10.1109/TVCG.2015.2467691	359	368	J	Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews.	Yong Wang 0021;Qiaomu Shen;Daniel Archambault;Zhiguang Zhou;Min Zhu;Sixiao Yang;Huamin Qu	Yong Wang;Qiaomu Shen;Daniel Archambault;Zhiguang Zhou;Min Zhu;Sixiao Yang;Huamin Qu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Swansea University;Zhejiang University of Finance and Economics;Sichuan University;Huawei Co. Ltd.;Hong Kong University of Science and Technology	10.1109/TVCG.2006.120;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.155;10.1109/TVCG.2012.189	Visual Ambiguity, Visualization, Node-link diagram, Graph layout, Graph visualization	10	19	20	56	
InfoVis	2015	Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions	10.1109/TVCG.2015.2467717	http://dx.doi.org/10.1109/TVCG.2015.2467717	629	638	J	We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.	Julian Stahnke;Marian Dörk;Boris Müller;Andreas Thom	Julian Stahnke;Marian Dörk;Boris Müller;Andreas Thom	Potsdam University of Applied Sciences;Potsdam University of Applied Sciences;Potsdam University of Applied Sciences;Potsdam University of Applied Sciences	10.1109/TVCG.2013.157;10.1109/TVCG.2011.255;10.1109/VAST.2010.5652392;10.1109/VISUAL.1990.146402;10.1109/TVCG.2009.153;10.1109/TVCG.2012.279;10.1109/TVCG.2014.2346419;10.1109/TVCG.2013.153;10.1109/TVCG.2009.127;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/INFVIS.2004.60;10.1109/INFVIS.1995.528686	Information visualization, interactivity, dimensionality reduction, multidimensional scaling	30	50	32	31	
InfoVis	2015	Beyond Memorability: Visualization Recognition and Recall	10.1109/TVCG.2015.2467732	http://dx.doi.org/10.1109/TVCG.2015.2467732	519	528	J	In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable “at-a-glance” are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.	Michelle Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva	Michelle A. Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva	University of British Columbia;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT);School of Engineering & Applied Sciences, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT);School of Engineering & Applied Sciences, Harvard University;University of Michigan;School of Engineering & Applied Sciences, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT)	10.1109/TVCG.2012.197;10.1109/TVCG.2013.234;10.1109/TVCG.2011.193;10.1109/TVCG.2012.233;10.1109/TVCG.2011.175;10.1109/TVCG.2013.234;10.1109/TVCG.2012.215;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.245;10.1109/TVCG.2012.221	Information visualization, memorability, recognition, recall, eye-tracking study	34	66	45	48	
VAST	2015	PhenoBlocks: Phenotype Comparison Visualizations	10.1109/TVCG.2015.2467733	http://dx.doi.org/10.1109/TVCG.2015.2467733	101	110	J	The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting.	Michael Glueck;Peter Hamilton;Fanny Chevalier;Simon Breslav;Azam Khan;Daniel J. Wigdor;Michael Brudno	Michael Glueck;Peter Hamilton;Fanny Chevalier;Simon Breslav;Azam Khan;Daniel Wigdor;Michael Brudno	Autodesk Research;University of Toronto;INRIA;Autodesk Research;Autodesk Research;University of Toronto;University of Toronto	10.1109/VAST.2011.6102439;10.1109/TVCG.2013.214;10.1109/TVCG.2013.231;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2009.167;10.1109/TVCG.2009.116;10.1109/INFVIS.2000.885091;10.1109/TVCG.2007.70529;10.1109/INFVIS.2003.1249030;10.1109/TVCG.2012.226	Clinical diagnosis, differential hierarchy comparison, ontology, genomics, phenomics, phenotype	9	13	9	60	
InfoVis	2015	TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data	10.1109/TVCG.2015.2467751	http://dx.doi.org/10.1109/TVCG.2015.2467751	549	558	J	Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques.	James S. Walker;Rita Borgo;Mark W. Jones	James Walker;Rita Borgo;Mark W. Jones	Swansea University;Swansea University;Swansea University	10.1109/TVCG.2009.181;10.1109/TVCG.2014.2346428;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.160;10.1109/TVCG.2010.162;10.1109/TVCG.2010.193;10.1109/INFVIS.1999.801860;10.1109/TVCG.2011.195	Time-series Exploration, Focus+Context, Lens, Interaction Techniques	13	21	18	38	
InfoVis	2015	Visual Encodings of Temporal Uncertainty: A Comparative User Study	10.1109/TVCG.2015.2467752	http://dx.doi.org/10.1109/TVCG.2015.2467752	539	548	J	A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation - using a lighter color value to represent uncertain regions - or error bars for judging durations and temporal bounds, and gradient plots - using fading color or transparency - for judging probability values.	Theresia Gschwandtner;Markus Bögl;Paolo Federico 0001;Silvia Miksch	Theresia Gschwandtnei;Markus Bögl;Paolo Federico;Silvia Miksch	Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology	10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.279;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.114	Uncertainty, temporal intervals, visualization	15	26	21	27	
InfoVis	2015	Visually Comparing Weather Features in Forecasts	10.1109/TVCG.2015.2467754	http://dx.doi.org/10.1109/TVCG.2015.2467754	389	398	J	Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data.	P. Samuel Quinan;Miriah D. Meyer	P. Samuel Quinan;Miriah Meyer	University of Utah;University of Utah	10.1109/VISUAL.1990.146361;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2011.209;10.1109/TVCG.2010.181;10.1109/TVCG.2012.213;10.1109/TVCG.2013.143	Design study, weather, geographic/geospatial visualization, ensemble data	14	24	24	38	
VAST	2015	Visual Analysis and Dissemination of Scientific Literature Collections with SurVis	10.1109/TVCG.2015.2467757	http://dx.doi.org/10.1109/TVCG.2015.2467757	180	189	J	Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.	Fabian Beck 0001;Sebastian Koch;Daniel Weiskopf	Fabian Beck;Sebastian Koch;Daniel Weiskopf	VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany	10.1109/TVCG.2011.169;10.1109/TVCG.2012.252;10.1109/TVCG.2015.2467621;10.1109/VAST.2009.5333564;10.1109/TVCG.2010.194;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.167	Visual analytics of documents, bibliographic data, dissemination, literature browser	19	34	33	37	
InfoVis	2015	Improving Bayesian Reasoning: The Effects of Phrasing, Visualization, and Spatial Ability	10.1109/TVCG.2015.2467758	http://dx.doi.org/10.1109/TVCG.2015.2467758	529	538	J	Decades of research have repeatedly shown that people perform poorly at estimating and understanding conditional probabilities that are inherent in Bayesian reasoning problems. Yet in the medical domain, both physicians and patients make daily, life-critical judgments based on conditional probability. Although there have been a number of attempts to develop more effective ways to facilitate Bayesian reasoning, reports of these findings tend to be inconsistent and sometimes even contradictory. For instance, the reported accuracies for individuals being able to correctly estimate conditional probability range from 6% to 62%. In this work, we show that problem representation can significantly affect accuracies. By controlling the amount of information presented to the user, we demonstrate how text and visualization designs can increase overall accuracies to as high as 77%. Additionally, we found that for users with high spatial ability, our designs can further improve their accuracies to as high as 100%. By and large, our findings provide explanations for the inconsistent reports on accuracy in Bayesian reasoning tasks and show a significant improvement over existing methods. We believe that these findings can have immediate impact on risk communication in health-related fields.	Alvitta Ottley;Evan M. Peck;Lane Harrison;Daniel Afergan;Caroline Ziemkiewicz;Holly A. Taylor;Paul K. J. Han;Remco Chang	Alvitta Ottley;Evan M. Peck;Lane T. Harrison;Daniel Afergan;Caroline Ziemkiewicz;Holly A. Taylor;Paul K. J. Han;Remco Chang	Tufts University;Bucknell University;Tufts University;Tufts University;Tufts University and Aptima Inc.;Tufts University;Maine Medical Center and Tufts Medical School;Tufts University	10.1109/TVCG.2014.2346575;10.1109/VAST.2010.5653587;10.1109/TVCG.2011.255;10.1109/TVCG.2013.119;10.1109/TVCG.2012.199;10.1109/TVCG.2010.179;10.1109/VISUAL.2005.1532836	Bayesian Reasoning, Visualization, Spatial Ability, Individual Differences	13	29	22	47	
InfoVis	2015	Guidelines for Effective Usage of Text Highlighting Techniques	10.1109/TVCG.2015.2467759	http://dx.doi.org/10.1109/TVCG.2015.2467759	489	498	J	Semi-automatic text analysis involves manual inspection of text. Often, different text annotations (like part-of-speech or named entities) are indicated by using distinctive text highlighting techniques. In typesetting there exist well-known formatting conventions, such as bold typeface, italics, or background coloring, that are useful for highlighting certain parts of a given text. Also, many advanced techniques for visualization and highlighting of text exist; yet, standard typesetting is common, and the effects of standard typesetting on the perception of text are not fully understood. As such, we surveyed and tested the effectiveness of common text highlighting techniques, both individually and in combination, to discover how to maximize pop-out effects while minimizing visual interference between techniques. To validate our findings, we conducted a series of crowd-sourced experiments to determine: i) a ranking of nine commonly-used text highlighting techniques; ii) the degree of visual interference between pairs of text highlighting techniques; iii) the effectiveness of techniques for visual conjunctive search. Our results show that increasing font size works best as a single highlighting technique, and that there are significant visual interferences between some pairs of highlighting techniques. We discuss the pros and cons of different combinations as a design guideline to choose text highlighting techniques for text viewers.	Hendrik Strobelt;Daniela Oelke;Bum Chul Kwon;Tobias Schreck;Hanspeter Pfister	Hendrik Strobelt;Daniela Oelke;Bum Chul Kwon;Tobias Schreck;Hanspeter Pfister	Harvard University;Siemens AG;University of Konstanz;TU Graz;Harvard University	10.1109/TVCG.2012.277;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.183;10.1109/TVCG.2009.139;10.1109/VAST.2011.6102453;10.1109/INFVIS.1995.528686	Text highlighting techniques, visual document analytics, text annotation, crowdsourced study	14	21	13	34	
VAST	2015	TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data	10.1109/TVCG.2015.2467771	http://dx.doi.org/10.1109/TVCG.2015.2467771	160	169	J	We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis.	Xiaoke Huang;Ye Zhao;Chao Ma;Jing Yang;Xinyue Ye;Chong Zhang	Xiaoke Huang;Ye Zhao;Chao Ma;Jing Yang;Xinyue Ye;Chong Zhang	Department of Computer Science, Kent State University;Department of Computer Science, Kent State University;Department of Computer Science, Kent State University;Department of Computer Science, University of North Carolina at Charlotte;Department of Geography, Kent State University;Department of Computer Science, University of North Carolina at Charlotte	10.1109/VAST.2009.5332593;10.1109/TVCG.2013.226;10.1109/TVCG.2009.145;10.1109/VAST.2011.6102455;10.1109/TVCG.2006.122;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2014.2346746	Graph based visual analytics, Centrality, Taxi trajectories, Urban network, Transportation assessment	33	63	65	39	
InfoVis	2015	Poemage: Visualizing the Sonic Topology of a Poem	10.1109/TVCG.2015.2467811	http://dx.doi.org/10.1109/TVCG.2015.2467811	439	448	J	The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies.	Nina McCurdy;Julie Lein;Katherine Coles;Miriah D. Meyer	Nina McCurdy;Julie Lein;Katharine Coles;Miriah Meyer	University of Utah School of Computing;University of Utah Department of English;University of Utah Department of English;University of Utah School of Computing	10.1109/TVCG.2011.186;10.1109/TVCG.2009.122;10.1109/VAST.2009.5333443;10.1109/TVCG.2008.135;10.1109/TVCG.2011.233;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2009.171;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2008.172;10.1109/INFVIS.1995.528686	Visualization in the humanities, design studies, text and document data, graph/network data	12	21	17	58	
VAST	2015	BiSet: Semantic Edge Bundling with Biclusters for Sensemaking	10.1109/TVCG.2015.2467813	http://dx.doi.org/10.1109/TVCG.2015.2467813	310	319	J	Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, “in-between”, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.	Maoyuan Sun;Peng Mi;Chris North;Naren Ramakrishnan	Maoyuan Sun;Peng Mi;Chris North;Naren Ramakrishnan	Department of Computer Science, Discovery Analytics Center;Department of Computer Science, Discovery Analytics Center;Department of Computer Science, Discovery Analytics Center;Department of Computer Science, Discovery Analytics Center	10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2008.135;10.1109/TVCG.2012.252;10.1109/TVCG.2012.260;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346260;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.147;10.1109/TVCG.2011.233;10.1109/VAST.2009.5333878;10.1109/TVCG.2011.250;10.1109/TVCG.2010.138;10.1109/TVCG.2014.2346752;10.1109/TVCG.2010.210;10.1109/TVCG.2011.183;10.1109/TVCG.2014.2346665	Bicluster, coordinated relationship, semantic edge bundling	16	24	23	58	
InfoVis	2015	Visual Mementos: Reflecting Memories with Personal Data	10.1109/TVCG.2015.2467831	http://dx.doi.org/10.1109/TVCG.2015.2467831	369	378	J	In this paper we discuss the creation of visual mementos as a new application area for visualization. We define visual mementos as visualizations of personally relevant data for the purpose of reminiscing, and sharing of life experiences. Today more people collect digital information about their life than ever before. The shift from physical to digital archives poses new challenges and opportunities for self-reflection and self-representation. Drawing on research on autobiographical memory and on the role of artifacts in reminiscing, we identified design challenges for visual mementos: mapping data to evoke familiarity, expressing subjectivity, and obscuring sensitive details for sharing. Visual mementos can make use of the known strengths of visualization in revealing patterns to show the familiar instead of the unexpected, and extend representational mappings beyond the objective to include the more subjective. To understand whether people's subjective views on their past can be reflected in a visual representation, we developed, deployed and studied a technology probe that exemplifies our concept of visual mementos. Our results show how reminiscing has been supported and reveal promising new directions for self-reflection and sharing through visual mementos of personal experiences.	Alice Thudt;Dominikus Baur;Samuel Huron;Sheelagh Carpendale	Alice Thudt;Dominikus Baur;Samuel Huron;Sheelagh Carpendale	University of Calgary;An Independent Researcher;University of Calgary;University of Calgary	10.1109/TVCG.2010.206;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/INFVIS.2004.8	Visual Memento, Memories, Personal Visualization, Movement Data, World Wide Web	15	21	17	69	
InfoVis	2015	Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data	10.1109/TVCG.2015.2467851	http://dx.doi.org/10.1109/TVCG.2015.2467851	559	568	J	We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.	Benjamin Bach;Conglei Shi;Nicolas Heulot;Tara M. Madhyastha;Thomas J. Grabowski;Pierre Dragicevic	Benjamin Bach;Conglei Shi;Nicolas Heulot;Tara Madhyastha;Tom Grabowski;Pierre Dragicevic	Microsoft Research-Inria Joint Centre;IBM T.J, Watson Research Center, Yorktown Height, NY;IRT SystemX;Department of Radiology, University of Washington;Department of Radiology and Neurology, University of Washington;Inria	10.1109/TVCG.2011.186;10.1109/TVCG.2007.70535;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346325;10.1109/TVCG.2013.192;10.1109/INFVIS.2002.1173155	Temporal data visualization, information visualization, multidimensional scaling	36	58	52	49	
VAST	2015	VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications	10.1109/TVCG.2015.2467871	http://dx.doi.org/10.1109/TVCG.2015.2467871	61	70	J	Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.	Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl	Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl	Institute for Visualization and Interactive Systems (VIS), Germany;Institute for Visualization and Interactive Systems (VIS), Germany;Visualization Research Center, Germany;Institute for Visualization and Interactive Systems (VIS), Germany;Institute for Visualization and Interactive Systems (VIS), Germany	10.1109/TVCG.2012.276;10.1109/TVCG.2013.124;10.1109/VAST.2008.4677361;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346677;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.273;10.1109/VISUAL.2005.1532837	visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data	24	36	29	53	HM
InfoVis	2015	Orientation-Enhanced Parallel Coordinate Plots	10.1109/TVCG.2015.2467872	http://dx.doi.org/10.1109/TVCG.2015.2467872	589	598	J	Parallel Coordinate Plots (PCPs) is one of the most powerful techniques for the visualization of multivariate data. However, for large datasets, the representation suffers from clutter due to overplotting. In this case, discerning the underlying data information and selecting specific interesting patterns can become difficult. We propose a new and simple technique to improve the display of PCPs by emphasizing the underlying data structure. Our Orientation-enhanced Parallel Coordinate Plots (OPCPs) improve pattern and outlier discernibility by visually enhancing parts of each PCP polyline with respect to its slope. This enhancement also allows us to introduce a novel and efficient selection method, the Orientation-enhanced Brushing (O-Brushing). Our solution is particularly useful when multiple patterns are present or when the view on certain patterns is obstructed by noise. We present the results of our approach with several synthetic and real-world datasets. Finally, we conducted a user evaluation, which verifies the advantages of the OPCPs in terms of discernibility of information in complex data. It also confirms that O-Brushing eases the selection of data patterns in PCPs and reduces the amount of necessary user interactions compared to state-of-the-art brushing techniques.	Renata G. Raidou;Martin Eisemann;Marcel Breeuwer;Elmar Eisemann;Anna Vilanova	Renata Georgia Raidou;Martin Eisemann;Marcel Breeuwer;Elmar Eisemann;Anna Vilanova	Eindhoven University of Technology;Delft University of Technology;Eindhoven University of Technology;Delft University of Technology;Delft University of Technology	10.1109/INFVIS.1998.729559;10.1109/INFVIS.2004.68;10.1109/TVCG.2006.138;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1999.809866;10.1109/TVCG.2011.166;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.15;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.179	Parallel Coordinates, Orientation-enhanced Parallel Coordinates, Brushing, Orientation-enhanced Brushing, Data Readability, Data Selection	7	9	10	45	
InfoVis	2015	Vials: Visualizing Alternative Splicing of Genes	10.1109/TVCG.2015.2467911	http://dx.doi.org/10.1109/TVCG.2015.2467911	399	408	J	Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets.	Hendrik Strobelt;Bilal Alsallakh;Joseph Botros;Brant Peterson;Mark Borowsky;Hanspeter Pfister;Alexander Lex	Hendrik Strobelt;Bilal Alsallakh;Joseph Botros;Brant Peterson;Mark Borowsky;Hanspeter Pfister;Alexander Lex	Harvard University;Vienna University of Technology;Harvard University;Institute of BioMedical Research;Institute of BioMedical Research;Harvard University;Harvard University	10.1109/TVCG.2013.214;10.1109/TVCG.2013.223;10.1109/TVCG.2014.2346248	Biology visualization, protein isoforms, mRNA-seq, directed acyclic graphs, multivariate networks	7	11	12	30	
VAST	2015	The Visual Causality Analyst: An Interactive Interface for Causal Reasoning	10.1109/TVCG.2015.2467931	http://dx.doi.org/10.1109/TVCG.2015.2467931	230	239	J	Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.	Jun Wang;Klaus Mueller	Jun Wang;Klaus Mueller	Computer Science Department, Visual Analytics and Imaging Lab, Stony Brook, NY;Computer Science Department, Visual Analytics and Imaging Lab, Stony Brook, NY	10.1109/INFVIS.2003.1249025;10.1109/TVCG.2007.70528;10.1109/TVCG.2012.225;10.1109/VAST.2007.4388999	Visual knowledge discovery, Causality, Hypothesis testing, Visual evidence, High-dimensional data	8	21	18	31	
InfoVis	2015	A Psychophysical Investigation of Size as a Physical Variable	10.1109/TVCG.2015.2467951	http://dx.doi.org/10.1109/TVCG.2015.2467951	479	488	J	Physical visualizations, or data physicalizations, encode data in attributes of physical shapes. Despite a considerable body of work on visual variables, “physical variables” remain poorly understood. One of them is physical size. A difficulty for solid elements is that “size” is ambiguous - it can refer to either length/diameter, surface, or volume. Thus, it is unclear for designers of physicalizations how to effectively encode quantities in physical size. To investigate, we ran an experiment where participants estimated ratios between quantities represented by solid bars and spheres. Our results suggest that solid bars are compared based on their length, consistent with previous findings for 2D and 3D bars on flat media. But for spheres, participants' estimates are rather proportional to their surface. Depending on the estimation method used, judgments are rather consistent across participants, thus the use of perceptually-optimized size scales seems possible. We conclude by discussing implications for the design of data physicalizations and the need for more empirical studies on physical variables.	Yvonne Jansen;Kasper Hornbæk	Yvonne Jansen;Kasper Hornbæk	University of Copenhagen;University of Copenhagen	10.1109/TVCG.2012.251;10.1109/TVCG.2013.234;10.1109/TVCG.2012.220;10.1109/TVCG.2013.134;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/TVCG.2014.2346320	Data physicalization, physical visualization, psychophysics, experiment, physical variable	9	12	7	65	
SciVis	2015	Visualization and Analysis of Rotating Stall for Transonic Jet Engine Simulation	10.1109/TVCG.2015.2467952	http://dx.doi.org/10.1109/TVCG.2015.2467952	847	856	J	Identification of early signs of rotating stall is essential for the study of turbine engine stability. With recent advancements of high performance computing, high-resolution unsteady flow fields allow in depth exploration of rotating stall and its possible causes. Performing stall analysis, however, involves significant effort to process large amounts of simulation data, especially when investigating abnormalities across many time steps. In order to assist scientists during the exploration process, we present a visual analytics framework to identify suspected spatiotemporal regions through a comparative visualization so that scientists are able to focus on relevant data in more detail. To achieve this, we propose efficient stall analysis algorithms derived from domain knowledge and convey the analysis results through juxtaposed interactive plots. Using our integrated visualization system, scientists can visually investigate the detected regions for potential stall initiation and further explore these regions to enhance the understanding of this phenomenon. Positive feedback from scientists demonstrate the efficacy of our system in analyzing rotating stall.	Chun-Ming Chen;Soumya Dutta;Xiaotong Liu;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen	Chun-Ming Chen;Soumya Dutta;Xiaotong Liu;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen	The Department of Computer Science and Engineering, The Ohio State University;The Department of Computer Science and Engineering, The Ohio State University;The Department of Computer Science and Engineering, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University;The Department of Computer Science and Engineering, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University	10.1109/VISUAL.1991.175794;10.1109/TVCG.2007.70599;10.1109/VISUAL.2000.885739;10.1109/TVCG.2013.122;10.1109/TVCG.2013.189;10.1109/VISUAL.2004.128;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2014.2346265	Turbine flow visualization, vortex extraction, anomaly detection, juxtaposition, brushing and linking, time series	2	6	6	49	
VAST	2015	VEEVVIE: Visual Explorer for Empirical Visualization, VR and Interaction Experiments	10.1109/TVCG.2015.2467954	http://dx.doi.org/10.1109/TVCG.2015.2467954	111	120	J	Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls.	Charilaos Papadopoulos;Ievgeniia Gutenko;Arie E. Kaufman	C. Papadopoulos;I. Gutenko;A. E. Kaufman	Dept. of Computer Science, Stony Brook University, Stony Brook, NY;Dept. of Computer Science, Stony Brook University, Stony Brook, NY;Dept. of Computer Science, Stony Brook University, Stony Brook, NY	10.1109/TVCG.2012.276;10.1109/TVCG.2012.251;10.1109/TVCG.2014.2346591;10.1109/TVCG.2010.157;10.1109/TVCG.2014.2346311;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12	Visual Analytics, Evaluation, User Studies, Ontology, Experiments, Interaction, Virtual Reality, Visualization	5	6	3	32	
SciVis	2015	Isosurface Visualization of Data with Nonparametric Models for Uncertainty	10.1109/TVCG.2015.2467958	http://dx.doi.org/10.1109/TVCG.2015.2467958	777	786	J	The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields.	Tushar M. Athawale;Elham Sakhaee;Alireza Entezari	Tushar Athawale;Elham Sakhaee;Alireza Entezari	Department of Computer and Information Science and Engineering, University of Florida;Department of Computer and Information Science and Engineering, University of Florida;Department of Computer and Information Science and Engineering, University of Florida	10.1109/TVCG.2013.208;10.1109/VISUAL.2002.1183769;10.1109/TVCG.2013.152;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/TVCG.2013.143	Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes, nonparametric statistics	13	27	24	44	
SciVis	2015	Occlusion-free Blood Flow Animation with Wall Thickness Visualization	10.1109/TVCG.2015.2467961	http://dx.doi.org/10.1109/TVCG.2015.2467961	728	737	J	We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool.	Kai Lawonn;Sylvia Saalfeld;Anna Vilanova;Bernhard Preim;Tobias Isenberg 0001	Kai Lawonn;Sylvia Glaßer;Anna Vilanova;Bernhard Preim;Tobias Isenberg	University of Magdeburg, Germany;University of Magdeburg, Germany;TU Delft, Netherlands;University of Magdeburg, Germany;Inria, France	10.1109/TVCG.2009.138;10.1109/TVCG.2011.243;10.1109/TVCG.2014.2346406;10.1109/TVCG.2010.153;10.1109/TVCG.2011.215;10.1109/VISUAL.2004.48	Medical visualization, aneurysms, blood flow, wall thickness, illustrative visualization	15	17	16	43	
SciVis	2015	Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces	10.1109/TVCG.2015.2467962	http://dx.doi.org/10.1109/TVCG.2015.2467962	926	934	J	Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudo-contour lines induced by banded color scales convey the same benefits.	Thomas Butkiewicz;Andrew H. Stevens	Thomas Butkiewicz;Andrew H. Stevens	The Center for Coastal and Ocean Mapping;The Center for Coastal and Ocean Mapping		Structured textures, terrain, deformation, dynamic surfaces	0	1	0	21	
SciVis	2015	Anisotropic Ambient Volume Shading	10.1109/TVCG.2015.2467963	http://dx.doi.org/10.1109/TVCG.2015.2467963	1015	1024	J	We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading.	Marco Ament;Carsten Dachsbacher	Marco Ament;Carsten Dachsbacher	Karlsruhe Institute of Technology, Germany;Karlsruhe Institute of Technology, Germany	10.1109/TVCG.2014.2346333;10.1109/TVCG.2013.129;10.1109/TVCG.2014.2346411;10.1109/TVCG.2012.232;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2011.161;10.1109/VISUAL.2005.1532772;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2002.1183771;10.1109/TVCG.2011.198;10.1109/VISUAL.2004.5;10.1109/TVCG.2012.267;10.1109/VISUAL.1996.567777	Direct volume rendering, volume illumination, anisotropic shading	5	7	7	52	
VAST	2015	VAiRoma: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History	10.1109/TVCG.2015.2467971	http://dx.doi.org/10.1109/TVCG.2015.2467971	210	219	J	Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents.	Isaac Cho;Wenwen Dou;Xiaoyu Wang;Eric Sauda;William Ribarsky	Isaac Cho;Wewnen Dou;Derek Xiaoyu Wang;Eric Sauda;William Ribarsky	UNC Charlotte;UNC Charlotte	10.1109/VAST.2014.7042493;10.1109/VAST.2007.4389012;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/TVCG.2008.178;10.1109/VAST.2010.5652885;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.179;10.1109/TVCG.2014.2346481;10.1109/INFVIS.2000.885091	Visual Analytics, Text Analytics, Wikipedia	15	26	19	40	
VAST	2015	Exploring Evolving Media Discourse Through Event Cueing	10.1109/TVCG.2015.2467991	http://dx.doi.org/10.1109/TVCG.2015.2467991	220	229	J	Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa.	Yafeng Lu;Michael Steptoe;Sarah Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas C. Montgomery;Steven R. Corman;Ross Maciejewski	Yafeng Lu;Michael Steptoe;Sarah Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas Montgomery;Steven R. Corman;Ross Maciejewski	Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University	10.1109/TVCG.2013.222;10.1109/VAST.2011.6102488;10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/VAST.2008.4677364;10.1109/TVCG.2014.2346682;10.1109/VAST.2014.7042484;10.1109/TVCG.2011.179;10.1109/VAST.2014.7042494;10.1109/VAST.2012.6400491;10.1109/VAST.2009.5333919;10.1109/INFVIS.1999.801851;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346913	Media Analysis, Time Series Analysis, Event Detection	12	15	16	43	
InfoVis	2015	A Simple Approach for Boundary Improvement of Euler Diagrams	10.1109/TVCG.2015.2467992	http://dx.doi.org/10.1109/TVCG.2015.2467992	678	687	J	General methods for drawing Euler diagrams tend to generate irregular polygons. Yet, empirical evidence indicates that smoother contours make these diagrams easier to read. In this paper, we present a simple method to smooth the boundaries of any Euler diagram drawing. When refining the diagram, the method must ensure that set elements remain inside their appropriate boundaries and that no region is removed or created in the diagram. Our approach uses a force system that improves the diagram while at the same time ensuring its topological structure does not change. We demonstrate the effectiveness of the approach through case studies and quantitative evaluations.	Paolo Simonetto;Daniel Archambault;Carlos Scheidegger	Paolo Simonetto;Daniel Archambault;Carlos Scheidegger	University of Arizona;University of Arizona;University of Arizona	10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210	Euler diagrams, Boundary Improvement, Force-Directed Approaches	9	10	7	35	
VAST	2015	LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design	10.1109/TVCG.2015.2468011	http://dx.doi.org/10.1109/TVCG.2015.2468011	290	299	J	State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty.	Johannes Sorger;Thomas Ortner;Christian Luksch;Michael Schwärzler;M. Eduard Gröller;Harald Piringer	Johannes Sorger;Thomas Ortner;Christian Luksch;Michael Schwärzler;Eduard Gröller;Harald Piringer	VRVis Research Center;VRVis Research Center;VRVis Research Center;VRVis Research Center;TU Wien;VRVis Research Center	10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.185;10.1109/TVCG.2010.190;10.1109/TVCG.2013.147;10.1109/INFVIS.2003.1249032;10.1109/TVCG.2013.173;10.1109/TVCG.2009.110;10.1109/TVCG.2014.2346321	Integrating Spatial and Non-Spatial Data Visualization, Visualization in Physical Sciences and Engineering, Coordinated and Multiple Views, Visual Knowledge Discovery	8	15	11	34	
SciVis	2015	Mining Graphs for Understanding Time-Varying Volumetric Data	10.1109/TVCG.2015.2468031	http://dx.doi.org/10.1109/TVCG.2015.2468031	965	974	J	A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.	Yi Gu;Chaoli Wang;Tom Peterka;Robert Jacob;Seung Hyun Kim	Yi Gu;Chaoli Wang;Tom Peterka;Robert Jacob;Seung Hyun Kim	Department Computer Science and Engineering, University of Notre Dame, Notre Dame, IN;Department Computer Science and Engineering, University of Notre Dame, Notre Dame, IN;Division of Mathematics and Computer Science, Argonne National Laboratory, Argonne, IL;Division of Mathematics and Computer Science, Argonne National Laboratory, Argonne, IL;Department of Mechanical and Aerospace Engineering, The Ohio State University, Columbus, OH	10.1109/TVCG.2009.122;10.1109/TVCG.2013.151;10.1109/TVCG.2011.246;10.1109/TVCG.2008.116;10.1109/VISUAL.1999.809871;10.1109/TVCG.2006.165;10.1109/TVCG.2009.165;10.1109/TVCG.2006.159	Time-varying data visualization, graph simplification, community detection, visual recommendation	6	9	9	28	
VAST	2015	Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration	10.1109/TVCG.2015.2468078	http://dx.doi.org/10.1109/TVCG.2015.2468078	1	10	J	We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.	Stef van den Elzen;Danny Holten;Jorik Blaas;Jarke J. van Wijk	Stef van den Elzen;Danny Holten;Jorik Blaas;Jarke J. van Wijk	Eindhoven University of Technology;SynerScope B. V.;SynerScope B. V.;Eindhoven University of Technology	10.1109/TVCG.2011.226;10.1109/INFVIS.2004.18;10.1109/TVCG.2013.198;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2008.125;10.1109/TVCG.2011.178;10.1109/INFVIS.1999.801851	Dynamic Networks, Exploration, Dimensionality Reduction	33	65	52	63	BP
SciVis	2015	Gaze Stripes: Image-Based Visualization of Eye Tracking Data	10.1109/TVCG.2015.2468091	http://dx.doi.org/10.1109/TVCG.2015.2468091	1005	1014	J	We present a new visualization approach for displaying eye tracking data from multiple participants. We aim to show the spatio-temporal data of the gaze points in the context of the underlying image or video stimulus without occlusion. Our technique, denoted as gaze stripes, does not require the explicit definition of areas of interest but directly uses the image data around the gaze points, similar to thumbnails for images. A gaze stripe consists of a sequence of such gaze point images, oriented along a horizontal timeline. By displaying multiple aligned gaze stripes, it is possible to analyze and compare the viewing behavior of the participants over time. Since the analysis is carried out directly on the image data, expensive post-processing or manual annotation are not required. Therefore, not only patterns and outliers in the participants' scanpaths can be detected, but the context of the stimulus is available as well. Furthermore, our approach is especially well suited for dynamic stimuli due to the non-aggregated temporal mapping. Complementary views, i.e., markers, notes, screenshots, histograms, and results from automatic clustering, can be added to the visualization to display analysis results. We illustrate the usefulness of our technique on static and dynamic stimuli. Furthermore, we discuss the limitations and scalability of our approach in comparison to established visualization techniques.	Kuno Kurzhals;Marcel Hlawatsch;Florian Heimerl;Michael Burch;Thomas Ertl;Daniel Weiskopf	Kuno Kurzhals;Marcel Hlawatsch;Florian Heimerl;Michael Burch;Thomas Ertl;Daniel Weiskopf	University of Stuttgart;University of Stuttgart;University of Stuttgart;University of Stuttgart;University of Stuttgart;University of Stuttgart	10.1109/TVCG.2011.232;10.1109/TVCG.2012.276;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2013.194;10.1109/TVCG.2008.125	Eye tracking, time-dependent data, spatio-temporal visualization	19	29	16	38	
SciVis	2015	Effective Visualization of Temporal Ensembles	10.1109/TVCG.2015.2468093	http://dx.doi.org/10.1109/TVCG.2015.2468093	787	796	J	An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions.	Lihua Hao;Christopher G. Healey;Steffen A. Bass	Lihua Hao;Christopher G. Healey;Steffen A. Bass	NC State University;NC State University;Duke University	10.1109/TVCG.2014.2346448;10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2014.2346751;10.1109/TVCG.2009.155;10.1109/TVCG.2014.2346455;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143	Ensemble visualization	9	14	13	28	
VAST	2015	MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering	10.1109/TVCG.2015.2468111	http://dx.doi.org/10.1109/TVCG.2015.2468111	11	20	J	Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.	Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia V. Andrienko;Gennady L. Andrienko;Andreas Kerren	Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia Andrienko;Gennady Andrienko;Andreas Kerren	Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Fraunhofer IAIS, Bonn, Germany;Fraunhofer IAIS, Bonn, Germany;Fraunhofer IAIS, Bonn, Germany	10.1109/TVCG.2011.202;10.1109/TVCG.2011.226;10.1109/TVCG.2011.233;10.1109/INFVIS.2004.18;10.1109/TVCG.2009.143;10.1109/TVCG.2014.2346271;10.1109/TVCG.2008.125;10.1109/TVCG.2014.2346441;10.1109/INFVIS.1999.801851;10.1109/VAST.2012.6400553;10.1109/VAST.2009.5333893;10.1109/INFVIS.2005.1532150	Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering	40	68	70	56	
VAST	2015	egoSlider: Visual Analysis of Egocentric Network Evolution	10.1109/TVCG.2015.2468151	http://dx.doi.org/10.1109/TVCG.2015.2468151	260	269	J	Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.	Yanhong Wu;Naveen Pitipornvivat;Jian Zhao 0010;Sixiao Yang;Guowei Huang;Huamin Qu	Yanhong Wu;Naveen Pitipornvivat;Jian Zhao;Sixiao Yang;Guowei Huang;Huamin Qu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Autodesk Research;Huawei Technologies Co. Ltd.;Huawei Technologies Co. Ltd.;Hong Kong University of Science and Technology	10.1109/TVCG.2011.169;10.1109/TVCG.2011.226;10.1109/TVCG.2006.147;10.1109/TVCG.2013.149	Egocentric network, dynamic graph, network visualization, glyph-based design, visual analytics	24	43	34	53	
VAST	2015	3D Regression Heat Map Analysis of Population Study Data	10.1109/TVCG.2015.2468291	http://dx.doi.org/10.1109/TVCG.2015.2468291	81	90	J	Epidemiological studies comprise heterogeneous data about a subject group to define disease-specific risk factors. These data contain information (features) about a subject's lifestyle, medical status as well as medical image data. Statistical regression analysis is used to evaluate these features and to identify feature combinations indicating a disease (the target feature). We propose an analysis approach of epidemiological data sets by incorporating all features in an exhaustive regression-based analysis. This approach combines all independent features w.r.t. a target feature. It provides a visualization that reveals insights into the data by highlighting relationships. The 3D Regression Heat Map, a novel 3D visual encoding, acts as an overview of the whole data set. It shows all combinations of two to three independent features with a specific target disease. Slicing through the 3D Regression Heat Map allows for the detailed analysis of the underlying relationships. Expert knowledge about disease-specific hypotheses can be included into the analysis by adjusting the regression model formulas. Furthermore, the influences of features can be assessed using a difference view comparing different calculation results. We applied our 3D Regression Heat Map method to a hepatic steatosis data set to reproduce results from a data mining-driven analysis. A qualitative analysis was conducted on a breast density data set. We were able to derive new hypotheses about relations between breast density and breast lesions with breast cancer. With the 3D Regression Heat Map, we present a visual overview of epidemiological data that allows for the first time an interactive regression-based analysis of large feature sets with respect to a disease.	Paul Klemm;Kai Lawonn;Sylvia Saalfeld;Uli Niemann;Katrin Hegenscheid;Henry Völzke;Bernhard Preim	Paul Klemm;Kai Lawonn;Sylvia Glaßer;Uli Niemann;Katrin Hegenscheid;Henry Völzke;Bernhard Preim	Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Otto-von-Guericke University Magdeburg, Germany	10.1109/TVCG.2011.229;10.1109/TVCG.2011.185;10.1109/VAST.2009.5333431;10.1109/TVCG.2013.160;10.1109/TVCG.2014.2346591;10.1109/TVCG.2013.161;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321	Interactive Visual Analysis, Regression Analysis, Heat Map, Epidemiology, Breast Cancer, Hepatic Steatosis	7	14	16	43	
VAST	2015	MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data	10.1109/TVCG.2015.2468292	http://dx.doi.org/10.1109/TVCG.2015.2468292	21	30	J	Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.	Sujin Jang;Niklas Elmqvist;Karthik Ramani	Sujin Jang;Niklas Elmqvist;Karthik Ramani	Purdue University, West Lafayette, IN, USA;University of Maryland, College Park, MD, USA;Purdue University, West Lafayette, IN, USA	10.1109/TVCG.2013.178;10.1109/TVCG.2009.181;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.258;10.1109/TVCG.2013.196;10.1109/TVCG.2013.200;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2013.181;10.1109/TVCG.2010.149;10.1109/VISUAL.2002.1183778;10.1109/TVCG.2008.172;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346920	Human motion visualization, interactive clustering, motion tracking data, expert reviews, user study	5	7	7	46	
InfoVis	2015	Spatial Reasoning and Data Displays	10.1109/TVCG.2015.2469125	http://dx.doi.org/10.1109/TVCG.2015.2469125	459	468	J	Graphics convey numerical information very efficiently, but rely on a different set of mental processes than tabular displays. Here, we present a study relating demographic characteristics and visual skills to perception of graphical lineups. We conclude that lineups are essentially a classification test in a visual domain, and that performance on the lineup protocol is associated with general aptitude, rather than specific tasks such as card rotation and spatial manipulation. We also examine the possibility that specific graphical tasks may be associated with certain visual skills and conclude that more research is necessary to understand which visual skills are required in order to understand certain plot types.	Susan VanderPlas;Heike Hofmann	Susan VanderPlas;Heike Hofmann	Post Doc in the Department of Statistics, Iowa State University;Member of the faculty in the Human Computer Interaction program, Statistics at Iowa State University	10.1109/TVCG.2012.230;10.1109/TVCG.2014.2346320;10.1109/TVCG.2010.161	Data visualization, Perception, Statistical graphics, Statistical computing	7	10	8	37	
VAST	2015	Wavelet-based visualization of time-varying data on graphs	10.1109/VAST.2015.7347624	http://dx.doi.org/10.1109/VAST.2015.7347624	1	8	C	Visualizing time-varying data defined on the nodes of a graph is a challenging problem that has been faced with different approaches. Although techniques based on aggregation, topology, and topic modeling have proven their usefulness, the visual analysis of smooth and/or abrupt data variations as well as the evolution of such variations over time are aspects not properly tackled by existing methods. In this work we propose a novel visualization methodology that relies on graph wavelet theory and stacked graph metaphor to enable the visual analysis of time-varying data defined on the nodes of a graph. The proposed method is able to identify regions where data presents abrupt and mild spacial and/or temporal variation while still been able to show how such changes evolve over time, making the identification of events an easier task. The usefulness of our approach is shown through a set of results using synthetic as well as a real data set involving taxi trips in downtown Manhattan. The methodology was able to reveal interesting phenomena and events such as the identification of specific locations with abrupt variation in the number of taxi pickups.	Paola Valdivia;Fabio Dias;Fabiano Petronetto;Cláudio T. Silva;Luis Gustavo Nonato	Paola Valdivia;Fabio Dias;Fabiano Petronetto;Cláudio T. Silva;L. G. Nonato	University of São Paulo, Brazil;University of São Paulo, Brazil;UFES, Brazil;New York University, USA;University of São Paulo, Brazil	10.1109/VAST.2008.4677356;10.1109/TVCG.2014.2346449;10.1109/TVCG.2013.226;10.1109/INFVIS.2000.885098;10.1109/TVCG.2013.228	Time-varying data, graph wavelets, stacked graph visualization	5	11	10	22	
VAST	2015	Mixed-initiative visual analytics using task-driven recommendations	10.1109/VAST.2015.7347625	http://dx.doi.org/10.1109/VAST.2015.7347625	9	16	C	Visual data analysis is composed of a collection of cognitive actions and tasks to decompose, internalize, and recombine data to produce knowledge and insight. Visual analytic tools provide interactive visual interfaces to data to support discovery and sensemaking tasks, including forming hypotheses, asking questions, and evaluating and organizing evidence. Myriad analytic models can be incorporated into visual analytic systems at the cost of increasing complexity in the analytic discourse between user and system. Techniques exist to increase the usability of interacting with analytic models, such as inferring data models from user interactions to steer the underlying models of the system via semantic interaction, shielding users from having to do so explicitly. Such approaches are often also referred to as mixed-initiative systems. Sensemaking researchers have called for development of tools that facilitate analytic sensemaking through a combination of human and automated activities. However, design guidelines do not exist for mixed-initiative visual analytic systems to support iterative sensemaking. In this paper, we present candidate design guidelines and introduce the Active Data Environment (ADE) prototype, a spatial workspace supporting the analytic process via task recommendations invoked by inferences about user interactions within the workspace. ADE recommends data and relationships based on a task model, enabling users to co-reason with the system about their data in a single, spatial workspace. This paper provides an illustrative use case, a technical description of ADE, and a discussion of the strengths and limitations of the approach.	Kristin A. Cook;Nick Cramer;David J. Israel;Michael Wolverton;Joe Bruce;Russ Burtner;Alex Endert	Kristin Cook;Nick Cramer;David Israel;Michael Wolverton;Joe Bruce;Russ Burtner;Alex Endert	Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;SRI International, USA;SRI International, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Georgia Institute of Technology, USA	10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/TVCG.2014.2346573;10.1109/VAST.2014.7042492;10.1109/TVCG.2008.174;10.1109/TVCG.2013.225	mixed-initiative visual analytics, task modeling, recommender systems, sensemaking	8	12	8	36	
VAST	2015	Integrating predictive analytics into a spatiotemporal epidemic simulation	10.1109/VAST.2015.7347626	http://dx.doi.org/10.1109/VAST.2015.7347626	17	24	C	The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.	Chris Bryan;Xue Wu;Susan M. Mniszewski;Kwan-Liu Ma	Chris Bryan;Xue Wu;Susan Mniszewski;Kwan-Liu Ma	VIDi @ U.C. Davis, USA;VIDi @ U.C. Davis, USA;Los Alamos National Lab, USA;VIDi @ U.C. Davis, USA	10.1109/VAST.2011.6102457;10.1109/INFVIS.1998.729563;10.1109/TVCG.2014.2346926;10.1109/TVCG.2013.125;10.1109/TVCG.2010.181;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2012.190	Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems	2	7	4	36	
VAST	2015	Collaborative visual analysis with RCloud	10.1109/VAST.2015.7347627	http://dx.doi.org/10.1109/VAST.2015.7347627	25	32	C	Consider the emerging role of data science teams embedded in larger organizations. Individual analysts work on loosely related problems, and must share their findings with each other and the organization at large, moving results from exploratory data analyses (EDA) into automated visualizations, diagnostics and reports deployed for wider consumption. There are two problems with the current practice. First, there are gaps in this workflow: EDA is performed with one set of tools, and automated reports and deployments with another. Second, these environments often assume a single-developer perspective, while data scientist teams could get much benefit from easier sharing of scripts and data feeds, experiments, annotations, and automated recommendations, which are well beyond what traditional version control systems provide. We contribute and justify the following three requirements for systems built to support current data science teams and users: discoverability, technology transfer, and coexistence. In addition, we contribute the design and implementation of RCloud, a system that supports the requirements of collaborative data analysis, visualization and web deployment. About 100 people used RCloud for two years. We report on interviews with some of these users, and discuss design decisions, tradeoffs and limitations in comparison to other approaches.	Stephen C. North;Carlos Scheidegger;Simon Urbanek;Gordon Woodhull	Stephen North;Carlos Scheidegger;Simon Urbanek;Gordon Woodhull	Infovisible, USA;University of Arizona, USA;AT&T Labs, USA;AT&T Labs, USA	10.1109/TVCG.2011.185;10.1109/VAST.2007.4389011;10.1109/TVCG.2012.219;10.1109/TVCG.2009.195;10.1109/TVCG.2007.70577	visual analytics process, provenance, collaboration, visualization, computer-supported cooperative work	1	2	1	40	
VAST	2015	Four considerations for supporting visual analysis in display ecologies	10.1109/VAST.2015.7347628	http://dx.doi.org/10.1109/VAST.2015.7347628	33	40	C	The current proliferation of large displays and mobile devices presents a number of exciting opportunities for visual analytics and information visualization. The display ecology enables multiple displays to function in concert within a broader technological environment to accomplish visual analysis tasks. Based on a comprehensive survey of multi-display systems from a variety of fields, we propose four key considerations for visual analysis in display ecologies: 1) Display Composition, 2) Information Coordination/Transfer, 3) Information Connection, and 4) Display Membership. Different aspects of display ecologies stemming from these design considerations will enable users to transform and empower multiple displays as a display ecology for visual analysis.	Haeyong Chung;Chris North;Sarang Joshi;Jian Chen	Haeyong Chung;Chris North;Sarang Joshi;Jian Chen	University of Alabama Huntsville, USA;Virginia Tech, USA;Virginia Tech, USA;University of Maryland Baltimore County, USA	10.1109/VAST.2008.4677358		6	7	5	51	
VAST	2015	Supporting activity recognition by visual analytics	10.1109/VAST.2015.7347629	http://dx.doi.org/10.1109/VAST.2015.7347629	41	48	C	Recognizing activities has become increasingly relevant in many application domains, such as security or ambient assisted living. To handle different scenarios, the underlying automated algorithms are configured using multiple input parameters. However, the influence and interplay of these parameters is often not clear, making exhaustive evaluations necessary. On this account, we propose a visual analytics approach to supporting users in understanding the complex relationships among parameters, recognized activities, and associated accuracies. First, representative parameter settings are determined. Then, the respective output is computed and statistically analyzed to assess parameters' influence in general. Finally, visualizing the parameter settings along with the activities provides overview and allows to investigate the computed results in detail. Coordinated interaction helps to explore dependencies, compare different settings, and examine individual activities. By integrating automated, visual, and interactive means users can select parameter values that meet desired quality criteria. We demonstrate the application of our solution in a use case with realistic complexity, involving a study of human protagonists in daily living with respect to hundreds of parameter settings.	Martin Röhlig;Martin Luboschik;Frank Krüger 0001;Thomas Kirste;Heidrun Schumann;Markus Bögl;Bilal Alsallakh;Silvia Miksch	Martin Röhlig;Martin Luboschik;Frank Krüger;Thomas Kirste;Heidrun Schumann;Markus Bögl;Bilal Alsallakh;Silvia Miksch	University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany;Vienna University of Technology, Austria;Vienna University of Technology, Austria;Vienna University of Technology, Austria	10.1109/TVCG.2014.2346454;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2009.187;10.1109/VAST.2009.5332595		5	6	4	23	
VAST	2015	iVizTRANS: Interactive visual learning for home and work place detection from massive public transportation data	10.1109/VAST.2015.7347630	http://dx.doi.org/10.1109/VAST.2015.7347630	49	56	C	Using transport smart card transaction data to understand the homework dynamics of a city for urban planning is emerging as an alternative to traditional surveys which may be conducted every few years are no longer effective and efficient for the rapidly transforming modern cities. As commuters travel patterns are highly diverse, existing rule-based methods are not fully adequate. In this paper, we present iVizTRANS - a tool which combines an interactive visual analytics (VA) component to aid urban planners to analyse complex travel patterns and decipher activity locations for single public transport commuters. It is coupled with a machine learning component that iteratively learns from the planners classifications to train a classifier. The classifier is then applied to the city-wide smart card data to derive the dynamics for all public transport commuters. Our evaluation shows it outperforms the rule-based methods in previous work.	Liang Yu;Wei Wu;Xiaohui Li;Guangxia Li;Wee Siong Ng;See-Kiong Ng;Zhongwen Huang;Anushiya Arunan;Hui Min Watt	Liang Yu;Wei Wu;Xiaohui Li;Guangxia Li;Wee Siong Ng;See-Kiong Ng;Zhongwen Huang;Anushiya Arunan;Hui Min Watt	Institute for Infocomm Research, Singapore;Institute for Infocomm Research, Singapore;Institute for Infocomm Research, Singapore;Institute for Infocomm Research, Singapore;Institute for Infocomm Research, Singapore;Institute for Infocomm Research, Singapore;Urban Redevelopment Authority, Singapore;Urban Redevelopment Authority, Singapore;Urban Redevelopment Authority, Singapore	10.1109/INFVIS.2004.27;10.1109/INFVIS.2002.1173155	Smart card data, origin-destination (OD), spatiotemporal visualization, clustering, machine learning	6	12	0	21	
VAST	2015	DemographicVis: Analyzing demographic information based on user generated content	10.1109/VAST.2015.7347631	http://dx.doi.org/10.1109/VAST.2015.7347631	57	64	C	The wide-spread of social media provides unprecedented sources of written language that can be used to model and infer online demographics. In this paper, we introduce a novel visual text analytics system, DemographicVis, to aid interactive analysis of such demographic information based on user-generated content. Our approach connects categorical data (demographic information) with textual data, allowing users to understand the characteristics of different demographic groups in a transparent and exploratory manner. The modeling and visualization are based on ground truth demographic information collected via a survey conducted on Reddit.com. Detailed user information is taken into our modeling process that connects the demographic groups with features that best describe the distinguishing characteristics of each group. Features including topical and linguistic are generated from the user-generated contents. Such features are then analyzed and ranked based on their ability to predict the users' demographic information. To enable interactive demographic analysis, we introduce a web-based visual interface that presents the relationship of the demographic groups, their topic interests, as well as the predictive power of various features. We present multiple case studies to showcase the utility of our visual analytics approach in exploring and understanding the interests of different demographic groups. We also report results from a comparative evaluation, showing that the DemographicVis is quantitatively superior or competitive and subjectively preferred when compared to a commercial text analysis tool.	Wenwen Dou;Isaac Cho;Omar ElTayeby;Jaegul Choo;Xiaoyu Wang;William Ribarsky	Wenwen Dou;Isaac Cho;Omar ElTayeby;Jaegul Choo;Xiaoyu Wang;William Ribarsky	UNC Charlotte, USA;UNC Charlotte, USA;UNC Charlotte, USA;Korea University, South Korea;Taste Analytics, USA;UNC Charlotte, USA	10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102461;10.1109/TVCG.2014.2346920	Visual Text Analysis, User Interface, Social Media, Demographic Analysis	4	10	7	24	
VAST	2015	EgoNetCloud: Event-based egocentric dynamic network visualization	10.1109/VAST.2015.7347632	http://dx.doi.org/10.1109/VAST.2015.7347632	65	72	C	Event-based egocentric dynamic networks are an important class of networks widely seen in many domains. In this paper, we present a visual analytics approach for these networks by combining data-driven network simplifications with a novel visualization design - EgoNetCloud. In particular, an integrated data processing pipeline is proposed to prune, compress and filter the networks into smaller but salient abstractions. To accommodate the simplified network into the visual design, we introduce a constrained graph layout algorithm on the dynamic network. Through a real-life case study as well as conversations with the domain expert, we demonstrate the effectiveness of the EgoNetCloud design and system in completing analysis tasks on event-based dynamic networks. The user study comparing EgoNetCloud with a working system on academic search confirms the effectiveness and convenience of our visual analytics based approach.	Qingsong Liu;Yifan Hu;Lei Shi;Xinzhu Mu;Yutao Zhang;Jie Tang 0001	Qingsong Liu;Yifan Hu;Lei Shi;Xinzhu Mu;Yutao Zhang;Jie Tang	SKLCS, Institute of Software, Chinese Academy of Sciences, China;Yahoo Labs, New York, USA;SKLCS, Institute of Software, Chinese Academy of Sciences, China;Academy of Art and Design, Tsinghua University, China;Department of Computer Science and Technology, Tsinghua University, China;Department of Computer Science and Technology, Tsinghua University, China	10.1109/TVCG.2010.159;10.1109/TVCG.2011.226;10.1109/TVCG.2011.213		6	13	1	31	
VAST	2015	FPSSeer: Visual analysis of game frame rate data	10.1109/VAST.2015.7347633	http://dx.doi.org/10.1109/VAST.2015.7347633	73	80	C	The rate at which frames are rendered in a computer game directly influences both game playability and enjoyability. Players frequently have to deal with the trade-off between high frame rates and good resolution. Analyzing patterns in frame rate data and their correlation with the overall game performance is important in designing games (e.g., graphic card/display setting suggestion and game performance measurement). However, this task is challenging because game frame rates vary both temporally and spatially. In addition, players may adjust their display settings based on their gaming experience and hardware conditions, which further contributes to the unpredictability of frame rates. In this paper, we present a comprehensive visual analytics system FPSSeer, to help game designers gain insight into frame rate data. Our system consists of four major views: 1) a frame rate view to show the overall distribution in a geographic scale, 2) a grid view to show the frame rate distribution and grid element clusters based on their similarity, 3) a FootRiver view to reveal the temporal patterns in game condition changes and potential spatiotemporal correlations, and 4) a comparison view to evaluate game performance discrepancy under different game tests. The real-world case studies demonstrate the effectiveness of our system. The system has been applied to an online commercial game to monitor its performance and to provide feedbacks to designers and developers.	Quan Li;Peng Xu;Huamin Qu	Quan Li;Peng Xu;Huamin Qu	NetEase Games, NetEase, Inc., Hong Kong University of Science and Technology, China;NetEase Games, NetEase, Inc., China;Hong Kong University of Science and Technology, China	10.1109/TVCG.2008.166;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346445;10.1109/INFVIS.2001.963273	frame rate data, game performance evaluation, visual analytics	2	2	0	24	
VAST	2015	Comparative visual analysis of vector field ensembles	10.1109/VAST.2015.7347634	http://dx.doi.org/10.1109/VAST.2015.7347634	81	88	C	We present a new visual analysis approach to support the comparative exploration of 2D vector-valued ensemble fields. Our approach enables the user to quickly identify the most similar groups of ensemble members, as well as the locations where the variation among the members is high. We further provide means to visualize the main features of the potentially multimodal directional distributions at user-selected locations. For this purpose, directional data is modelled using mixtures of probability density functions (pdfs), which allows us to characterize and classify complex distributions with relatively few parameters. The resulting mixture models are used to determine the degree of similarity between ensemble members, and to construct glyphs showing the direction, spread, and strength of the principal modes of the directional distributions. We also propose several similarity measures, based on which we compute pairwise member similarities in the spatial domain and form clusters of similar members. The hierarchical clustering is shown using dendrograms and similarity matrices, which can be used to select particular members and visualize their variations. A user interface providing multiple linked views enables the simultaneous visualization of aggregated global and detailed local variations, as well as the selection of members for a detailed comparison.	Mihaela Jarema;Ismail Demir;Johannes Kehrer;Rüdiger Westermann	Mihaela Jarema;Ismail Demir;Johannes Kehrer;Rüdiger Westermann	Technische Universität München, Germany;Technische Universität München, Germany;Technische Universität München, Germany;Technische Universität München, Germany	10.1109/TVCG.2014.2346626;10.1109/TVCG.2010.190;10.1109/VAST.2009.5332611;10.1109/TVCG.2006.160;10.1109/TVCG.2013.141;10.1109/TVCG.2013.177;10.1109/TVCG.2010.199;10.1109/TVCG.2014.2346321	Uncertainty Visualization, Vector Field Data, Coordinated and Multiple Views, Glyph-based Techniques	10	20	14	43	
VAST	2015	Interactive visual steering of hierarchical simulation ensembles	10.1109/VAST.2015.7347635	http://dx.doi.org/10.1109/VAST.2015.7347635	89	96	C	Multi-level simulation models, i.e., models where different components are simulated using sub-models of varying levels of complexity, belong to the current state-of-the-art in simulation. The existing analysis practice for multi-level simulation results is to manually compare results from different levels of complexity, amounting to a very tedious and error-prone, trial-and-error exploration process. In this paper, we introduce hierarchical visual steering, a new approach to the exploration and design of complex systems. Hierarchical visual steering makes it possible to explore and analyze hierarchical simulation ensembles at different levels of complexity. At each level, we deal with a dynamic simulation ensemble - the ensemble grows during the exploration process. There is at least one such ensemble per simulation level, resulting in a collection of dynamic ensembles, analyzed simultaneously. The key challenge is to map the multi-dimensional parameter space of one ensemble to the multi-dimensional parameter space of another ensemble (from another level). In order to support the interactive visual analysis of such complex data we propose a novel approach to interactive and semi-automatic parameter space segmentation and comparison. The approach combines a novel interaction technique and automatic, computational methods - clustering, concave hull computation, and concave polygon overlapping - to support the analysts in the cross-ensemble parameter space mapping. In addition to the novel parameter space segmentation we also deploy coordinated multiple views with standard plots. We describe the abstract analysis tasks, identified during a case study, i.e., the design of a variable valve actuation system of a car engine. The study is conducted in cooperation with experts from the automotive industry. Very positive feedback indicates the usefulness and efficiency of the newly proposed approach.	Rainer Splechtna;Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Helwig Hauser	Rainer Splechtna;Krešimir Matković;Denis Gračanin;Mario Jelović;Helwig Hauser	VRVis Research Center in Vienna, Austria;VRVis Research Center in Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;AVL-AST Zagreb, Croatia;University of Bergen, Norway	10.1109/TVCG.2008.145;10.1109/TVCG.2014.2346744;10.1109/TVCG.2014.2346321;10.1109/VAST.2009.5333081;10.1109/TVCG.2010.223	Interactive Visual Analysis, Simulation-Ensemble Steering, Multi-resolution simulation	1	6	7	20	
VAST	2015	Urbane: A 3D framework to support data driven decision making in urban development	10.1109/VAST.2015.7347636	http://dx.doi.org/10.1109/VAST.2015.7347636	97	104	C	Architects working with developers and city planners typically rely on experience, precedent and data analyzed in isolation when making decisions that impact the character of a city. These decisions are critical in enabling vibrant, sustainable environments but must also negotiate a range of complex political and social forces. This requires those shaping the built environment to balance maximizing the value of a new development with its impact on the character of a neighborhood. As a result architects are focused on two issues throughout the decision making process: a) what defines the character of a neighborhood? and b) how will a new development change its neighborhood? In the first, character can be influenced by a variety of factors and understanding the interplay between diverse data sets is crucial; including safety, transportation access, school quality and access to entertainment. In the second, the impact of a new development is measured, for example, by how it impacts the view from the buildings that surround it. In this paper, we work in collaboration with architects to design Urbane, a 3-dimensional multi-resolution framework that enables a data-driven approach for decision making in the design of new urban development. This is accomplished by integrating multiple data layers and impact analysis techniques facilitating architects to explore and assess the effect of these attributes on the character and value of a neighborhood. Several of these data layers, as well as impact analysis, involve working in 3-dimensions and operating in real time. Efficient computation and visualization is accomplished through the use of techniques from computer graphics. We demonstrate the effectiveness of Urbane through a case study of development in Manhattan depicting how a data-driven understanding of the value and impact of speculative buildings can benefit the design-development process between architects, planners and developers.	Nivan Ferreira;Marcos Lage;Harish Doraiswamy;Huy T. Vo;Luc Wilson;Heidi Werner;Muchan Park;Cláudio T. Silva	Nivan Ferreira;Marcos Lage;Harish Doraiswamy;Huy Vo;Luc Wilson;Heidi Werner;Muchan Park;Cláudio Silva	New York University, USA;Universidade Federal Fluminense, Brazil;New York University, USA;New York University, USA;Kohn Pedersen Fox Associates PC, USA;Kohn Pedersen Fox Associates PC, USA;Kohn Pedersen Fox Associates PC, USA;New York University, USA	10.1109/VAST.2008.4677356;10.1109/TVCG.2014.2346446;10.1109/TVCG.2007.70574;10.1109/TVCG.2013.226;10.1109/TVCG.2007.70523;10.1109/TVCG.2013.228;10.1109/TVCG.2014.2346893;10.1109/TVCG.2014.2346898		10	17	10	39	
VAST	2015	FeatureInsight: Visual support for error-driven feature ideation in text classification	10.1109/VAST.2015.7347637	http://dx.doi.org/10.1109/VAST.2015.7347637	105	112	C	Machine learning requires an effective combination of data, features, and algorithms. While many tools exist for working with machine learning data and algorithms, support for thinking of new features, or feature ideation, remains poor. In this paper, we investigate two general approaches to support feature ideation: visual summaries and sets of errors. We present FeatureInsight, an interactive visual analytics tool for building new dictionary features (semantically related groups of words) for text classification problems. FeatureInsight supports an error-driven feature ideation process and provides interactive visual summaries of sets of misclassified documents. We conducted a controlled experiment evaluating both visual summaries and sets of errors in FeatureInsight. Our results show that visual summaries significantly improve feature ideation, especially in combination with sets of errors. Users preferred visual summaries over viewing raw data, and only preferred examining sets when visual summaries were provided. We discuss extensions of both approaches to data types other than text, and point to areas for future research.	Michael Brooks;Saleema Amershi;Bongshin Lee;Steven Mark Drucker;Ashish Kapoor;Patrice Y. Simard	Michael Brooks;Saleema Amershi;Bongshin Lee;Steven M. Drucker;Ashish Kapoor;Patrice Simard	University of Washington, USA;Microsoft Research, USA;Microsoft Research, USA;Microsoft Research, USA;Microsoft Research, USA;Microsoft Research, USA	10.1109/VAST.2010.5652443		19	39	20	37	
VAST	2015	Visual scalability of spatial ensemble uncertainty	10.1109/VAST.2015.7347671	http://dx.doi.org/10.1109/VAST.2015.7347671	187	188	M	Weather Research and Forecasting (WRF) models simulate weather conditions by generating 2D numerical weather prediction ensemble members either through perturbing initial conditions or by changing different parameterization schemes, e.g., cumulus and microphysics schemes. These simulations are often used by weather analysts to analyze the nature of uncertainty attributed by these simulations to forecast weather conditions with good accuracy. The number of simulations used for forecasting is growing with the advent of increase in computing power. Hence, there is a need for providing better visual insights of uncertainty with growing number of ensemble members. We propose a geo visual analytical framework that uses visual analytics approach to resolve visual scalability of these ensemble members. Our approach naturally fits with the workflow of an analyst analyzing ensemble spatial uncertainty. Meteorologists evaluated our framework qualitatively and found it to be effective in acquiring insights of spatial uncertainty associated with multiple ensemble runs that are simulated using multiple parameterization schemes.	Sujan Anreddy;Song Zhang 0004;Andrew Mercer 0001;Jamie Dyer;J. Edward Swan	Sujan Anreddy;Song Zhang;Andrew Mercer;Jamie Dyer;J. Edward Swan	Mississippi State University, USA;Mississippi State University, USA;Mississippi State University, USA;Mississippi State University, USA;Mississippi State University, USA			0	1	1	6	
VAST	2015	Visually and statistically guided imputation of missing values in univariate seasonal time series	10.1109/VAST.2015.7347672	http://dx.doi.org/10.1109/VAST.2015.7347672	189	190	M	Missing values are a problem in many real world applications, for example failing sensor measurements. For further analysis these missing values need to be imputed. Thus, imputation of such missing values is important in a wide range of applications. We propose a visually and statistically guided imputation approach, that allows applying different imputation techniques to estimate the missing values as well as evaluating and fine tuning the imputation by visual guidance. In our approach we include additional visual information about uncertainty and employ the cyclic structure of time inherent in the data. Including this cyclic structure enables visually judging the adequateness of the estimated values with respect to the uncertainty/error boundaries and according to the patterns of the neighbouring time points in linear and cyclic (e.g., the months of the year) time.	Markus Bögl;Peter Filzmoser;Theresia Gschwandtner;Silvia Miksch;Wolfgang Aigner;Alexander Rind;Tim Lammarsch	M. Bögl;P. Filzmoser;T. Gschwandtner;S. Miksch;W. Aigner;A. Rind;T. Lammarsch	Vienna University of Technology, Austria;Vienna University of Technology, Austria;Vienna University of Technology, Austria;Vienna University of Technology, Austria;St. Pölten University of Applied Sciences, Germany;St. Pölten University of Applied Sciences, Germany;MODUL University Vienna, Austria			0	4	3	11	
VAST	2015	StreamVisND: Visualizing relationships in streaming multivariate data	10.1109/VAST.2015.7347673	http://dx.doi.org/10.1109/VAST.2015.7347673	191	192	M	In streaming acquisitions the data changes over time. ThemeRiver and line charts are common methods to display data over time. However, these methods can only show the values of the variables (or attributes) but not the relationships among them over time. We propose a framework we call StreamVis&lt;sup&gt;ND&lt;/sup&gt; that can display these types of streaming data relations. It first slices the data stream into different time slices, then it visualizes each slice with a sequence of multivariate 2D data layouts, and finally it flattens this series of displays into a parallel coordinate type display. Our framework is fully interactive and lends itself well to real-time displays.	Shenghui Cheng;Yue Wang;Dan Zhang;Zhifang Jiang;Klaus Mueller	Shenghui Cheng;Yue Wang;Dan Zhang;Zhifang Jiang;Klaus Mueller	Visual Analytics and Imaging Lab, Computer Science Department, Stony Brook University and SUNY Korea;Department of Computer Science, Shandong University, China;Visual Analytics and Imaging Lab, Computer Science Department, Stony Brook University and SUNY Korea;Department of Computer Science, Shandong University, China;Visual Analytics and Imaging Lab, Computer Science Department, Stony Brook University and SUNY Korea			1	1	0	3	
VAST	2015	A software developer's guide to informal evaluation of Visual Analytics environments using VAST Challenge information	10.1109/VAST.2015.7347674	http://dx.doi.org/10.1109/VAST.2015.7347674	193	194	M	The VAST Challenge has been a popular venue for academic and industry participants for over ten years. Many participants comment that the majority of their time in preparing VAST Challenge entries is discovering elements in their software environments that need to be redesigned in order to solve the given task. Fortunately, there is no need to wait until the VAST Challenge is announced to test out software systems. The Visual Analytics Benchmark Repository contains all past VAST Challenge tasks, data, solutions and submissions. In this poster we describe how developers can perform informal evaluations of various aspects of their visual analytics environments using VAST Challenge information.	Kristin A. Cook;Jean Scholtz;Mark A. Whiting	Kristin A. Cook;Jean Scholtz;Mark A. Whiting	Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA			1	1	1	2	
VAST	2015	HTMVS: Visualizing hierarchical topics and their evolution	10.1109/VAST.2015.7347675	http://dx.doi.org/10.1109/VAST.2015.7347675	195	196	M	Topic model has been an active research area for many years, it can be used for discovering latent semantics and finding hidden knowledge in unstructured data corpus. In this paper, we investigated the problems in visualizing hierarchical topic and their evolution. The contribution of this paper is threefold, first we explore the static visualization of hierarchical topics using the `nested circle' layout, and then in order to present the topic evolution over time, we extended a hierarchical topic model and employ topic transformation visualizations to track the arising, splitting and disappearing of certain topics under the dynamic topical hierarchy. Finally, a Hierarchical Topic Model Visualization System (HTMVS) is designed to take advantage of both static and dynamic hierarchical topic visualization.	Haoling Dong;Siliang Tang;Si Li;Fei Wu 0001;Yueting Zhuang	Haoling Dong;Siliang Tang;Si Li;Fei Wu;Yueting Zhuang	College of Computer Science, Zhejiang University, Hangzhou, China;College of Computer Science, Zhejiang University, Hangzhou, China;College of Computer Science, Zhejiang University, Hangzhou, China;College of Computer Science, Zhejiang University, Hangzhou, China;College of Computer Science, Zhejiang University, Hangzhou, China			0	0	0	6	
VAST	2015	Interactive semi-automatic categorization for spinel group minerals	10.1109/VAST.2015.7347676	http://dx.doi.org/10.1109/VAST.2015.7347676	197	198	M	Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist's workflow significantly.	Maria Luján Ganuza;Maria Florencia Gargiulo;Gabriela Ferracutti;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic	María Luján Ganuza;Florencia Gargiulo;Gabriela Ferracutti;Silvia Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković	VyGLab, UNS, USA;INGEOSUR CONICET, Argentina;INGEOSUR CONICET, Argentina;VyGLab, UNS, USA;INGEOSUR CONICET, Argentina;TU Wien, Austria;VRVis, Austria			0	0	0	5	
VAST	2015	A System for visual exploration of caution spots from vehicle recorder data	10.1109/VAST.2015.7347677	http://dx.doi.org/10.1109/VAST.2015.7347677	199	200	M	It is vital for the transportation industry, which performs most of its work by automobiles, to reduce its accident rate. This paper proposes a 3D visual interaction method for exploring caution areas from large-scale vehicle recorder data. Our method provides (i) a flexible filtering interface for driving operations such as braking or handling operations by various combinations of their attribute values such as velocity and acceleration, and (ii) a 3D visual environment for spatio-temporal exploration of caution areas. The proposed method was able to extract caution areas where some accidents have actually occurred or that are on very narrow roads with bad visibility by using real data given by one of the biggest transportation companies in Japan.	Masahiko Itoh;Daisaku Yokoyama;Masashi Toyoda;Masaru Kitsuregawa	Masahiko Itoh;Daisaku Yokoyama;Masashi Toyoda;Masaru Kitsuregawa	The University of Tokyo, and National Institute of Information and Communications Technology, Japan;The University of Tokyo, Japan;The University of Tokyo, Japan;National Institute of Informatics, and The University of Tokyo, Japan			0	0	0	4	
VAST	2015	Visual Analytics for fraud detection and monitoring	10.1109/VAST.2015.7347678	http://dx.doi.org/10.1109/VAST.2015.7347678	201	202	M	One of the primary concerns of financial institutions is to guarantee security and legitimacy in their services. Being able to detect and avoid fraudulent schemes also enhances the credibility of these institutions. Currently, fraud detection approaches still lack Visual Analytics techniques. We propose a Visual Analytics process that tackles the main challenges in the area of fraud detection.	Roger A. Leite;Theresia Gschwandtner;Silvia Miksch;Erich Gstrein;Johannes Kuntner	Roger A. Leite;Theresia Gschwandtner;Silvia Miksch;Erich Gstrein;Johannes Kuntner	Vienna University of Technology, Austria;Vienna University of Technology, Austria;Vienna University of Technology, Austria;Erste Group IT, USA;Erste Group IT, USA			2	4	3	7	
VAST	2015	Visual analysis of route choice behaviour based on GPS trajectories	10.1109/VAST.2015.7347679	http://dx.doi.org/10.1109/VAST.2015.7347679	203	204	M	There are often multiple routes between regions. Many factors potentially affect driver's route choice, such as expected time cost, length etc. In this work, we present a visual analysis system to explore driver's route choice behaviour based on taxi GPS trajectory data. With interactive trajectory filtering, the system constructs feasible routes between regions of interest. Using a rank-based visualization, the attributes of multiple routes are explored and compared. Based on a statistical model, the system supports to verify trajectory-related factors' impact on route choice behaviour. The effectiveness of the system is demonstrated by applying to real trajectory dataset.	Min Lu;Chufan Lai;Tangzhi Ye;Jie Liang 0004;Xiaoru Yuan	Min Lu;Chufan Lai;Tangzhi Ye;Jie Liang;Xiaoru Yuan	Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China			2	3	1	8	
VAST	2015	Using visualization and analysis with efficient dimension Reduction to determine underlying factors in hospital inpatient procedure costs	10.1109/VAST.2015.7347680	http://dx.doi.org/10.1109/VAST.2015.7347680	205	206	M	The Centers for Medicare and Medicaid Services (CMS) has made public a data set showing what hospitals charged and what Medicare paid for the one hundred most common inpatient stays. Here we present the application of Reduced Basis Decomposition (RBD), an efficient novel dimension reduction algorithm for data processing, to the CMS data. This was paired with a comparative visual exploration of the results when put into context with characteristics of the hospitals and marketplaces in which they operate. We used Weave Analyst, a new web-based analysis and visualization environment, to visualize the relationship between the hospital groups, their charge levels, and distinguishing indicator variables. Particular insights to the relatively small number of underlying factors that exert greatest influence on hospital pricing surfaced thanks to the combined synergetic integration of the modeling, reduction, and visualization techniques.	Miriam Perkins;Yanlai Chen	Miriam Perkins;Yanlai Chen	University of Massachusetts Lowell, USA;University of Massachusetts Dartmouth, USA			0	0	0	6	
VAST	2015	Topicks: Visualizing complex topic models for user comprehension	10.1109/VAST.2015.7347681	http://dx.doi.org/10.1109/VAST.2015.7347681	207	208	M	The interactive visualization of topic models is a promising approach to summarizing large sets of textual data. Topicks is the working title for a means to visualize topic modelling outputs. Incorporating a radial layout, users can view the relationships between topics, terms and the corpus as a whole. Interacting with topic and term nodes, as well as a related bar chart, provides the user with various ways to manipulate the visualization and explore the data. We describe the visualization and potential user interactions before discussing future work.	Jessica Peter;Steve James Szigeti;Ana Jofre;Sara Diamond	Jessica Peter;Steve Szigeti;Ana Jofre;Sara Diamond	OCAD University, Canada;OCAD University, Canada;OCAD University, Canada;OCAD University, Canada			1	1	0	6	
VAST	2015	TimeStitch: Interactive multi-focus cohort discovery and comparison	10.1109/VAST.2015.7347682	http://dx.doi.org/10.1109/VAST.2015.7347682	209	210	M	Whereas event-based timelines for healthcare enable users to visualize the chronology of events surrounding events of interest, they are often not designed to aid the discovery, construction, or comparison of associated cohorts. We present TimeStitch, a system that helps health researchers discover and understand events that may cause abstinent smokers to lapse. TimeStitch extracts common sequences of events performed by abstinent smokers from large amounts of mobile health sensor data, and offers a suite of interactive and visualization techniques to enable cohort discovery, construction, and comparison, using extracted sequences as interactive elements. We are extending TimeStitch to support more complex health conditions with high mortality risk, such as reducing hospital readmission in congestive heart failure.	Peter J. Polack Jr.;Shang-Tse Chen;Minsuk Kahng;Moushumi Sharmin;Duen Horng Chau	Peter J. Polack;Shang-Tse Chen;Minsuk Kahng;Moushumi Sharmin;Duen Horng Chau	Georgia Tech., USA;Georgia Tech., USA;Georgia Tech., USA;University of Memphis., USA;Georgia Tech., USA			3	7	7	7	
VAST	2015	Tell me what do you see: Detecting perceptually-separable visual patterns via clustering of image-space features in visualizations	10.1109/VAST.2015.7347683	http://dx.doi.org/10.1109/VAST.2015.7347683	211	212	M	Visualization helps users infer structures and relationships in the data by encoding information as visual features that can be processed by the human visual-perceptual system. However, users would typically need to expend significant effort to scan and analyze a large number of views before they can begin to recognize relationships in a visualization. We propose a technique to partially automate the process of analyzing visualizations. By deriving and analyzing image-space features from visualizations, we can detect perceptually-separable patterns in the information space. We summarize these patterns with a tree-based meta-visualization and present it to the user to aid exploration. We illustrate this technique with an example scenario involving the analysis of census data.	Khairi Reda;Alberto Gonzalez;Jason Leigh;Michael E. Papka	Khairi Reda;Alberto González;Jason Leigh;Michael E. Papka	Argonne National Laboratory, USA;University of Hawai'i at Mānoa, USA;University of Hawai'i at Mānoa, USA;Argonne National Laboratory, USA			0	0	0	6	
VAST	2015	Sequencing of categorical time series	10.1109/VAST.2015.7347684	http://dx.doi.org/10.1109/VAST.2015.7347684	213	214	M	Exploring and comparing categorical time series and finding temporal patterns are complex tasks in the field of time series data mining. Although different analysis approaches exist, these tasks remain challenging, especially when numerous time series are considered at once. We propose a visual analysis approach that supports exploring such data by ordering time series in meaningful ways. We provide interaction techniques to steer the automated arrangement and to allow users to investigate patterns in detail.	Christian Richter;Martin Luboschik;Martin Röhlig;Heidrun Schumann	Christian Richter;Martin Luboschik;Martin Röhlig;Heidrun Schumann	University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany			1	1	2	5	
VAST	2015	Visual Pruner: Visually guided cohort selection for observational studies	10.1109/VAST.2015.7347685	http://dx.doi.org/10.1109/VAST.2015.7347685	215	216	M	Observational studies are a widely used and challenging class of studies. A key challenge is selecting a study cohort from the available data, or “pruning” the data, in a way that produces both sufficient balance in pre-treatment covariates and an easily described cohort from which results can be generalized. Even with advanced pruning methods, it is often difficult for researchers to see how the cohort is being selected; consequently, these methods are underutilized in research. Visual Pruner is a free, easy-to-use web application that can improve both the credibility and generalizability of observational studies by letting analysts use updatable visual displays of estimated propensity scores and key baseline covariates to refine inclusion criteria. By helping researchers see how covariate distributions in their data relate to the estimated probabilities of treatment assignment, the app lets researchers make pruning decisions based on pre-treatment covariate patterns that are otherwise hard to discover. The app yields a set of inclusion criteria that can be used in conjunction with further statistical analysis in any statistical software.	Lauren R. Samuels;Robert A. Greevy	Lauren R. Samuels;Robert A. Greevy	Department of Biostatistics, Vanderbilt University School of Medicine, USA;Department of Biostatistics, Vanderbilt University School of Medicine, USA			0	0	0	10	
VAST	2015	uRank: Visual analytics approach for search result exploration	10.1109/VAST.2015.7347686	http://dx.doi.org/10.1109/VAST.2015.7347686	217	218	M	uRank is a Web-based tool combining lightweight text analytics and visual methods for topic-wise exploration of document sets. It includes a view summarizing the content of the document set in meaningful terms, a dynamic document ranking view and a detailed view for further inspection of individual documents. Its major strength lies in how it supports users in reorganizing documents on-the-fly as their information interests change. We present a preliminary evaluation showing that uRank helps to reduce cognitive load compared to a traditional list-based representation.	Cecilia di Sciascio;Vedran Sabol;Eduardo E. Veas	Cecilia di Sciascio;Vedran Sabol;Eduardo Veas	Know-Center GmbH, Graz, Austria;Know-Center GmbH, Graz, Austria;Know-Center GmbH, Graz, Austria			1	1	1	5	
VAST	2015	Evolution inspector: Interactive visual analysis for evolutionary molecular design	10.1109/VAST.2015.7347687	http://dx.doi.org/10.1109/VAST.2015.7347687	219	220	M	De novo design is a computational-chemistry method, where a computer program utilizes an optimization method, in our case an evolutionary algorithm, to design compounds with desired chemical properties. The optimization is performed with respect to a quantity called fitness, defined by the chemists. We present a tool that connects interactive visual analysis and evolutionary algorithm-based molecular design. We employ linked views to communicate different aspects of the data: the statistical distribution of molecule fitness, connections between individual molecules during the evolution and 3D molecular structure. The application is already used by chemists to explore and analyze the results of their evolution experiments and has proved to be highly useful.	Veronika Soltészová;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen	Veronika Solteszova;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen	Christian Michelsen Research, Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway			0	0	0	10	
VAST	2015	Trending pool: Visual analytics for trending event compositions for time-series categorical log data	10.1109/VAST.2015.7347688	http://dx.doi.org/10.1109/VAST.2015.7347688	221	222	M	Although many visualization tools provide us plenty of ways to view the data, users can not easily find the trending events and their explanation from the data. In this work, we address the issue by leveraging the real music streaming log data as an example to better understand a million-scale dataset. Trending event explanation turns out to be challenging when it comes to categorical log data. Therefore, we propose to use a learning-based method with an interface design to uncover the trending event compositions for time-series categorical log data, which can be extend to other datasets, e.g., the hashtags in social media. First, we perform “trending pool” operation to save the memory and time cost. Second, we apply sparse coding to learn important trending candidate combination sets instead of traditional brute-force way or manual investigation for generating combinations. Besides the contributions above, we also observe some interesting user behaviors by exploring detected trending candidate combinations visually through our interface.	Yi-Chih Tsai;Liang-Chi Hsieh;Wen-Feng Cheng;Yin-Hsi Kuo;Winston H. Hsu;Wen-Chin Chen	Yi-Chih Tsai;Liang-Chi Hsieh;Wen-Feng Cheng;Yin-Hsi Kuo;Winston Hsu;Wen-Chin Chen	National Taiwan University, Taipei, Taiwan;National Taiwan University, Taipei, Taiwan;National Taiwan University, Taipei, Taiwan;National Taiwan University, Taipei, Taiwan;National Taiwan University, Taipei, Taiwan;National Taiwan University, Taipei, Taiwan			0	0	0	4	
VAST	2015	Visual data quality analysis for taxi GPS data	10.1109/VAST.2015.7347689	http://dx.doi.org/10.1109/VAST.2015.7347689	223	224	M	We present a novel visual analysis method to systematically discover data quality problems in raw taxi GPS data. It combines semi-supervised active learning and interactive visual exploration. It helps analysts interactively discover unknown data quality problems, and automatically extract known problems. We report analysis results on Beijing taxi GPS data.	Zuchao Wang;Xiaoru Yuan;Tangzhi Ye;Youfeng Hao;Siming Chen;Jie Liang 0004;Qiusheng Li;Haiyang Wang;Yadong Wu	Zuchao Wang;Xiaoru Yuan;Tangzhi Ye;Youfeng hao;Siming Chen;Jie Liangk;Qiusheng Li;Haiyang Wang;Yadong Wu	Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;School of Computer Science and Technology, Southwest University of Science and Technology, China;School of Computer Science and Technology, Southwest University of Science and Technology, China;School of Computer Science and Technology, Southwest University of Science and Technology, China			2	2	0	4	
VAST	2016	A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games	10.1109/TVCG.2016.2598415	http://dx.doi.org/10.1109/TVCG.2016.2598415	211	220	J	To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players' positions, status and the occurrences of events. Our system can reveal players' strategies and performance throughout a single match and suggest patterns, e.g., specific player' actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset.	Quan Li;Peng Xu;Yeukyin Chan;Yun Wang 0012;Zhipeng Wang;Huamin Qu;Xiaojuan Ma	Quan Li;Peng Xu;Yeuk Yin Chan;Yun Wang;Zhipeng Wang;Huamin Qu;Xiaojuan Ma	Hong Kong University of Science and Technology;NetEase, Inc.;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;China Academy of Art;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology	10.1109/TVCG.2014.2346445;10.1109/VISUAL.2004.120;10.1109/VAST.2015.7347633;10.1109/VAST.2014.7042477;10.1109/VAST.2014.7042478;10.1109/TVCG.2013.192;10.1109/TVCG.2012.263	Game play data visualization;visual knowledge discovery;visual knowledge representation;and game reconstruction	5	14	13	41	
VAST	2016	SemanticTraj: A New Approach to Interacting with Massive Taxi Trajectories	10.1109/TVCG.2016.2598416	http://dx.doi.org/10.1109/TVCG.2016.2598416	11	20	J	Massive taxi trajectory data is exploited for knowledge discovery in transportation and urban planning. Existing tools typically require users to select and brush geospatial regions on a map when retrieving and exploring taxi trajectories and passenger trips. To answer seemingly simple questions such as “What were the taxi trips starting from Main Street and ending at Wall Street in the morning?” or “Where are the taxis arriving at the Art Museum at noon typically coming from?”, tedious and time consuming interactions are usually needed since the numeric GPS points of trajectories are not directly linked to the keywords such as “Main Street”, “Wall Street”, and “Art Museum”. In this paper, we present SemanticTraj, a new method for managing and visualizing taxi trajectory data in an intuitive, semantic rich, and efficient means. With SemanticTraj, domain and public users can find answers to the aforementioned questions easily through direct queries based on the terms. They can also interactively explore the retrieved data in visualizations enhanced by semantic information of the trajectories and trips. In particular, taxi trajectories are converted into taxi documents through a textualization transformation process. This process maps GPS points into a series of street/POI names and pick-up/drop-off locations. It also converts vehicle speeds into user-defined descriptive terms. Then, a corpus of taxi documents is formed and indexed to enable flexible semantic queries over a text search engine. Semantic labels and meta-summaries of the results are integrated with a set of visualizations in a SemanticTraj prototype, which helps users study taxi trajectories quickly and easily. A set of usage scenarios are presented to show the usability of the system. We also collected feedback from domain experts and conducted a preliminary user study to evaluate the visual system.	Shamal Al-Dohuki;Yingyu Wu;Farah Kamw;Jing Yang;Xin Li;Ye Zhao;Xinyue Ye;Wei Chen 0001;Chao Ma;Fei Wang 0016	Shamal Al-Dohuki;Yingyu Wu;Farah Kamw;Jing Yang;Xin Li;Ye Zhao;Xinyue Ye;Wei Chen;Chao Ma;Fei Wang	Kent State University;Kent State University;Kent State University;UNC Charlotte;China Petroleum University;Kent State University;Kent State University;Zhejiang University;Kent State University;Zhejiang University	10.1109/TVCG.2015.2467732;10.1109/TVCG.2013.226;10.1109/VAST.2014.7042486;10.1109/VAST.2011.6102455;10.1109/TVCG.2014.2346746;10.1109/TVCG.2013.228;10.1109/VAST.2010.5652885	Taxi Trajectories;Taxi Document;Textualization;Name Query;Semantic Interaction;Text Search Engine	17	38	43	44	
SciVis	2016	Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data	10.1109/TVCG.2016.2598430	http://dx.doi.org/10.1109/TVCG.2016.2598430	901	910	J	We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.	Daniel Jönsson;Anders Ynnerman	Daniel Jönsson;Anders Ynnerman	Linköping University, Nörrköping, Sweden;Linköping University, Nörrköping, Sweden	10.1109/TVCG.2011.161;10.1109/TVCG.2014.2346333;10.1109/TVCG.2012.232;10.1109/TVCG.2007.70518;10.1109/TVCG.2011.198;10.1109/TVCG.2011.211	Volume rendering;photon mapping;global illumination;participating media	2	5	5	45	HM
VAST	2016	SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations	10.1109/TVCG.2016.2598432	http://dx.doi.org/10.1109/TVCG.2016.2598432	1	10	J	The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.	Dongyu Liu;Di Weng;Yuhong Li;Jie Bao 0003;Yu Zheng 0004;Huamin Qu;Yingcai Wu	Dongyu Liu;Di Weng;Yuhong Li;Jie Bao;Yu Zheng;Huamin Qu;Yingcai Wu	Zhejiang UniversityHong Kong University of Science and Technology;State Key Lab of CAD & CGZhejiang University;University of Macau;Microsoft Research, Beijing, China;Microsoft Research, Beijing, China;Hong Kong University of Science and Technology;State Key Lab of CAD & CGZhejiang University	10.1109/TVCG.2013.122;10.1109/TVCG.2015.2467051;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/TVCG.2013.228;10.1109/TVCG.2015.2467112;10.1109/TVCG.2012.265;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346912;10.1109/TVCG.2007.70521;10.1109/TVCG.2015.2467771;10.1109/TVCG.2013.173;10.1109/TVCG.2011.181;10.1109/TVCG.2009.111	optimal billboard locations;taxi trajectory;visual analytics;comparative analysis	30	58	53	51	
VAST	2016	Visual Analysis of MOOC Forums with iForum	10.1109/TVCG.2016.2598444	http://dx.doi.org/10.1109/TVCG.2016.2598444	201	210	J	Discussion forums of Massive Open Online Courses (MOOC) provide great opportunities for students to interact with instructional staff as well as other students. Exploration of MOOC forum data can offer valuable insights for these staff to enhance the course and prepare the next release. However, it is challenging due to the large, complicated, and heterogeneous nature of relevant datasets, which contain multiple dynamically interacting objects such as users, posts, and threads, each one including multiple attributes. In this paper, we present a design study for developing an interactive visual analytics system, called iForum, that allows for effectively discovering and understanding temporal patterns in MOOC forums. The design study was conducted with three domain experts in an iterative manner over one year, including a MOOC instructor and two official teaching assistants. iForum offers a set of novel visualization designs for presenting the three interleaving aspects of MOOC forums (i.e., posts, users, and threads) at three different scales. To demonstrate the effectiveness and usefulness of iForum, we describe a case study involving field experts, in which they use iForum to investigate real MOOC forum data for a course on JAVA programming.	Siwei Fu;Jian Zhao 0010;Weiwei Cui;Huamin Qu	Siwei Fu;Jian Zhao;Weiwei Cui;Huamin Qu	Hong Kong University of Science and Technology;Autodesk Research;Microsoft Research;Hong Kong University of Science and Technology	10.1109/TVCG.2006.147;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2015.2467555	Discussion forum;MOOC;temporal visualization;visual analytics	12	20	19	40	
VAST	2016	TopicLens: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections	10.1109/TVCG.2016.2598445	http://dx.doi.org/10.1109/TVCG.2016.2598445	151	160	J	Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. Instead, most such systems are limited to utilizing a fixed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly. To support this interaction in real time while maintaining view consistency, we propose a novel efficient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets.	Minjeong Kim;Kyeongpil Kang;Deok Gun Park 0001;Jaegul Choo;Niklas Elmqvist	Minjeong Kim;Kyeongpil Kang;Deokgun Park;Jaegul Choo;Niklas Elmqvist	Korea University;Korea University;University of Maryland, College Park, MD, USA;Korea University;University of Maryland, College Park, MD, USA	10.1109/INFVIS.2003.1249014;10.1109/TVCG.2013.212;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2004.43;10.1109/TVCG.2014.2346574;10.1109/TVCG.2011.239;10.1109/TVCG.2010.154;10.1109/VAST.2014.7042494	topic modeling;nonnegative matrix factorization;t-distributed stochastic neighbor embedding;magic lens;text analytics	10	26	21	51	
VAST	2016	AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations through User Drawings	10.1109/TVCG.2016.2598446	http://dx.doi.org/10.1109/TVCG.2016.2598446	221	230	J	Visual analytics techniques help users explore high-dimensional data. However, it is often challenging for users to express their domain knowledge in order to steer the underlying data model, especially when they have little attribute-level knowledge. Furthermore, users' complex, high-level domain knowledge, compared to low-level attributes, posits even greater challenges. To overcome these challenges, we introduce a technique to interpret a user's drawings with an interactive, nonlinear axis mapping approach called AxiSketcher. This technique enables users to impose their domain knowledge on a visualization by allowing interaction with data entries rather than with data attributes. The proposed interaction is performed through directly sketching lines over the visualization. Using this technique, users can draw lines over selected data points, and the system forms the axes that represent a nonlinear, weighted combination of multidimensional attributes. In this paper, we describe our techniques in three areas: 1) the design space of sketching methods for eliciting users' nonlinear domain knowledge; 2) the underlying model that translates users' input, extracts patterns behind the selected data points, and results in nonlinear axes reflecting users' complex intent; and 3) the interactive visualization for viewing, assessing, and reconstructing the newly formed, nonlinear axes.	Bum Chul Kwon;Hannah Kim;Emily Wall;Jaegul Choo;Haesun Park;Alex Endert	Bum Chul Kwon;Hannah Kim;Emily Wall;Jaegul Choo;Haesun Park;Alex Endert	IBM T.J. Watson Research Center, Yorktown Heights, NY, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Korea University, Seoul, South Korea;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA	10.1109/INFVIS.2004.60;10.1109/TVCG.2013.190;10.1109/TVCG.2015.2467615;10.1109/TVCG.2013.188;10.1109/TVCG.2014.2346481;10.1109/VAST.2011.6102449;10.1109/TVCG.2012.262;10.1109/TVCG.2015.2467591;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.261;10.1109/TVCG.2013.191;10.1109/TVCG.2013.212;10.1109/TVCG.2013.167;10.1109/VAST.2012.6400486	axis mapping;interactive model steering;sketch;axis visualization;human-centered visual analytics	12	23	18	54	
VAST	2016	TextTile: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text	10.1109/TVCG.2016.2598447	http://dx.doi.org/10.1109/TVCG.2016.2598447	161	170	J	We describe TextTile, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. TextTile is based on real-world data analysis problems gathered through our interaction with a number of domain experts and provides a general purpose solution to such problems. The system integrates a set of operations that can interchangeably be applied to the structured as well as to unstructured text part of the data to generate useful data summaries. Such summaries are then organized in visual tiles in a grid layout to allow their analysis and comparison. We validate TextTile with task analysis, use cases and a user study showing the system can be easily learned and proficiently used to carry out nontrivial tasks.	Cristian Felix;Anshul Vikram Pandey;Enrico Bertini	Cristian Felix;Anshul Vikram Pandey;Enrico Bertini	New York University;New York University;New York University	10.1109/TVCG.2011.176;10.1109/INFVIS.2000.885098;10.1109/VAST.2012.6400485;10.1109/VAST.2009.5333443;10.1109/TVCG.2015.2467191;10.1109/TVCG.2009.128;10.1109/INFVIS.2000.885086;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346919	Exploratory Text Analysis;Knowledge Discovery;Text Visualization	8	13	9	43	
SciVis	2016	Hairy Slices: Evaluating the Perceptual Effectiveness of Cutting Plane Glyphs for 3D Vector Fields	10.1109/TVCG.2016.2598448	http://dx.doi.org/10.1109/TVCG.2016.2598448	990	999	J	Three-dimensional vector fields are common datasets throughout the sciences. Visualizing these fields is inherently difficult due to issues such as visual clutter and self-occlusion. Cutting planes are often used to overcome these issues by presenting more manageable slices of data. The existing literature provides many techniques for visualizing the flow through these cutting planes; however, there is a lack of empirical studies focused on the underlying perceptual cues that make popular techniques successful. This paper presents a quantitative human factors study that evaluates static monoscopic depth and orientation cues in the context of cutting plane glyph designs for exploring and analyzing 3D flow fields. The goal of the study was to ascertain the relative effectiveness of various techniques for portraying the direction of flow through a cutting plane at a given point, and to identify the visual cues and combinations of cues involved, and how they contribute to accurate performance. It was found that increasing the dimensionality of line-based glyphs into tubular structures enhances their ability to convey orientation through shading, and that increasing their diameter intensifies this effect. These tube-based glyphs were also less sensitive to visual clutter issues at higher densities. Adding shadows to lines was also found to increase perception of flow direction. Implications of the experimental results are discussed and extrapolated into a number of guidelines for designing more perceptually effective glyphs for 3D vector field visualizations.	Andrew H. Stevens;Thomas Butkiewicz;Colin Ware	Andrew H. Stevens;Thomas Butkiewicz;Colin Ware	The Center for Coastal and Ocean MappingThe University of New Hampshire;The Center for Coastal and Ocean MappingThe University of New Hampshire;The Center for Coastal and Ocean MappingThe University of New Hampshire	10.1109/VISUAL.1996.568139;10.1109/TVCG.2009.126;10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2004.59;10.1109/VISUAL.1991.175792;10.1109/TVCG.2012.216;10.1109/VISUAL.1999.809918;10.1109/VISUAL.1998.745317;10.1109/VISUAL.2005.1532772;10.1109/TVCG.2009.138;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1996.567777	Flow visualization;3D vector fields;Cutting planes;Glyphs;Perception;Evaluation;Human factors	0	0	0	47	
VAST	2016	Toward Theoretical Techniques for Measuring the Use of Human Effort in Visual Analytic Systems	10.1109/TVCG.2016.2598460	http://dx.doi.org/10.1109/TVCG.2016.2598460	121	130	J	Visual analytic systems have long relied on user studies and standard datasets to demonstrate advances to the state of the art, as well as to illustrate the efficiency of solutions to domain-specific challenges. This approach has enabled some important comparisons between systems, but unfortunately the narrow scope required to facilitate these comparisons has prevented many of these lessons from being generalized to new areas. At the same time, advanced visual analytic systems have made increasing use of human-machine collaboration to solve problems not tractable by machine computation alone. To continue to make progress in modeling user tasks in these hybrid visual analytic systems, we must strive to gain insight into what makes certain tasks more complex than others. This will require the development of mechanisms for describing the balance to be struck between machine and human strengths with respect to analytical tasks and workload. In this paper, we argue for the necessity of theoretical tools for reasoning about such balance in visual analytic systems and demonstrate the utility of the Human Oracle Model for this purpose in the context of sensemaking in visual analytics. Additionally, we make use of the Human Oracle Model to guide the development of a new system through a case study in the domain of cybersecurity.	R. Jordan Crouser;Lyndsey Franklin;Alex Endert;Kristin A. Cook	R. Jordan Crouser;Lyndsey Franklin;Alex Endert;Kris Cook	Smith College;Smith College;Smith College;Smith College	10.1109/VAST.2011.6102467;10.1109/VAST.2010.5652910;10.1109/VAST.2011.6102438;10.1109/TVCG.2012.195;10.1109/VAST.2015.7347625;10.1109/VAST.2007.4389009;10.1109/VAST.2011.6102449;10.1109/VAST.2012.6400486	Theoretical models;human oracle;visual analytics;mixed initiative systems;semantic interaction;sensemaking	4	8	7	87	
VAST	2016	AnaFe: Visual Analytics of Image-derived Temporal Features Focusing on the Spleen	10.1109/TVCG.2016.2598463	http://dx.doi.org/10.1109/TVCG.2016.2598463	171	180	J	We present a novel visualization framework, AnaFe, targeted at observing changes in the spleen over time through multiple image-derived features. Accurate monitoring of progressive changes is crucial for diseases that result in enlargement of the organ. Our system is comprised of multiple linked views combining visualization of temporal 3D organ data, related measurements, and features. Thus it enables the observation of progression and allows for simultaneous comparison within and between the subjects. AnaFe offers insights into the overall distribution of robustly extracted and reproducible quantitative imaging features and their changes within the population, and also enables detailed analysis of individual cases. It performs similarity comparison of temporal series of one subject to all other series in both sick and healthy groups. We demonstrate our system through two use case scenarios on a population of 189 spleen datasets from 68 subjects with various conditions observed over time.	Ievgeniia Gutenko;Konstantin Dmitriev;Arie E. Kaufman;Matthew Barish	Ievgeniia Gutenko;Konstantin Dmitriev;Arie E. Kaufman;Matthew A. Barish	Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY	10.1109/TVCG.2014.2346591;10.1109/TVCG.2009.152;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.225;10.1109/VISUAL.2000.885739;10.1109/TVCG.2013.200;10.1109/VAST.2006.261421	Visual Knowledge Discovery;Temporal Feature Analysis;Radiomics;Spleen;Abdominal Imaging	0	0	0	48	
VAST	2016	NameClarifier: A Visual Analytics System for Author Name Disambiguation	10.1109/TVCG.2016.2598465	http://dx.doi.org/10.1109/TVCG.2016.2598465	141	150	J	In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.	Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui	Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research	10.1109/TVCG.2012.252;10.1109/TVCG.2011.188;10.1109/VAST.2006.261429	Name disambiguation;analytical reasoning	4	9	10	41	
VAST	2016	Visualizing Dimension Coverage to Support Exploratory Analysis	10.1109/TVCG.2016.2598466	http://dx.doi.org/10.1109/TVCG.2016.2598466	21	30	J	Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.	Ali Sarvghad;Melanie Tory;Narges Mahyar	Ali Sarvghad;Melanie Tory;Narges Mahyar	University of Victoria;Tableau Research;University of British Columbia	10.1109/TVCG.2015.2467191;10.1109/TVCG.2006.120;10.1109/INFVIS.1999.801862;10.1109/INFVIS.2000.885086;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346452;10.1109/VAST.2009.5333020;10.1109/INFVIS.2001.963289;10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/VISUAL.1993.398857;10.1109/TVCG.2007.70589;10.1109/TVCG.2013.167;10.1109/TVCG.2008.109	Dimension coverage;Tabular data;History;Empirical laboratory study;Exploratory data analysis;Scented widgets	8	16	13	33	
VAST	2016	Magnostics: Image-Based Search of Interesting Matrix Views for Guided Network Exploration	10.1109/TVCG.2016.2598467	http://dx.doi.org/10.1109/TVCG.2016.2598467	31	40	J	In this work we address the problem of retrieving potentially interesting matrix views to support the exploration of networks. We introduce Matrix Diagnostics (or Magnostics), following in spirit related approaches for rating and ranking other visualization techniques, such as Scagnostics for scatter plots. Our approach ranks matrix views according to the appearance of specific visual patterns, such as blocks and lines, indicating the existence of topological motifs in the data, such as clusters, bi-graphs, or central nodes. Magnostics can be used to analyze, query, or search for visually similar matrices in large collections, or to assess the quality of matrix reordering algorithms. While many feature descriptors for image analyzes exist, there is no evidence how they perform for detecting patterns in matrices. In order to make an informed choice of feature descriptors for matrix diagnostics, we evaluate 30 feature descriptors-27 existing ones and three new descriptors that we designed specifically for MAGNOSTICS-with respect to four criteria: pattern response, pattern variability, pattern sensibility, and pattern discrimination. We conclude with an informed set of six descriptors as most appropriate for Magnostics and demonstrate their application in two scenarios; exploring a large collection of matrices and analyzing temporal networks.	Michael Behrisch 0001;Benjamin Bach;Michael Blumenschein;Michael Delz;Laura von Rüden;Jean-Daniel Fekete;Tobias Schreck	Michael Behrisch;Benjamin Bach;Michael Hund;Michael Delz;Laura Von Rüden;Jean-Daniel Fekete;Tobias Schreck	University of Konstanz, Germany;Microsoft Research-Inria Joint Centre, Saclay, France;University of Konstanz, Germany;University of Konstanz, Germany;Capgemini, RWTH Aachen University;Inria, Saclay, France;Graz University of Technology, Austria	10.1109/VAST.2012.6400488;10.1109/INFVIS.2004.15;10.1109/VAST.2014.7042480;10.1109/VAST.2010.5652433;10.1109/TVCG.2010.184;10.1109/VAST.2006.261423;10.1109/TVCG.2007.70582;10.1109/TVCG.2007.70535;10.1109/TVCG.2011.229;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3	Matrix Visualization;Visual Quality Measures;Quality Metrics;Feature Detection/Selection;Relational Data	6	13	11	49	
VAST	2016	Characterizing Guidance in Visual Analytics	10.1109/TVCG.2016.2598468	http://dx.doi.org/10.1109/TVCG.2016.2598468	111	120	J	Visual analytics (VA) is typically applied in scenarios where complex data has to be analyzed. Unfortunately, there is a natural correlation between the complexity of the data and the complexity of the tools to study them. An adverse effect of complicated tools is that analytical goals are more difficult to reach. Therefore, it makes sense to consider methods that guide or assist users in the visual analysis process. Several such methods already exist in the literature, yet we are lacking a general model that facilitates in-depth reasoning about guidance. We establish such a model by extending van Wijk's model of visualization with the fundamental components of guidance. Guidance is defined as a process that gradually narrows the gap that hinders effective continuation of the data analysis. We describe diverse inputs based on which guidance can be generated and discuss different degrees of guidance and means to incorporate guidance into VA tools. We use existing guidance approaches from the literature to illustrate the various aspects of our model. As a conclusion, we identify research challenges and suggest directions for future studies. With our work we take a necessary step to pave the way to a systematic development of guidance techniques that effectively support users in the context of VA.	Davide Ceneda;Theresia Gschwandtner;Thorsten May;Silvia Miksch;Hans-Jörg Schulz;Marc Streit;Christian Tominski	Davide Ceneda;Theresia Gschwandtner;Thorsten May;Silvia Miksch;Hans-Jörg Schulz;Marc Streit;Christian Tominski	Vienna University of Technology, Austria;Vienna University of Technology, Austria;Fraunhofer IGD, Darmstadt, Germany;Vienna University of Technology, Austria;University of Rostock, Germany;Johannes Kepler University, Linz, Austria;University of Rostock, Germany	10.1109/VISUAL.2000.885678;10.1109/TVCG.2015.2467191;10.1109/VISUAL.1990.146375;10.1109/TVCG.2014.2346260;10.1109/TVCG.2014.2346481;10.1109/INFVIS.2004.2;10.1109/TVCG.2013.120;10.1109/VISUAL.1997.663889;10.1109/TVCG.2015.2467691;10.1109/VISUAL.2002.1183803;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.174;10.1109/TVCG.2014.2346482	Visual analytics;guidance model;assistance;user support	14	37	37	55	
VAST	2016	PhenoStacks: Cross-Sectional Cohort Phenotype Comparison Visualizations	10.1109/TVCG.2016.2598469	http://dx.doi.org/10.1109/TVCG.2016.2598469	191	200	J	Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design.	Michael Glueck;Alina Gvozdik;Fanny Chevalier;Azam Khan;Michael Brudno;Daniel J. Wigdor	Michael Glueck;Alina Gvozdik;Fanny Chevalier;Azam Khan;Michael Brudno;Daniel Wigdor	Autodesk ResearchUniversity of Toronto;University of Toronto;Inria;Autodesk Research;Hospital for Sick Children, University of Toronto, Toronto;University of Toronto	10.1109/TVCG.2014.2346248;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346279;10.1109/TVCG.2009.167;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467622;10.1109/TVCG.2015.2467733;10.1109/TVCG.2009.116	Cross-sectional cohort analysis;Phenotypes;Human Phenotype Ontology (HPO)	5	11	9	45	
VAST	2016	Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis	10.1109/TVCG.2016.2598470	http://dx.doi.org/10.1109/TVCG.2016.2598470	131	140	J	In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data.	Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser	Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser	City University, London, UK;Sabanci University, Turkey;Sabanci University, Turkey;University of Bergen, Norway	10.1109/TVCG.2007.70539;10.1109/VAST.2008.4677361;10.1109/TVCG.2008.153;10.1109/TVCG.2014.2346481;10.1109/TVCG.2014.2346574;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.213;10.1109/TVCG.2013.125;10.1109/TVCG.2012.256;10.1109/VAST.2008.4677357;10.1109/TVCG.2015.2467613;10.1109/TVCG.2014.2346265;10.1109/TVCG.2011.178;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1996.559223;10.1109/TVCG.2011.229;10.1109/TVCG.2008.125	Progressive analytics;high dimensional data;iterative refinement;visual analytics	16	24	24	48	
VAST	2016	A Grammar-based Approach for Modeling User Interactions and Generating Suggestions During the Data Exploration Process	10.1109/TVCG.2016.2598471	http://dx.doi.org/10.1109/TVCG.2016.2598471	41	50	J	Despite the recent popularity of visual analytics focusing on big data, little is known about how to support users that use visualization techniques to explore multi-dimensional datasets and accomplish specific tasks. Our lack of models that can assist end-users during the data exploration process has made it challenging to learn from the user's interactive and analytical process. The ability to model how a user interacts with a specific visualization technique and what difficulties they face are paramount in supporting individuals with discovering new patterns within their complex datasets. This paper introduces the notion of visualization systems understanding and modeling user interactions with the intent of guiding a user through a task thereby enhancing visual data exploration. The challenges faced and the necessary future steps to take are discussed; and to provide a working example, a grammar-based model is presented that can learn from user interactions, determine the common patterns among a number of subjects using a K-Reversible algorithm, build a set of rules, and apply those rules in the form of suggestions to new users with the goal of guiding them along their visual analytic process. A formal evaluation study with 300 subjects was performed showing that our grammar-based model is effective at capturing the interactive process followed by users and that further research in this area has the potential to positively impact how users interact with a visualization system.	Filip Dabek;Jesus J. Caban	Filip Dabek;Jesus J Caban	National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD;National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD	10.1109/TVCG.2014.2346575;10.1109/TVCG.2015.2467613;10.1109/VAST.2010.5650854;10.1109/TVCG.2015.2467871;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.219;10.1109/VAST.2009.5333020;10.1109/VAST.2006.261436;10.1109/TVCG.2015.2467611;10.1109/TVCG.2015.2467551;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70589	Machine Learning;Visual Analytics;User Interactions;Analytic Provenance	6	12	9	41	
VAST	2016	Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation	10.1109/TVCG.2016.2598472	http://dx.doi.org/10.1109/TVCG.2016.2598472	181	190	J	Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.	Xinsong Yang;Lei Shi;Madelaine Daianu;Hanghang Tong;Qingsong Liu;Paul M. Thompson	Xinsong Yang;Lei Shi;Madelaine Daianu;Hanghang Tong;Qingsong Liu;Paul Thompson	Chinese Academy of Sciences, SKLCSInstitute of Software;Chinese Academy of Sciences, SKLCSInstitute of Software;Imaging Genetics CenterMark &#x0026; Mary Stevens Institute for Neuroimaging &#x0026; InformaticsUniversity of Southern California;School of Computing, Informatics and Decision Systems EngineeringArizona State University;Chinese Academy of Sciences, SKLCSInstitute of Software;Imaging Genetics CenterMark &#x0026; Mary Stevens Institute for Neuroimaging &#x0026; InformaticsUniversity of Southern California	10.1109/TVCG.2014.2346312;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2007.70582	Brain Network;Visual Comparison;Hybrid Representation	10	17	13	42	
VAST	2016	A Visual Analytics Approach for Categorical Joint Distribution Reconstruction from Marginal Projections	10.1109/TVCG.2016.2598479	http://dx.doi.org/10.1109/TVCG.2016.2598479	51	60	J	Oftentimes multivariate data are not available as sets of equally multivariate tuples, but only as sets of projections into subspaces spanned by subsets of these attributes. For example, one may find data with five attributes stored in six tables of two attributes each, instead of a single table of five attributes. This prohibits the visualization of these data with standard high-dimensional methods, such as parallel coordinates or MDS, and there is hence the need to reconstruct the full multivariate (joint) distribution from these marginal ones. Most of the existing methods designed for this purpose use an iterative procedure to estimate the joint distribution. With insufficient marginal distributions and domain knowledge, they lead to results whose joint errors can be large. Moreover, enforcing smoothness for regularizations in the joint space is not applicable if the attributes are not numerical but categorical. We propose a visual analytics approach that integrates both anecdotal data and human experts to iteratively narrow down a large set of plausible solutions. The solution space is populated using a Monte Carlo procedure which uniformly samples the solution space. A level-of-detail high dimensional visualization system helps the user understand the patterns and the uncertainties. Constraints that narrow the solution space can then be added by the user interactively during the iterative exploration, and eventually a subset of solutions with narrow uncertainty intervals emerges.	Cong Xie;Wen Zhong;Klaus Mueller	Cong Xie;Wen Zhong;Klaus Mueller	Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University	10.1109/TVCG.2010.181;10.1109/TVCG.2013.190;10.1109/VAST.2009.5332586;10.1109/TVCG.2015.2467552;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/TVCG.2011.248	Parallel Coordinates;Joint Distribution Reconstruction;Solution Space;High-dimensional Data;Multivariate Data	3	9	9	35	HM
VAST	2016	Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis	10.1109/TVCG.2016.2598495	http://dx.doi.org/10.1109/TVCG.2016.2598495	241	250	J	Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a “human in the loop” process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.	Dominik Sacha;Leishi Zhang;Michael Sedlmair;John A. Lee;Jaakko Peltonen;Daniel Weiskopf;Stephen C. North;Daniel A. Keim	Dominik Sacha;Leishi Zhang;Michael Sedlmair;John A. Lee;Jaakko Peltonen;Daniel Weiskopf;Stephen C. North;Daniel A. Keim	University of Konstanz, Germany;Middlesex University, UK;University of Vienna, Austria;SSS, IREC, MIRO, Université catholique de LouvainUCLBelgian F.R.S.-FNRS.;Helsinki Institute for Information Technology HIIT, Aalto University, University of Tampere, Finland;University of Konstanz, Germany;Infovisible LLC, Oldwick, U.S.A.;VISUS, University of Stuttgart, Germany	10.1109/TVCG.2012.195;10.1109/TVCG.2009.153;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346481;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/VAST.2008.4677350;10.1109/VAST.2009.5332629;10.1109/VAST.2010.5652443;10.1109/VAST.2014.7042492;10.1109/TVCG.2015.2467132;10.1109/TVCG.2015.2467553;10.1109/TVCG.2014.2346321;10.1109/TVCG.2013.153;10.1109/VAST.2010.5652484;10.1109/TVCG.2006.156;10.1109/TVCG.2015.2467717;10.1109/TVCG.2011.229;10.1109/TVCG.2013.124;10.1109/VAST.2010.5652392;10.1109/TVCG.2013.126	Interactive visualization;machine learning;visual analytics;dimensionality reduction	26	64	57	59	
InfoVis	2016	PowerSet: A Comprehensive Visualization of Set Intersections	10.1109/TVCG.2016.2598496	http://dx.doi.org/10.1109/TVCG.2016.2598496	361	370	J	When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques.	Bilal Alsallakh;Liu Ren	Bilal Alsallakh;Liu Ren	BOSCH Research;BOSCH Research	10.1109/TVCG.2014.2346248;10.1109/TVCG.2015.2467051;10.1109/TVCG.2006.142;10.1109/INFVIS.2001.963283;10.1109/TVCG.2010.186;10.1109/VISUAL.1991.175815;10.1109/TVCG.2012.233;10.1109/VISUAL.1993.398863;10.1109/TVCG.2011.227;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346249;10.1109/TVCG.2012.205;10.1109/TVCG.2008.144;10.1109/TVCG.2011.185;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186	scalability;Set visualization;treemaps;interaction	6	9	8	47	
VAST	2016	VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model	10.1109/TVCG.2016.2598497	http://dx.doi.org/10.1109/TVCG.2016.2598497	251	260	J	Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.	Bowen Yu;Cláudio T. Silva	Bowen Yu;Cláudio T. Silva	New York University;New York University	10.1109/TVCG.2009.195;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102440;10.1109/INFVIS.1998.729560;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.225;10.1109/INFVIS.2003.1249013;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346753;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346291	Visualization framework;data flow;subset flow model;tabular data	3	0	8	47	
InfoVis	2016	Investigating the Use of a Dynamic Physical Bar Chart for Data Exploration and Presentation	10.1109/TVCG.2016.2598498	http://dx.doi.org/10.1109/TVCG.2016.2598498	451	460	J	Physical data representations, or data physicalizations, are a promising new medium to represent and communicate data. Previous work mostly studied passive physicalizations which require humans to perform all interactions manually. Dynamic shape-changing displays address this limitation and facilitate data exploration tasks such as sorting, navigating in data sets which exceed the fixed size of a given physical display, or preparing “views” to communicate insights about data. However, it is currently unclear how people approach and interact with such data representations. We ran an exploratory study to investigate how non-experts made use of a dynamic physical bar chart for an open-ended data exploration and presentation task. We asked 16 participants to explore a data set on European values and to prepare a short presentation of their insights using a physical display. We analyze: (1) users' body movements to understand how they approach and react to the physicalization, (2) their hand-gestures to understand how they interact with physical data, (3) system interactions to understand which subsets of the data they explored and which features they used in the process, and (4) strategies used to explore the data and present observations. We discuss the implications of our findings for the use of dynamic data physicalizations and avenues for future work.	Faisal Taher;Yvonne Jansen;Jonathan Woodruff;John Hardy;Kasper Hornbæk;Jason Alexander	Faisal Taher;Yvonne Jansen;Jonathan Woodruff;John Hardy;Kasper Hornbæk;Jason Alexander	Lancaster University;University of Copenhagen;Lancaster University;Lancaster University;University of Copenhagen;Lancaster University	10.1109/TVCG.2014.2346292;10.1109/TVCG.2014.2352953;10.1109/TVCG.2013.124	Shape-changing displays;physicalization;physical visualization;bar charts;user behaviour;data presentation	7	12	9	33	
InfoVis	2016	booc.io: An Education System with Hierarchical Concept Maps and Dynamic Non-linear Learning Plans	10.1109/TVCG.2016.2598518	http://dx.doi.org/10.1109/TVCG.2016.2598518	571	580	J	Information hierarchies are difficult to express when real-world space or time constraints force traversing the hierarchy in linear presentations, such as in educational books and classroom courses. We present booc.io, which allows linear and non-linear presentation and navigation of educational concepts and material. To support a breadth of material for each concept, booc.io is Web based, which allows adding material such as lecture slides, book chapters, videos, and LTIs. A visual interface assists the creation of the needed hierarchical structures. The goals of our system were formed in expert interviews, and we explain how our design meets these goals. We adapt a real-world course into booc.io, and perform introductory qualitative evaluation with students.	Michail Schwab;Hendrik Strobelt;James Tompkin;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister	Michail Schwab;Hendrik Strobelt;James Tompkin;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister	Harvard Paulson SEAS;Harvard Paulson SEAS;Harvard Paulson SEAS;HarvardX;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Paulson SEAS	;10.1109/TVCG.2006.147	education;Hierarchies;information visualization	5	8	5	37	
InfoVis	2016	Quantifying the Visual Impact of Classification Boundaries in Choropleth Maps	10.1109/TVCG.2016.2598541	http://dx.doi.org/10.1109/TVCG.2016.2598541	371	380	J	One critical visual task when using choropleth maps is to identify spatial clusters in the data. If spatial units have the same color and are in the same neighborhood, this region can be visually identified as a spatial cluster. However, the choice of classification method used to create the choropleth map determines the visual output. The critical map elements in the classification scheme are those that lie near the classification boundary as those elements could potentially belong to different classes with a slight adjustment of the classification boundary. Thus, these elements have the most potential to impact the visual features (i.e., spatial clusters) that occur in the choropleth map. We present a methodology to enable analysts and designers to identify spatial regions where the visual appearance may be the result of spurious data artifacts. The proposed methodology automatically detects the critical boundary cases that can impact the overall visual presentation of the choropleth map using a classification metric of cluster stability. The map elements that belong to a critical boundary case are then automatically assessed to quantify the visual impact of classification edge effects. Our results demonstrate the impact of boundary elements on the resulting visualization and suggest that special attention should be given to these elements during map design.	Yifan Zhang 0007;Ross Maciejewski	Yifan Zhang;Ross Maciejewski	Arizona State University;Arizona State University	10.1109/VAST.2009.5332584;10.1109/TVCG.2012.233;10.1109/TVCG.2011.197	Choropleth;Classification;Visualization;Geodemographics;Geovisualization	3	4	4	52	
InfoVis	2016	Small Multiples with Gaps	10.1109/TVCG.2016.2598542	http://dx.doi.org/10.1109/TVCG.2016.2598542	381	390	J	Small multiples enable comparison by providing different views of a single data set in a dense and aligned manner. A common frame defines each view, which varies based upon values of a conditioning variable. An increasingly popular use of this technique is to project two-dimensional locations into a gridded space (e.g. grid maps), using the underlying distribution both as the conditioning variable and to determine the grid layout. Using whitespace in this layout has the potential to carry information, especially in a geographic context. Yet, the effects of doing so on the spatial properties of the original units are not understood. We explore the design space offered by such small multiples with gaps. We do so by constructing a comprehensive suite of metrics that capture properties of the layout used to arrange the small multiples for comparison (e.g. compactness and alignment) and the preservation of the original data (e.g. distance, topology and shape). We study these metrics in geographic data sets with varying properties and numbers of gaps. We use simulated annealing to optimize for each metric and measure the effects on the others. To explore these effects systematically, we take a new approach, developing a system to visualize this design space using a set of interactive matrices. We find that adding small amounts of whitespace to small multiple arrays improves some of the characteristics of 2D layouts, such as shape, distance and direction. This comes at the cost of other metrics, such as the retention of topology. Effects vary according to the input maps, with degree of variation in size of input regions found to be a factor. Optima exist for particular metrics in many cases, but at different amounts of whitespace for different maps. We suggest multiple metrics be used in optimized layouts, finding topology to be a primary factor in existing manually-crafted solutions, followed by a trade-off between shape and displacement. But the rich range of possible optimized layouts leads us to challenge single-solution thinking; we suggest to consider alternative optimized layouts for small multiples with gaps. Key to our work is the systematic, quantified and visual approach to exploring design spaces when facing a trade-off between many competing criteria-an approach likely to be of value to the analysis of other design spaces.	Wouter Meulemans;Jason Dykes;Aidan Slingsby;Cagatay Turkay;Jo Wood	Wouter Meulemans;Jason Dykes;Aidan Slingsby;Cagatay Turkay;Jo Wood	giCentre, City University, London;giCentre, City University, London;giCentre, City University, London;giCentre, City University, London;giCentre, City University, London	10.1109/TVCG.2014.2346276;10.1109/TVCG.2011.174;10.1109/TVCG.2016.2598862;10.1109/TVCG.2008.165	Geographic visualization;small multiples;whitespace;design space;metrics;optimization	4	13	9	41	
VAST	2016	Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations	10.1109/TVCG.2016.2598543	http://dx.doi.org/10.1109/TVCG.2016.2598543	261	270	J	User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst's manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.	Jian Zhao 0010;Michael Glueck;Simon Breslav;Fanny Chevalier;Azam Khan	Jian Zhao;Michael Glueck;Simon Breslav;Fanny Chevalier;Azam Khan	Autodesk Research;Autodesk Research;Autodesk Research;INRIA;Autodesk Research	10.1109/VAST.2009.5333878;10.1109/TVCG.2015.2467871;10.1109/VAST.2009.5333023;10.1109/VAST.2011.6102447;10.1109/TVCG.2008.137;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.124;10.1109/TVCG.2007.70577;10.1109/VAST.2010.5652879	Externalization user-authored annotation;exploratory sequential data analysis;graph-based visualization	5	11	11	39	
VAST	2016	Familiarity Vs Trust: A Comparative Study of Domain Scientists' Trust in Visual Analytics and Conventional Analysis Methods	10.1109/TVCG.2016.2598544	http://dx.doi.org/10.1109/TVCG.2016.2598544	271	280	J	Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts' trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems.	Aritra Dasgupta;Joon-Yong Lee;Ryan Wilson;Robert A. Lafrance;Nick Cramer;Kristin A. Cook;Samuel H. Payne	Aritra Dasgupta;Joon-Yong Lee;Ryan Wilson;Robert A. Lafrance;Nick Cramer;Kristin Cook;Samuel Payne	Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory	10.1109/TVCG.2015.2467591;10.1109/VAST.2015.7347625;10.1109/TVCG.2012.224;10.1109/INFVIS.2005.1532136;10.1109/VAST.2006.261416;10.1109/TVCG.2013.124;10.1109/TVCG.2013.120	trust;transparency;familiarity;uncertainty;biological data analysis	6	14	9	41	
VAST	2016	What do Constraint Programming Users Want to See? Exploring the Role of Visualisation in Profiling of Models and Search	10.1109/TVCG.2016.2598545	http://dx.doi.org/10.1109/TVCG.2016.2598545	281	290	J	Constraint programming allows difficult combinatorial problems to be modelled declaratively and solved automatically. Advances in solver technologies over recent years have allowed the successful use of constraint programming in many application areas. However, when a particular solver's search for a solution takes too long, the complexity of the constraint program execution hinders the programmer's ability to profile that search and understand how it relates to their model. Therefore, effective tools to support such profiling and allow users of constraint programming technologies to refine their model or experiment with different search parameters are essential. This paper details the first user-centred design process for visual profiling tools in this domain. We report on: our insights and opportunities identified through an on-line questionnaire and a creativity workshop with domain experts carried out to elicit requirements for analytical and visual profiling techniques; our designs and functional prototypes realising such techniques; and case studies demonstrating how these techniques shed light on the behaviour of the solvers in practice.	Sarah Goodwin;Christopher Mears;Tim Dwyer;Maria Garcia de la Banda;Guido Tack;Mark Wallace 0001	Sarah Goodwin;Christopher Mears;Tim Dwyer;Maria Garcia de la Banda;Guido Tack;Mark Wallace	Adaptive Visualisation LabMonash University;Faculty of Information Technology, Monash University;Adaptive Visualisation LabMonash University;Faculty of Information Technology, Monash University;Faculty of Information Technology, Monash University;Faculty of Information Technology, Monash University	10.1109/TVCG.2013.145;10.1109/TVCG.2014.2346321;10.1109/TVCG.2015.2467751;10.1109/INFVIS.2004.70;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.151;10.1109/TVCG.2015.2467851;10.1109/INFVIS.2000.885103	visual analytics;user-centred design;profiling;constraint programming;tree visualisations	5	8	8	39	
SciVis	2016	Urban Pulse: Capturing the Rhythm of Cities	10.1109/TVCG.2016.2598585	http://dx.doi.org/10.1109/TVCG.2016.2598585	791	800	J	Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an “urban pulse” which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.	Fábio Miranda;Harish Doraiswamy;Marcos Lage;Kai Zhao;Bruno Gonçalves;Luc Wilson;Mondrian Hsieh;Cláudio T. Silva	Fabio Miranda;Harish Doraiswamy;Marcos Lage;Kai Zhao;Bruno Gonçalves;Luc Wilson;Mondrian Hsieh;Cláudio T. Silva	New York University;New York University;Universidade Federal Fluminense;New York University;New York University;Kohn Pedersen Fox Associates PC;Kohn Pedersen Fox Associates PC;New York University	10.1109/TVCG.2015.2467592;10.1109/VAST.2015.7347636;10.1109/TVCG.2014.2346898;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/TVCG.2015.2467619;10.1109/TVCG.2015.2467194;10.1109/VAST.2015.7347630;10.1109/TVCG.2011.181;10.1109/TVCG.2013.131;10.1109/TVCG.2015.2468111;10.1109/TVCG.2014.2346449	Topology-based techniques;urban data;visual exploration	9	29	21	53	
InfoVis	2016	Exploring the Possibilities of Embedding Heterogeneous Data Attributes in Familiar Visualizations	10.1109/TVCG.2016.2598586	http://dx.doi.org/10.1109/TVCG.2016.2598586	581	590	J	Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering.	Mona Hosseinkhani Loorak;Charles Perin;Christopher Collins 0001;Sheelagh Carpendale	Mona Hosseinkhani Loorak;Charles Perin;Christopher Collins;Sheelagh Carpendale	Department of Computer Science, University of Calgary;Department of Computer Science, University of Calgary;University of Ontario;Department of Computer Science, University of Calgary	10.1109/TVCG.2014.2346248;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2005.1532151;10.1109/INFVIS.2005.1532129;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.179;10.1109/INFVIS.2003.1249016;10.1109/TVCG.2010.205;10.1109/TVCG.2013.227;10.1109/TVCG.2013.210;10.1109/TVCG.2011.201;10.1109/TVCG.2015.2467325;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346279;10.1109/TVCG.2013.192;10.1109/TVCG.2013.167;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2011.186	Multi-dimensional data;Hybrid visualization	5	8	6	54	
InfoVis	2016	Screenit: Visual Analysis of Cellular Screens	10.1109/TVCG.2016.2598587	http://dx.doi.org/10.1109/TVCG.2016.2598587	591	600	J	High-throughput and high-content screening enables large scale, cost-effective experiments in which cell cultures are exposed to a wide spectrum of drugs. The resulting multivariate data sets have a large but shallow hierarchical structure. The deepest level of this structure describes cells in terms of numeric features that are derived from image data. The subsequent level describes enveloping cell cultures in terms of imposed experiment conditions (exposure to drugs). We present Screenit, a visual analysis approach designed in close collaboration with screening experts. Screenit enables the navigation and analysis of multivariate data at multiple hierarchy levels and at multiple levels of detail. Screenit integrates the interactive modeling of cell physical states (phenotypes) and the effects of drugs on cell cultures (hits). In addition, quality control is enabled via the detection of anomalies that indicate low-quality data, while providing an interface that is designed to match workflows of screening experts. We demonstrate analyses for a real-world data set, CellMorph, with 6 million cells across 20,000 cell cultures.	Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister	Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister	Harvard University;Harvard University;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Harvard University	10.1109/VAST.2012.6400492;10.1109/TVCG.2014.2346752;10.1109/TVCG.2015.2466971;10.1109/TVCG.2011.253;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.213;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.173;10.1109/VAST.2011.6102453;10.1109/TVCG.2014.2346482	High-content screening;visual analysis;feature selection;image classification;biology;multivariate;hierarchy	0	1	3	48	
InfoVis	2016	PROACT: Iterative Design of a Patient-Centered Visualization for Effective Prostate Cancer Health Risk Communication	10.1109/TVCG.2016.2598588	http://dx.doi.org/10.1109/TVCG.2016.2598588	601	610	J	Prostate cancer is the most common cancer among men in the US, and yet most cases represent localized cancer for which the optimal treatment is unclear. Accumulating evidence suggests that the available treatment options, including surgery and conservative treatment, result in a similar prognosis for most men with localized prostate cancer. However, approximately 90% of patients choose surgery over conservative treatment, despite the risk of severe side effects like erectile dysfunction and incontinence. Recent medical research suggests that a key reason is the lack of patient-centered tools that can effectively communicate personalized risk information and enable them to make better health decisions. In this paper, we report the iterative design process and results of developing the PROgnosis Assessment for Conservative Treatment (PROACT) tool, a personalized health risk communication tool for localized prostate cancer patients. PROACT utilizes two published clinical prediction models to communicate the patients' personalized risk estimates and compare treatment options. In collaboration with the Maine Medical Center, we conducted two rounds of evaluations with prostate cancer survivors and urologists to identify the design elements and narrative structure that effectively facilitate patient comprehension under emotional distress. Our results indicate that visualization can be an effective means to communicate complex risk information to patients with low numeracy and visual literacy. However, the visualizations need to be carefully chosen to balance readability with ease of comprehension. In addition, due to patients' charged emotional state, an intuitive narrative structure that considers the patients' information need is critical to aid the patients' comprehension of their risk information.	Anzu Hakone;Lane Harrison;Alvitta Ottley;Nathan Winters;Caitlin Gutheil;Paul K. J. Han;Remco Chang	Anzu Hakone;Lane Harrison;Alvitta Ottley;Nathan Winters;Caitlin Gutheil;Paul K. J. Han;Remco Chang	Tufts University;Worcester Polytechnic Institute;Tufts University;Tufts University;Maine Medical Center;Maine Medical Center;Tufts University	10.1109/TVCG.2012.225;10.1109/TVCG.2013.200;10.1109/TVCG.2014.2346984;10.1109/TVCG.2015.2467758;10.1109/TVCG.2012.219;10.1109/TVCG.2014.2346682	Design studies;task and requirement analysis;presentation;production;and dissemination;medical visualization	1	6	4	54	
InfoVis	2016	WeightLifter: Visual Weight Space Exploration for Multi-Criteria Decision Making	10.1109/TVCG.2016.2598589	http://dx.doi.org/10.1109/TVCG.2016.2598589	611	620	J	A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is WeightLifter, a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions.	Stephan Pajer;Marc Streit;Thomas Torsney-Weir;Florian Spechtenhauser;Torsten Möller;Harald Piringer	Stephan Pajer;Marc Streit;Thomas Torsney-Weir;Florian Spechtenhauser;Torsten Möller;Harald Piringer	VRVis Research Center;University Linz;University of Vienna;VRVis Research Center;University of Vienna;VRVis Research Center	10.1109/TVCG.2015.2468011;10.1109/TVCG.2013.147;10.1109/VAST.2015.7347686;10.1109/VISUAL.1993.398859;10.1109/TVCG.2008.145;10.1109/VAST.2011.6102457;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2010.190;10.1109/TVCG.2009.110;10.1109/VAST.2010.5652460;10.1109/TVCG.2013.173;10.1109/TVCG.2011.248;10.1109/TVCG.2009.111	Visual analysis;decision making;multi-objective optimization;interactive ranking;rank sensitivity	9	20	19	41	
InfoVis	2016	Visualizing Social Media Content with SentenTree	10.1109/TVCG.2016.2598590	http://dx.doi.org/10.1109/TVCG.2016.2598590	621	630	J	We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.	Mengdie Hu;Krist Wongsuphasawat;John T. Stasko	Mengdie Hu;Krist Wongsuphasawat;John Stasko	Georgia Institute of Technology;Twitter Inc.;Georgia Institute of Technology	10.1109/TVCG.2009.171;10.1109/TVCG.2008.172;10.1109/VAST.2009.5333443;10.1109/INFVIS.1995.528686;10.1109/TVCG.2010.154;10.1109/VAST.2012.6400485;10.1109/TVCG.2011.179;10.1109/TVCG.2010.194;10.1109/TVCG.2013.221;10.1109/TVCG.2006.156;10.1109/TVCG.2009.165;10.1109/VAST.2011.6102488;10.1109/TVCG.2014.2346920;10.1109/TVCG.2015.2467991;10.1109/TVCG.2011.239	text visualization;social media;natural language processing;word cloud;Twitter	10	0	15	46	
InfoVis	2016	Optimizing Hierarchical Visualizations with the Minimum Description Length Principle	10.1109/TVCG.2016.2598591	http://dx.doi.org/10.1109/TVCG.2016.2598591	631	640	J	In this paper we examine how the Minimum Description Length (MDL) principle can be used to efficiently select aggregated views of hierarchical datasets that feature a good balance between clutter and information. We present MDL formulae for generating uneven tree cuts tailored to treemap and sunburst diagrams, taking into account the available display space and information content of the data. We present the results of a proof-of-concept implementation. In addition, we demonstrate how such tree cuts can be used to enhance drill-down interaction in hierarchical visualizations by implementing our approach in an existing visualization tool. Validation is done with the feature congestion measure of clutter in views of a subset of the current DMOZ web directory, which contains nearly half million categories. The results show that MDL views achieve near constant clutter level across display resolutions. We also present the results of a crowdsourced user study where participants were asked to find targets in views of DMOZ generated by our approach and a set of baseline aggregation methods. The results suggest that, in some conditions, participants are able to locate targets (in particular, outliers) faster using the proposed approach.	Rafael Veras;Christopher Collins 0001	Rafael Veras;Christopher Collins	University of OntarioInstitute of Technology;University of OntarioInstitute of Technology	10.1109/TVCG.2006.120;10.1109/TVCG.2007.70535;10.1109/INFVIS.1998.729557;10.1109/TVCG.2006.184;10.1109/TVCG.2012.233;10.1109/TVCG.2006.161	antichain;Hierarchy data;data aggregation;multiscale visualization;tree cut	4	6	6	33	
InfoVis	2016	Visplause: Visual Data Quality Assessment of Many Time Series Using Plausibility Checks	10.1109/TVCG.2016.2598592	http://dx.doi.org/10.1109/TVCG.2016.2598592	641	650	J	Trends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ.	Clemens Arbesser;Florian Spechtenhauser;Thomas Mühlbacher;Harald Piringer	Clemens Arbesser;Florian Spechtenhauser;Thomas Mühlbacher;Harald Piringer	VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria	10.1109/TVCG.2014.2346248;10.1109/TVCG.2012.213;10.1109/TVCG.2012.256;10.1109/TVCG.2014.2346260;10.1109/VAST.2011.6102458;10.1109/TVCG.2009.110;10.1109/TVCG.2015.2466971	Data Quality Assessment;High-Dimensional Data;Hierarchical Aggregation;Linked Views	4	11	12	49	
InfoVis	2016	The Attraction Effect in Information Visualization	10.1109/TVCG.2016.2598594	http://dx.doi.org/10.1109/TVCG.2016.2598594	471	480	J	The attraction effect is a well-studied cognitive bias in decision making research, where one's choice between two alternatives is influenced by the presence of an irrelevant (dominated) third alternative. We examine whether this cognitive bias, so far only tested with three alternatives and simple presentation formats such as numerical tables, text and pictures, also appears in visualizations. Since visualizations can be used to support decision making - e.g., when choosing a house to buy or an employee to hire - a systematic bias could have important implications. In a first crowdsource experiment, we indeed partially replicated the attraction effect with three alternatives presented as a numerical table, and observed similar effects when they were presented as a scatterplot. In a second experiment, we investigated if the effect extends to larger sets of alternatives, where the number of alternatives is too large for numerical tables to be practical. Our findings indicate that the bias persists for larger sets of alternatives presented as scatterplots. We discuss implications for future research on how to further study and possibly alleviate the attraction effect.	Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic	Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic	Inria and Universit&#x00E9; Paris-Saclay;Inria, Univ Paris-Sud &#x0026; CNRS (LRI)Universit&#x00E9; Paris-Saclay;Inria and Universit&#x00E9; Paris-Saclay	10.1109/TVCG.2008.153;10.1109/TVCG.2014.2346984;10.1109/VAST.2008.4677363;10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.199;10.1109/TVCG.2010.174;10.1109/VAST.2009.5333920	cognitive bias;Information visualization;decision-making;decoy effect;attraction effect;asymmetric dominance effect	13	0	24	61	HM
SciVis	2016	Comparing Cross-Sections and 3D Renderings for Surface Matching Tasks Using Physical Ground Truths	10.1109/TVCG.2016.2598602	http://dx.doi.org/10.1109/TVCG.2016.2598602	781	790	J	Within the visualization community there are some well-known techniques for visualizing 3D spatial data and some general assumptions about how perception affects the performance of these techniques in practice. However, there is a lack of empirical research backing up the possible performance differences among the basic techniques for general tasks. One such assumption is that 3D renderings are better for obtaining an overview, whereas cross sectional visualizations such as the commonly used Multi-Planar Reformation (MPR) are better for supporting detailed analysis tasks. In the present study we investigated this common assumption by examining the difference in performance between MPR and 3D rendering for correctly identifying a known surface. We also examined whether prior experience working with image data affects the participant's performance, and whether there was any difference between interactive or static versions of the visualizations. Answering this question is important because it can be used as part of a scientific and empirical basis for determining when to use which of the two techniques. An advantage of the present study compared to other studies is that several factors were taken into account to compare the two techniques. The problem was examined through an experiment with 45 participants, where physical objects were used as the known surface (ground truth). Our findings showed that: 1. The 3D renderings largely outperformed the cross sections; 2. Interactive visualizations were partially more effective than static visualizations; and 3. The high experience group did not generally outperform the low experience group.	Andreas J. Lind;Stefan Bruckner	Andreas J. Lind;Stefan Bruckner	University of Bergen, Norway;University of Bergen, Norway	10.1109/TVCG.2007.70569;10.1109/TVCG.2011.161;10.1109/TVCG.2013.121;10.1109/TVCG.2008.108;10.1109/VISUAL.2005.1532856;10.1109/SciVis.2015.7429485;10.1109/TVCG.2007.70542	Human-Computer Interaction;Quantitative Evaluation and Volume Visualization	0	2	1	46	
SciVis	2016	Visualization and Extraction of Carvings for Heritage Conservation	10.1109/TVCG.2016.2598603	http://dx.doi.org/10.1109/TVCG.2016.2598603	801	810	J	We present novel techniques for visualizing, illustrating, analyzing, and generating carvings in surfaces. In particular, we consider the carvings in the plaster of the cloister of the Magdeburg cathedral, which dates to the 13th century. Due to aging and weathering, the carvings have flattened. Historians and restorers are highly interested in using digitalization techniques to analyze carvings in historic artifacts and monuments and to get impressions and illustrations of their original shape and appearance. Moreover, museums and churches are interested in such illustrations for presenting them to visitors. The techniques that we propose allow for detecting, selecting, and visualizing carving structures. In addition, we introduce an example-based method for generating carvings. The resulting tool, which integrates all techniques, was evaluated by three experienced restorers to assess the usefulness and applicability. Furthermore, we compared our approach with exaggerated shading and other state-of-the-art methods.	Kai Lawonn;Erik Trostmann;Bernhard Preim;Klaus Hildebrandt	Kai Lawonn;Erik Trostmann;Bernhard Preim;Klaus Hildebrandt	University of Koblenz-Landau, Germany;Fraunhofer Institute for Factory Operation and Automation IFF, Germany;University of Magdeburg, Germany;Delft University of Technology, The Netherlands	10.1109/TVCG.2007.70538;10.1109/TVCG.2012.248	feature filtering;Feature extraction;heritage preservation;Frangi filter;surface analysis	5	6	3	42	
SciVis	2016	In Situ Distribution Guided Analysis and Visualization of Transonic Jet Engine Simulations	10.1109/TVCG.2016.2598604	http://dx.doi.org/10.1109/TVCG.2016.2598604	811	820	J	Study of flow instability in turbine engine compressors is crucial to understand the inception and evolution of engine stall. Aerodynamics experts have been working on detecting the early signs of stall in order to devise novel stall suppression technologies. A state-of-the-art Navier-Stokes based, time-accurate computational fluid dynamics simulator, TURBO, has been developed in NASA to enhance the understanding of flow phenomena undergoing rotating stall. Despite the proven high modeling accuracy of TURBO, the excessive simulation data prohibits post-hoc analysis in both storage and I/O time. To address these issues and allow the expert to perform scalable stall analysis, we have designed an in situ distribution guided stall analysis technique. Our method summarizes statistics of important properties of the simulation data in situ using a probabilistic data modeling scheme. This data summarization enables statistical anomaly detection for flow instability in post analysis, which reveals the spatiotemporal trends of rotating stall for the expert to conceive new hypotheses. Furthermore, the verification of the hypotheses and exploratory visualization using the summarized data are realized using probabilistic visualization techniques such as uncertain isocontouring. Positive feedback from the domain scientist has indicated the efficacy of our system in exploratory stall analysis.	Soumya Dutta;Chun-Ming Chen;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen	Soumya Dutta;Chun-Ming Chen;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen	The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University;The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University	10.1109/TVCG.2008.140;10.1109/TVCG.2013.152;10.1109/TVCG.2015.2467436;10.1109/TVCG.2007.70615;10.1109/TVCG.2015.2467952;10.1109/TVCG.2015.2467958;10.1109/TVCG.2015.2467411	In situ analysis;rotating stall analysis;Gaussian mixture model;incremental distribution modeling;feature analysis;high performance computing;collaborative development	4	18	11	52	HM
InfoVis	2016	Embedded Data Representations	10.1109/TVCG.2016.2598608	http://dx.doi.org/10.1109/TVCG.2016.2598608	461	470	J	We introduce embedded data representations, the use of visual and physical representations of data that are deeply integrated with the physical spaces, objects, and entities to which the data refers. Technologies like lightweight wireless displays, mixed reality hardware, and autonomous vehicles are making it increasingly easier to display data in-context. While researchers and artists have already begun to create embedded data representations, the benefits, trade-offs, and even the language necessary to describe and compare these approaches remain unexplored. In this paper, we formalize the notion of physical data referents - the real-world entities and spaces to which data corresponds - and examine the relationship between referents and the visual and physical representations of their data. We differentiate situated representations, which display data in proximity to data referents, and embedded representations, which display data so that it spatially coincides with data referents. Drawing on examples from visualization, ubiquitous computing, and art, we explore the role of spatial indirection, scale, and interaction for embedded representations. We also examine the tradeoffs between non-situated, situated, and embedded data displays, including both visualizations and physicalizations. Based on our observations, we identify a variety of design challenges for embedded data representation, and suggest opportunities for future research and applications.	Wesley Willett;Yvonne Jansen;Pierre Dragicevic	Wesley Willett;Yvonne Jansen;Pierre Dragicevic	University of Calgary;University of Copenhagen;Inria	10.1109/TVCG.2013.134;10.1109/INFVIS.1998.729560	augmented reality;Information visualization;data physicalization;ambient displays;ubiquitous computing	18	39	22	54	
InfoVis	2016	Iterating between Tools to Create and Edit Visualizations	10.1109/TVCG.2016.2598609	http://dx.doi.org/10.1109/TVCG.2016.2598609	481	490	J	A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.	Alex Bigelow;Steven Mark Drucker;Danyel Fisher;Miriah D. Meyer	Alex Bigelow;Steven Drucker;Danyel Fisher;Miriah Meyer	University of Utah;Microsoft Research;Microsoft Research;University of Utah	10.1109/TVCG.2014.2346292;10.1109/TVCG.2015.2467191;10.1109/TVCG.2014.2346291;10.1109/TVCG.2015.2467091;10.1109/INFVIS.2004.12;10.1109/TVCG.2011.209;10.1109/TVCG.2007.70584;10.1109/TVCG.2011.185	illustration;Visualization;iteration	11	0	14	32	
InfoVis	2016	Surprise! Bayesian Weighting for De-Biasing Thematic Maps	10.1109/TVCG.2016.2598618	http://dx.doi.org/10.1109/TVCG.2016.2598618	651	660	J	Thematic maps are commonly used for visualizing the density of events in spatial data. However, these maps can mislead by giving visual prominence to known base rates (such as population densities) or to artifacts of sample size and normalization (such as outliers arising from smaller, and thus more variable, samples). In this work, we adapt Bayesian surprise to generate maps that counter these biases. Bayesian surprise, which has shown promise for modeling human visual attention, weights information with respect to how it updates beliefs over a space of models. We introduce Surprise Maps, a visualization technique that weights event data relative to a set of spatia-temporal models. Unexpected events (those that induce large changes in belief over the model space) are visualized more prominently than those that follow expected patterns. Using both synthetic and real-world datasets, we demonstrate how Surprise Maps overcome some limitations of traditional event maps.	Michael Correll;Jeffrey Heer	Michael Correll;Jeffrey Heer	University of Washington;University of Washington	10.1109/TVCG.2014.2346248;10.1109/TVCG.2007.70561;10.1109/TVCG.2014.2346594;10.1109/TVCG.2014.2346325;10.1109/TVCG.2011.179;10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.199;10.1109/INFVIS.2001.963274;10.1109/TVCG.2015.2467758;10.1109/TVCG.2013.184	Thematic Maps;Bayesian Surprise;Event Visualization;Spatia-temporal data	3	8	7	47	
InfoVis	2016	Multi-Granular Trend Detection for Time-Series Analysis	10.1109/TVCG.2016.2598619	http://dx.doi.org/10.1109/TVCG.2016.2598619	661	670	J	Time series (such as stock prices) and ensembles (such as model runs for weather forecasts) are two important types of one-dimensional time-varying data. Such data is readily available in large quantities but visual analysis of the raw data quickly becomes infeasible, even for moderately sized data sets. Trend detection is an effective way to simplify time-varying data and to summarize salient information for visual display and interactive analysis. We propose a geometric model for trend-detection in one-dimensional time-varying data, inspired by topological grouping structures for moving objects in two- or higher-dimensional space. Our model gives provable guarantees on the trends detected and uses three natural parameters: granularity, support-size, and duration. These parameters can be changed on-demand. Our system also supports a variety of selection brushes and a time-sweep to facilitate refined searches and interactive visualization of (sub-)trends. We explore different visual styles and interactions through which trends, their persistence, and evolution can be explored.	Arthur van Goethem;Frank Staals;Maarten Löffler;Jason Dykes;Bettina Speckmann	Goethem Arthur Van;Frank Staals;Maarten Löffler;Jason Dykes;Bettina Speckmann	TU, Eindhoven;MADALGO, Aarhus University;Utrecht University;City University, London;TU, Eindhoven	10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/TVCG.2006.147;10.1109/TVCG.2014.2346448;10.1109/TVCG.2007.70558;10.1109/TVCG.2008.166;10.1109/TVCG.2008.125;10.1109/TVCG.2014.2346455	Interactive Exploration;Trend Detection;Time Series	1	3	4	41	
InfoVis	2016	Data-Driven Guides: Supporting Expressive Design for Information Graphics	10.1109/TVCG.2016.2598620	http://dx.doi.org/10.1109/TVCG.2016.2598620	491	500	J	In recent years, there is a growing need for communicating complex data in an accessible graphical form. Existing visualization creation tools support automatic visual encoding, but lack flexibility for creating custom design; on the other hand, freeform illustration tools require manual visual encoding, making the design process time-consuming and error-prone. In this paper, we present Data-Driven Guides (DDG), a technique for designing expressive information graphics in a graphic design environment. Instead of being confined by predefined templates or marks, designers can generate guides from data and use the guides to draw, place and measure custom shapes. We provide guides to encode data using three fundamental visual encoding channels: length, area, and position. Users can combine more than one guide to construct complex visual structures and map these structures to data. When underlying data is changed, we use a deformation technique to transform custom shapes using the guides as the backbone of the shapes. Our evaluation shows that data-driven guides allow users to create expressive and more accurate custom data-driven graphics.	Nam Wook Kim;Eston Schweickart;Zhicheng Liu;Mira Dontcheva;Wilmot Li;Jovan Popovic;Hanspeter Pfister	Nam Wook Kim;Eston Schweickart;Zhicheng Liu;Mira Dontcheva;Wilmot Li;Jovan Popovic;Hanspeter Pfister	John A. Paulson School of Engineering and Applied SciencesHarvard University;Computer Science department, Cornell University;Adobe Research;Adobe Research;Adobe Research;Adobe Research;John A. Paulson School of Engineering and Applied SciencesHarvard University	10.1109/TVCG.2014.2346292;10.1109/INFVIS.1996.559212;10.1109/TVCG.2011.175;10.1109/TVCG.2016.2598609;10.1109/TVCG.2013.234;10.1109/INFVIS.2004.64;10.1109/TVCG.2012.197;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2000.885093;10.1109/TVCG.2014.2346979;10.1109/TVCG.2014.2346320;10.1109/TVCG.2014.2346291;10.1109/TVCG.2015.2467732;10.1109/INFVIS.2004.12;10.1109/TVCG.2013.191;10.1109/TVCG.2011.251;10.1109/TVCG.2010.144;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577	Information graphics;visualization;design tools;2D graphics	14	30	21	55	
InfoVis	2016	Hashedcubes: Simple, Low Memory, Real-Time Visual Exploration of Big Data	10.1109/TVCG.2016.2598624	http://dx.doi.org/10.1109/TVCG.2016.2598624	671	680	J	We propose Hashedcubes, a data structure that enables real-time visual exploration of large datasets that improves the state of the art by virtue of its low memory requirements, low query latencies, and implementation simplicity. In some instances, Hashedcubes notably requires two orders of magnitude less space than recent data cube visualization proposals. In this paper, we describe the algorithms to build and query Hashedcubes, and how it can drive well-known interactive visualizations such as binned scatterplots, linked histograms and heatmaps. We report memory usage, build time and query latencies for a variety of synthetic and real-world datasets, and find that although sometimes Hashedcubes offers slightly slower querying times to the state of the art, the typical query is answered fast enough to easily sustain a interaction. In datasets with hundreds of millions of elements, only about 2% of the queries take longer than 40ms. Finally, we discuss the limitations of data structure, potential spacetime tradeoffs, and future research directions.	Cícero A. L. Pahins;Sean A. Stephens;Carlos Scheidegger;João Luiz Dihl Comba	Cícero A. L. Pahins;Sean A. Stephens;Carlos Scheidegger;João L. D. Comba	Instituto de InformáticaUFRGS;University of Arizona;University of Arizona;Instituto de InformáticaUFRGS	10.1109/TVCG.2013.179;10.1109/TVCG.2014.2346452;10.1109/TVCG.2014.2346574;10.1109/TVCG.2015.2467771	Scalability;data cube;multidimensional data;interactive exploration	15	32	18	45	
InfoVis	2016	Authoring Data-Driven Videos with DataClips	10.1109/TVCG.2016.2598647	http://dx.doi.org/10.1109/TVCG.2016.2598647	501	510	J	Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce DataClips, an authoring tool aimed at lowering the barriers to crafting data videos. DataClips allows non-experts to assemble data-driven “clips” together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that DataClips can reproduce over 90% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using DataClips, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use DataClips with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.	Fereshteh Amini;Nathalie Henry Riche;Bongshin Lee;Andrés Monroy-Hernández;Pourang Irani	Fereshteh Amini;Nathalie Henry Riche;Bongshin Lee;Andres Monroy-Hernandez;Pourang Irani	University of Manitoba, Canada;Microsoft;Microsoft;Microsoft;University of Manitoba, Canada	10.1109/TVCG.2007.70539;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992;10.1109/TVCG.2013.234;10.1109/TVCG.2013.119;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/VAST.2012.6400487	data video;narrative visualization;data storytelling;authoring tools;visualization systems	7	13	11	44	
VAST	2016	ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories	10.1109/TVCG.2016.2598664	http://dx.doi.org/10.1109/TVCG.2016.2598664	291	300	J	Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey's graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.	Panpan Xu;Honghui Mei;Liu Ren;Wei Chen 0001	Panpan Xu;Honghui Mei;Liu Ren;Wei Chen	Bosch Research North America;Zhejiang University;Bosch Research North America;Zhejiang University	10.1109/TVCG.2014.2346454;10.1109/TVCG.2015.2467592;10.1109/TVCG.2006.170;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.225;10.1109/TVCG.2013.200;10.1109/INFVIS.2002.1173149;10.1109/TVCG.2011.185	Temporal Data;Marey's Graph;Visual Analytics;Manufacturing;Smart Factory;Connected Industry;Industry 4.0	11	32	30	36	HM
InfoVis	2016	cite2vec: Citation-Driven Document Exploration via Word Embeddings	10.1109/TVCG.2016.2598667	http://dx.doi.org/10.1109/TVCG.2016.2598667	691	700	J	Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.	Matthew Berger;Katherine McDonough;Lee M. Seversky	Matthew Berger;Katherine McDonough;Lee M. Seversky	Air Force Research Laboratory;Northeastern University;Air Force Research Laboratory	10.1109/TVCG.2014.2346431;10.1109/VAST.2011.6102461;10.1109/TVCG.2011.220;10.1109/TVCG.2015.2467451;10.1109/TVCG.2010.207;10.1109/TVCG.2014.2346978;10.1109/TVCG.2015.2467757;10.1109/VAST.2009.5333428;10.1109/TVCG.2013.212;10.1109/TVCG.2015.2467621;10.1109/VAST.2014.7042493;10.1109/TVCG.2013.162;10.1109/TVCG.2009.202;10.1109/TVCG.2008.138	word embeddings;document visualization	7	22	21	44	
InfoVis	2016	Gaussian Cubes: Real-Time Modeling for Visual Exploration of Large Multidimensional Datasets	10.1109/TVCG.2016.2598694	http://dx.doi.org/10.1109/TVCG.2016.2598694	681	690	J	Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.	Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger	Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger	University of Arizona;Universidade Federal de Pernambuco;University of Arizona;University of Arizona;University of Arizona	10.1109/VAST.2008.4677357;10.1109/INFVIS.2000.885086;10.1109/TVCG.2013.179;10.1109/TVCG.2014.2346452;10.1109/TVCG.2009.129;10.1109/TVCG.2013.141;10.1109/TVCG.2014.2346325;10.1109/VAST.2012.6400490	data cubes;Data modeling;dimensionality reduction;interactive visualization	11	21	16	45	
VAST	2016	Visual Analytics for Mobile Eye Tracking	10.1109/TVCG.2016.2598695	http://dx.doi.org/10.1109/TVCG.2016.2598695	301	310	J	The analysis of eye tracking data often requires the annotation of areas of interest (AOIs) to derive semantic interpretations of human viewing behavior during experiments. This annotation is typically the most time-consuming step of the analysis process. Especially for data from wearable eye tracking glasses, every independently recorded video has to be annotated individually and corresponding AOIs between videos have to be identified. We provide a novel visual analytics approach to ease this annotation process by image-based, automatic clustering of eye tracking data integrated in an interactive labeling and analysis system. The annotation and analysis are tightly coupled by multiple linked views that allow for a direct interpretation of the labeled data in the context of the recorded video stimuli. The components of our analytics environment were developed with a user-centered design approach in close cooperation with an eye tracking expert. We demonstrate our approach with eye tracking data from a real experiment and compare it to an analysis of the data by manual annotation of dynamic AOIs. Furthermore, we conducted an expert user study with 6 external eye tracking researchers to collect feedback and identify analysis strategies they used while working with our application.	Kuno Kurzhals;Marcel Hlawatsch;Christof Seeger;Daniel Weiskopf	Kuno Kurzhals;Marcel Hlawatsch;Christof Seeger;Daniel Weiskopf	University of Stuttgart;University of Stuttgart;Stuttgart Media University;University of Stuttgart	10.1109/TVCG.2010.149;10.1109/TVCG.2015.2468091;10.1109/VAST.2006.261433;10.1109/TVCG.2009.111	Eye tracking;visual analytics;video visualization	7	16	9	34	
SciVis	2016	Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution	10.1109/TVCG.2016.2598789	http://dx.doi.org/10.1109/TVCG.2016.2598789	711	720	J	Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.	Chris Bryan;Gregory Guterman;Kwan-Liu Ma;Harris A. Lewin;Denis M. Larkin;Jaebum Kim;Jian Ma 0004;Marta Farre	Chris Bryan;Gregory Guterman;Kwan-Liu Ma;Harris Lewin;Denis Larkin;Jaebum Kim;Jian Ma;Marta Farré	University of California, Davis;University of California, Davis;University of California, Davis;University of California, Davis;Royal Veterinary College, University of London;Konkuk University, Seoul;Carnegie Mellon University;Royal Veterinary College, University of London	;10.1109/TVCG.2007.70539;10.1109/TVCG.2012.272;10.1109/TVCG.2010.163;10.1109/TVCG.2009.167;10.1109/TVCG.2011.232;10.1109/TVCG.2010.137;10.1109/TVCG.2013.214	Bioinformatic visualization;education;learning;genome evolution;chromosome;user study	3	5	3	53	
SciVis	2016	Visualizing Shape Deformations with Variation of Geometric Spectrum	10.1109/TVCG.2016.2598790	http://dx.doi.org/10.1109/TVCG.2016.2598790	721	730	J	This paper presents a novel approach based on spectral geometry to quantify and visualize non-isometric deformations of 3D surfaces by mapping two manifolds. The proposed method can determine multi-scale, non-isometric deformations through the variation of Laplace-Beltrami spectrum of two shapes. Given two triangle meshes, the spectra can be varied from one to another with a scale function defined on each vertex. The variation is expressed as a linear interpolation of eigenvalues of the two shapes. In each iteration step, a quadratic programming problem is constructed, based on our derived spectrum variation theorem and smoothness energy constraint, to compute the spectrum variation. The derivation of the scale function is the solution of such a problem. Therefore, the final scale function can be solved by integral of the derivation from each step, which, in turn, quantitatively describes non-isometric deformations between two shapes. To evaluate the method, we conduct extensive experiments on synthetic and real data. We employ real epilepsy patient imaging data to quantify the shape variation between the left and right hippocampi in epileptic brains. In addition, we use longitudinal Alzheimer data to compare the shape deformation of diseased and healthy hippocampus. In order to show the accuracy and effectiveness of the proposed method, we also compare it with spatial registration-based methods, e.g., non-rigid Iterative Closest Point (ICP) and voxel-based method. These experiments demonstrate the advantages of our method.	Jiaxi Hu;Hajar Hamidian;Zichun Zhong;Jing Hua	Jiaxi Hu;Hajar Hamidian;Zichun Zhong;Jing Hua	Wayne State University;Wayne State University;Wayne State University;Wayne State University	10.1109/TVCG.2009.159;10.1109/TVCG.2015.2467198;10.1109/TVCG.2011.171	Geometry-based Technique;Spectral Analysis;Biomedical Visualization	0	1	3	44	
SciVis	2016	Corresponding Supine and Prone Colon Visualization Using Eigenfunction Analysis and Fold Modeling	10.1109/TVCG.2016.2598791	http://dx.doi.org/10.1109/TVCG.2016.2598791	751	760	J	We present a method for registration and visualization of corresponding supine and prone virtual colonoscopy scans based on eigenfunction analysis and fold modeling. In virtual colonoscopy, CT scans are acquired with the patient in two positions, and their registration is desirable so that physicians can corroborate findings between scans. Our algorithm performs this registration efficiently through the use of Fiedler vector representation (the second eigenfunction of the Laplace-Beltrami operator). This representation is employed to first perform global registration of the two colon positions. The registration is then locally refined using the haustral folds, which are automatically segmented using the 3D level sets of the Fiedler vector. The use of Fiedler vectors and the segmented folds presents a precise way of visualizing corresponding regions across datasets and visual modalities. We present multiple methods of visualizing the results, including 2D flattened rendering and the corresponding 3D endoluminal views. The precise fold modeling is used to automatically find a suitable cut for the 2D flattening, which provides a less distorted visualization. Our approach is robust, and we demonstrate its efficiency and efficacy by showing matched views on both the 2D flattened colons and in the 3D endoluminal view. We analytically evaluate the results by measuring the distance between features on the registered colons, and we also assess our fold segmentation against 20 manually labeled datasets. We have compared our results analytically to previous methods, and have found our method to achieve superior results. We also prove the hot spots conjecture for modeling cylindrical topology using Fiedler vector representation, which allows our approach to be used for general cylindrical geometry modeling and feature extraction.	Saad Nadeem;Joseph Marino;Xianfeng Gu;Arie E. Kaufman	Saad Nadeem;Joseph Marino;Xianfeng Gu;Arie Kaufman	Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY	10.1109/TVCG.2006.112;10.1109/TVCG.2010.200;10.1109/VISUAL.2001.964540;10.1109/TVCG.2006.158;10.1109/TVCG.2013.139;10.1109/TVCG.2015.2467413;10.1109/TVCG.2011.182;10.1109/VISUAL.2005.1532806	Medical visualization;colon registration;geometry-based techniques;mathematical foundations for visualization	2	8	8	38	
SciVis	2016	Combined Visualization of Vessel Deformation and Hemodynamics in Cerebral Aneurysms	10.1109/TVCG.2016.2598795	http://dx.doi.org/10.1109/TVCG.2016.2598795	761	770	J	We present the first visualization tool that combines patient-specific hemodynamics with information about the vessel wall deformation and wall thickness in cerebral aneurysms. Such aneurysms bear the risk of rupture, whereas their treatment also carries considerable risks for the patient. For the patient-specific rupture risk evaluation and treatment analysis, both morphological and hemodynamic data have to be investigated. Medical researchers emphasize the importance of analyzing correlations between wall properties such as the wall deformation and thickness, and hemodynamic attributes like the Wall Shear Stress and near-wall flow. Our method uses a linked 2.5D and 3D depiction of the aneurysm together with blood flow information that enables the simultaneous exploration of wall characteristics and hemodynamic attributes during the cardiac cycle. We thus offer medical researchers an effective visual exploration tool for aneurysm treatment risk assessment. The 2.5D view serves as an overview that comprises a projection of the vessel surface to a 2D map, providing an occlusion-free surface visualization combined with a glyph-based depiction of the local wall thickness. The 3D view represents the focus upon which the data exploration takes place. To support the time-dependent parameter exploration and expert collaboration, a camera path is calculated automatically, where the user can place landmarks for further exploration of the properties. We developed a GPU-based implementation of our visualizations with a flexible interactive data exploration mechanism. We designed our techniques in collaboration with domain experts, and provide details about the evaluation.	Monique Meuschke;Samuel Voß;Oliver Beuing;Bernhard Preim;Kai Lawonn	Monique Meuschke;Samuel Voss;Oliver Beuing;Bernhard Preim;Kai Lawonn	University of Magdeburg, Germany;University of Magdeburg, Germany;University of Magdeburg, Germany;University of Magdeburg, Germany;University of Koblenz-Landau, Germany	10.1109/TVCG.2011.215;10.1109/TVCG.2011.243;10.1109/TVCG.2014.2346406;10.1109/TVCG.2010.153;10.1109/TVCG.2015.2467961;10.1109/TVCG.2013.189;10.1109/TVCG.2012.202	Medical visualizations;aneurysms;blood flow;wall thickness;wall deformation;projections	6	8	8	47	
VAST	2016	GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images	10.1109/TVCG.2016.2598796	http://dx.doi.org/10.1109/TVCG.2016.2598796	311	320	J	We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients' volumetric CT images.	Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bo Hyoung Kim;Jinwook Seo	Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bohyoung Kim;Jinwook Seo	Seoul National University;Soongsil University;Samsung Medical Center;Bundang Hospital, Seoul National University;Hankuk University of Foreign Studies;Seoul National University	10.1109/VAST.2011.6102435;10.1109/TVCG.2010.149	Eye tracking;gaze visualization;gaze pattern comparison;volumetric medical images;context-embedded interactive scatterplot;interactive temporal chart	0	1	1	32	
VAST	2016	Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths	10.1109/TVCG.2016.2598797	http://dx.doi.org/10.1109/TVCG.2016.2598797	321	330	J	Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.	Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson 0004	Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson	Adobe Research;University of California, Davis;Adobe Research;Adobe Research;Adobe Research;Adobe Systems Inc.	10.1109/VAST.2010.5652910;10.1109/VAST.2010.5652926;10.1109/TVCG.2013.225;10.1109/TVCG.2013.200;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346574;10.1109/VAST.2007.4389008;10.1109/TVCG.2011.185;10.1109/VAST.2014.7042487;10.1109/TVCG.2015.2467622;10.1109/VAST.2012.6400494	event sequences;Clickstream Data;sequence mining;visual analytics	16	46	38	38	
SciVis	2016	Molecular Surface Maps	10.1109/TVCG.2016.2598824	http://dx.doi.org/10.1109/TVCG.2016.2598824	701	710	J	We present Molecular Surface Maps, a novel, view-independent, and concise representation for molecular surfaces. It transfers the well-known world map metaphor to molecular visualization. Our application maps the complex molecular surface to a simple 2D representation through a spherical intermediate, the Molecular Surface Globe. The Molecular Surface Map concisely shows arbitrary attributes of the original molecular surface, such as biochemical properties or geometrical features. This results in an intuitive overview, which allows researchers to assess all molecular surface attributes at a glance. Our representation can be used as a visual summarization of a molecule's interface with its environment. In particular, Molecular Surface Maps simplify the analysis and comparison of different data sets or points in time. Furthermore, the map representation can be used in a Space-time Cube to analyze time-dependent data from molecular simulations without the need for animation. We show the feasibility of Molecular Surface Maps for different typical analysis tasks of biomolecular data.	Michael Krone;Florian Friess;Katrin Scharnowski;Guido Reina;Silvia Fademrecht;Tobias Kulschewski;Jürgen Pleiss;Thomas Ertl	Michael Krone;Florian Frieß;Katrin Scharnowski;Guido Reina;Silvia Fademrecht;Tobias Kulschewski;Jürgen Pleiss;Thomas Ertl	Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany	10.1109/TVCG.2013.194;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2015.2467413	Molecular Visualization;Maps;Cartography;Data Aggregation;Dimensionality Reduction;Space-time Cube	4	8	8	64	
SciVis	2016	Physics-Based Visual Characterization of Molecular Interaction Forces	10.1109/TVCG.2016.2598825	http://dx.doi.org/10.1109/TVCG.2016.2598825	731	740	J	Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.	Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Alvar Vinacua;Pere-Pau Vázquez	Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez	ViRVIG Group, Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Visual Computing Group, Ulm University;ViRVIG Group, UPC, Barcelona;ViRVIG Group, UPC, Barcelona	10.1109/TVCG.2009.168;10.1109/TVCG.2012.282;10.1109/TVCG.2015.2467293;10.1109/TVCG.2007.70578;10.1109/TVCG.2006.115;10.1109/TVCG.2007.70517;10.1109/TVCG.2014.2346403;10.1109/TVCG.2009.157	Molecular visualization;binding analysis	2	8	8	52	
SciVis	2016	PelVis: Atlas-based Surgical Planning for Oncological Pelvic Surgery	10.1109/TVCG.2016.2598826	http://dx.doi.org/10.1109/TVCG.2016.2598826	741	750	J	Due to the intricate relationship between the pelvic organs and vital structures, such as vessels and nerves, pelvic anatomy is often considered to be complex to comprehend. In oncological pelvic surgery, a trade-off has to be made between complete tumor resection and preserving function by preventing damage to the nerves. Damage to the autonomic nerves causes undesirable post-operative side-effects such as fecal and urinal incontinence, as well as sexual dysfunction in up to 80 percent of the cases. Since these autonomic nerves are not visible in pre-operative MRI scans or during surgery, avoiding nerve damage during such a surgical procedure becomes challenging. In this work, we present visualization methods to represent context, target, and risk structures for surgical planning. We employ distance-based and occlusion management techniques in an atlas-based surgical planning tool for oncological pelvic surgery. Patient-specific pre-operative MRI scans are registered to an atlas model that includes nerve information. Through several interactive linked views, the spatial relationships and distances between the organs, tumor and risk zones are visualized to improve understanding, while avoiding occlusion. In this way, the surgeon can examine surgically relevant structures and plan the procedure before going into the operating theater, thus raising awareness of the autonomic nerve zone regions and potentially reducing post-operative complications. Furthermore, we present the results of a domain expert evaluation with surgical oncologists that demonstrates the advantages of our approach.	Noeska N. Smit;Kai Lawonn;Annelot Kraima;Marco DeRuiter;Hessam Sokooti;Stefan Bruckner;Elmar Eisemann;Anna Vilanova	Noeska Smit;Kai Lawonn;Annelot Kraima;Marco DeRuiter;Hessam Sokooti;Stefan Bruckner;Elmar Eisemann;Anna Vilanova	Delft University of TechnologyUniversity of Bergen;University of Koblenz, Landau;Leiden University Medical Center;Leiden University Medical Center;Leiden University Medical Center;University of Bergen;Delft University of Technology;Delft University of Technology	10.1109/TVCG.2008.180;10.1109/VISUAL.2002.1183769;10.1109/TVCG.2011.207;10.1109/TVCG.2015.2467961;10.1109/TVCG.2011.189;10.1109/TVCG.2013.143;10.1109/VISUAL.2003.1250400	Atlas;surgical planning;medical visualization	3	9	7	51	
SciVis	2016	Visualization as Seen through its Research Paper Keywords	10.1109/TVCG.2016.2598827	http://dx.doi.org/10.1109/TVCG.2016.2598827	771	780	J	We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices.	Petra Isenberg;Tobias Isenberg 0001;Michael Sedlmair;Jian Chen;Torsten Möller	Petra Isenberg;Tobias Isenberg;Michael Sedlmair;Jian Chen;Torsten Möller	Inria, France;Inria, France;University of Vienna, Austria;University of Maryland, Baltimore County, USA;University of Vienna, Austria	10.1109/TVCG.2012.195;10.1109/TVCG.2012.213;10.1109/INFVIS.2000.885092;10.1109/TVCG.2011.229;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70515;10.1109/TVCG.2013.126	data analysis;research themes;research topics;taxonomy;visualization history;theory	13	24	16	48	
VAST	2016	Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers	10.1109/TVCG.2016.2598828	http://dx.doi.org/10.1109/TVCG.2016.2598828	61	70	J	Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.	Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams	Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams	University of California, Santa Barbara;Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research	10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.277;10.1109/TVCG.2014.2346660;10.1109/VAST.2011.6102453;10.1109/TVCG.2011.185	Performance analysis;classification;usable machine learning	18	52	33	38	
VAST	2016	An Analysis of Machine- and Human-Analytics in Classification	10.1109/TVCG.2016.2598829	http://dx.doi.org/10.1109/TVCG.2016.2598829	71	80	J	In this work, we present a study that traces the technical and cognitive processes in two visual analytics applications to a common theoretic model of soft knowledge that may be added into a visual analytics process for constructing a decision-tree model. Both case studies involved the development of classification models based on the “bag of features” approach. Both compared a visual analytics approach using parallel coordinates with a machine-learning approach using information theory. Both found that the visual analytics approach had some advantages over the machine learning approach, especially when sparse datasets were used as the ground truth. We examine various possible factors that may have contributed to such advantages, and collect empirical evidence for supporting the observation and reasoning of these factors. We propose an information-theoretic model as a common theoretic basis to explain the phenomena exhibited in these two case studies. Together we provide interconnected empirical and theoretical evidence to support the usefulness of visual analytics.	Gary K. L. Tam;Vivek Kothari;Min Chen	Gary K. L. Tam;Vivek Kothari;Min Chen	Swansea University;University of Oxford;University of Oxford	10.1109/VAST.2010.5652467;10.1109/TVCG.2015.2467615;10.1109/VAST.2012.6400492;10.1109/TVCG.2013.207;10.1109/TVCG.2015.2467552;10.1109/TVCG.2015.2467612;10.1109/VAST.2010.5652398;10.1109/TVCG.2010.132;10.1109/TVCG.2014.2346660;10.1109/VAST.2015.7347629;10.1109/VAST.2011.6102453;10.1109/VAST.2011.6102448	information theory;Visual analytics;classification;decision tree;model;facial expression;visualization image	13	24	20	51	BP
VAST	2016	Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots	10.1109/TVCG.2016.2598830	http://dx.doi.org/10.1109/TVCG.2016.2598830	81	90	J	Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science.	Junpeng Wang;Xiaotong Liu;Han-Wei Shen;Guang Lin	Junpeng Wang;Xiaotong Liu;Han-Wei Shen;Guang Lin	The Ohio State University;The Ohio State University;The Ohio State University;Purdue University	10.1109/TVCG.2010.181;10.1109/TVCG.2008.153;10.1109/INFVIS.1998.729559;10.1109/TVCG.2012.237;10.1109/INFVIS.2004.68;10.1109/TVCG.2014.2346755;10.1109/SciVis.2015.7429487;10.1109/VISUAL.1999.809866;10.1109/TVCG.2013.122;10.1109/INFVIS.2004.15;10.1109/TVCG.2015.2467431;10.1109/TVCG.2015.2468093;10.1109/TVCG.2010.184;10.1109/TVCG.2014.2346321	Parallel coordinates plots;parameter analysis;multi-resolution climate ensembles	6	0	27	48	
VAST	2016	Towards Better Analysis of Deep Convolutional Neural Networks	10.1109/TVCG.2016.2598831	http://dx.doi.org/10.1109/TVCG.2016.2598831	91	100	J	Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.	Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu 0001;Shixia Liu	Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu	School of Software and TNListTsinghua University;Dept. of Comp. Sci. &#x0026; Tech., State Key Lab of Intell. Tech. &#x0026; Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;Dept. of Comp. Sci. &#x0026; Tech., State Key Lab of Intell. Tech. &#x0026; Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;School of Software and TNListTsinghua University	10.1109/TVCG.2015.2468151;10.1109/TVCG.2015.2467554;10.1109/TVCG.2015.2467813;10.1109/TVCG.2010.132;10.1109/TVCG.2008.135;10.1109/TVCG.2014.2346919;10.1109/TVCG.2011.239;10.1109/VISUAL.1991.175815;10.1109/VISUAL.2005.1532820;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346433	Deep convolutional neural networks;rectangle packing;matrix reordering;edge bundling;biclustering	40	122	97	60	
VAST	2016	Visualizing the Hidden Activity of Artificial Neural Networks	10.1109/TVCG.2016.2598838	http://dx.doi.org/10.1109/TVCG.2016.2598838	101	110	J	In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles.	Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falcão;Alexandru Telea	Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falcão;Alexandru C. Telea	University of GroningenUniversity of Campinas;University of São Paulo;University of Campinas;University of Groningen	10.1109/TVCG.2011.178;10.1109/TVCG.2011.220;10.1109/TVCG.2013.150;10.1109/TVCG.2014.2346578;10.1109/TVCG.2008.125;10.1109/TVCG.2015.2467553	Artificial neural networks;dimensionality reduction;algorithm understanding	21	0	70	50	
InfoVis	2016	Visualization by Demonstration: An Interaction Paradigm for Visual Data Exploration	10.1109/TVCG.2016.2598839	http://dx.doi.org/10.1109/TVCG.2016.2598839	331	340	J	Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations.	Bahador Saket;Hannah Kim;Eli T. Brown;Alex Endert	Bahador Saket;Hannah Kim;Eli T. Brown;Alex Endert	Georgia Institute of Technology;Georgia Institute of Technology;DePaul University;Georgia Institute of Technology	10.1109/TVCG.2014.2346292;10.1109/TVCG.2015.2467191;10.1109/TVCG.2007.70594;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2014.2346250;10.1109/TVCG.2012.275;10.1109/TVCG.2015.2467153;10.1109/TVCG.2013.191;10.1109/TVCG.2011.251;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346291;10.1109/VAST.2012.6400486	Visual Data Exploration;Visualization by Demonstration;Visualization Tools	10	22	20	35	
InfoVis	2016	Map LineUps: Effects of spatial structure on graphical inference	10.1109/TVCG.2016.2598862	http://dx.doi.org/10.1109/TVCG.2016.2598862	391	400	J	Fundamental to the effective use of visualization as an analytic and descriptive tool is the assurance that presenting data visually provides the capability of making inferences from what we see. This paper explores two related approaches to quantifying the confidence we may have in making visual inferences from mapped geospatial data. We adapt Wickham et al.'s `Visual Line-up' method as a direct analogy with Null Hypothesis Significance Testing (NHST) and propose a new approach for generating more credible spatial null hypotheses. Rather than using as a spatial null hypothesis the unrealistic assumption of complete spatial randomness, we propose spatially autocorrelated simulations as alternative nulls. We conduct a set of crowdsourced experiments (n=361) to determine the just noticeable difference (JND) between pairs of choropleth maps of geographic units controlling for spatial autocorrelation (Moran's I statistic) and geometric configuration (variance in spatial unit area). Results indicate that people's abilities to perceive differences in spatial autocorrelation vary with baseline autocorrelation structure and the geometric configuration of geographic units. These results allow us, for the first time, to construct a visual equivalent of statistical power for geospatial data. Our JND results add to those provided in recent years by Klippel et al. (2011), Harrison et al. (2014) and Kay &amp;amp; Heer (2015) for correlation visualization. Importantly, they provide an empirical basis for an improved construction of visual line-ups for maps and the development of theory to inform geospatial tests of graphical inference.	Roger Beecham;Jason Dykes;Wouter Meulemans;Aidan Slingsby;Cagatay Turkay;Jo Wood	Roger Beecham;Jason Dykes;Wouter Meulemans;Aidan Slingsby;Cagatay Turkay;Jo Wood	giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London	10.1109/TVCG.2015.2467671;10.1109/TVCG.2015.2469125;10.1109/TVCG.2014.2346979;10.1109/TVCG.2010.161	Graphical inference;spatial autocorrelation;just noticeable difference;geovisualization;statistical significance	5	13	12	20	HM
SciVis	2016	Decal-Maps: Real-Time Layering of Decals on Surfaces for Multivariate Visualization	10.1109/TVCG.2016.2598866	http://dx.doi.org/10.1109/TVCG.2016.2598866	821	830	J	We introduce the use of decals for multivariate visualization design. Decals are visual representations that are used for communication; for example, a pattern, a text, a glyph, or a symbol, transferred from a 2D-image to a surface upon contact. By creating what we define as decal-maps, we can design a set of images or patterns that represent one or more data attributes. We place decals on the surface considering the data pertaining to the locations we choose. We propose a (texture mapping) local parametrization that allows placing decals on arbitrary surfaces interactively, even when dealing with a high number of decals. Moreover, we extend the concept of layering to allow the co-visualization of an increased number of attributes on arbitrary surfaces. By combining decal-maps, color-maps and a layered visualization, we aim to facilitate and encourage the creative process of designing multivariate visualizations. Finally, we demonstrate the general applicability of our technique by providing examples of its use in a variety of contexts.	Allan Rocha;Usman R. Alim;Julio Daniel Silva;Mario Costa Sousa	Allan Rocha;Usman Alim;Julio Daniel Silva;Mario Costa Sousa	University of Calgary;University of Calgary;University of Calgary;University of Calgary	10.1109/VISUAL.1991.175811;10.1109/TVCG.2010.181;10.1109/TVCG.2011.243;10.1109/VISUAL.1998.745294;10.1109/TVCG.2015.2467153;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.1999.809905;10.1109/TVCG.2011.170	Multivariate;Visualization;Real-time;Decal;Surface;Layering;Design	3	9	8	60	
InfoVis	2016	Evaluation of Graph Sampling: A Visualization Perspective	10.1109/TVCG.2016.2598867	http://dx.doi.org/10.1109/TVCG.2016.2598867	401	410	J	Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.	Yanhong Wu;Nan Cao;Daniel Archambault;Qiaomu Shen;Huamin Qu;Weiwei Cui	Yanhong Wu;Nan Cao;Daniel Archambault;Qiaomu Shen;Huamin Qu;Weiwei Cui	Hong Kong University of Science and Technology;New York University, Shanghai;Swansea University;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research Asia	10.1109/TVCG.2015.2468151;10.1109/VISUAL.2005.1532819;10.1109/TVCG.2008.151;10.1109/TVCG.2006.147;10.1109/TVCG.2006.120;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.135;10.1109/TVCG.2012.238;10.1109/TVCG.2013.232	Graph visualization;graph sampling;empirical evaluation	8	17	17	52	
SciVis	2016	Time-Hierarchical Clustering and Visualization of Weather Forecast Ensembles	10.1109/TVCG.2016.2598868	http://dx.doi.org/10.1109/TVCG.2016.2598868	831	840	J	We propose a new approach for analyzing the temporal growth of the uncertainty in ensembles of weather forecasts which are started from perturbed but similar initial conditions. As an alternative to traditional approaches in meteorology, which use juxtaposition and animation of spaghetti plots of iso-contours, we make use of contour clustering and provide means to encode forecast dynamics and spread in one single visualization. Based on a given ensemble clustering in a specified time window, we merge clusters in time-reversed order to indicate when and where forecast trajectories start to diverge. We present and compare different visualizations of the resulting time-hierarchical grouping, including space-time surfaces built by connecting cluster representatives over time, and stacked contour variability plots. We demonstrate the effectiveness of our visual encodings with forecast examples of the European Centre for Medium-Range Weather Forecasts, which convey the evolution of specific features in the data as well as the temporally increasing spatial variability.	Florian Ferstl;Mathias Kanzler;Marc Rautenhaus;Rüdiger Westermann	Florian Ferstl;Mathias Kanzler;Marc Rautenhaus;Rüdiger Westermann	Technical University of Munich;Technical University of Munich;Technical University of Munich;Technical University of Munich	10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/INFVIS.1999.801851;10.1109/TVCG.2015.2467754;10.1109/TVCG.2013.143;10.1109/TVCG.2013.141;10.1109/TVCG.2011.203;10.1109/TVCG.2014.2346332;10.1109/TVCG.2006.168	Ensemble visualization;uncertainty visualization;meteorological visualization;iso-contours;time-varying data;clustering	6	18	24	52	
SciVis	2016	Visualization of Time-Varying Weather Ensembles across Multiple Resolutions	10.1109/TVCG.2016.2598869	http://dx.doi.org/10.1109/TVCG.2016.2598869	841	850	J	Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow.	Ayan Biswas;Guang Lin;Xiaotong Liu;Han-Wei Shen	Ayan Biswas;Guang Lin;Xiaotong Liu;Han-Wei Shen	GRAVITY group, The Ohio State University;Purdue University;GRAVITY group, The Ohio State University;GRAVITY group, The Ohio State University	10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/SciVis.2015.7429487;10.1109/TVCG.2013.138;10.1109/TVCG.2015.2468093;10.1109/TVCG.2013.143;10.1109/TVCG.2014.2346448;10.1109/VAST.2015.7347634;10.1109/TVCG.2012.249;10.1109/TVCG.2014.2346455;10.1109/TVCG.2013.144	Ensemble;time-varying;multi-resolution;sensitivity analysis	4	12	14	46	
SciVis	2016	A Fractional Cartesian Composition Model for Semi-Spatial Comparative Visualization Design	10.1109/TVCG.2016.2598870	http://dx.doi.org/10.1109/TVCG.2016.2598870	851	860	J	The study of spatial data ensembles leads to substantial visualization challenges in a variety of applications. In this paper, we present a model for comparative visualization that supports the design of according ensemble visualization solutions by partial automation. We focus on applications, where the user is interested in preserving selected spatial data characteristics of the data as much as possible-even when many ensemble members should be jointly studied using comparative visualization. In our model, we separate the design challenge into a minimal set of user-specified parameters and an optimization component for the automatic configuration of the remaining design variables. We provide an illustrated formal description of our model and exemplify our approach in the context of several application examples from different domains in order to demonstrate its generality within the class of comparative visualization problems for spatial data ensembles.	Ivan Kolesár;Stefan Bruckner;Ivan Viola;Helwig Hauser	Ivan Kolesár;Stefan Bruckner;Ivan Viola;Helwig Hauser	Department of Informatics, University of Bergen, Norway;Department of Informatics, University of Bergen, Norway;TU Wien, Austria;Department of Informatics, University of Bergen, Norway	10.1109/TVCG.2014.2346591;10.1109/TVCG.2008.180;10.1109/TVCG.2009.153;10.1109/TVCG.2007.70550;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2006.164;10.1109/TVCG.2013.120;10.1109/TVCG.2009.136;10.1109/TVCG.2014.2346325;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.227;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2011.235;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2009.111	Visualization Models;Integrating Spatial and Non-Spatial Data Visualization;Design Methodologies	2	6	5	41	
InfoVis	2016	Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement	10.1109/TVCG.2016.2598876	http://dx.doi.org/10.1109/TVCG.2016.2598876	511	520	J	Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.	Chris Bryan;Kwan-Liu Ma;Jonathan Woodring	Chris Bryan;Kwan-Liu Ma;Jonathan Woodring	University of California, Davis;University of California, Davis;Los Alamos National Laboratory	10.1109/TVCG.2008.166;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/VAST.2010.5652890;10.1109/TVCG.2012.229;10.1109/TVCG.2012.212;10.1109/TVCG.2011.195;10.1109/VAST.2012.6400487	Narrative visualization;storytelling;annotations;comic strip visualization;time-varying data	11	20	15	46	
InfoVis	2016	Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation	10.1109/TVCG.2016.2598885	http://dx.doi.org/10.1109/TVCG.2016.2598885	411	420	J	Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar.	Yalong Yang 0001;Tim Dwyer;Sarah Goodwin;Kim Marriott	Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott	Monash University, Data61, CSIRO, Victoria;Monash University;Monash University;Monash University, Data61, CSIRO, Victoria	10.1109/INFVIS.2004.1;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346441;10.1109/TVCG.2008.165;10.1109/INFVIS.2005.1532150	Flow Maps;Matrix Visualisation;Cartographic Information Visualisation	8	27	25	39	HM
InfoVis	2016	An Evaluation of Visual Search Support in Maps	10.1109/TVCG.2016.2598898	http://dx.doi.org/10.1109/TVCG.2016.2598898	421	430	J	Visual search can be time-consuming, especially if the scene contains a large number of possibly relevant objects. An instance of this problem is present when using geographic or schematic maps with many different elements representing cities, streets, sights, and the like. Unless the map is well-known to the reader, the full map or at least large parts of it must be scanned to find the elements of interest. In this paper, we present a controlled eye-tracking study (30 participants) to compare four variants of map annotation with labels: within-image annotations, grid reference annotation, directional annotation, and miniature annotation. Within-image annotation places labels directly within the map without any further search support. Grid reference annotation corresponds to the traditional approach known from atlases. Directional annotation utilizes a label in combination with an arrow pointing in the direction of the label within the map. Miniature annotation shows a miniature grid to guide the reader to the area of the map in which the label is located. The study results show that within-image annotation is outperformed by all other annotation approaches. Best task completion times are achieved with miniature annotation. The analysis of eye-movement data reveals that participants applied significantly different visual task solution strategies for the different visual annotations.	Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf	Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf	VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart	10.1109/TVCG.2014.2346420;10.1109/TVCG.2010.191	Visual search;laboratory study;eye tracking;map visualization	5	10	7	37	
InfoVis	2016	Colorgorical: Creating discriminable and preferable color palettes for information visualization	10.1109/TVCG.2016.2598918	http://dx.doi.org/10.1109/TVCG.2016.2598918	521	530	J	We present an evaluation of Colorgorical, a web-based tool for creating discriminable and aesthetically preferable categorical color palettes. Colorgorical uses iterative semi-random sampling to pick colors from CIELAB space based on user-defined discriminability and preference importances. Colors are selected by assigning each a weighted sum score that applies the user-defined importances to Perceptual Distance, Name Difference, Name Uniqueness, and Pair Preference scoring functions, which compare a potential sample to already-picked palette colors. After, a color is added to the palette by randomly sampling from the highest scoring palettes. Users can also specify hue ranges or build off their own starting palettes. This procedure differs from previous approaches that do not allow customization (e.g., pre-made ColorBrewer palettes) or do not consider visualization design constraints (e.g., Adobe Color and ACE). In a Palette Score Evaluation, we verified that each scoring function measured different color information. Experiment 1 demonstrated that slider manipulation generates palettes that are consistent with the expected balance of discriminability and aesthetic preference for 3-, 5-, and 8-color palettes, and also shows that the number of colors may change the effectiveness of pair-based discriminability and preference scores. For instance, if the Pair Preference slider were upweighted, users would judge the palettes as more preferable on average. Experiment 2 compared Colorgorical palettes to benchmark palettes (ColorBrewer, Microsoft, Tableau, Random). Colorgorical palettes are as discriminable and are at least as preferable or more preferable than the alternative palette sets. In sum, Colorgorical allows users to make customized color palettes that are, on average, as effective as current industry standards by balancing the importance of discriminability and aesthetic preference.	Connor Gramazio;David H. Laidlaw;Karen B. Schloss	Connor C. Gramazio;David H. Laidlaw;Karen B. Schloss	Dept. of Computer Science at Brown University;Dept. of Computer Science at Brown University;Dept. of Cognitive, Linguistic, and Psychological Sciences at Brown University	10.1109/VISUAL.1996.568118;10.1109/TVCG.2014.2346978;10.1109/TVCG.2015.2467471;10.1109/TVCG.2014.2346983;10.1109/TVCG.2012.233	Aesthetics in Visualization;Color Perception;Metrics & Benchmarks;Visual Design;Visualization	11	29	24	37	
InfoVis	2016	Probabilistic Graph Layout for Uncertain Network Visualization	10.1109/TVCG.2016.2598919	http://dx.doi.org/10.1109/TVCG.2016.2598919	531	540	J	We present a novel uncertain network visualization technique based on node-link diagrams. Nodes expand spatially in our probabilistic graph layout, depending on the underlying probability distributions of edges. The visualization is created by computing a two-dimensional graph embedding that combines samples from the probabilistic graph. A Monte Carlo process is used to decompose a probabilistic graph into its possible instances and to continue with our graph layout technique. Splatting and edge bundling are used to visualize point clouds and network topology. The results provide insights into probability distributions for the entire network-not only for individual nodes and edges. We validate our approach using three data sets that represent a wide range of network types: synthetic data, protein-protein interactions from the STRING database, and travel times extracted from Google Maps. Our approach reveals general limitations of the force-directed layout and allows the user to recognize that some nodes of the graph are at a specific position just by chance.	Christoph Schulz;Arlind Nocaj;Jochen Görtler;Oliver Deussen;Ulrik Brandes;Daniel Weiskopf	Christoph Schulz;Arlind Nocaj;Jochen Goertler;Oliver Deussen;Ulrik Brandes;Daniel Weiskopf	VISUSUniversity of Stuttgart;University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;VISUSUniversity of Stuttgart	10.1109/TVCG.2006.147;10.1109/TVCG.2010.176;10.1109/TVCG.2009.150;10.1109/TVCG.2009.127;10.1109/TVCG.2015.2467691;10.1109/TVCG.2015.2467591;10.1109/VAST.2009.5332611;10.1109/TVCG.2009.122;10.1109/TVCG.2013.232	Uncertainty visualization;graph layout;graph visualization;edge bundling;Monte Carlo method	7	14	13	45	
InfoVis	2016	VLAT: Development of a Visualization Literacy Assessment Test	10.1109/TVCG.2016.2598920	http://dx.doi.org/10.1109/TVCG.2016.2598920	551	560	J	The Information Visualization community has begun to pay attention to visualization literacy; however, researchers still lack instruments for measuring the visualization literacy of users. In order to address this gap, we systematically developed a visualization literacy assessment test (VLAT), especially for non-expert users in data visualization, by following the established procedure of test development in Psychological and Educational Measurement: (1) Test Blueprint Construction, (2) Test Item Generation, (3) Content Validity Evaluation, (4) Test Tryout and Item Analysis, (5) Test Item Selection, and (6) Reliability Evaluation. The VLAT consists of 12 data visualizations and 53 multiple-choice test items that cover eight data visualization tasks. The test items in the VLAT were evaluated with respect to their essentialness by five domain experts in Information Visualization and Visual Analytics (average content validity ratio = 0.66). The VLAT was also tried out on a sample of 191 test takers and showed high reliability (reliability coefficient omega = 0.76). In addition, we demonstrated the relationship between users' visualization literacy and aptitude for learning an unfamiliar visualization and showed that they had a fairly high positive relationship (correlation coefficient = 0.64). Finally, we discuss evidence for the validity of the VLAT and potential research areas that are related to the instrument.	Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon	Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon	School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Samsung Electronics Co., Ltd., Seoul, South Korea;IBM T.J. Watson Research Center, Yorktown Heights, NY, USA	10.1109/TVCG.2014.2346419;10.1109/TVCG.2014.2346481;10.1109/TVCG.2014.2346984;10.1109/VISUAL.1991.175815;10.1109/TVCG.2007.70515;10.1109/TVCG.2015.2467195;10.1109/VAST.2011.6102435;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467201	Visualization Literacy;Assessment Test;Instrument;Measurement;Aptitude;Education	6	20	15	55	
InfoVis	2016	Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization	10.1109/TVCG.2016.2598958	http://dx.doi.org/10.1109/TVCG.2016.2598958	541	550	J	In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity.	Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer	Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer	Microsoft Research-Inria Joint Centre, France;Microsoft Research, WA, USA;ENAC, Toulouse, France;Monash University, Melbourne, Australia;Monash University, Melbourne, Australia	10.1109/TVCG.2006.120;10.1109/TVCG.2006.147;10.1109/TVCG.2011.233;10.1109/TVCG.2011.190;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2012.208;10.1109/TVCG.2006.160;10.1109/TVCG.2013.151;10.1109/INFVIS.2005.1532150	bundling;Network visualization;edge compression;confluent;power graph	11	25	20	45	
SciVis	2016	Glyphs for General Second-Order 2D and 3D Tensors	10.1109/TVCG.2016.2598998	http://dx.doi.org/10.1109/TVCG.2016.2598998	980	989	J	Glyphs are a powerful tool for visualizing second-order tensors in a variety of scientic data as they allow to encode physical behavior in geometric properties. Most existing techniques focus on symmetric tensors and exclude non-symmetric tensors where the eigenvectors can be non-orthogonal or complex. We present a new construction of 2d and 3d tensor glyphs based on piecewise rational curves and surfaces with the following properties: invariance to (a) isometries and (b) scaling, (c) direct encoding of all real eigenvalues and eigenvectors, (d) one-to-one relation between the tensors and glyphs, (e) glyph continuity under changing the tensor. We apply the glyphs to visualize the Jacobian matrix fields of a number of 2d and 3d vector fields.	Tim Gerrits;Christian Rössl;Holger Theisel	Tim Gerrits;Christian Rössl;Holger Theisel	Visual Computing group at the University of Magdeburg, Germany;Visual Computing group at the University of Magdeburg, Germany;Visual Computing group at the University of Magdeburg, Germany	10.1109/TVCG.2014.2346325;10.1109/TVCG.2010.199;10.1109/VISUAL.1991.175773;10.1109/VISUAL.2004.115;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.1993.398849;10.1109/TVCG.2009.184	Glyph-based Techniques;Tensor Field Data;Flow Visualization	3	5	5	20	
SciVis	2016	Backward Finite-Time Lyapunov Exponents in Inertial Flows	10.1109/TVCG.2016.2599016	http://dx.doi.org/10.1109/TVCG.2016.2599016	970	979	J	Inertial particles are finite-sized objects that are carried by fluid flows and in contrast to massless tracer particles they are subject to inertia effects. In unsteady flows, the dynamics of tracer particles have been extensively studied by the extraction of Lagrangian coherent structures (LCS), such as hyperbolic LCS as ridges of the Finite-Time Lyapunov Exponent (FTLE). The extension of the rich LCS framework to inertial particles is currently a hot topic in the CFD literature and is actively under research. Recently, backward FTLE on tracer particles has been shown to correlate with the preferential particle settling of small inertial particles. For larger particles, inertial trajectories may deviate strongly from (massless) tracer trajectories, and thus for a better agreement, backward FTLE should be computed on inertial trajectories directly. Inertial backward integration, however, has not been possible until the recent introduction of the influence curve concept, which - given an observation and an initial velocity - allows to recover all sources of inertial particles as tangent curves of a derived vector field. In this paper, we show that FTLE on the influence curve vector field is in agreement with preferential particle settling and more importantly it is not only valid for small (near-tracer) particles. We further generalize the influence curve concept to general equations of motion in unsteady spatio-velocity phase spaces, which enables backward integration with more general equations of motion. Applying the influence curve concept to tracer particles in the spatio-velocity domain emits streaklines in massless flows as tangent curves of the influence curve vector field. We demonstrate the correlation between inertial backward FTLE and the preferential particle settling in a number of unsteady vector fields	Tobias Günther;Holger Theisel	Tobias Günther;Holger Theisel	Visual Computing Group, University of Magdeburg;Visual Computing Group, University of Magdeburg	10.1109/TVCG.2007.70551;10.1109/TVCG.2007.70554;10.1109/TVCG.2010.198;10.1109/TVCG.2014.2346415;10.1109/TVCG.2013.128	Inertial particles;finite-time Lyapunov exponents;backward integration;preferential particle settling	2	4	2	72	
SciVis	2016	Jacobi Fiber Surfaces for Bivariate Reeb Space Computation	10.1109/TVCG.2016.2599017	http://dx.doi.org/10.1109/TVCG.2016.2599017	960	969	J	This paper presents an efficient algorithm for the computation of the Reeb space of an input bivariate piecewise linear scalar function f defined on a tetrahedral mesh. By extending and generalizing algorithmic concepts from the univariate case to the bivariate one, we report the first practical, output-sensitive algorithm for the exact computation of such a Reeb space. The algorithm starts by identifying the Jacobi set of f, the bivariate analogs of critical points in the univariate case. Next, the Reeb space is computed by segmenting the input mesh along the new notion of Jacobi Fiber Surfaces, the bivariate analog of critical contours in the univariate case. We additionally present a simplification heuristic that enables the progressive coarsening of the Reeb space. Our algorithm is simple to implement and most of its computations can be trivially parallelized. We report performance numbers demonstrating orders of magnitude speedups over previous approaches, enabling for the first time the tractable computation of bivariate Reeb spaces in practice. Moreover, unlike range-based quantization approaches (such as the Joint Contour Net), our algorithm is parameter-free. We demonstrate the utility of our approach by using the Reeb space as a semi-automatic segmentation tool for bivariate data. In particular, we introduce continuous scatterplot peeling, a technique which enables the reduction of the cluttering in the continuous scatterplot, by interactively selecting the features of the Reeb space to project. We provide a VTK-based C++ implementation of our algorithm that can be used for reproduction purposes or for the development of new Reeb space based visualization techniques.	Julien Tierny;Hamish A. Carr	Julien Tierny;Hamish Carr	Sorbonne Universites, UPMC UnivParis06, CNRS, LIP6 UMR 7606, France;University of Leeds	10.1109/TVCG.2009.163;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/TVCG.2010.146;10.1109/TVCG.2006.165;10.1109/VISUAL.2004.96;10.1109/TVCG.2015.2467432;10.1109/TVCG.2008.116;10.1109/TVCG.2008.119;10.1109/TVCG.2014.2346332;10.1109/TVCG.2008.110	Topological data analysis;multivariate data;data segmentation	4	11	6	48	BP
SciVis	2016	Topological Analysis of Inertial Dynamics	10.1109/TVCG.2016.2599018	http://dx.doi.org/10.1109/TVCG.2016.2599018	950	959	J	Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.	Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo	Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo	Heidelberg University, Germany;Heidelberg University, Germany;ZAH, Heidelberg University, Germany;Universidade de Såo Paulo, Såo Carlos, Brazil;Universidade de Såo Paulo, Såo Carlos, Brazil;Heidelberg University, Germany	10.1109/VISUAL.1993.398859;10.1109/TVCG.2014.2346415;10.1109/VISUAL.1990.146386	Visualization of inertial dynamics;N-body systems;magnetism;acceleration	3	8	5	30	
InfoVis	2016	Vega-Lite: A Grammar of Interactive Graphics	10.1109/TVCG.2016.2599030	http://dx.doi.org/10.1109/TVCG.2016.2599030	341	350	J	We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.	Arvind Satyanarayan;Dominik Moritz;Kanit Wongsuphasawat;Jeffrey Heer	Arvind Satyanarayan;Dominik Moritz;Kanit Wongsuphasawat;Jeffrey Heer	Stanford University;University of Washington;University of Washington;University of Washington	10.1109/TVCG.2015.2467091;10.1109/TVCG.2009.174;10.1109/TVCG.2015.2467191;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70515;10.1109/TVCG.2011.185	Information visualization;interaction;systems;toolkits;declarative specification	44	116	79	31	BP
SciVis	2016	Direct Multifield Volume Ray Casting of Fiber Surfaces	10.1109/TVCG.2016.2599040	http://dx.doi.org/10.1109/TVCG.2016.2599040	941	949	J	Multifield data are common in visualization. However, reducing these data to comprehensible geometry is a challenging problem. Fiber surfaces, an analogy of isosurfaces to bivariate volume data, are a promising new mechanism for understanding multifield volumes. In this work, we explore direct ray casting of fiber surfaces from volume data without any explicit geometry extraction. We sample directly along rays in domain space, and perform geometric tests in range space where fibers are defined, using a signed distance field derived from the control polygons. Our method requires little preprocess, and enables real-time exploration of data, dynamic modification and pixel-exact rendering of fiber surfaces, and support for higher-order interpolation in domain space. We demonstrate this approach on several bivariate datasets, including analysis of multi-field combustion data.	Kui Wu 0003;Aaron Knoll;Benjamin J. Isaac;Hamish A. Carr;Valerio Pascucci	Kui Wu;Aaron Knoll;Benjamin J Isaac;Hamish Carr;Valerio Pascucci	University of Utah;SCI InstituteUniversity of UtahArgonne National Laboratory;ICSE, University of Utah;School of ComputingUniversity of Leeds;SCI InstituteUniversity of Utah	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.89;10.1109/TVCG.2009.185;10.1109/TVCG.2009.204;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1998.745713;10.1109/TVCG.2006.157;10.1109/TVCG.2010.145;10.1109/TVCG.2015.2467433;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1998.745300;10.1109/TVCG.2008.119;10.1109/VISUAL.2004.52	Volume Rendering;Isosurface;Multidimensional Data	0	3	5	42	
SciVis	2016	OSPRay - A CPU Ray Tracing Framework for Scientific Visualization	10.1109/TVCG.2016.2599041	http://dx.doi.org/10.1109/TVCG.2016.2599041	931	940	J	Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.	Ingo Wald;Gregory P. Johnson;Jefferson Amstutz;Carson Brownlee;Aaron Knoll;Jim Jeffers;Johannes Günther 0001;Paul A. Navrátil	I Wald;GP Johnson;J Amstutz;C Brownlee;A Knoll;J Jeffers;J Günther;P Navratil	Intel Corp;Intel Corp;Intel Corp;Intel Corp;SCI InsituteUniversity of Utah;Intel Corp;Intel Corp;Texas Advanced Computing Center	10.1109/SciVis.2015.7429492;10.1109/TVCG.2010.173;10.1109/TVCG.2015.2467963		15	38	35	51	
SciVis	2016	Progressive Direct Volume-to-Volume Transformation	10.1109/TVCG.2016.2599042	http://dx.doi.org/10.1109/TVCG.2016.2599042	921	930	J	We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets.	Steffen Frey;Thomas Ertl	Steffen Frey;Thomas Ertl	University of Stuttgart;University of Stuttgart	10.1109/TVCG.2008.140;10.1109/TVCG.2012.284;10.1109/VISUAL.1994.346333;10.1109/TVCG.2008.143;10.1109/TVCG.2009.200;10.1109/VISUAL.2002.1183809	Volume transformation;Volume visualization;progressive;automatic;parallel;time-varying data;streaming data	2	4	4	47	
SciVis	2016	A Versatile and Efficient GPU Data Structure for Spatial Indexing	10.1109/TVCG.2016.2599043	http://dx.doi.org/10.1109/TVCG.2016.2599043	911	920	J	In this paper we present a novel GPU-based data structure for spatial indexing. Based on Fenwick trees-a special type of binary indexed trees-our data structure allows construction in linear time. Updates and prefixes can be computed in logarithmic time, whereas point queries require only constant time on average. Unlike competing data structures such as summed-area tables and spatial hashing, our data structure requires a constant amount of bits for each data element, and it offers unconstrained point queries. This property makes our data structure ideally suited for applications requiring unconstrained indexing of large data, such as block-storage of large and block-sparse volumes. Finally, we provide asymptotic bounds on both run-time and memory requirements, and we show applications for which our new data structure is useful.	Jens Schneider;Peter Rautek	Jens Schneider;Peter Rautek	Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST);Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST)	10.1109/TVCG.2015.2467331	GPU-based Data Structures;Binary Index Trees;Sparse Data	0	1	2	21	
SciVis	2016	GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization	10.1109/TVCG.2016.2599049	http://dx.doi.org/10.1109/TVCG.2016.2599049	891	900	J	Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs.	Xin Tong;Cheng Li;Han-Wei Shen	Xin Tong;Cheng Li;Han-Wei Shen	The Ohio State University;The Ohio State University;The Ohio State University	10.1109/TVCG.2013.121;10.1109/INFVIS.1996.559215;10.1109/TVCG.2010.199;10.1109/TVCG.2010.127;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.1993.398849;10.1109/TVCG.2015.2467202;10.1109/TVCG.2006.167;10.1109/TVCG.2010.157	View-dependent visualization;focus + context techniques;manipulation and deformation;glyph-based techniques;human-computer interaction	2	10	9	48	
InfoVis	2016	HindSight: Encouraging Exploration through Direct Encoding of Personal Interaction History	10.1109/TVCG.2016.2599058	http://dx.doi.org/10.1109/TVCG.2016.2599058	351	360	J	Physical and digital objects often leave markers of our use. Website links turn purple after we visit them, for example, showing us information we have yet to explore. These “footprints” of interaction offer substantial benefits in information saturated environments - they enable us to easily revisit old information, systematically explore new information, and quickly resume tasks after interruption. While applying these design principles have been successful in HCI contexts, direct encodings of personal interaction history have received scarce attention in data visualization. One reason is that there is little guidance for integrating history into visualizations where many visual channels are already occupied by data. More importantly, there is not firm evidence that making users aware of their interaction history results in benefits with regards to exploration or insights. Following these observations, we propose HindSight - an umbrella term for the design space of representing interaction history directly in existing data visualizations. In this paper, we examine the value of HindSight principles by augmenting existing visualizations with visual indicators of user interaction history (e.g. How the Recession Shaped the Economy in 255 Charts, NYTimes). In controlled experiments of over 400 participants, we found that HindSight designs generally encouraged people to visit more data and recall different insights after interaction. The results of our experiments suggest that simple additions to visualizations can make users aware of their interaction history, and that these additions significantly impact users' exploration and insights.	Mi Feng;Cheng Deng;Evan M. Peck;Lane Harrison	Mi Feng;Cheng Deng;Evan M. Peck;Lane Harrison	Worcester Polytechnic Institute;Worcester Polytechnic Institute;Bucknell University;Worcester Polytechnic Institute	10.1109/VISUAL.2002.1183791;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346452;10.1109/TVCG.2008.137;10.1109/TVCG.2014.2346424;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.109	History;Visualization;Interaction	6	19	11	36	
InfoVis	2016	Evaluating the Impact of Binning 2D Scalar Fields	10.1109/TVCG.2016.2599106	http://dx.doi.org/10.1109/TVCG.2016.2599106	431	440	J	The expressiveness principle for visualization design asserts that a visualization should encode all of the available data, and only the available data, implying that continuous data types should be visualized with a continuous encoding channel. And yet, in many domains binning continuous data is not only pervasive, but it is accepted as standard practice. Prior work provides no clear guidance for when encoding continuous data continuously is preferable to employing binning techniques or how this choice affects data interpretation and decision making. In this paper, we present a study aimed at better understanding the conditions in which the expressiveness principle can or should be violated for visualizing continuous data. We provided participants with visualizations employing either continuous or binned greyscale encodings of geospatial elevation data and compared participants' ability to complete a wide variety of tasks. For various tasks, the results indicate significant differences in decision making, confidence in responses, and task completion time between continuous and binned encodings of the data. In general, participants with continuous encodings were faster to complete many of the tasks, but never outperformed those with binned encodings, while performance accuracy with binned encodings was superior to continuous encodings in some tasks. These findings suggest that strict adherence to the expressiveness principle is not always advisable. We discuss both the implications and limitations of our results and outline various avenues for potential work needed to further improve guidelines for using continuous versus binned encodings for continuous data types.	Lace M. K. Padilla;P. Samuel Quinan;Miriah D. Meyer;Sarah H. Creem-Regehr	Lace Padilla;P. Samuel Quinan;Miriah Meyer;Sarah H. Creem-Regehr	Department of Psychology, University of Utah;University of UtahSchool of Computing;University of UtahSchool of Computing;Department of Psychology, University of Utah	10.1109/TVCG.2011.175;10.1109/TVCG.2015.2467754;10.1109/VISUAL.1999.809932;10.1109/VISUAL.1996.568118;10.1109/VISUAL.1995.480803;10.1109/TVCG.2013.124	Geographic/Geospatial Visualization;Qualitative Evaluation;Color Perception;Perceptual Cognition	11	21	16	54	
InfoVis	2016	Immersive Collaborative Analysis of Network Connectivity: CAVE-style or Head-Mounted Display?	10.1109/TVCG.2016.2599107	http://dx.doi.org/10.1109/TVCG.2016.2599107	441	450	J	High-quality immersive display technologies are becoming mainstream with the release of head-mounted displays (HMDs) such as the Oculus Rift. These devices potentially represent an affordable alternative to the more traditional, centralised CAVE-style immersive environments. One driver for the development of CAVE-style immersive environments has been collaborative sense-making. Despite this, there has been little research on the effectiveness of collaborative visualisation in CAVE-style facilities, especially with respect to abstract data visualisation tasks. Indeed, very few studies have focused on the use of these displays to explore and analyse abstract data such as networks and there have been no formal user studies investigating collaborative visualisation of abstract data in immersive environments. In this paper we present the results of the first such study. It explores the relative merits of HMD and CAVE-style immersive environments for collaborative analysis of network connectivity, a common and important task involving abstract data. We find significant differences between the two conditions in task completion time and the physical movements of the participants within the space: participants using the HMD were faster while the CAVE2 condition introduced an asymmetry in movement between collaborators. Otherwise, affordances for collaborative data analysis offered by the low-cost HMD condition were not found to be different for accuracy and communication with the CAVE2. These results are notable, given that the latest HMDs will soon be accessible (in terms of cost and potentially ubiquity) to a massive audience.	Maxime Cordeil;Tim Dwyer;Karsten Klein 0001;Bireswar Laha;Kim Marriott;Bruce H. Thomas	Maxime Cordeil;Tim Dwyer;Karsten Klein;Bireswar Laha;Kim Marriott;Bruce H. Thomas	Monash University;Monash University;Monash University;Stanford University, USA;Monash University;University of South Australia	10.1109/VISUAL.2001.964545;10.1109/TVCG.2014.2346573;10.1109/VAST.2007.4389011;10.1109/TVCG.2006.156;10.1109/TVCG.2011.234	3D Network;Oculus Rift;CAVE;Immersive Analytics;Collaboration	30	59	42	41	
SciVis	2016	Vol²velle: Printable Interactive Volume Visualization	10.1109/TVCG.2016.2599211	http://dx.doi.org/10.1109/TVCG.2016.2599211	861	870	J	Interaction is an indispensable aspect of data visualization. The presentation of volumetric data, in particular, often significantly benefits from interactive manipulation of parameters such as transfer functions, rendering styles, or clipping planes. However, when we want to create hardcopies of such visualizations, this essential aspect is lost. In this paper, we present a novel approach for creating hardcopies of volume visualizations which preserves a certain degree of interactivity. We present a method for automatically generating Volvelles, printable tangible wheel charts that can be manipulated to explore different parameter settings. Our interactive system allows the flexible mapping of arbitrary visualization parameters and supports advanced features such as linked views. The resulting designs can be easily reproduced using a standard printer and assembled within a few minutes.	Sergej Stoppel;Stefan Bruckner	Sergej Stoppel;Stefan Bruckner	University of Bergen;University of Bergen	10.1109/TVCG.2014.2346292;10.1109/TVCG.2013.121;10.1109/TVCG.2013.134;10.1109/TVCG.2006.140;10.1109/TVCG.2006.148;10.1109/VISUAL.1999.809871;10.1109/TVCG.2015.2467294;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2014.2352953;10.1109/TVCG.2007.70584	Illustrative Visualization;Physical Visualization;Interaction;Volume Visualization			3	45	
SciVis	2016	Categorical Colormap Optimization with Visualization Case Studies	10.1109/TVCG.2016.2599214	http://dx.doi.org/10.1109/TVCG.2016.2599214	871	880	J	Mapping a set of categorical values to different colors is an elementary technique in data visualization. Users of visualization software routinely rely on the default colormaps provided by a system, or colormaps suggested by software such as ColorBrewer. In practice, users often have to select a set of colors in a semantically meaningful way (e.g., based on conventions, color metaphors, and logological associations), and consequently would like to ensure their perceptual differentiation is optimized. In this paper, we present an algorithmic approach for maximizing the perceptual distances among a set of given colors. We address two technical problems in optimization, i.e., (i) the phenomena of local maxima that halt the optimization too soon, and (ii) the arbitrary reassignment of colors that leads to the loss of the original semantic association. We paid particular attention to different types of constraints that users may wish to impose during the optimization process. To demonstrate the effectiveness of this work, we tested this technique in two case studies. To reach out to a wider range of users, we also developed a web application called Colourmap Hospital.	Hui Fang;Simon J. Walton;E. Delahaye;J. Harris;D. A. Storchak;Min Chen 0001	H. Fang;S. Walton;E. Delahaye;J. Harris;D. A. Storchak;M. Chen	University of Oxford and International Seismological Centre;University of Oxford, UK;International Seismological Centre, UK;International Seismological Centre, UK;International Seismological Centre, UK;University of Oxford, UK	10.1109/VISUAL.1996.568118;10.1109/TVCG.2014.2346978;10.1109/TVCG.2008.112;10.1109/VISUAL.1995.480803;10.1109/TVCG.2010.150;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2008.118	London tube map;Color;categorical colormap;optimization;seismological data visualization	1	5	6	53	
SciVis	2016	Hybrid Tactile/Tangible Interaction for 3D Data Exploration	10.1109/TVCG.2016.2599217	http://dx.doi.org/10.1109/TVCG.2016.2599217	881	890	J	We present the design and evaluation of an interface that combines tactile and tangible paradigms for 3D visualization. While studies have demonstrated that both tactile and tangible input can be efficient for a subset of 3D manipulation tasks, we reflect here on the possibility to combine the two complementary input types. Based on a field study and follow-up interviews, we present a conceptual framework of the use of these different interaction modalities for visualization both separately and combined-focusing on free exploration as well as precise control. We present a prototypical application of a subset of these combined mappings for fluid dynamics data visualization using a portable, position-aware device which offers both tactile input and tangible sensing. We evaluate our approach with domain experts and report on their qualitative feedback.	Lonni Besançon;Paul Issartel;Mehdi Ammi;Tobias Isenberg 0001	Lonni Besançon;Paul Issartel;Mehdi Ammi;Tobias Isenberg	Inria Saclay, Univ. Paris Saclay, France;Univ. Paris Saclay, France;Limsi/CNRS, France;Inria, France	10.1109/TVCG.2013.121;10.1109/TVCG.2010.164;10.1109/VISUAL.2004.47;10.1109/TVCG.2007.70515;10.1109/TVCG.2010.157;10.1109/VISUAL.2005.1532846;10.1109/TVCG.2011.224;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467202;10.1109/TVCG.2012.292;10.1109/TVCG.2013.126;10.1109/TVCG.2012.217	3D data visualization;Interaction;tactile input;tangible input	9	23	14	89	
InfoVis	2016	VizItCards: A Card-Based Toolkit for Infovis Design Education	10.1109/TVCG.2016.2599338	http://dx.doi.org/10.1109/TVCG.2016.2599338	561	570	J	Shifts in information visualization practice are forcing a reconsideration of how infovis is taught. Traditional curricula that focused on conveying research-derived knowledge are slowly integrating design thinking as a key learning objective. In part, this is motivated by the realization that infovis is a wicked design problem, requiring a different kind of design work. In this paper we describe, VizItCards, a card-driven workshop developed for our graduate infovis class. The workshop is intended to provide practice with good design techniques and to simultaneously reinforce key concepts. VizItCards relies on principles of collaborative-learning and research on parallel design to generate positive collaborations and high-quality designs. From our experience of simulating a realistic design scenario in a classroom setting, we find that our students were able to meet key learning objectives and their design performance improved during the class. We describe variants of the workshop, discussing which techniques we think match to which learning goals.	Shiqing He;Eytan Adar	Shiqing He;Eytan Adar	School of Information at the University of Michigan;School of Information at the University of Michigan	10.1109/TVCG.2015.2467271;10.1109/TVCG.2012.213;10.1109/VAST.2009.5333245;10.1109/TVCG.2014.2346331;10.1109/INFVIS.1996.559229;10.1109/TVCG.2007.70515;10.1109/TVCG.2013.184;10.1109/TVCG.2009.111	information visualization education;peer learning;toolkit;card;design workshop	7	12	6	69	
VAST	2016	VisMatchmaker: Cooperation of the User and the Computer in Centralized Matching Adjustment	10.1109/TVCG.2016.2599378	http://dx.doi.org/10.1109/TVCG.2016.2599378	231	240	J	Centralized matching is a ubiquitous resource allocation problem. In a centralized matching problem, each agent has a preference list ranking the other agents and a central planner is responsible for matching the agents manually or with an algorithm. While algorithms can find a matching which optimizes some performance metrics, they are used as a black box and preclude the central planner from applying his domain knowledge to find a matching which aligns better with the user tasks. Furthermore, the existing matching visualization techniques (i.e. bipartite graph and adjacency matrix) fail in helping the central planner understand the differences between matchings. In this paper, we present VisMatchmaker, a visualization system which allows the central planner to explore alternatives to an algorithm-generated matching. We identified three common tasks in the process of matching adjustment: problem detection, matching recommendation and matching evaluation. We classified matching comparison into three levels and designed visualization techniques for them, including the number line view and the stacked graph view. Two types of algorithmic support, namely direct assignment and range search, and their interactive operations are also provided to enable the user to apply his domain knowledge in matching adjustment.	Po-Ming Law;Wenchao Wu;Yixian Zheng;Huamin Qu	Po-Ming Law;Wenchao Wu;Yixian Zheng;Huamin Qu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology	10.1109/INFVIS.2004.1;10.1109/TVCG.2006.122;10.1109/TVCG.2014.2346249;10.1109/TVCG.2014.2346441;10.1109/VAST.2011.6102453	Centralized matching;matching visualization;interaction techniques;visual analytics	0	1	2	32	
VAST	2016	Supporting visual exploration for multiple users in large display environments	10.1109/VAST.2016.7883506	http://dx.doi.org/10.1109/VAST.2016.7883506	1	10	C	We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.	Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani	Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani	University of Maryland, College Park, USA;University of Manitoba, Winnipeg, Canada;University of Maryland, College Park, USA;University of Manitoba, Winnipeg, Canada	10.1109/TVCG.2013.166;10.1109/TVCG.2009.162;10.1109/TVCG.2013.163;10.1109/TVCG.2011.185		4	7	5	41	
VAST	2016	DocuCompass: Effective exploration of document landscapes	10.1109/VAST.2016.7883507	http://dx.doi.org/10.1109/VAST.2016.7883507	11	20	C	The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users' requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach.	Florian Heimerl;Markus John;Qi Han;Steffen Koch;Thomas Ertl	Florian Heimerl;Markus John;Qi Han;Steffen Koch;Thomas Ertl		10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5333443;10.1109/TVCG.2012.277;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.186;10.1109/VAST.2012.6400487;10.1109/TVCG.2014.2346433;10.1109/TVCG.2008.152;10.1109/TVCG.2013.212;10.1109/TVCG.2013.162;10.1109/TVCG.2015.2467717;10.1109/VAST.2011.6102488;10.1109/VAST.2011.6102456		3	11	8	54	
VAST	2016	C2A: Crowd consensus analytics for virtual colonoscopy	10.1109/VAST.2016.7883508	http://dx.doi.org/10.1109/VAST.2016.7883508	21	30	C	We present a medical crowdsourcing visual analytics platform called C<sup>2</sup>A to visualize, classify and filter crowdsourced clinical data. More specifically, C<sup>2</sup>A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C<sup>2</sup>A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C<sup>2</sup>A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers' output quality, the potential to reduce the radiologists' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.	Ji Hwan Park;Saad Nadeem;Seyedkoosha Mirhosseini;Arie E. Kaufman	Ji Hwan Park;Saad Nadeem;Seyedkoosha Mirhosseini;Arie Kaufman	Stony Brook University, United States of America;Stony Brook University, United States of America;Stony Brook University, United States of America;Stony Brook University, United States of America	10.1109/TVCG.2015.2467196;10.1109/TVCG.2006.112;10.1109/TVCG.2009.171;10.1109/TVCG.2006.158;10.1109/VAST.2015.7347631;10.1109/TVCG.2013.164;10.1109/TVCG.2015.2467555		0	2	1	39	
VAST	2016	The DataSpace for HIV vaccine studies	10.1109/VAST.2016.7883509	http://dx.doi.org/10.1109/VAST.2016.7883509	31	40	C	The DataSpace for HIV vaccine studies is a discovery tool available on the web to hundreds of investigators. We designed it to help them better understand activity in the field and explore new ideas latent in completed research. The DataSpace harmonizes immunoassay results and study metadata so that a broader research community can pursue more flexible discovery than the typical centrally planned analyses. Insights from human-centered design and beta evaluation suggest strong potential for visual analytics that may also apply to other efforts in open science. The contribution of this paper is to elucidate key domain challenges and demonstrate an application that addresses them. We made several changes to familiar visualizations to support key tasks such as identifying and filtering to a cohort of interest, making meaningful comparisons of time series data from multiple studies that have different plans, and preserving analytic context when making data transformations and comparisons that would normally exclude some data.	David McColgin;Paul Hoover;Mark Igra	David McColgin;Paul Hoover;Mark Igra	LabKey Software, United States of America;LabKey Software, United States of America;LabKey Software, United States of America			1	1	1	18	
VAST	2016	D-Map: Visual Analysis of Ego-centric Information Diffusion Patterns in Social Media	10.1109/VAST.2016.7883510	http://dx.doi.org/10.1109/VAST.2016.7883510	41	50	C	Popular social media platforms could rapidly propagate vital information over social networks among a significant number of people. In this work we present D-Map (Diffusion Map), a novel visualization method to support exploration and analysis of social behaviors during such information diffusion and propagation on typical social media through a map metaphor. In D-Map, users who participated in reposting (i.e., resending a message initially posted by others) one central user's posts (i.e., a series of original tweets) are collected and mapped to a hexagonal grid based on their behavior similarities and in chronological order of the repostings. With additional interaction and linking, D-Map is capable of providing visual portraits of the influential users and describing their social behaviors. A comprehensive visual analysis system is developed to support interactive exploration with D-Map. We evaluate our work with real world social media data and find interesting patterns among users. Key players, important information diffusion paths, and interactions among social communities can be identified.	Siming Chen;Shuai Chen 0001;Zhenhuang Wang;Jie Liang 0004;Xiaoru Yuan;Nan Cao;Yadong Wu	Siming Chen;Shuai Chen;Zhenhuang Wang;Jie Liang;Xiaoru Yuan;Nan Cao;Yadong Wu	Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;New York University, Shanghai, China;Southwest University of Science and Technology, China	10.1109/TVCG.2015.2467196;10.1109/TVCG.2014.2346922;10.1109/TVCG.2012.291;10.1109/TVCG.2010.154;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346919;10.1109/TVCG.2014.2346920;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346277		5	12	16	52	
VAST	2016	How ideas flow across multiple social groups	10.1109/VAST.2016.7883511	http://dx.doi.org/10.1109/VAST.2016.7883511	51	60	C	Tracking how correlated ideas flow within and across multiple social groups facilitates the understanding of the transfer of information, opinions, and thoughts on social media. In this paper, we present IdeaFlow, a visual analytics system for analyzing the lead-lag changes within and across pre-defined social groups regarding a specific set of correlated ideas, each of which is described by a set of words. To model idea flows accurately, we develop a random-walk-based correlation model and integrate it with Bayesian conditional cointegration and a tensor-based technique. To convey complex lead-lag relationships over time, IdeaFlow combines the strengths of a bubble tree, a flow map, and a timeline. In particular, we develop a Voronoi-treemap-based bubble tree to help users get an overview of a set of ideas quickly. A correlated-clustering-based layout algorithm is used to simultaneously generate multiple flow maps with less ambiguity. We also introduce a focus+context timeline to explore huge amounts of temporal data at different levels of time granularity. Quantitative evaluation and case studies demonstrate the accuracy and effectiveness of IdeaFlow.	Xiting Wang;Shixia Liu;Yang Chen;Tai-Quan Peng;Jing Su;Jing Yang;Baining Guo	Xiting Wang;Shixia Liu;Yang Chen;Tai-Quan Peng;Jing Su;Jing Yang;Baining Guo	School of Software, Tsinghua University, China;School of Software, Tsinghua University, China;School of Software, Tsinghua University, China;Michigan State University, United States of America;Tsinghua University, China;UNCC, United States of America;Microsoft Research, United States of America	10.1109/VAST.2011.6102461;10.1109/VAST.2010.5652931;10.1109/TVCG.2015.2467554;10.1109/TVCG.2014.2346433;10.1109/TVCG.2015.2467992;10.1109/TVCG.2015.2467691;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.196;10.1109/TVCG.2015.2467757;10.1109/TVCG.2012.212;10.1109/TVCG.2010.129;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346919;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2014.2346920;10.1109/TVCG.2015.2467991;10.1109/TVCG.2011.239;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2009.111;10.1109/INFVIS.2005.1532128		4	12	12	56	
VAST	2016	EventAction: Visual analytics for temporal event sequence recommendation	10.1109/VAST.2016.7883512	http://dx.doi.org/10.1109/VAST.2016.7883512	61	70	C	Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users' goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students.	Fan Du;Catherine Plaisant;Neil Spring;Ben Shneiderman	Fan Du;Catherine Plaisant;Neil Spring;Ben Shneiderman	University of Maryland, United States of America;University of Maryland, United States of America;University of Maryland, United States of America;University of Maryland, United States of America	10.1109/TVCG.2009.187;10.1109/TVCG.2012.225;10.1109/TVCG.2012.213;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682		7	30	21	45	
VAST	2016	SocialBrands: Visual analysis of public perceptions of brands on social media	10.1109/VAST.2016.7883513	http://dx.doi.org/10.1109/VAST.2016.7883513	71	80	C	Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.	Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen	Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen	Ohio State University, United States of America;IBM Research, United States of America;Visa Research, United States of America;IBM Research, United States of America;IBM Research, United States of America;Ohio State University, United States of America	10.1109/TVCG.2014.2346922;10.1109/VAST.2014.7042496;10.1109/TVCG.2013.227;10.1109/TVCG.2012.291;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/INFVIS.2000.885091;10.1109/TVCG.2011.183		2	4	3	42	
VAST	2016	DimScanner: A Relation-based Visual Exploration Approach Towards Data Dimension Inspection	10.1109/VAST.2016.7883514	http://dx.doi.org/10.1109/VAST.2016.7883514	81	90	C	Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data.	Jing Xia;Wei Chen 0001;Yumeng Hou;Wanqi Hu;Xinxin Huang;David S. Ebert	Jing Xia;Wei Chen;Yumeng Hou;Wanqi Hu;Xinxin Huang;David S. Ebertk	State Key Lab of CAD&amp;CG, Zhejiang University, China;State Key Lab of CAD&amp;CG, Zhejiang University, China;State Key Lab of CAD&amp;CG, Zhejiang University, China;State Key Lab of CAD&amp;CG, Zhejiang University, China;State Key Lab of CAD&amp;CG, Zhejiang University, China;Purdue University, United States of America	10.1109/TVCG.2015.2467191;10.1109/TVCG.2009.153;10.1109/INFVIS.1998.729559;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2010.5652450;10.1109/VAST.2006.261423;10.1109/TVCG.2013.160;10.1109/TVCG.2013.150;10.1109/TVCG.2011.229;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3		4	13	3	35	
VAST	2016	SenseMap: Supporting browser-based online sensemaking through analytic provenance	10.1109/VAST.2016.7883515	http://dx.doi.org/10.1109/VAST.2016.7883515	91	100	C	Sensemaking is described as the process in which people collect, organize and create representations of information, all centered around some problem they need to understand. People often get lost when solving complicated tasks using big datasets over long periods of exploration and analysis. They may forget what they have done, are unaware of where they are in the context of the overall task, and are unsure where to continue. In this paper, we introduce a tool, SenseMap, to address these issues in the context of browser-based online sensemaking. We conducted a semi-structured interview with nine participants to explore their behaviors in online sensemaking with existing browser functionality. A simplified sensemaking model based on Pirolli and Card's model is derived to better represent the behaviors we found: users iteratively collect information sources relevant to the task, curate them in a way that makes sense, and finally communicate their findings to others. SenseMap automatically captures provenance of user sensemaking actions and provides multi-linked views to visualize the collected information and enable users to curate and communicate their findings. To explore how SenseMap is used, we conducted a user study in a naturalistic work setting with five participants completing the same sensemaking task related to their daily work activities. All participants found the visual representation and interaction of the tool intuitive to use. Three of them engaged with the tool and produced successful outcomes. It helped them to organize information sources, to quickly find and navigate to the sources they wanted, and to effectively communicate their findings.	Phong H. Nguyen;Kai Xu 0003;Andy Bardill;Betul Salman;Kate Herd;B. L. William Wong	Phong H. Nguyen;Kai Xu;Andy Bardill;Betul Salman;Kate Herd;B.L. William Wong	Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK	10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.132;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.124;10.1109/TVCG.2011.185		3	7	6	41	
VAST	2016	PorosityAnalyzer: Visual Analysis and Evaluation of Segmentation Pipelines to Determine the Porosity in Fiber-Reinforced Polymers	10.1109/VAST.2016.7883516	http://dx.doi.org/10.1109/VAST.2016.7883516	101	110	C	In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.	Johannes Weissenböck;Artem Amirkhanov;M. Eduard Gröller;Johann Kastner;Christoph Heinzl	Johannes Weissenböck;Artem Amirkhanov;Eduard Gröller;Johann Kastner;Christoph Heinzl	University of Applied Sciences, Upper Austria, Wels, Austria;University of Applied Sciences, Upper Austria, Wels, Austria;TU Wien, Vienna, Austria;University of Applied Sciences, Upper Austria, Wels, Austria;University of Applied Sciences, Upper Austria, Wels, Austria	10.1109/TVCG.2013.147;10.1109/TVCG.2008.153;10.1109/VISUAL.1993.398859;10.1109/TVCG.2012.200;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2013.177;10.1109/TVCG.2011.248		0	3	5	33	
VAST	2016	DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction	10.1109/VAST.2016.7883517	http://dx.doi.org/10.1109/VAST.2016.7883517	111	120	C	Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.	Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu	Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu	Hong Kong University of Science and Technology, China;Hong Kong University of Science and Technology, China;Hong Kong University of Science and Technology, China;Massachusetts Institute of Technology, United States of America;Massachusetts Institute of Technology, United States of America;Hong Kong University of Science and Technology, China	10.1109/INFVIS.1999.801851;10.1109/TVCG.2015.2468151;10.1109/INFVIS.2000.885098;10.1109/VAST.2010.5652931;10.1109/TVCG.2010.129;10.1109/VAST.2012.6400557;10.1109/INFVIS.2001.963273;10.1109/TVCG.2013.221;10.1109/TVCG.2007.70515;10.1109/TVCG.2011.239		4	11	8	41	
VAST	2016	Shape Grammar Extraction for Efficient Query-by-Sketch Pattern Matching in Long Time Series	10.1109/VAST.2016.7883518	http://dx.doi.org/10.1109/VAST.2016.7883518	121	130	C	Long time-series, involving thousands or even millions of time steps, are common in many application domains but remain very difficult to explore interactively. Often the analytical task in such data is to identify specific patterns, but this is a very complex and computationally difficult problem and so focusing the search in order to only identify interesting patterns is a common solution. We propose an efficient method for exploring user-sketched patterns, incorporating the domain expert's knowledge, in time series data through a shape grammar based approach. The shape grammar is extracted from the time series by considering the data as a combination of basic elementary shapes positioned across different amplitudes. We represent these basic shapes using a ratio value, perform binning on ratio values and apply a symbolic approximation. Our proposed method for pattern matching is amplitude-, scale- and translation-invariant and, since the pattern search and pattern constraint relaxation happen at the symbolic level, is very efficient permitting its use in a real-time/online system. We demonstrate the effectiveness of our method in a case study on stock market data although it is applicable to any numeric time series data.	Prithiviraj K. Muthumanickam;Katerina Vrotsou;Matthew D. Cooper;Jimmy Johansson	Prithiviraj K. Muthumanickam;Katerina Vrotsou;Matthew Cooper;Jimmy Johansson	Link&#x00F6;ping University, Sweden;Link&#x00F6;ping University, Sweden;Link&#x00F6;ping University, Sweden;Link&#x00F6;ping University, Sweden	10.1109/TVCG.2008.184;10.1109/VAST.2010.5652530;10.1109/TVCG.2009.200;10.1109/TVCG.2010.137		0	1	1	55	
VAST	2016	The semantics of sketch: Flexibility in visual query systems for time series data	10.1109/VAST.2016.7883519	http://dx.doi.org/10.1109/VAST.2016.7883519	131	140	C	Sketching allows analysts to specify complex and free-form patterns of interest. Visual query systems can make use of sketches to locate these patterns of interest in large datasets. However, sketching is ambiguous: the same drawing could represent a multitude of potential queries. In this work, we investigate these ambiguities as they apply to visual query systems for time series data. We define a class of “invariants” - the properties of a time series that the analyst wishes to ignore when performing a sketch-based query. We present the results of a crowd-sourced study, showing that these invariants are key components of how people rate the strength of match between sketch and target. We adapt a number of algorithms for time series matching to support invariants in sketches. Lastly, we present a web-deployed prototype sketch-based visual query system that relies on these invariants. We apply the prototype to data from finance, the digital humanities, and political science.	Michael Correll;Michael Gleicher	Michael Correll;Michael Gleicher	University of Washington, United States of America;University of Wisconsin-Madison, United States of America	10.1109/TVCG.2014.2346455;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2013.191;10.1109/TVCG.2012.204;10.1109/TVCG.2014.2346452;10.1109/TVCG.2010.162		1	7	7	35	
VAST	2016	Visual analysis and coding of data-rich user behavior	10.1109/VAST.2016.7883520	http://dx.doi.org/10.1109/VAST.2016.7883520	141	150	C	Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.	Tanja Blascheck;Fabian Beck 0001;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf	Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf	University of Stuttgart, Germany;University of Stuttgart, Germany;University of Trier, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany	10.1109/VAST.2009.5333443;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.226;10.1109/TVCG.2014.2346452;10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/TVCG.2015.2467757;10.1109/TVCG.2010.194;10.1109/TVCG.2014.2346677;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.124		4	7	3	58	
InfoVis	2017	What Would a Graph Look Like in this Layout? A Machine Learning Approach to Large Graph Visualization	10.1109/TVCG.2017.2743858	http://dx.doi.org/10.1109/TVCG.2017.2743858	478	488	J	Using different methods for laying out a graph can lead to very different visual appearances, with which the viewer perceives different information. Selecting a “good” layout method is thus important for visualizing a graph. The selection can be highly subjective and dependent on the given task. A common approach to selecting a good layout is to use aesthetic criteria and visual inspection. However, fully calculating various layouts and their associated aesthetic metrics is computationally expensive. In this paper, we present a machine learning approach to large graph visualization based on computing the topological similarity of graphs using graph kernels. For a given graph, our approach can show what the graph would look like in different layouts and estimate their corresponding aesthetic metrics. An important contribution of our work is the development of a new framework to design graph kernels. Our experimental study shows that our estimation calculation is considerably faster than computing the actual layouts and their aesthetic metrics. Also, our graph kernels outperform the state-of-the-art ones in both time and accuracy. In addition, we conducted a user study to demonstrate that the topological similarity computed with our graph kernel matches perceptual similarity assessed by human users.	Oh-Hyun Kwon;Tarik Crnovrsanin;Kwan-Liu Ma	Oh-Hyun Kwon;Tarik Crnovrsanin;Kwan-Liu Ma	University of California, Davis;University of California, Davis;University of California, Davis	10.1109/TVCG.2016.2598467;10.1109/TVCG.2007.70580;10.1109/TVCG.2015.2467451;10.1109/INFVIS.2002.1173159;10.1109/TVCG.2008.158;10.1109/TVCG.2008.155;10.1109/TVCG.2016.2598867	Graph visualization,graph layout,aesthetics,machine learning,graph kernel,graphlet	0	11	4	92	
InfoVis	2017	MyBrush: Brushing and Linking with Personal Agency	10.1109/TVCG.2017.2743859	http://dx.doi.org/10.1109/TVCG.2017.2743859	605	615	J	We extend the popular brushing and linking technique by incorporating personal agency in the interaction. We map existing research related to brushing and linking into a design space that deconstructs the interaction technique into three components: source (what is being brushed), link (the expression of relationship between source and target), and target (what is revealed as related to the source). Using this design space, we created MyBrush, a unified interface that offers personal agency over brushing and linking by giving people the flexibility to configure the source, link, and target of multiple brushes. The results of three focus groups demonstrate that people with different backgrounds leveraged personal agency in different ways, including performing complex tasks and showing links explicitly. We reflect on these results, paving the way for future research on the role of personal agency in information visualization.	Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale	Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale	University of CalgaryAugsburg University;City, University of LondonUniversity of Calgary;University of Calgary;Augsburg University;University of Calgary	10.1109/TVCG.2011.185;10.1109/VISUAL.1991.175794;10.1109/INFVIS.2003.1249024;10.1109/TVCG.2011.201;10.1109/TVCG.2007.70521;10.1109/VAST.2009.5333443;10.1109/TVCG.2008.153;10.1109/INFVIS.2004.64;10.1109/INFVIS.1999.801858;10.1109/TVCG.2014.2346260;10.1109/VISUAL.2000.885739;10.1109/INFVIS.2002.1173157;10.1109/VAST.2007.4389011;10.1109/TVCG.2006.147;10.1109/TVCG.2008.116;10.1109/TVCG.2013.154;10.1109/TVCG.2010.138;10.1109/VISUAL.1995.485139;10.1109/TVCG.2011.183;10.1109/TVCG.2009.162;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2004.12;10.1109/VISUAL.1996.567800	Brushing,linking,personal agency,coordinated multiple views,interaction,design space,information visualization	1	10	4	82	
InfoVis	2017	Imagining Replications: Graphical Prediction & Discrete Visualizations Improve Recall & Estimation of Effect Uncertainty	10.1109/TVCG.2017.2743898	http://dx.doi.org/10.1109/TVCG.2017.2743898	446	456	J	People often have erroneous intuitions about the results of uncertain processes, such as scientific experiments. Many uncertainty visualizations assume considerable statistical knowledge, but have been shown to prompt erroneous conclusions even when users possess this knowledge. Active learning approaches been shown to improve statistical reasoning, but are rarely applied in visualizing uncertainty in scientific reports. We present a controlled study to evaluate the impact of an interactive, graphical uncertainty prediction technique for communicating uncertainty in experiment results. Using our technique, users sketch their prediction of the uncertainty in experimental effects prior to viewing the true sampling distribution from an experiment. We find that having a user graphically predict the possible effects from experiment replications is an effective way to improve one's ability to make predictions about replications of new experiments. Additionally, visualizing uncertainty as a set of discrete outcomes, as opposed to a continuous probability distribution, can improve recall of a sampling distribution from a single experiment. Our work has implications for various applications where it is important to elicit peoples' estimates of probability distributions and to communicate uncertainty effectively.	Jessica Hullman;Matthew Kay;Yea-Seul Kim;Samana Shrestha	Jessica Hullman;Matthew Kay;Yea-Seul Kim;Samana Shrestha	University of Washington;University of Michigan;University of Washington;Vassar College	10.1109/TVCG.2012.199	Graphical prediction,interactive uncertainty visualization,replication crisis,probability distribution	0	10	5	67	
InfoVis	2017	Assessing the Graphical Perception of Time and Speed on 2D+Time Trajectories	10.1109/TVCG.2017.2743918	http://dx.doi.org/10.1109/TVCG.2017.2743918	698	708	J	We empirically evaluate the extent to which people perceive non-constant time and speed encoded on 2D paths. In our graphical perception study, we evaluate nine encodings from the literature for both straight and curved paths. Visualizing time and speed information is a challenge when the x and y axes already encode other data dimensions, for example when plotting a trip on a map. This is particularly true in disciplines such as time-geography and movement analytics that often require visualizing spatio-temporal trajectories. A common approach is to use 2D+time trajectories, which are 2D paths for which time is an additional dimension. However, there are currently no guidelines regarding how to represent time and speed on such paths. Our study results provide InfoVis designers with clear guidance regarding which encodings to use and which ones to avoid; in particular, we suggest using color value to encode speed and segment length to encode time whenever possible.	Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale	Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale	City, University of LondonUniversity of Calgary;University of Calgary;University of Calgary;University of Calgary	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2015.2467851;10.1109/TVCG.2012.251;10.1109/TVCG.2012.220;10.1109/TVCG.2014.2346424;10.1109/TVCG.2014.2346298;10.1109/TVCG.2016.2598594;10.1109/TVCG.2015.2467752;10.1109/TVCG.2015.2467951;10.1109/TVCG.2015.2467951;10.1109/VAST.2008.4677355;10.1109/TVCG.2014.2346250;10.1109/TVCG.2012.229;10.1109/TVCG.2009.126;10.1109/TVCG.2007.70594;10.1109/TVCG.2014.2346279;10.1109/TVCG.2013.192;10.1109/TVCG.2009.114;10.1109/TVCG.2014.2346320;10.1109/TVCG.2012.265	Trajectory visualization,visual encoding,movement data,graphical perception,quantitative evaluation	1	2	1	79	
SciVis	2017	The Topology ToolKit	10.1109/TVCG.2017.2743938	http://dx.doi.org/10.1109/TVCG.2017.2743938	832	842	J	This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code. online documentation and video tutorials are available on TTK's website [108].	Julien Tierny;Guillaume Favelier;Joshua A. Levine;Charles Gueunet;Michael Michaux	Julien Tierny;Guillaume Favelier;Joshua A. Levine;Charles Gueunet;Michael Michaux	Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France;Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France;University of Arizona, USA;Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France;Sorbonne Universites, UPMC Univ Paris 06, CNRS, LIP6 UMR 7606, France	10.1109/TVCG.2008.119;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.2004.96;10.1109/TVCG.2014.2346322;10.1109/TVCG.2010.213;10.1109/TVCG.2014.2346403;10.1109/TVCG.2008.110;10.1109/TVCG.2012.209;10.1109/TVCG.2014.2346434;10.1109/TVCG.2015.2467432;10.1109/TVCG.2007.70603;10.1109/TVCG.2015.2467449;10.1109/TVCG.2006.186;10.1109/TVCG.2014.2346318;10.1109/TVCG.2014.2346332;10.1109/TVCG.2016.2599017;10.1109/TVCG.2009.163;10.1109/TVCG.2012.228	Topological data analysis,scalar data,data segmentation,feature extraction,bivariate data,uncertain data	3	24	6	118	HM
InfoVis	2017	Data Visualization Saliency Model: A Tool for Evaluating Abstract Data Visualizations	10.1109/TVCG.2017.2743939	http://dx.doi.org/10.1109/TVCG.2017.2743939	563	573	J	Evaluating the effectiveness of data visualizations is a challenging undertaking and often relies on one-off studies that test a visualization in the context of one specific task. Researchers across the fields of data science, visualization, and human-computer interaction are calling for foundational tools and principles that could be applied to assessing the effectiveness of data visualizations in a more rapid and generalizable manner. One possibility for such a tool is a model of visual saliency for data visualizations. Visual saliency models are typically based on the properties of the human visual cortex and predict which areas of a scene have visual features (e.g. color, luminance, edges) that are likely to draw a viewer's attention. While these models can accurately predict where viewers will look in a natural scene, they typically do not perform well for abstract data visualizations. In this paper, we discuss the reasons for the poor performance of existing saliency models when applied to data visualizations. We introduce the Data Visualization Saliency (DVS) model, a saliency model tailored to address some of these weaknesses, and we test the performance of the DVS model and existing saliency models by comparing the saliency maps produced by the models to eye tracking data obtained from human viewers. Finally, we describe how modified saliency models could be used as general tools for assessing the effectiveness of visualizations, including the strengths and weaknesses of this approach.	Laura E. Matzen;Michael J. Haass;Kristin Divis;Zhiyuan Wang;Andrew T. Wilson	Laura E. Matzen;Michael J. Haass;Kristin M. Divis;Zhiyuan Wang;Andrew T. Wilson	Sandia National Laboratories;Sandia National Laboratories;Sandia National Laboratories;University of Illinois, Urbana-Champaign;Sandia National Laboratories	10.1109/TVCG.2015.2467732	Visual saliency,evaluation,eye tracking	2	8	2	49	
SciVis	2017	Globe Browsing: Contextualized Spatio-Temporal Planetary Surface Visualization	10.1109/TVCG.2017.2743958	http://dx.doi.org/10.1109/TVCG.2017.2743958	802	811	J	Results of planetary mapping are often shared openly for use in scientific research and mission planning. In its raw format, however, the data is not accessible to non-experts due to the difficulty in grasping the context and the intricate acquisition process. We present work on tailoring and integration of multiple data processing and visualization methods to interactively contextualize geospatial surface data of celestial bodies for use in science communication. As our approach handles dynamic data sources, streamed from online repositories, we are significantly shortening the time between discovery and dissemination of data and results. We describe the image acquisition pipeline, the pre-processing steps to derive a 2.5D terrain, and a chunked level-of-detail, out-of-core rendering approach to enable interactive exploration of global maps and high-resolution digital terrain models. The results are demonstrated for three different celestial bodies. The first case addresses high-resolution map data on the surface of Mars. A second case is showing dynamic processes, such as concurrent weather conditions on Earth that require temporal datasets. As a final example we use data from the New Horizons spacecraft which acquired images during a single flyby of Pluto. We visualize the acquisition process as well as the resulting surface data. Our work has been implemented in the OpenSpace software [8], which enables interactive presentations in a range of environments such as immersive dome theaters, interactive touch tables, and virtual reality headsets.	Karl Bladin;Emil Axelsson;Erik Broberg;Carter Emmart;Patric Ljung;Alexander Bock;Anders Ynnerman	Karl Bladin;Emil Axelsson;Erik Broberg;Carter Emmart;Patric Ljung;Alexander Bock;Anders Ynnerman	Link&#x00F6;ping University;Link&#x00F6;ping University;Link&#x00F6;ping University;American Museum of Natural History;Link&#x00F6;ping University;New York UniversityLink&#x00F6;ping University;Link&#x00F6;ping University	10.1109/SciVis.2015.7429503;10.1109/VISUAL.2003.1250366;10.1109/VISUAL.1997.663860	Astronomical visualization,globe rendering,public dissemination,science communication,space mission visualization	0	5	4	63	BP
InfoVis	2017	Bubble Treemaps for Uncertainty Visualization	10.1109/TVCG.2017.2743959	http://dx.doi.org/10.1109/TVCG.2017.2743959	719	728	J	We present a novel type of circular treemap, where we intentionally allocate extra space for additional visual variables. With this extended visual design space, we encode hierarchically structured data along with their uncertainties in a combined diagram. We introduce a hierarchical and force-based circle-packing algorithm to compute Bubble Treemaps, where each node is visualized using nested contour arcs. Bubble Treemaps do not require any color or shading, which offers additional design choices. We explore uncertainty visualization as an application of our treemaps using standard error and Monte Carlo-based statistical models. To this end, we discuss how uncertainty propagates within hierarchies. Furthermore, we show the effectiveness of our visualization using three different examples: the package structure of Flare, the S&amp;P 500 index, and the US consumer expenditure survey.	Jochen Görtler;Christoph Schulz;Daniel Weiskopf;Oliver Deussen	Jochen Görtler;Christoph Schulz;Daniel Weiskopf;Oliver Deussen	University of Konstanz;VISUSUniversity of Stuttgart;VISUSUniversity of Stuttgart;University of Konstanz	10.1109/TVCG.2012.220;10.1109/TVCG.2009.122;10.1109/VAST.2009.5332611;10.1109/TVCG.2014.2346298;10.1109/TVCG.2015.2467752;10.1109/VISUAL.1991.175815;10.1109/TVCG.2013.180;10.1109/TVCG.2012.279;10.1109/TVCG.2010.210;10.1109/TVCG.2016.2598919;10.1109/TVCG.2015.2467992;10.1109/TVCG.2013.232	Uncertainty visualization,hierarchy visualization,treemaps,tree layout,circle packing,contours	2	15	7	46	
SciVis	2017	The Good, the Bad, and the Ugly: A Theoretical Framework for the Assessment of Continuous Colormaps	10.1109/TVCG.2017.2743978	http://dx.doi.org/10.1109/TVCG.2017.2743978	923	933	J	A myriad of design rules for what constitutes a “good” colormap can be found in the literature. Some common rules include order, uniformity, and high discriminative power. However, the meaning of many of these terms is often ambiguous or open to interpretation. At times, different authors may use the same term to describe different concepts or the same rule is described by varying nomenclature. These ambiguities stand in the way of collaborative work, the design of experiments to assess the characteristics of colormaps, and automated colormap generation. In this paper, we review current and historical guidelines for colormap design. We propose a specified taxonomy and provide unambiguous mathematical definitions for the most common design rules.	Roxana Bujack;Terece L. Turton;Francesca Samsel;Colin Ware;David H. Rogers;James P. Ahrens	Roxana Bujack;Terece L. Turton;Francesca Samsel;Colin Ware;David H. Rogers;James Ahrens	Los Alamos National Laboratory;University of Texas, Austin;University of Texas, Austin;University of New Hampshire;Los Alamos National Laboratory;Los Alamos National Laboratory	10.1109/VISUAL.1995.480803;10.1109/TVCG.2014.2346978;10.1109/TVCG.2016.2599214;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2014.2346325;10.1109/TVCG.2016.2599106;10.1109/VISUAL.1990.146383;10.1109/VISUAL.1990.146372;10.1109/VISUAL.2001.964510	colormap,survey,taxonomy,order,uniformity,discriminative power,smoothness,monotonicity,linearity,speed	3	17	8	90	
SciVis	2017	Screen-Space Normal Distribution Function Caching for Consistent Multi-Resolution Rendering of Large Particle Data	10.1109/TVCG.2017.2743979	http://dx.doi.org/10.1109/TVCG.2017.2743979	944	953	J	Molecular dynamics (MD) simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from strong aliasing artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios.	Mohamed Ibrahim;Patrick Wickenhauser;Peter Rautek;Guido Reina;Markus Hadwiger	Mohamed Ibrahim;Patrick Wickenhäuser;Peter Rautek;Guido Reina;Markus Hadwiger	King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visualization Research Center (VISUS), University of Stuttgart, Germany;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visualization Research Center (VISUS), University of Stuttgart, Germany;King Abdullah University of Science and Technology (KAUST), Saudi Arabia	10.1109/VISUAL.2004.103;10.1109/TVCG.2009.142;10.1109/VISUAL.2003.1250404;10.1109/TVCG.2014.2346324;10.1109/TVCG.2010.215;10.1109/TVCG.2016.2599041;10.1109/SciVis.2015.7429492	Multiresolution Techniques,Point-Based Data,Glyph-based Techniques,Scalability Issues,Molecular Visualization	0	1	0	40	
SciVis	2017	TopoAngler: Interactive Topology-Based Extraction of Fishes	10.1109/TVCG.2017.2743980	http://dx.doi.org/10.1109/TVCG.2017.2743980	812	821	J	We present TopoAngler, a visualization framework that enables an interactive user-guided segmentation of fishes contained in a micro-CT scan. The inherent noise in the CT scan coupled with the often disconnected (and sometimes broken) skeletal structure of fishes makes an automatic segmentation of the volume impractical. To overcome this, our framework combines techniques from computational topology with an interactive visual interface, enabling the human-in-the-Ioop to effectively extract fishes from the volume. In the first step, the join tree of the input is used to create a hierarchical segmentation of the volume. Through the use of linked views, the visual interface then allows users to interactively explore this hierarchy, and gather parts of individual fishes into a coherent sub-volume, thus reconstructing entire fishes. Our framework was primarily developed for its application to CT scans of fishes, generated as part of the ScanAllFish project, through close collaboration with their lead scientist. However, we expect it to also be applicable in other biological applications where a single dataset contains multiple specimen; a common routine that is now widely followed in laboratories to increase throughput of expensive CT scanners.	Alexander Bock;Harish Doraiswamy;Adam Summers;Cláudio T. Silva	Alexander Bock;Harish Doraiswamy;Adam Summers;Cláudio Silva	New York University;New York University;University of Washington;New York University	10.1109/VISUAL.2004.96;10.1109/TVCG.2007.70565;10.1109/TVCG.2014.2346449;10.1109/TVCG.2009.178;10.1109/TVCG.2006.186;10.1109/TVCG.2014.2346351;10.1109/TVCG.2016.2598585;10.1109/TVCG.2009.111;10.1109/TVCG.2010.208	Computational topology,join trees,branch decomposition,hierarchical segmentation,interaction,visualization system	1	6	3	48	
SciVis	2017	Multiscale Visualization and Scale-Adaptive Modification of DNA Nanostructures	10.1109/TVCG.2017.2743981	http://dx.doi.org/10.1109/TVCG.2017.2743981	1014	1024	J	We present an approach to represent DNA nanostructures in varying forms of semantic abstraction, describe ways to smoothly transition between them, and thus create a continuous multiscale visualization and interaction space for applications in DNA nanotechnology. This new way of observing, interacting with, and creating DNA nanostructures enables domain experts to approach their work in any of the semantic abstraction levels, supporting both low-level manipulations and high-level visualization and modifications. Our approach allows them to deal with the increasingly complex DNA objects that they are designing, to improve their features, and to add novel functions in a way that no existing single-scale approach offers today. For this purpose we collaborated with DNA nanotechnology experts to design a set of ten semantic scales. These scales take the DNA's chemical and structural behavior into account and depict it from atoms to the targeted architecture with increasing levels of abstraction. To create coherence between the discrete scales, we seamlessly transition between them in a well-defined manner. We use special encodings to allow experts to estimate the nanoscale object's stability. We also add scale-adaptive interactions that facilitate the intuitive modification of complex structures at multiple scales. We demonstrate the applicability of our approach on an experimental use case. Moreover, feedback from our collaborating domain experts confirmed an increased time efficiency and certainty for analysis and modification tasks on complex DNA structures. Our method thus offers exciting new opportunities with promising applications in medicine and biotechnology.	Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg 0001;M. Eduard Gröller;Ivan Barisic;Ivan Viola	Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg;M. Eduard Gröller;Ivan Barišić;Ivan Viola	TU Wien, Austria;Austrian Institute of Technology;TU Wien, Austria;Austrian Institute of Technology;Austrian Institute of Technology;Université Paris-Saclay, France;TU Wien, Austria;Austrian Institute of Technology;TU Wien, Austria	10.1109/VISUAL.2004.103;10.1109/TVCG.2007.70578;10.1109/TVCG.2009.168;10.1109/TVCG.2013.126;10.1109/TVCG.2009.111	Nano,nanotechnology,assembly,multiscale,abstraction,DNA,origami,scale-adaptive modification	2	7	2	54	
SciVis	2017	Robust Detection and Visualization of Jet-Stream Core Lines in Atmospheric Flow	10.1109/TVCG.2017.2743989	http://dx.doi.org/10.1109/TVCG.2017.2743989	893	902	J	Jet-streams, their core lines and their role in atmospheric dynamics have been subject to considerable meteorological research since the first half of the twentieth century. Yet, until today no consistent automated feature detection approach has been proposed to identify jet-stream core lines from 3D wind fields. Such 3D core lines can facilitate meteorological analyses previously not possible. Although jet-stream cores can be manually analyzed by meteorologists in 2D as height ridges in the wind speed field, to the best of our knowledge no automated ridge detection approach has been applied to jet-stream core detection. In this work, we -a team of visualization scientists and meteorologists-propose a method that exploits directional information in the wind field to extract core lines in a robust and numerically less involved manner than traditional 3D ridge detection. For the first time, we apply the extracted 3D core lines to meteorological analysis, considering real-world case studies and demonstrating our method's benefits for weather forecasting and meteorological research.	Michael Kern;Tim Hewson;Filip Sadlo;Rüdiger Westermann;Marc Rautenhaus	Michael Kern;Tim Hewson;Filip Sadlo;Rüdiger Westermann;Marc Rautenhaus	Computer Graphics & Visualization Group, Technische Universität, München, Garching, Germany;European Centre for Medium-Range Weather Forecasts, Reading, UK;Visual Computing Group, Heidelberg University, Heidelberg, Germany;Computer Graphics & Visualization Group, Technische Universität, München, Garching, Germany;Computer Graphics & Visualization Group, Technische Universität, München, Garching, Germany	10.1109/TVCG.2007.70554	Meteorology,weather forecast,jet-stream,feature detection	0	8	7	54	
VAST	2017	The Interactive Visualization Gap in Initial Exploratory Data Analysis	10.1109/TVCG.2017.2743990	http://dx.doi.org/10.1109/TVCG.2017.2743990	278	287	J	Data scientists and other analytic professionals often use interactive visualization in the dissemination phase at the end of a workflow during which findings are communicated to a wider audience. Visualization scientists, however, hold that interactive representation of data can also be used during exploratory analysis itself. Since the use of interactive visualization is optional rather than mandatory, this leaves a “visualization gap” during initial exploratory analysis that is the onus of visualization researchers to fill. In this paper, we explore areas where visualization would be beneficial in applied research by conducting a design study using a novel variation on contextual inquiry conducted with professional data analysts. Based on these interviews and experiments, we propose a set of interactive initial exploratory visualization guidelines which we believe will promote adoption by this type of user.	Andrea Batch;Niklas Elmqvist	Andrea Batch;Niklas Elmqvist	College Park, University of Maryland, MD, USA;College Park, University of Maryland, MD, USA	10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2008.166;10.1109/TVCG.2016.2598545;10.1109/TVCG.2012.219;10.1109/TVCG.2014.2346747;10.1109/TVCG.2014.2346578;10.1109/TVCG.2016.2599030;10.1109/TVCG.2014.2346321;10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.171	Data science,visualization,visual analytics,contextual inquiry,semi-structured interviews	1	13	5	62	
InfoVis	2017	Structuring Visualization Mock-Ups at the Graphical Level by Dividing the Display Space	10.1109/TVCG.2017.2743998	http://dx.doi.org/10.1109/TVCG.2017.2743998	424	434	J	Mock-ups are rapid, low fidelity prototypes, that are used in many design-related fields to generate and share ideas. While their creation is supported by many mature methods and tools, surprisingly few are suited for the needs of information visualization. In this article, we introduce a novel approach to creating visualizations mock-ups, based on a dialogue between graphic design and parametric toolkit explorations. Our approach consists in iteratively subdividing the display space, while progressively informing each division with realistic data. We show that a wealth of mock-ups can easily be created using only temporary data attributes, as we wait for more realistic data to become available. We describe the implementation of this approach in a D3-based toolkit, which we use to highlight its generative power, and we discuss the potential for transitioning towards higher fidelity prototypes.	Romain Vuillemot;Jeremy Boy	Romain Vuillemot;Jeremy Boy	LIRIS, Univ Lyon, &#x00C9;cole Centrale de Lyon, CNRS, UMR5205, France;UN Global Pulse	10.1109/TVCG.2011.185;10.1109/INFVIS.1997.636761;10.1109/TVCG.2010.197;10.1109/TVCG.2008.153;10.1109/TVCG.2013.187;10.1109/TVCG.2013.227;10.1109/TVCG.2013.160;10.1109/TVCG.2013.134;10.1109/VISUAL.1991.175815;10.1109/TVCG.2016.2598620;10.1109/TVCG.2012.229;10.1109/TVCG.2013.191;10.1109/TVCG.2014.2346248;10.1109/TVCG.2014.2346291;10.1109/TVCG.2015.2467271;10.1109/TVCG.2016.2599030;10.1109/TVCG.2006.166;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398859;10.1109/TVCG.2015.2467191	Design Methodologies,Rapid Prototyping,Graphic Design,Mock-Ups,Toolkit Design	3	4	0	61	
InfoVis	2017	Nonlinear Dot Plots	10.1109/TVCG.2017.2744018	http://dx.doi.org/10.1109/TVCG.2017.2744018	616	625	J	Conventional dot plots use a constant dot size and are typically applied to show the frequency distribution of small data sets. Unfortunately, they are not designed for a high dynamic range of frequencies. We address this problem by introducing nonlinear dot plots. Adopting the idea of nonlinear scaling from logarithmic bar charts, our plots allow for dots of varying size so that columns with a large number of samples are reduced in height. For the construction of these diagrams, we introduce an efficient two-way sweep algorithm that leads to a dense and symmetrical layout. We compensate aliasing artifacts at high dot densities by a specifically designed low-pass filtering method. Examples of nonlinear dot plots are compared to conventional dot plots as well as linear and logarithmic histograms. Finally, we include feedback from an expert review.	Nils Rodrigues;Daniel Weiskopf	Nils Rodrigues;Daniel Weiskopf	VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany	10.1109/TVCG.2016.2598592;10.1109/TVCG.2014.2346428;10.1109/TVCG.2010.197;10.1109/TVCG.2011.160;10.1109/TVCG.2009.127	Nonlinear dot plot,statistical graphics,sweep algorithm,layout	0	3	1	38	
InfoVis	2017	VisTiles: Coordinating and Combining Co-located Mobile Devices for Visual Data Exploration	10.1109/TVCG.2017.2744019	http://dx.doi.org/10.1109/TVCG.2017.2744019	626	636	J	We present VisTiles, a conceptual framework that uses a set of mobile devices to distribute and coordinate visualization views for the exploration of multivariate data. In contrast to desktop-based interfaces for information visualization, mobile devices offer the potential to provide a dynamic and user-defined interface supporting co-located collaborative data exploration with different individual workflows. As part of our framework, we contribute concepts that enable users to interact with coordinated &amp; multiple views (CMV) that are distributed across several mobile devices. The major components of the framework are: (i) dynamic and flexible layouts for CMV focusing on the distribution of views and (ii) an interaction concept for smart adaptations and combinations of visualizations utilizing explicit side-by-side arrangements of devices. As a result, users can benefit from the possibility to combine devices and organize them in meaningful spatial layouts. Furthermore, we present a web-based prototype implementation as a specific instance of our concepts. This implementation provides a practical application case enabling users to explore a multivariate data collection. We also illustrate the design process including feedback from a preliminary user study, which informed the design of both the concepts and the final prototype.	Ricardo Langner;Tom Horak;Raimund Dachselt	Ricardo Langner;Tom Horak;Raimund Dachselt	Interactive Media Lab, Technische Universität Dresden, Germany;Interactive Media Lab, Technische Universität Dresden, Germany;Interactive Media Lab, Technische Universität Dresden, Germany	10.1109/VAST.2015.7347628;10.1109/TVCG.2007.70568;10.1109/TVCG.2012.204;10.1109/TVCG.2016.2598586;10.1109/TVCG.2014.2346573;10.1109/TVCG.2009.162;10.1109/TVCG.2012.237;10.1109/TVCG.2007.70515	Mobile devices,coordinated & multiple views,multi-display environment,cross-device interaction	6	16	6	59	
SciVis	2017	Interactive Design and Visualization of Branched Covering Spaces	10.1109/TVCG.2017.2744038	http://dx.doi.org/10.1109/TVCG.2017.2744038	843	852	J	Branched covering spaces are a mathematical concept which originates from complex analysis and topology and has applications in tensor field topology and geometry remeshing. Given a manifold surface and an<inline-formula><tex-math notation="LaTeX">$N$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-zhang-2744038-ieq-1-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>-way rotational symmetry field, a branched covering space is a manifold surface that has an<inline-formula><tex-math notation="LaTeX">$N$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-zhang-2744038-ieq-2-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>-to-1 map to the original surface except at the<italic>ramification points</italic>, which correspond to the singularities in the rotational symmetry field. Understanding the notion and mathematical properties of branched covering spaces is important to researchers in tensor field visualization and geometry processing, and their application areas. In this paper, we provide a framework to interactively design and visualize the branched covering space (BCS) of an input mesh surface and a rotational symmetry field defined on it. In our framework, the user can visualize not only the BCSs but also their construction process. In addition, our system allows the user to design the geometric realization of the BCS using mesh deformation techniques as well as connecting tubes. This enables the user to verify important facts about BCSs such as that they are manifold surfaces around singularities, as well as the<italic>Riemann-Hurwitz formula</italic>which relates the Euler characteristic of the BCS to that of the original mesh. Our system is evaluated by student researchers in scientific visualization and geometry processing as well as faculty members in mathematics at our university who teach topology. We include their evaluations and feedback in the paper.	Lawrence Roy;Prashant Kumar;Sanaz Golbabaei;Yue Zhang 0009;Eugene Zhang	Lawrence Roy;Prashant Kumar;Sanaz Golbabaei;Yue Zhang;Eugene Zhang	Roy Family Homeschool;Oregon State University;Oregon State University;Oregon State University;Oregon State University		Tensor field topology,math visualization,branched covering spaces visualization,rotational symmetries,ramification points	1	2	0	31	
SciVis	2017	On the Treatment of Field Quantities and Elemental Continuity in FEM Solutions	10.1109/TVCG.2017.2744058	http://dx.doi.org/10.1109/TVCG.2017.2744058	903	912	J	As the finite element method (FEM) and the finite volume method (FVM), both traditional and high-order variants, continue their proliferation into various applied engineering disciplines, it is important that the visualization techniques and corresponding data analysis tools that act on the results produced by these methods faithfully represent the underlying data. To state this in another way: the interpretation of data generated by simulation needs to be consistent with the numerical schemes that underpin the specific solver technology. As the verifiable visualization literature has demonstrated: visual artifacts produced by the introduction of either explicit or implicit data transformations, such as data resampling, can sometimes distort or even obfuscate key scientific features in the data. In this paper, we focus on the handling of elemental continuity, which is often only<inline-formula><tex-math notation="LaTeX">$C^{0}$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-jallepalli-2744058-ieq-1-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>continuous or piecewise discontinuous, when visualizing primary or derived fields from FEM or FVM simulations. We demonstrate that traditional data handling and visualization of these fields introduce visual errors. In addition, we show how the use of the recently proposed line-SIAC filter provides a way of handling elemental continuity issues in an accuracy-conserving manner with the added benefit of casting the data in a smooth context even if the representation is element discontinuous.	Ashok Jallepalli;Julia Docampo-Sánchez;Jennifer K. Ryan;Robert Haimes;Robert Michael Kirby	Ashok Jallepalli;Julia Docampo-Sánchez;Jennifer K. Ryan;Robert Haimes;Robert M. Kirby	SCI InstituteUniversity of Utah;School of MathematicsUniversity of East Anglia;School of MathematicsUniversity of East Anglia;Department of AeronauticsMIT;SCI InstituteUniversity of Utah	10.1109/VISUAL.2004.65;10.1109/TVCG.2011.206;10.1109/TVCG.2012.218	Flow Visualization,discontinuous Galerkin (dG) methods,continuous Galerkin (cG) methods,finite element methods (FEM),finite volume methods,filtering techniques,Scalar Field Data,Irregular and Unstructured Grids,Extraction of Surfaces((Isosurfaces)	1	8	3	30	
SciVis	2017	Dynamic Load Balancing Based on Constrained K-D Tree Decomposition for Parallel Particle Tracing	10.1109/TVCG.2017.2744059	http://dx.doi.org/10.1109/TVCG.2017.2744059	954	963	J	We propose a dynamically load-balanced algorithm for parallel particle tracing, which periodically attempts to evenly redistribute particles across processes based on k-d tree decomposition. Each process is assigned with (1) a statically partitioned, axis-aligned data block that partially overlaps with neighboring blocks in other processes and (2) a dynamically determined k-d tree leaf node that bounds the active particles for computation; the bounds of the k-d tree nodes are constrained by the geometries of data blocks. Given a certain degree of overlap between blocks, our method can balance the number of particles as much as possible. Compared with other load-balancing algorithms for parallel particle tracing, the proposed method does not require any preanalysis, does not use any heuristics based on flow features, does not make any assumptions about seed distribution, does not move any data blocks during the run, and does not need any master process for work redistribution. Based on a comprehensive performance study up to 8K processes on a Blue Gene/Q system, the proposed algorithm outperforms baseline approaches in both load balance and scalability on various flow visualization and analysis problems.	Jiang Zhang;Hanqi Guo;Fan Hong;Xiaoru Yuan;Tom Peterka	Jiang Zhang;Hanqi Guo;Fan Hong;Xiaoru Yuan;Tom Peterka	Ministry of EducationKey Laboratory of Machine PerceptionSchool of EECSPeking University;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Ministry of EducationKey Laboratory of Machine PerceptionSchool of EECSPeking University;Ministry of EducationKey Laboratory of Machine PerceptionSchool of EECSPeking University;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA	10.1109/TVCG.2013.128;10.1109/TVCG.2007.70551;10.1109/TVCG.2013.144;10.1109/TVCG.2011.219;10.1109/VISUAL.1997.663898;10.1109/TVCG.2017.2744059	Parallel particle tracing,dynamic load balancing,k-d trees,performance analysis	1	5	5	37	
SciVis	2017	An Intelligent System Approach for Probabilistic Volume Rendering Using Hierarchical 3D Convolutional Sparse Coding	10.1109/TVCG.2017.2744078	http://dx.doi.org/10.1109/TVCG.2017.2744078	964	973	J	In this paper, we propose a novel machine learning-based voxel classification method for highly-accurate volume rendering. Unlike conventional voxel classification methods that incorporate intensity-based features, the proposed method employs dictionary based features learned directly from the input data using hierarchical multi-scale 3D convolutional sparse coding, a novel extension of the state-of-the-art learning-based sparse feature representation method. The proposed approach automatically generates high-dimensional feature vectors in up to 75 dimensions, which are then fed into an intelligent system built on a random forest classifier for accurately classifying voxels from only a handful of selection scribbles made directly on the input data by the user. We apply the probabilistic transfer function to further customize and refine the rendered result. The proposed method is more intuitive to use and more robust to noise in comparison with conventional intensity-based classification methods. We evaluate the proposed method using several synthetic and real-world volume datasets, and demonstrate the methods usability through a user study.	Tran Minh Quan;Junyoung Choi;Haejin Jeong;Won-Ki Jeong	Tran Minh Quan;Junyoung Choi;Haejin Jeong;Won-Ki Jeong	Ulsan Nat'l Inst. of Science and Technology (UNIST);Ulsan Nat'l Inst. of Science and Technology (UNIST);Ulsan Nat'l Inst. of Science and Technology (UNIST);Ulsan Nat'l Inst. of Science and Technology (UNIST)	10.1109/TVCG.2008.162;10.1109/TVCG.2011.261;10.1109/TVCG.2012.231	Volume Rendering,Machine Learning,Hierarchically Convolutional Sparse Coding	0	5	3	39	
SciVis	2017	A Virtual Reality Visualization Tool for Neuron Tracing	10.1109/TVCG.2017.2744079	http://dx.doi.org/10.1109/TVCG.2017.2744079	994	1003	J	Tracing neurons in large-scale microscopy data is crucial to establishing a wiring diagram of the brain, which is needed to understand how neural circuits in the brain process information and generate behavior. Automatic techniques often fail for large and complex datasets, and connectomics researchers may spend weeks or months manually tracing neurons using 2D image stacks. We present a design study of a new virtual reality (VR) system, developed in collaboration with trained neuroanatomists, to trace neurons in microscope scans of the visual cortex of primates. We hypothesize that using consumer-grade VR technology to interact with neurons directly in 3D will help neuroscientists better resolve complex cases and enable them to trace neurons faster and with less physical and mental strain. We discuss both the design process and technical challenges in developing an interactive system to navigate and manipulate terabyte-sized image volumes in VR. Using a number of different datasets, we demonstrate that, compared to widely used commercial software, consumer-grade VR presents a promising alternative for scientists.	William Usher;Pavol Klacansky;Frederick Federer;Peer-Timo Bremer;Aaron Knoll;Jeff Yarch;Alessandra Angelucci;Valerio Pascucci	Will Usher;Pavol Klacansky;Frederick Federer;Peer-Timo Bremer;Aaron Knoll;Jeff Yarch;Alessandra Angelucci;Valerio Pascucci	SCI Institute, University of Utah, USA;SCI Institute, University of Utah, USA;Moran Eye Institute, University of Utah, USA;Lawrence Livermore National Laboratory, USA;SCI Institute, University of Utah, USA;Moran Eye Institute, University of Utah, USA;Moran Eye Institute, University of Utah, USA;SCI Institute, University of Utah, USA	10.1109/TVCG.2009.204;10.1109/TVCG.2012.213	Virtual reality,interaction design,design studies	2	19	9	47	
VAST	2017	How Do Ancestral Traits Shape Family Trees Over Generations?	10.1109/TVCG.2017.2744080	http://dx.doi.org/10.1109/TVCG.2017.2744080	205	214	J	Whether and how does the structure of family trees differ by ancestral traits over generations? This is a fundamental question regarding the structural heterogeneity of family trees for the multi-generational transmission research. However, previous work mostly focuses on parent-child scenarios due to the lack of proper tools to handle the complexity of extending the research to multi-generational processes. Through an iterative design study with social scientists and historians, we develop TreeEvo that assists users to generate and test empirical hypotheses for multi-generational research. TreeEvo summarizes and organizes family trees by structural features in a dynamic manner based on a traditional Sankey diagram. A pixel-based technique is further proposed to compactly encode trees with complex structures in each Sankey Node. Detailed information of trees is accessible through a space-efficient visualization with semantic zooming. Moreover, TreeEvo embeds Multinomial Logit Model (MLM) to examine statistical associations between tree structure and ancestral traits. We demonstrate the effectiveness and usefulness of TreeEvo through an in-depth case-study with domain experts using a real-world dataset (containing 54,128 family trees of 126,196 individuals).	Siwei Fu;Hao Dong 0008;Weiwei Cui;Jian Zhao 0010;Huamin Qu	Siwei Fu;Hao Dong;Weiwei Cui;Jian Zhao;Huamin Qu	Hong Kong University of Science and Technology;Princeton University;Microsoft Research;FX Palo Alto Laboratory;Hong Kong University of Science and Technology	10.1109/INFVIS.2002.1173150;10.1109/TVCG.2010.159;10.1109/VAST.2006.261450;10.1109/TVCG.2014.2346433;10.1109/TVCG.2014.2346276;10.1109/TVCG.2007.70556;10.1109/INFVIS.2005.1532124;10.1109/TVCG.2013.200;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2012.213;10.1109/TVCG.2012.226	Quantitative social science,Design study,Multiple tree visualization,Sankey diagram	0	6	3	48	
VAST	2017	LDSScanner: Exploratory Analysis of Low-Dimensional Structures in High-Dimensional Datasets	10.1109/TVCG.2017.2744098	http://dx.doi.org/10.1109/TVCG.2017.2744098	236	245	J	Many approaches for analyzing a high-dimensional dataset assume that the dataset contains specific structures, e.g., clusters in linear subspaces or non-linear manifolds. This yields a trial-and-error process to verify the appropriate model and parameters. This paper contributes an exploratory interface that supports visual identification of low-dimensional structures in a high-dimensional dataset, and facilitates the optimized selection of data models and configurations. Our key idea is to abstract a set of global and local feature descriptors from the neighborhood graph-based representation of the latent low-dimensional structure, such as pairwise geodesic distance (GD) among points and pairwise local tangent space divergence (LTSD) among pointwise local tangent spaces (LTS). We propose a new LTSD-GD view, which is constructed by mapping LTSD and GD to the<inline-formula><tex-math notation="LaTeX">$x$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-xia-2744098-ieq-1-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>axis and<inline-formula><tex-math notation="LaTeX">$y$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-xia-2744098-ieq-2-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>axis using 1D multidimensional scaling, respectively. Unlike traditional dimensionality reduction methods that preserve various kinds of distances among points, the LTSD-GD view presents the distribution of pointwise LTS (<inline-formula><tex-math notation="LaTeX">$x$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-xia-2744098-ieq-3-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>axis) and the variation of LTS in structures (the combination of<inline-formula><tex-math notation="LaTeX">$x$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-xia-2744098-ieq-4-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>axis and<inline-formula><tex-math notation="LaTeX">$y$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-xia-2744098-ieq-5-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>axis). We design and implement a suite of visual tools for navigating and reasoning about intrinsic structures of a high-dimensional dataset. Three case studies verify the effectiveness of our approach.	Jiazhi Xia;Fenjin Ye;Wei Chen 0001;Yusi Wang;Weifeng Chen 0002;Yuxin Ma;Anthony K. H. Tung	Jiazhi Xia;Fenjin Ye;Wei Chen;Yusi Wang;Weifeng Chen;Yuxin Ma;Anthony K.H. Tung	Central South University;Central South University;Zhejiang University;Central South University;Zhejiang University of Finance & Economics;Zhejiang University;National University of Singapore	10.1109/TVCG.2011.229;10.1109/VAST.2010.5652450;10.1109/VISUAL.1997.663916;10.1109/TVCG.2013.160;10.1109/VAST.2010.5652392;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2003.1249013;10.1109/TVCG.2015.2467324;10.1109/TVCG.2016.2598495;10.1109/TVCG.2016.2598466;10.1109/INFVIS.2004.3;10.1109/TVCG.2015.2467717;10.1109/VAST.2009.5332628;10.1109/VAST.2012.6400488;10.1109/TVCG.2015.2467191;10.1109/VAST.2016.7883514;10.1109/TVCG.2013.150	High-dimensional data,low-dimensional structure,subspace,manifold,visual exploration	5	13	10	44	
SciVis	2017	Uncertainty Visualization Using Copula-Based Analysis in Mixed Distribution Models	10.1109/TVCG.2017.2744099	http://dx.doi.org/10.1109/TVCG.2017.2744099	934	943	J	Distributions are often used to model uncertainty in many scientific datasets. To preserve the correlation among the spatially sampled grid locations in the dataset, various standard multivariate distribution models have been proposed in visualization literature. These models treat each grid location as a univariate random variable which models the uncertainty at that location. Standard multivariate distributions (both parametric and nonparametric) assume that all the univariate marginals are of the same type/family of distribution. But in reality, different grid locations show different statistical behavior which may not be modeled best by the same type of distribution. In this paper, we propose a new multivariate uncertainty modeling strategy to address the needs of uncertainty modeling in scientific datasets. Our proposed method is based on a statistically sound multivariate technique called Copula, which makes it possible to separate the process of estimating the univariate marginals and the process of modeling dependency, unlike the standard multivariate distributions. The modeling flexibility offered by our proposed method makes it possible to design distribution fields which can have different types of distribution (Gaussian, Histogram, KDE etc.) at the grid locations, while maintaining the correlation structure at the same time. Depending on the results of various standard statistical tests, we can choose an optimal distribution representation at each location, resulting in a more cost efficient modeling without significantly sacrificing on the analysis quality. To demonstrate the efficacy of our proposed modeling strategy, we extract and visualize uncertain features like isocontours and vortices in various real world datasets. We also study various modeling criterion to help users in the task of univariate model selection.	Subhashis Hazarika;Ayan Biswas;Han-Wei Shen	Subhashis Hazarika;Ayan Biswas;Han-Wei Shen	Department of Computer Science and EngineeringGRAVITY research groupThe Ohio State University;Los Alamos National Laboratory;Department of Computer Science and EngineeringGRAVITY research groupThe Ohio State University	10.1109/TVCG.2013.208;10.1109/TVCG.2015.2467958;10.1109/TVCG.2016.2598604;10.1109/TVCG.2015.2467436;10.1109/TVCG.2012.249;10.1109/TVCG.2013.143	Uncertainty visualization,probability distribution,probabilistic feature,statistical modeling,copula	0	5	3	54	
InfoVis	2017	Visualizing Nonlinear Narratives with Story Curves	10.1109/TVCG.2017.2744118	http://dx.doi.org/10.1109/TVCG.2017.2744118	595	604	J	In this paper, we present story curves, a visualization technique for exploring and communicating nonlinear narratives in movies. A nonlinear narrative is a storytelling device that portrays events of a story out of chronological order, e.g., in reverse order or going back and forth between past and future events. Many acclaimed movies employ unique narrative patterns which in turn have inspired other movies and contributed to the broader analysis of narrative patterns in movies. However, understanding and communicating nonlinear narratives is a difficult task due to complex temporal disruptions in the order of events as well as no explicit records specifying the actual temporal order of the underlying story. Story curves visualize the nonlinear narrative of a movie by showing the order in which events are told in the movie and comparing them to their actual chronological order, resulting in possibly meandering visual patterns in the curve. We also present Story Explorer, an interactive tool that visualizes a story curve together with complementary information such as characters and settings. Story Explorer further provides a script curation interface that allows users to specify the chronological order of events in movies. We used Story Explorer to analyze 10 popular nonlinear movies and describe the spectrum of narrative patterns that we discovered, including some novel patterns not previously described in the literature. Feedback from experts highlights potential use cases in screenplay writing and analysis, education and film production. A controlled user study shows that users with no expertise are able to understand visual patterns of nonlinear narratives using story curves.	Nam Wook Kim;Benjamin Bach;Hyejin Im;Sasha Schriber;Markus H. Gross;Hanspeter Pfister	Nam Wook Kim;Benjamin Bach;Hyejin Im;Sasha Schriber;Markus Gross;Hanspeter Pfister	John A. Paulson School of Engineering and Applied SciencesHarvard University;John A. Paulson School of Engineering and Applied SciencesHarvard University;Independent scholar;Disney Research, Z&#x00FC;rich;Disney Research, Z&#x00FC;rich;John A. Paulson School of Engineering and Applied SciencesHarvard University	10.1109/TVCG.2016.2598920;10.1109/TVCG.2013.196;10.1109/TVCG.2015.2467811;10.1109/TVCG.2009.167;10.1109/TVCG.2012.212;10.1109/TVCG.2015.2468151	Nonlinear narrative,storytelling,visualization	3	8	0	54	
InfoVis	2017	Priming and Anchoring Effects in Visualization	10.1109/TVCG.2017.2744138	http://dx.doi.org/10.1109/TVCG.2017.2744138	584	594	J	We investigate priming and anchoring effects on perceptual tasks in visualization. Priming or anchoring effects depict the phenomena that a stimulus might influence subsequent human judgments on a perceptual level, or on a cognitive level by providing a frame of reference. Using visual class separability in scatterplots as an example task, we performed a set of five studies to investigate the potential existence of priming and anchoring effects. Our findings show that - under certain circumstances - such effects indeed exist. In other words, humans judge class separability of the same scatterplot differently depending on the scatterplot(s) they have seen before. These findings inform future work on better understanding and more accurately modeling human perception of visual patterns.	André Calero Valdez;Martina Ziefle;Michael Sedlmair	André Calero Valdez;Martina Ziefle;Michael Sedlmair	RWTH Aachen University;RWTH Aachen University;University of Vienna	10.1109/TVCG.2014.2346297;10.1109/TVCG.2011.229;10.1109/TVCG.2013.183;10.1109/VAST.2010.5653587;10.1109/TVCG.2012.233;10.1109/TVCG.2014.2346979;10.1109/TVCG.2015.2467671;10.1109/TVCG.2014.2346325;10.1109/TVCG.2007.70594;10.1109/TVCG.2012.199;10.1109/TVCG.2013.153;10.1109/TVCG.2012.196;10.1109/INFVIS.2005.1532142	Perception,Anchoring,Bias,Scatterplots,Visualization,MTurk Study	4	22	6	66	
InfoVis	2017	LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks	10.1109/TVCG.2017.2744158	http://dx.doi.org/10.1109/TVCG.2017.2744158	667	676	J	Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community.	Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush	Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush	Harvard SEAS;Harvard SEAS;Harvard SEAS;Harvard SEAS	10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/VISUAL.2005.1532820	Visualization,Machine Learning,Recurrent Neural Networks,LSTM	14	3	30	35	
SciVis	2017	StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views	10.1109/TVCG.2017.2744159	http://dx.doi.org/10.1109/TVCG.2017.2744159	1004	1013	J	Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks.	Qiaomu Shen;Wei Zeng;Yu Ye;Stefan Müller Arisona;Simon Schubiger-Banz;Remo Aslak Burkhard;Huamin Qu	Qiaomu Shen;Wei Zeng;Yu Ye;Stefan Müller Arisona;Simon Schubiger;Remo Burkhard;Huamin Qu	Hong Kong University of Science and Technology;Future Cities LaboratoryETH Zurich;Tongji University;University of Applied Sciences and Arts Northwestern Switzerland FHNW;University of Applied Sciences and Arts Northwestern Switzerland FHNW;Future Cities LaboratoryETH Zurich;Hong Kong University of Science and Technology	10.1109/TVCG.2014.2346446;10.1109/TVCG.2008.166;10.1109/TVCG.2014.2346594;10.1109/TVCG.2015.2467619;10.1109/TVCG.2011.176;10.1109/TVCG.2013.226;10.1109/VISUAL.1999.809866;10.1109/TVCG.2015.2467199;10.1109/TVCG.2013.179;10.1109/TVCG.2016.2598432;10.1109/TVCG.2007.70523;10.1109/TVCG.2011.181;10.1109/TVCG.2014.2346265;10.1109/TVCG.2016.2598694;10.1109/TVCG.2013.228;10.1109/TVCG.2013.221;10.1109/TVCG.2016.2598472	Urban forms,human scale,street view,visual analytics	3	14	3	47	
InfoVis	2017	Scatterplots: Tasks, Data, and Designs	10.1109/TVCG.2017.2744184	http://dx.doi.org/10.1109/TVCG.2017.2744184	402	412	J	Traditional scatterplots fail to scale as the complexity and amount of data increases. In response, there exist many design options that modify or expand the traditional scatterplot design to meet these larger scales. This breadth of design options creates challenges for designers and practitioners who must select appropriate designs for particular analysis goals. In this paper, we help designers in making design choices for scatterplot visualizations. We survey the literature to catalog scatterplot-specific analysis tasks. We look at how data characteristics influence design decisions. We then survey scatterplot-like designs to understand the range of design options. Building upon these three organizations, we connect data characteristics, analysis tasks, and design choices in order to generate challenges, open questions, and example best practices for the effective design of scatterplots.	Alper Sarikaya;Michael Gleicher	Alper Sarikaya;Michael Gleicher	University of Wisconsin&#x2014;Madison;University of Wisconsin&#x2014;Madison	10.1109/TVCG.2015.2467618;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2008.119;10.1109/TVCG.2011.229;10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400486;10.1109/VAST.2010.5652460;10.1109/TVCG.2014.2346594;10.1109/TVCG.2009.122;10.1109/TVCG.2006.161;10.1109/TVCG.2007.70535;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2013.187;10.1109/TVCG.2013.183;10.1109/TVCG.2014.2346983;10.1109/TVCG.2006.163;10.1109/VAST.2016.7883507;10.1109/TVCG.2011.223;10.1109/TVCG.2015.2467615;10.1109/VAST.2009.5333895;10.1109/TVCG.2013.182;10.1109/TVCG.2013.130;10.1109/TVCG.2016.2598839;10.1109/TVCG.2013.120;10.1109/TVCG.2013.153;10.1109/TVCG.2011.167;10.1109/TVCG.2007.70596;10.1109/TVCG.2010.197;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.150;10.1109/TVCG.2010.174	Scatterplots,task taxonomies,study of designs	6	19	11	76	
InfoVis	2017	Keeping Multiple Views Consistent: Constraints, Validations, and Exceptions in Visualization Authoring	10.1109/TVCG.2017.2744198	http://dx.doi.org/10.1109/TVCG.2017.2744198	468	477	J	Visualizations often appear in multiples, either in a single display (e.g., small multiples, dashboard) or across time or space (e.g., slideshow, set of dashboards). However, existing visualization design guidelines typically focus on single rather than multiple views. Solely following these guidelines can lead to effective yet inconsistent views (e.g., the same field has different axes domains across charts), making interpretation slow and error-prone. Moreover, little is known how consistency balances with other design considerations, making it difficult to incorporate consistency mechanisms in visualization authoring software. We present a wizard-of-oz study in which we observed how Tableau users achieve and sacrifice consistency in an exploration-to-presentation visualization design scenario. We extend (from our prior work) a set of encoding-specific constraints defining consistency across multiple views. Using the constraints as a checklist in our study, we observed cases where participants spontaneously maintained consistent encodings and warned cases where consistency was overlooked. In response to the warnings, participants either revised views for consistency or stated why they thought consistency should be overwritten. We categorize participants' actions and responses as constraint validations and exceptions, depicting the relative importance of consistency and other design considerations under various circumstances (e.g., data cardinality, available encoding resources, chart layout). We discuss automatic consistency checking as a constraint-satisfaction problem and provide design implications for communicating inconsistencies to users.	Zening Qu;Jessica Hullman	Zening Qu;Jessica Hullman	University of Washington;University of Washington	10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2013.119;10.1109/TVCG.2014.2346325;10.1109/TVCG.2007.70594;10.1109/TVCG.2016.2599030;10.1109/INFVIS.2000.885086;10.1109/TVCG.2012.275;10.1109/TVCG.2015.2467191	Visualization Design,Qualitative Study,Evaluation	3	14	14	34	HM
InfoVis	2017	Considerations for Visualizing Comparison	10.1109/TVCG.2017.2744199	http://dx.doi.org/10.1109/TVCG.2017.2744199	413	423	J	Supporting comparison is a common and diverse challenge in visualization. Such support is difficult to design because solutions must address both the specifics of their scenario as well as the general issues of comparison. This paper aids designers by providing a strategy for considering those general issues. It presents four considerations that abstract comparison. These considerations identify issues and categorize solutions in a domain independent manner. The first considers how the common elements of comparison-a target set of items that are related and an action the user wants to perform on that relationship-are present in an analysis problem. The second considers why these elements lead to challenges because of their scale, in number of items, complexity of items, or complexity of relationship. The third considers what strategies address the identified scaling challenges, grouping solutions into three broad categories. The fourth considers which visual designs map to these strategies to provide solutions for a comparison analysis problem. In sequence, these considerations provide a process for developers to consider support for comparison in the design of visualization tools. Case studies show how these considerations can help in the design and evaluation of visualization solutions for comparison problems.	Michael Gleicher	Michael Gleicher	University of Wisconsin-Madison	10.1109/TVCG.2011.232;10.1109/TVCG.2015.2467618;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346298;10.1109/TVCG.2007.70535;10.1109/TVCG.2015.2467204;10.1109/TVCG.2012.284;10.1109/TVCG.2014.2346426;10.1109/TVCG.2013.183;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70615;10.1109/VAST.2015.7347634;10.1109/TVCG.2010.162;10.1109/TVCG.2013.122;10.1109/TVCG.2010.177;10.1109/TVCG.2011.194;10.1109/TVCG.2009.167;10.1109/TVCG.2014.2346578;10.1109/TVCG.2009.111;10.1109/TVCG.2013.213;10.1109/VAST.2014.7042491;10.1109/TVCG.2013.120;10.1109/TVCG.2009.128;10.1109/TVCG.2012.237;10.1109/VISUAL.1990.146375;10.1109/TVCG.2008.165	Information Visualization,Comparison,Taxonomies,Visualization Models,Task Analysis	3	29	17	82	
InfoVis	2017	iTTVis: Interactive Visualization of Table Tennis Data	10.1109/TVCG.2017.2744218	http://dx.doi.org/10.1109/TVCG.2017.2744218	709	718	J	The rapid development of information technology paved the way for the recording of fine-grained data, such as stroke techniques and stroke placements, during a table tennis match. This data recording creates opportunities to analyze and evaluate matches from new perspectives. Nevertheless, the increasingly complex data poses a significant challenge to make sense of and gain insights into. Analysts usually employ tedious and cumbersome methods which are limited to watching videos and reading statistical tables. However, existing sports visualization methods cannot be applied to visualizing table tennis competitions due to different competition rules and particular data attributes. In this work, we collaborate with data analysts to understand and characterize the sophisticated domain problem of analysis of table tennis data. We propose iTTVis, a novel interactive table tennis visualization system, which to our knowledge, is the first visual analysis system for analyzing and exploring table tennis data. iTTVis provides a holistic visualization of an entire match from three main perspectives, namely, time-oriented, statistical, and tactical analyses. The proposed system with several well-coordinated views not only supports correlation identification through statistics and pattern detection of tactics with a score timeline but also allows cross analysis to gain insights. Data analysts have obtained several new insights by using iTTVis. The effectiveness and usability of the proposed system are demonstrated with four case studies.	Yingcai Wu;Ji Lan;Xinhuan Shu;Chenyang Ji;Kejian Zhao;Jiachen Wang;Hui Zhang	Yingcai Wu;Ji Lan;Xinhuan Shu;Chenyang Ji;Kejian Zhao;Jiachen Wang;Hui Zhang	State Key Lab of CAD &#x0026; CGZhejiang University;State Key Lab of CAD &#x0026; CGZhejiang University;State Key Lab of CAD &#x0026; CGZhejiang University;State Key Lab of CAD &#x0026; CGZhejiang University;State Key Lab of CAD &#x0026; CGZhejiang University;State Key Lab of CAD &#x0026; CGZhejiang University;Department of Physical EducationCollege of EducationZhejiang University	10.1109/VAST.2014.7042478;10.1109/VAST.2014.7042477;10.1109/INFVIS.1996.559229;10.1109/TVCG.2011.208;10.1109/TVCG.2013.192;10.1109/TVCG.2012.263;10.1109/TVCG.2014.2346445;10.1109/TVCG.2012.213	Sports visualization,visual knowledge discovery,sports analytics,visual knowledge representation	6	14	6	35	
SciVis	2017	SparseLeap: Efficient Empty Space Skipping for Large-Scale Volume Rendering	10.1109/TVCG.2017.2744238	http://dx.doi.org/10.1109/TVCG.2017.2744238	974	983	J	Recent advances in data acquisition produce volume data of very high resolution and large size, such as terabyte-sized microscopy volumes. These data often contain many fine and intricate structures, which pose huge challenges for volume rendering, and make it particularly important to efficiently skip empty space. This paper addresses two major challenges: (1) The complexity of large volumes containing fine structures often leads to highly fragmented space subdivisions that make empty regions hard to skip efficiently. (2) The classification of space into empty and non-empty regions changes frequently, because the user or the evaluation of an interactive query activate a different set of objects, which makes it unfeasible to pre-compute a well-adapted space subdivision. We describe the novel SparseLeap method for efficient empty space skipping in very large volumes, even around fine structures. The main performance characteristic of SparseLeap is that it moves the major cost of empty space skipping out of the ray-casting stage. We achieve this via a hybrid strategy that balances the computational load between determining empty ray segments in a rasterization (object-order) stage, and sampling non-empty volume data in the ray-casting (image-order) stage. Before ray-casting, we exploit the fast hardware rasterization of GPUs to create a ray segment list for each pixel, which identifies non-empty regions along the ray. The ray-casting stage then leaps over empty space without hierarchy traversal. Ray segment lists are created by rasterizing a set of fine-grained, view-independent bounding boxes. Frame coherence is exploited by re-using the same bounding boxes unless the set of active objects changes. We show that SparseLeap scales better to large, sparse data than standard octree empty space skipping.	Markus Hadwiger;Ali K. Al-Awami;Johanna Beyer;Marco Agus;Hanspeter Pfister	Markus Hadwiger;Ali K. Al-Awami;Johanna Beyer;Marco Agus;Hanspeter Pfister	King Abdullah University of Science and Technology (KAUST), Saudi Arabia;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA	10.1109/VISUAL.1992.235231;10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2009.161;10.1109/VISUAL.2005.1532793;10.1109/VISUAL.2005.1532799;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2015.2467331;10.1109/VISUAL.2004.63;10.1109/VISUAL.1999.809908;10.1109/VISUAL.2003.1250388;10.1109/TVCG.2006.197;10.1109/TVCG.2007.70532;10.1109/VISUAL.1995.480792;10.1109/VISUAL.1990.146377;10.1109/VISUAL.2002.1183775;10.1109/VISUAL.1999.809911;10.1109/VISUAL.2001.964521	Empty Space Skipping,Volume Rendering,Segmented Volume Data,Hybrid Image/Object-Order Approaches	2	8	5	50	
SciVis	2017	Instant Construction and Visualization of Crowded Biological Environments	10.1109/TVCG.2017.2744258	http://dx.doi.org/10.1109/TVCG.2017.2744258	862	872	J	We present the first approach to integrative structural modeling of the biological mesoscale within an interactive visual environment. These complex models can comprise up to millions of molecules with defined atomic structures, locations, and interactions. Their construction has previously been attempted only within a non-visual and non-interactive environment. Our solution unites the modeling and visualization aspect, enabling interactive construction of atomic resolution mesoscale models of large portions of a cell. We present a novel set of GPU algorithms that build the basis for the rapid construction of complex biological structures. These structures consist of multiple membrane-enclosed compartments including both soluble molecules and fibrous structures. The compartments are defined using volume voxelization of triangulated meshes. For membranes, we present an extension of the Wang Tile concept that populates the bilayer with individual lipids. Soluble molecules are populated within compartments distributed according to a Halton sequence. Fibrous structures, such as RNA or actin filaments, are created by self-avoiding random walks. Resulting overlaps of molecules are resolved by a forced-based system. Our approach opens new possibilities to the world of interactive construction of cellular compartments. We demonstrate its effectiveness by showcasing scenes of different scale and complexity that comprise blood plasma, mycoplasma, and HIV.	Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur J. Olson;M. Eduard Gröller;Ivan Viola	Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur Olson;M. Eduard Gröller;Ivan Viola	TU Wien, Austria;The Scripps Research Institute, California, USA;Masaryk University, Brno, Czech Republic;The Scripps Research Institute, California, USA;The Scripps Research Institute, California, USA;TU Wien, VRVis Research Center, Austria;TU Wien, Austria		Interactive modeling,population,biological data,interactive visualization	6	16	2	49	HM
SciVis	2017	Abstractocyte: A Visual Tool for Exploring Nanoscale Astroglial Cells	10.1109/TVCG.2017.2744278	http://dx.doi.org/10.1109/TVCG.2017.2744278	853	861	J	This paper presents Abstractocyte, a system for the visual analysis of astrocytes and their relation to neurons, in nanoscale volumes of brain tissue. Astrocytes are glial cells, i.e., non-neuronal cells that support neurons and the nervous system. The study of astrocytes has immense potential for understanding brain function. However, their complex and widely-branching structure requires high-resolution electron microscopy imaging and makes visualization and analysis challenging. Furthermore, the structure and function of astrocytes is very different from neurons, and therefore requires the development of new visualization and analysis tools. With Abstractocyte, biologists can explore the morphology of astrocytes using various visual abstraction levels, while simultaneously analyzing neighboring neurons and their connectivity. We define a novel, conceptual 2D abstraction space for jointly visualizing astrocytes and neurons. Neuroscientists can choose a specific joint visualization as a point in this space. Interactively moving this point allows them to smoothly transition between different abstraction levels in an intuitive manner. In contrast to simply switching between different visualizations, this preserves the visual context and correlations throughout the transition. Users can smoothly navigate from concrete, highly-detailed 3D views to simplified and abstracted 2D views. In addition to investigating astrocytes, neurons, and their relationships, we enable the interactive analysis of the distribution of glycogen, which is of high importance to neuroscientists. We describe the design of Abstractocyte, and present three case studies in which neuroscientists have successfully used our system to assess astrocytic coverage of synapses, glycogen distribution in relation to synapses, and astrocytic-mitochondria coverage.	Haneen Mohammed;Ali K. Al-Awami;Johanna Beyer;Corrado Calì;Pierre J. Magistretti;Hanspeter Pfister;Markus Hadwiger	Haneen Mohammed;Ali K. Al-Awami;Johanna Beyer;Corrado Cali;Pierre Magistretti;Hanspeter Pfister;Markus Hadwiger	King Abdullah University of Science and Technology (KAUST), Saudi Arabia;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;King Abdullah University of Science and Technology (KAUST), Saudi Arabia	10.1109/TVCG.2015.2467441;10.1109/TVCG.2014.2346312;10.1109/TVCG.2013.142;10.1109/TVCG.2009.121;10.1109/TVCG.2008.153;10.1109/TVCG.2007.70539;10.1109/TVCG.2016.2598472	Connectomics,Neuroscience,Data Abstraction,Interactive 3D Visualization	3	13	4	39	
InfoVis	2017	Blinded with Science or Informed by Charts? A Replication Study	10.1109/TVCG.2017.2744298	http://dx.doi.org/10.1109/TVCG.2017.2744298	781	790	J	We provide a reappraisal of Tal and Wansink's study “Blinded with Science”, where seemingly trivial charts were shown to increase belief in drug efficacy, presumably because charts are associated with science. Through a series of four replications conducted on two crowdsourcing platforms, we investigate an alternative explanation, namely, that the charts allowed participants to better assess the drug's efficacy. Considered together, our experiments suggest that the chart seems to have indeed promoted understanding, although the effect is likely very small. Meanwhile, we were unable to replicate the original study's findings, as text with chart appeared to be no more persuasive - and sometimes less persuasive - than text alone. This suggests that the effect may not be as robust as claimed and may need specific conditions to be reproduced. Regardless, within our experimental settings and considering our study as a whole (<inline-formula><tex-math notation="LaTeX">$\mathrm{N}=623$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-dragicevic-2744298-ieq-1-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>), the chart's contribution to understanding was clearly larger than its contribution to persuasion.	Pierre Dragicevic;Yvonne Jansen	Pierre Dragicevic;Yvonne Jansen	Inria;Sorbonne UniversitésUPMC Univ Paris 6CNRSISIR	10.1109/TVCG.2014.2346984;10.1109/TVCG.2016.2598594;10.1109/TVCG.2014.2346435;10.1109/TVCG.2012.199;10.1109/TVCG.2014.2346419;10.1109/TVCG.2015.2467717	Replication study,persuasion,charts,data comprehension,methodology	0	5	2	57	
SciVis	2017	Decision Graph Embedding for High-Resolution Manometry Diagnosis	10.1109/TVCG.2017.2744299	http://dx.doi.org/10.1109/TVCG.2017.2744299	873	882	J	High-resolution manometry is an imaging modality which enables the categorization of esophageal motility disorders. Spatio-temporal pressure data along the esophagus is acquired using a tubular device and multiple test swallows are performed by the patient. Current approaches visualize these swallows as individual instances, despite the fact that aggregated metrics are relevant in the diagnostic process. Based on the current Chicago Classification, which serves as the gold standard in this area, we introduce a visualization supporting an efficient and correct diagnosis. To reach this goal, we propose a novel decision graph representing the Chicago Classification with workflow optimization in mind. Based on this graph, we are further able to prioritize the different metrics used during diagnosis and can exploit this prioritization in the actual data visualization. Thus, different disorders and their related parameters are directly represented and intuitively influence the appearance of our visualization. Within this paper, we introduce our novel visualization, justify the design decisions, and provide the results of a user study we performed with medical students as well as a domain expert. On top of the presented visualization, we further discuss how to derive a visual signature for individual patients that allows us for the first time to perform an intuitive comparison between subjects, in the form of small multiples.	Julian Kreiser;Alexander Hann;Eugen Zizer;Timo Ropinski	Julian Kreiser;Alexander Hann;Eugen Zizer;Timo Ropinski	Visual Computing GroupUlm University;Department of Internal Medicine IUlm University;Department of Internal Medicine IUlm University;Visual Computing GroupUlm University	10.1109/INFVIS.2001.963292;10.1109/TVCG.2013.122;10.1109/INFVIS.2003.1249006	Small multiples,manometry,chicago classification	0	1	0	29	
InfoVis	2017	CyteGuide: Visual Guidance for Hierarchical Single-Cell Analysis	10.1109/TVCG.2017.2744318	http://dx.doi.org/10.1109/TVCG.2017.2744318	739	748	J	Single-cell analysis through mass cytometry has become an increasingly important tool for immunologists to study the immune system in health and disease. Mass cytometry creates a high-dimensional description vector for single cells by time-of-flight measurement. Recently, t-Distributed Stochastic Neighborhood Embedding (t-SNE) has emerged as one of the state-of-the-art techniques for the visualization and exploration of single-cell data. Ever increasing amounts of data lead to the adoption of Hierarchical Stochastic Neighborhood Embedding (HSNE), enabling the hierarchical representation of the data. Here, the hierarchy is explored selectively by the analyst, who can request more and more detail in areas of interest. Such hierarchies are usually explored by visualizing disconnected plots of selections in different levels of the hierarchy. This poses problems for navigation, by imposing a high cognitive load on the analyst. In this work, we present an interactive summary-visualization to tackle this problem. CyteGuide guides the analyst through the exploration of hierarchically represented single-cell data, and provides a complete overview of the current state of the analysis. We conducted a two-phase user study with domain experts that use HSNE for data exploration. We first studied their problems with their current workflow using HSNE and the requirements to ease this workflow in a field study. These requirements have been the basis for our visual design. In the second phase, we verified our proposed solution in a user evaluation.	Thomas Höllt;Nicola Pezzotti;Vincent van Unen;Frits Koning;Boudewijn P. F. Lelieveldt;Anna Vilanova	Thomas Höllt;Nicola Pezzotti;Vincent van Unen;Frits Koning;Boudewijn P.F. Lelieveldt;Anna Vilanova	Computer Graphics and Visualization Group, Delft University of Technology, The Netherlands;Computer Graphics and Visualization Group, Delft University of Technology, The Netherlands;Department of Immunohematology and Blood Transfusion, Leiden University Medical Center, The Netherlands;Department of Immunohematology and Blood Transfusion, Leiden University Medical Center, The Netherlands;Department of Radiology, Division of Image Processing, Leiden University Medical Center, The Netherlands;Computer Graphics and Visualization Group, Delft University of Technology, The Netherlands	10.1109/TVCG.2007.70540;10.1109/TVCG.2011.185;10.1109/VISUAL.1991.175815;10.1109/TVCG.2014.2346578;10.1109/TVCG.2008.138;10.1109/INFVIS.2001.963283;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346574;10.1109/TVCG.2016.2598470;10.1109/INFVIS.1999.801860;10.1109/TVCG.2006.200	Hierarchical Data,HSNE,Single-Cell Analysis,Visual Guidance	1	11	5	43	
InfoVis	2017	Bridging from Goals to Tasks with Design Study Analysis Reports	10.1109/TVCG.2017.2744319	http://dx.doi.org/10.1109/TVCG.2017.2744319	435	445	J	Visualization researchers and practitioners engaged in generating or evaluating designs are faced with the difficult problem of transforming the questions asked and actions taken by target users from domain-specific language and context into more abstract forms. Existing abstract task classifications aim to provide support for this endeavour by providing a carefully delineated suite of actions. Our experience is that this bottom-up approach is part of the challenge: low-level actions are difficult to interpret without a higher-level context of analysis goals and the analysis process. To bridge this gap, we propose a framework based on analysis reports derived from open-coding 20 design study papers published at IEEE InfoVis 2009-2015, to build on the previous work of abstractions that collectively encompass a broad variety of domains. The framework is organized in two axes illustrated by nine analysis goals. It helps situate the analysis goals by placing each goal under axes of specificity (Explore, Describe, Explain, Confirm) and number of data populations (Single, Multiple). The single-population types are Discover Observation, Describe Observation, Identify Main Cause, and Collect Evidence. The multiple-population types are Compare Entities, Explain Differences, and Evaluate Hypothesis. Each analysis goal is scoped by an input and an output and is characterized by analysis steps reported in the design study papers. We provide examples of how we and others have used the framework in a top-down approach to abstracting domain problems: visualization designers or researchers first identify the analysis goals of each unit of analysis in an analysis stream, and then encode the individual steps using existing task classifications with the context of the goal, the level of specificity, and the number of populations involved in the analysis.	Heidi Lam;Melanie Tory;Tamara Munzner	Heidi Lam;Melanie Tory;Tamara Munzner	Tableau Research;Tableau Research;University of British Columbia	10.1109/TVCG.2014.2346312;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2013.124;10.1109/TVCG.2011.176;10.1109/TVCG.2013.214;10.1109/VAST.2008.4677365;10.1109/TVCG.2010.164;10.1109/TVCG.2014.2346456;10.1109/TVCG.2013.126;10.1109/TVCG.2010.193;10.1109/TVCG.2012.286;10.1109/TVCG.2013.154;10.1109/TVCG.2009.180;10.1109/TVCG.2014.2346573;10.1109/TVCG.2015.2467811;10.1109/TVCG.2010.137;10.1109/TVCG.2009.111;10.1109/TVCG.2009.116;10.1109/TVCG.2014.2346311;10.1109/TVCG.2013.192;10.1109/TVCG.2012.263;10.1109/TVCG.2014.2346445;10.1109/TVCG.2011.253;10.1109/TVCG.2015.2467754;10.1109/TVCG.2013.130;10.1109/TVCG.2013.120;10.1109/TVCG.2014.2346321;10.1109/TVCG.2015.2467911;10.1109/VISUAL.1990.146375;10.1109/TVCG.2011.174;10.1109/TVCG.2012.226	Framework,Data Analysis,Analysis Goals,Design Studies,Open Coding,Task Classifications	1	11	7	53	HM
InfoVis	2017	Extracting and Retargeting Color Mappings from Bitmap Images of Visualizations	10.1109/TVCG.2017.2744320	http://dx.doi.org/10.1109/TVCG.2017.2744320	637	646	J	Visualization designers regularly use color to encode quantitative or categorical data. However, visualizations “in the wild” often violate perceptual color design principles and may only be available as bitmap images. In this work, we contribute a method to semi-automatically extract color encodings from a bitmap visualization image. Given an image and a legend location, we classify the legend as describing either a discrete or continuous color encoding, identify the colors used, and extract legend text using OCR methods. We then combine this information to recover the specific color mapping. Users can also correct interpretation errors using an annotation interface. We evaluate our techniques using a corpus of images extracted from scientific papers and demonstrate accurate automatic inference of color mappings across a variety of chart types. In addition, we present two applications of our method: automatic recoloring to improve perceptual effectiveness, and interactive overlays to enable improved reading of static visualizations.	Jorge Poco;Angela Mayhua;Jeffrey Heer	Jorge Poco;Angela Mayhua;Jeffrey Heer	University of Washington;Universidad Católica San Pablo;University of Washington	10.1109/TVCG.2011.192;10.1109/TVCG.2011.185;10.1109/TVCG.2016.2598918;10.1109/TVCG.2012.229	Visualization,color,chart understanding,information extraction,redesign,computer vision	1	10	6	27	
SciVis	2017	Clique Community Persistence: A Topological Visual Analysis Approach for Complex Networks	10.1109/TVCG.2017.2744321	http://dx.doi.org/10.1109/TVCG.2017.2744321	822	831	J	Complex networks require effective tools and visualizations for their analysis and comparison. Clique communities have been recognized as a powerful concept for describing cohesive structures in networks. We propose an approach that extends the computation of clique communities by considering persistent homology, a topological paradigm originally introduced to characterize and compare the global structure of shapes. Our persistence-based algorithm is able to detect clique communities and to keep track of their evolution according to different edge weight thresholds. We use this information to define comparison metrics and a new centrality measure, both reflecting the relevance of the clique communities inherent to the network. Moreover, we propose an interactive visualization tool based on nested graphs that is capable of compactly representing the evolving relationships between communities for different thresholds and clique degrees. We demonstrate the effectiveness of our approach on various network types.	Bastian Rieck;Ulderico Fugacci;Jonas Lukasczyk;Heike Leitte	Bastian Rieck;Ulderico Fugacci;Jonas Lukasczyk;Heike Leitte	TU Kaiserslautern;TU Kaiserslautern;TU Kaiserslautern;TU Kaiserslautern	10.1109/INFVIS.2004.66;10.1109/TVCG.2008.151	Persistent homology,topological persistence,cliques,complex networks,visual analysis	0	11	0	49	
VAST	2017	Clustering Trajectories by Relevant Parts for Air Traffic Analysis	10.1109/TVCG.2017.2744322	http://dx.doi.org/10.1109/TVCG.2017.2744322	34	44	J	Clustering of trajectories of moving objects by similarity is an important technique in movement analysis. Existing distance functions assess the similarity between trajectories based on properties of the trajectory points or segments. The properties may include the spatial positions, times, and thematic attributes. There may be a need to focus the analysis on certain parts of trajectories, i.e., points and segments that have particular properties. According to the analysis focus, the analyst may need to cluster trajectories by similarity of their relevant parts only. Throughout the analysis process, the focus may change, and different parts of trajectories may become relevant. We propose an analytical workflow in which interactive filtering tools are used to attach relevance flags to elements of trajectories, clustering is done using a distance function that ignores irrelevant elements, and the resulting clusters are summarized for further analysis. We demonstrate how this workflow can be useful for different analysis tasks in three case studies with real data from the domain of air traffic. We propose a suite of generic techniques and visualization guidelines to support movement data analysis by means of relevance-aware trajectory clustering.	Gennady L. Andrienko;Natalia V. Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia	Gennady Andrienko;Natalia Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia	Fraunhofer IAIS, City University, London;Fraunhofer IAIS, City University, London;Fraunhofer Institute IAIS;CRIDA (Reference Center for Research, Development and Innovation in ATM)	10.1109/VAST.2009.5332584;10.1109/TVCG.2013.193;10.1109/TVCG.2011.233;10.1109/TVCG.2015.2468292;10.1109/VAST.2008.4677350	Visual analytics,movement data analysis,trajectory clustering,air traffic	3	16	10	53	
InfoVis	2017	Functional Decomposition for Bundled Simplification of Trail Sets	10.1109/TVCG.2017.2744338	http://dx.doi.org/10.1109/TVCG.2017.2744338	500	510	J	Bundling visually aggregates curves to reduce clutter and help finding important patterns in trail-sets or graph drawings. We propose a new approach to bundling based on functional decomposition of the underling dataset. We recover the functional nature of the curves by representing them as linear combinations of piecewise-polynomial basis functions with associated expansion coefficients. Next, we express all curves in a given cluster in terms of a centroid curve and a complementary term, via a set of so-called principal component functions. Based on the above, we propose a two-fold contribution: First, we use cluster centroids to design a new bundling method for 2D and 3D curve-sets. Secondly, we deform the cluster centroids and generate new curves along them, which enables us to modify the underlying data in a statistically-controlled way via its simplified (bundled) view. We demonstrate our method by applications on real-world 2D and 3D datasets for graph bundling, trajectory analysis, and vector field and tensor field visualization.	Christophe Hurter;Stéphane Puechmorel;Florence Nicol;Alexandru Telea	Christophe Hurter;Stéphane Puechmorel;Florence Nicol;Alexandru Telea	ENAC;ENAC;ENAC;University of Groningen	10.1109/TVCG.2013.124;10.1109/TVCG.2011.202;10.1109/TVCG.2008.135;10.1109/TVCG.2011.233;10.1109/TVCG.2009.138;10.1109/VAST.2008.4677380;10.1109/VISUAL.2004.32;10.1109/TVCG.2006.147;10.1109/TVCG.2011.223;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.2005.1532779;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2011.181;10.1109/TVCG.2011.190	path visualization,trajectory visualization,edge bundles,functional decomposition,path generation,streamlines	2	8	3	74	
InfoVis	2017	Skeleton-Based Scagnostics	10.1109/TVCG.2017.2744339	http://dx.doi.org/10.1109/TVCG.2017.2744339	542	552	J	Scatterplot matrices (SPLOMs) are widely used for exploring multidimensional data. Scatterplot diagnostics (scagnostics) approaches measure characteristics of scatterplots to automatically find potentially interesting plots, thereby making SPLOMs more scalable with the dimension count. While statistical measures such as regression lines can capture orientation, and graph-theoretic scagnostics measures can capture shape, there is no scatterplot characterization measure that uses both descriptors. Based on well-known results in shape analysis, we propose a scagnostics approach that captures both scatterplot shape and orientation using skeletons (or medial axes). Our representation can handle complex spatial distributions, helps discovery of principal trends in a multiscale way, scales visually well with the number of samples, is robust to noise, and is automatic and fast to compute. We define skeleton-based similarity metrics for the visual exploration and analysis of SPLOMs. We perform a user study to measure the human perception of scatterplot similarity and compare the outcome to our results as well as to graph-based scagnostics and other visual quality metrics. Our skeleton-based metrics outperform previously defined measures both in terms of closeness to perceptually-based similarity and computation time efficiency.	José Matute;Alexandru Telea;Lars Linsen	José Matute;Alexandru C. Telea;Lars Linsen	Institute of Computer Science, Westfälische Wilhelms-Universität Münster, Germany;Johann Bernoulli Institute for Mathematics and Computer Science, University of Groningen, Groningen, The Netherlands;Institute of Computer Science, Westfälische Wilhelms-Universität Münster, Germany	10.1109/VAST.2011.6102437;10.1109/TVCG.2011.233;10.1109/TVCG.2010.213;10.1109/TVCG.2011.223;10.1109/TVCG.2011.220;10.1109/VAST.2008.4677367;10.1109/VAST.2009.5332628	Multidimensional Data (primary keyword),High-Dimensional Data	1	6	5	65	
VAST	2017	DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks	10.1109/TVCG.2017.2744358	http://dx.doi.org/10.1109/TVCG.2017.2744358	98	108	J	Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.	Nicola Pezzotti;Thomas Höllt;Jan C. van Gemert;Boudewijn P. F. Lelieveldt;Elmar Eisemann;Anna Vilanova	Nicola Pezzotti;Thomas Höllt;Jan Van Gemert;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova	Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Department of Radiology, Division of Image Processing, Leiden University Medical Center, Leiden, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands;Intelligent Systems department, Delft University of Technology, Delft, The Netherlands	10.1109/TVCG.2016.2598468;10.1109/TVCG.2014.2346578;10.1109/TVCG.2016.2598838;10.1109/TVCG.2014.2346574;10.1109/TVCG.2016.2598470	Progressive visual analytics,deep neural networks,machine learning	10	51	23	50	
InfoVis	2017	Modeling Color Difference for Visualization Design	10.1109/TVCG.2017.2744359	http://dx.doi.org/10.1109/TVCG.2017.2744359	392	401	J	Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.	Danielle Albers Szafir	Danielle Albers Szafir	University of Colorado	10.1109/VISUAL.1995.480803;10.1109/TVCG.2011.185;10.1109/TVCG.2010.154;10.1109/TVCG.2014.2346978;10.1109/TVCG.2016.2598918;10.1109/VISUAL.1996.568118;10.1109/TVCG.2011.194;10.1109/TVCG.2012.279;10.1109/TVCG.2016.2599106;10.1109/TVCG.2016.2599030;10.1109/TVCG.2008.118	Color Perception,Graphical Perception,Color Models,Crowdsourcing		32	18	55	BP
VAST	2017	Visual Diagnosis of Tree Boosting Methods	10.1109/TVCG.2017.2744378	http://dx.doi.org/10.1109/TVCG.2017.2744378	163	173	J	Tree boosting, which combines weak learners (typically decision trees) to generate a strong learner, is a highly effective and widely used machine learning method. However, the development of a high performance tree boosting model is a time-consuming process that requires numerous trial-and-error experiments. To tackle this issue, we have developed a visual diagnosis tool, BOOSTVis, to help experts quickly analyze and diagnose the training process of tree boosting. In particular, we have designed a temporal confusion matrix visualization, and combined it with a t-SNE projection and a tree visualization. These visualization components work together to provide a comprehensive overview of a tree boosting model, and enable an effective diagnosis of an unsatisfactory training process. Two case studies that were conducted on the Otto Group Product Classification Challenge dataset demonstrate that BOOSTVis can provide informative feedback and guidance to improve understanding and diagnosis of tree boosting algorithms.	Shixia Liu;Jiannan Xiao;Junlin Liu;Xiting Wang;Jing Wu;Jun Zhu 0001	Shixia Liu;Jiannan Xiao;Junlin Liu;Xiting Wang;Jing Wu;Jun Zhu	Tsinghua University and National Engineering Lab for Big Data Software;Tsinghua University and National Engineering Lab for Big Data Software;Tsinghua University and National Engineering Lab for Big Data Software;Microsoft Research;Cardiff University;Tsinghua University and National Engineering Lab for Big Data Software	10.1109/TVCG.2014.2346660;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400492;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/VISUAL.2000.885740;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453	tree boosting,model analysis,temporal confusion matrix,tree visualization	2	18	6	68	
VAST	2017	Understanding the Relationship Between Interactive Optimisation and Visual Analytics in the Context of Prostate Brachytherapy	10.1109/TVCG.2017.2744418	http://dx.doi.org/10.1109/TVCG.2017.2744418	319	329	J	The fields of operations research and computer science have long sought to find automatic solver techniques that can find high-quality solutions to difficult real-world optimisation problems. The traditional workflow is to exactly model the problem and then enter this model into a general-purpose “black-box” solver. In practice, however, many problems cannot be solved completely automatically, but require a “human-in-the-loop” to iteratively refine the model and give hints to the solver. In this paper, we explore the parallels between this interactive optimisation workflow and the visual analytics sense-making loop. We assert that interactive optimisation is essentially a visual analytics task and propose a problem-solving loop analogous to the sense-making loop. We explore these ideas through an in-depth analysis of a use-case in prostate brachytherapy, an application where interactive optimisation may be able to provide significant assistance to practitioners in creating prostate cancer treatment plans customised to each patient's tumour characteristics. However, current brachytherapy treatment planning is usually a careful, mostly manual process involving multiple professionals. We developed a prototype interactive optimisation tool for brachytherapy that goes beyond current practice in supporting focal therapy - targeting tumour cells directly rather than simply seeking coverage of the whole prostate gland. We conducted semi-structured interviews, in two stages, with seven radiation oncology professionals in order to establish whether they would prefer to use interactive optimisation for treatment planning and whether such a tool could improve their trust in the novel focal therapy approach and in machine generated solutions to the problem.	Jie Liu;Tim Dwyer;Kim Marriott;Jeremy Millar;Annette Haworth	Jie Liu;Tim Dwyer;Kim Marriott;Jeremy Millar;Annette Haworth	Monash University and Data61;Monash University;Monash University and Data61;Monash University and Alfred Health;University of Sydney	10.1109/TVCG.2009.170;10.1109/TVCG.2010.190;10.1109/TVCG.2013.147;10.1109/TVCG.2016.2598545;10.1109/VAST.2014.7042481;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248	Visual analytics,interactive optimisation,interactive systems and tools,prostate brachytherapy	3	4	0	49	
VAST	2017	Voila: Visual Anomaly Detection and Monitoring with Streaming Spatiotemporal Data	10.1109/TVCG.2017.2744419	http://dx.doi.org/10.1109/TVCG.2017.2744419	23	33	J	The increasing availability of spatiotemporal data continuously collected from various sources provides new opportunities for a timely understanding of the data in their spatial and temporal context. Finding abnormal patterns in such data poses significant challenges. Given that there is often no clear boundary between normal and abnormal patterns, existing solutions are limited in their capacity of identifying anomalies in large, dynamic and heterogeneous data, interpreting anomalies in their multifaceted, spatiotemporal context, and allowing users to provide feedback in the analysis loop. In this work, we introduce a unified visual interactive system and framework, Voila, for interactively detecting anomalies in spatiotemporal data collected from a streaming data source. The system is designed to meet two requirements in real-world applications, i.e., online monitoring and interactivity. We propose a novel tensor-based anomaly analysis algorithm with visualization and interaction design that dynamically produces contextualized, interpretable data summaries and allows for interactively ranking anomalous patterns based on user input. Using the “smart city” as an example scenario, we demonstrate the effectiveness of the proposed framework through quantitative evaluation and qualitative case studies.	Nan Cao;Chaoguang Lin;Qiuhan Zhu;Yu-Ru Lin;Xian Teng;Xidao Wen	Nan Cao;Chaoguang Lin;Qiuhan Zhu;Yu-Ru Lin;Xian Teng;Xidao Wen	Intelligent Big Data Visualization (iDVx) LabTongji University;Intelligent Big Data Visualization (iDVx) LabTongji University;Intelligent Big Data Visualization (iDVx) LabTongji University;University of Pittsburgh;University of Pittsburgh;University of Pittsburgh	10.1109/TVCG.2015.2467196;10.1109/VAST.2012.6400557;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102438;10.1109/VAST.2010.5652467;10.1109/TVCG.2016.2598432;10.1109/TVCG.2016.2598829;10.1109/TVCG.2015.2467194;10.1109/TVCG.2014.2346922	Anomaly Detection,Visual Analysis	1	16	7	61	
SciVis	2017	Interactive Dynamic Volume Illumination with Refraction and Caustics	10.1109/TVCG.2017.2744438	http://dx.doi.org/10.1109/TVCG.2017.2744438	984	993	J	In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction - despite being an important aspect of light propagation in participating media - has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty.	Jens G. Magnus;Stefan Bruckner	Jens G. Magnus;Stefan Bruckner	University of Bergen, Norway;University of Bergen, Norway	10.1109/TVCG.2014.2346333;10.1109/TVCG.2013.129;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/TVCG.2011.211	Interactive volume rendering,illumination,refraction,shadows,caustics	0	5	1	46	
VAST	2017	BiDots: Visual Exploration of Weighted Biclusters	10.1109/TVCG.2017.2744458	http://dx.doi.org/10.1109/TVCG.2017.2744458	195	204	J	Discovering and analyzing biclusters, i.e., two sets of related entities with close relationships, is a critical task in many real-world applications, such as exploring entity co-occurrences in intelligence analysis, and studying gene expression in bio-informatics. While the output of biclustering techniques can offer some initial low-level insights, visual approaches are required on top of that due to the algorithmic output complexity. This paper proposes a visualization technique, called BiDots, that allows analysts to interactively explore biclusters over multiple domains. BiDots overcomes several limitations of existing bicluster visualizations by encoding biclusters in a more compact and cluster-driven manner. A set of handy interactions is incorporated to support flexible analysis of biclustering results. More importantly, BiDots addresses the cases of weighted biclusters, which has been underexploited in the literature. The design of BiDots is grounded by a set of analytical tasks derived from previous work. We demonstrate its usefulness and effectiveness for exploring computed biclusters with an investigative document analysis task, in which suspicious people and activities are identified from a text corpus.	Jian Zhao 0010;Maoyuan Sun;Francine Chen;Patrick Chiu	Jian Zhao;Maoyuan Sun;Francine Chen;Patrick Chiu	FX Palo Alto Laboratory;University of Massachusetts, Dartmouth;FX Palo Alto Laboratory;FX Palo Alto Laboratory	10.1109/TVCG.2012.252;10.1109/TVCG.2008.153;10.1109/TVCG.2013.223;10.1109/TVCG.2007.70582;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.250;10.1109/TVCG.2010.138;10.1109/TVCG.2016.2598831;10.1109/TVCG.2014.2346752;10.1109/VAST.2007.4389006;10.1109/TVCG.2015.2467813;10.1109/TVCG.2014.2346665;10.1109/TVCG.2013.167	Biclustering,coordinated relationship analysis,visual analytics	0	5	5	41	
SciVis	2017	Activity-Centered Domain Characterization for Problem-Driven Scientific Visualization	10.1109/TVCG.2017.2744459	http://dx.doi.org/10.1109/TVCG.2017.2744459	913	922	J	Although visualization design models exist in the literature in the form of higher-level methodological frameworks, these models do not present a clear methodological prescription for the domain characterization step. This work presents a framework and end-to-end model for requirements engineering in problem-driven visualization application design. The framework and model are based on the activity-centered design paradigm, which is an enhancement of human-centered design. The proposed activity-centered approach focuses on user tasks and activities, and allows an explicit link between the requirements engineering process with the abstraction stage - and its evaluation - of existing, higher-level visualization design models. In a departure from existing visualization design models, the resulting model: assigns value to a visualization based on user activities; ranks user tasks before the user data; partitions requirements in activity-related capabilities and nonfunctional characteristics and constraints; and explicitly incorporates the user workflows into the requirements process. A further merit of this model is its explicit integration of functional specifications, a concept this work adapts from the software engineering literature, into the visualization design nested model. A quantitative evaluation using two sets of interdisciplinary projects supports the merits of the activity-centered model. The result is a practical roadmap to the domain characterization step of visualization design for problem-driven data visualization. Following this domain characterization model can help remove a number of pitfalls that have been identified multiple times in the visualization design literature.	G. Elisabeta Marai	G. Elisabeta Marai	Electronic Visualization Laboratory, University of Illinois, Chicago	10.1109/TVCG.2013.124;10.1109/TVCG.2013.145;10.1109/TVCG.2011.209;10.1109/TVCG.2013.161;10.1109/TVCG.2014.2346331;10.1109/TVCG.2009.111;10.1109/TVCG.2013.120;10.1109/TVCG.2012.213;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2014.2346323	Design studies,Tasks and requirements analysis,Visualization models,Domain characterization,Activity-centered design,Functional specifications	1	8	6	61	
VAST	2017	ConceptVector: Text Visual Analytics via Interactive Lexicon Building Using Word Embedding	10.1109/TVCG.2017.2744478	http://dx.doi.org/10.1109/TVCG.2017.2744478	361	370	J	Central to many text analysis methods is the notion of a concept: a set of semantically related keywords characterizing a specific object, phenomenon, or theme. Advances in word embedding allow building a concept from a small set of seed terms. However, naive application of such techniques may result in false positive errors because of the polysemy of natural language. To mitigate this problem, we present a visual analytics system called ConceptVector that guides a user in building such concepts and then using them to analyze documents. Document-analysis case studies with real-world datasets demonstrate the fine-grained analysis provided by ConceptVector. To support the elaborate modeling of concepts, we introduce a bipolar concept model and support for specifying irrelevant words. We validate the interactive lexicon building interface by a user study and expert reviews. Quantitative evaluation shows that the bipolar lexicon generated with our methods is comparable to human-generated ones.	Deok Gun Park 0001;Seungyeon Kim;Jurim Lee;Jaegul Choo;Nicholas Diakopoulos;Niklas Elmqvist	Deokgun Park;Seungyeon Kim;Jurim Lee;Jaegul Choo;Nicholas Diakopoulos;Niklas Elmqvist	University of Maryland, College Park, MD, USA;Google Inc., Mountain View, CA, USA;Korea University, Seoul, Republic of Korea;Korea University, Seoul, Republic of Korea;Northwestern University, Evanston, IL, USA;University of Maryland, College Park, MD, USA	10.1109/TVCG.2016.2598667;10.1109/TVCG.2013.212;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/TVCG.2016.2598446;10.1109/TVCG.2015.2467555	Text analytics,visual analytics,word embedding,text summarization,text classification,concepts	3	21	6	44	
SciVis	2017	BASTet: Shareable and Reproducible Analysis and Visualization of Mass Spectrometry Imaging Data via OpenMSI	10.1109/TVCG.2017.2744479	http://dx.doi.org/10.1109/TVCG.2017.2744479	1025	1035	J	Mass spectrometry imaging (MSI) is a transformative imaging method that supports the untargeted, quantitative measurement of the chemical composition and spatial heterogeneity of complex samples with broad applications in life sciences, bioenergy, and health. While MSI data can be routinely collected, its broad application is currently limited by the lack of easily accessible analysis methods that can process data of the size, volume, diversity, and complexity generated by MSI experiments. The development and application of cutting-edge analytical methods is a core driver in MSI research for new scientific discoveries, medical diagnostics, and commercial-innovation. However, the lack of means to share, apply, and reproduce analyses hinders the broad application, validation, and use of novel MSI analysis methods. To address this central challenge, we introduce the Berkeley Analysis and Storage Toolkit (BASTet), a novel framework for shareable and reproducible data analysis that supports standardized data and analysis interfaces, integrated data storage, data provenance, workflow management, and a broad set of integrated tools. Based on BASTet, we describe the extension of the OpenMSI mass spectrometry imaging science gateway to enable web-based sharing, reuse, analysis, and visualization of data analyses and derived data products. We demonstrate the application of BASTet and OpenMSI in practice to identify and compare characteristic substructures in the mouse brain based on their chemical composition measured via MSI.	Oliver Rübel;Benjamin P. Bowen	Oliver Rübel;Benjamin P. Bowen	Computational Research DivisionLawrence Berkeley National Laboratory (LBNL);Environmental Genomics & Systems Biology DivisionLBNL	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2015.2467091	Mass spectrometry imaging,Data provenance,Visualization,Data management,Analysis Workflows,Data sharing	0	1	1	55	
SciVis	2017	Visualization Multi-Pipeline for Communicating Biology	10.1109/TVCG.2017.2744518	http://dx.doi.org/10.1109/TVCG.2017.2744518	883	892	J	We propose a system to facilitate biology communication by developing a pipeline to support the instructional visualization of heterogeneous biological data on heterogeneous user-devices. Discoveries and concepts in biology are typically summarized with illustrations assembled manually from the interpretation and application of heterogenous data. The creation of such illustrations is time consuming, which makes it incompatible with frequent updates to the measured data as new discoveries are made. Illustrations are typically non-interactive, and when an illustration is updated, it still has to reach the user. Our system is designed to overcome these three obstacles. It supports the integration of heterogeneous datasets, reflecting the knowledge that is gained from different data sources in biology. After pre-processing the datasets, the system transforms them into visual representations as inspired by scientific illustrations. As opposed to traditional scientific illustration these representations are generated in real-time - they are interactive. The code generating the visualizations can be embedded in various software environments. To demonstrate this, we implemented both a desktop application and a remote-rendering server in which the pipeline is embedded. The remote-rendering server supports multi-threaded rendering and it is able to handle multiple users simultaneously. This scalability to different hardware environments, including multi-GPU setups, makes our system useful for efficient public dissemination of biological discoveries.	Peter Mindek;David Kouril;Johannes Sorger;Daniel Toloudis;Blair Lyons;Graham Johnson;M. Eduard Gröller;Ivan Viola	Peter Mindek;David Kouřil;Johannes Sorger;Daniel Toloudis;Blair Lyons;Graham Johnson;M. Eduard Gröller;Ivan Viola	TU Wien;TU Wien;TU Wien;Allen Institute for Cell Science;Allen Institute for Cell Science;Allen Institute for Cell Science;TU Wien;TU Wien	10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2000.885729	Biological visualization,remote rendering,public dissemination	1	5	3	33	
VAST	2017	Do Convolutional Neural Networks Learn Class Hierarchy?	10.1109/TVCG.2017.2744683	http://dx.doi.org/10.1109/TVCG.2017.2744683	152	162	J	Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data.	Bilal Alsallakh;Amin Jourabloo;Mao Ye;Xiaoming Liu 0002;Liu Ren	Alsallakh Bilal;Amin Jourabloo;Mao Ye;Xiaoming Liu;Liu Ren	Bosch Research North AmericaPalo Alto, CA;Michigan State University;Bosch Research North AmericaPalo Alto, CA;Michigan State University;Bosch Research North AmericaPalo Alto, CA	10.1109/TVCG.2014.2346660;10.1109/VAST.2015.7347637;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/TVCG.2017.2744158;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453	Convolutional Neural Networks,deep learning,image classification,large-scale classification,confusion matrix	9	41	12	77	
VAST	2017	Applying Pragmatics Principles for Interaction with Visual Analytics	10.1109/TVCG.2017.2744684	http://dx.doi.org/10.1109/TVCG.2017.2744684	309	318	J	Interactive visual data analysis is most productive when users can focus on answering the questions they have about their data, rather than focusing on how to operate the interface to the analysis tool. One viable approach to engaging users in interactive conversations with their data is a natural language interface to visualizations. These interfaces have the potential to be both more expressive and more accessible than other interaction paradigms. We explore how principles from language pragmatics can be applied to the flow of visual analytical conversations, using natural language as an input modality. We evaluate the effectiveness of pragmatics support in our system Evizeon, and present design considerations for conversation interfaces to visual analytics tools.	Enamul Hoque;Vidya Setlur;Melanie Tory;Isaac Dykeman	Enamul Hoque;Vidya Setlur;Melanie Tory;Isaac Dykeman	Stanford University;Tableau Research;Tableau Research;Rice University	10.1109/TVCG.2014.2346435;10.1109/TVCG.2010.164;10.1109/TVCG.2007.70594;10.1109/INFVIS.2005.1532146	natural language,interaction,language pragmatics,visual analytics,ambiguity,feedback	1	10	4	41	
VAST	2017	Visualizing Big Data Outliers Through Distributed Aggregation	10.1109/TVCG.2017.2744685	http://dx.doi.org/10.1109/TVCG.2017.2744685	256	266	J	Visualizing outliers in massive datasets requires statistical pre-processing in order to reduce the scale of the problem to a size amenable to rendering systems like D3, Plotly or analytic systems like R or SAS. This paper presents a new algorithm, called<monospace>hdoutliers</monospace>, for detecting multidimensional outliers. It is unique for a) dealing with a mixture of categorical and continuous variables, b) dealing with big-p (many columns of data), c) dealing with big-<inline-formula><tex-math notation="LaTeX">$n$</tex-math><alternatives><inline-graphic xlink:href="24tvcg01-wilkinson-2744685-ieq-1-source.tif" xmlns:xlink="http://www.w3.org/1999/xlink"/></alternatives></inline-formula>(many rows of data), d) dealing with outliers that mask other outliers, and e) dealing consistently with unidimensional and multidimensional datasets. Unlike ad hoc methods found in many machine learning papers,<monospace>hdoutliers</monospace>is based on a distributional model that allows outliers to be tagged with a probability. This critical feature reduces the likelihood of false discoveries.	Leland Wilkinson	Leland Wilkinson	H2O.aiUIC	10.1109/INFVIS.2004.68;10.1109/TVCG.2010.197;10.1109/TVCG.2014.2346572;10.1109/INFVIS.2005.1532138;10.1109/VAST.2012.6400487;10.1109/TVCG.2006.170;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2005.1532142	Outliers,Anomalies	0	13	5	84	
VAST	2017	Understanding a Sequence of Sequences: Visual Exploration of Categorical States in Lake Sediment Cores	10.1109/TVCG.2017.2744686	http://dx.doi.org/10.1109/TVCG.2017.2744686	66	76	J	This design study focuses on the analysis of a time sequence of categorical sequences. Such data is relevant for the geoscientific research field of landscape and climate development. It results from microscopic analysis of lake sediment cores. The goal is to gain hypotheses about landscape evolution and climate conditions in the past. To this end, geoscientists identify which categorical sequences are similar in the sense that they indicate similar conditions. Categorical sequences are similar if they have similar meaning (semantic similarity) and appear in similar time periods (temporal similarity). For data sets with many different categorical sequences, the task to identify similar sequences becomes a challenge. Our contribution is a tailored visual analysis concept that effectively supports the analytical process. Our visual interface comprises coupled visualizations of semantics and temporal context for the exploration and assessment of the similarity of categorical sequences. Integrated automatic methods reduce the analytical effort substantially. They (1) extract unique sequences in the data and (2) rank sequences by a similarity measure during the search for similar sequences. We evaluated our concept by demonstrations of our prototype to a larger audience and hands-on analysis sessions for two different lakes. According to geoscientists, our approach fills an important methodological gap in the application domain.	Andrea Unger;Nadine Drager;Mike Sips;Dirk J. Lehmann	Andrea Unger;Nadine Dräger;Mike Sips;Dirk J. Lehmann	GFZ German Research Centre for Geosciences;GFZ German Research Centre for Geosciences;GFZ German Research Centre for Geosciences;University of Magdeburg	10.1109/TVCG.2011.232;10.1109/VISUAL.1997.663916;10.1109/TVCG.2013.182;10.1109/TVCG.2013.200;10.1109/TVCG.2011.212;10.1109/TVCG.2009.117;10.1109/TVCG.2015.2467751;10.1109/VAST.2009.5332595	Visualization in Earth Science,Time Series Data,Categorical Data,Design Study	0	6	2	46	
VAST	2017	ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models	10.1109/TVCG.2017.2744718	http://dx.doi.org/10.1109/TVCG.2017.2744718	88	97	J	While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models.	Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng Chau	Minsuk Kahng;Pierre Y. Andrews;Aditya Kalro;Duen Horng (Polo) Chau	Georgia Institute of Technology;Facebook;Facebook;Georgia Institute of Technology	10.1109/VAST.2015.7347637;10.1109/VAST.2010.5652443;10.1109/TVCG.2013.157;10.1109/TVCG.2014.2346482;10.1109/TVCG.2015.2467622;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453	Visual analytics,deep learning,machine learning,information visualization	18	68	32	38	
VAST	2017	SkyLens: Visual Analysis of Skyline on Multi-Dimensional Data	10.1109/TVCG.2017.2744738	http://dx.doi.org/10.1109/TVCG.2017.2744738	246	255	J	Skyline queries have wide-ranging applications in fields that involve multi-criteria decision making, including tourism, retail industry, and human resources. By automatically removing incompetent candidates, skyline queries allow users to focus on a subset of superior data items (i.e., the skyline), thus reducing the decision-making overhead. However, users are still required to interpret and compare these superior items manually before making a successful choice. This task is challenging because of two issues. First, people usually have fuzzy, unstable, and inconsistent preferences when presented with multiple candidates. Second, skyline queries do not reveal the reasons for the superiority of certain skyline points in a multi-dimensional space. To address these issues, we propose SkyLens, a visual analytic system aiming at revealing the superiority of skyline points from different perspectives and at different scales to aid users in their decision making. Two scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of attributes. A qualitative study is also conducted to show that users can efficiently accomplish skyline understanding and comparison tasks with SkyLens.	Xun Zhao;Yanhong Wu;Weiwei Cui;Xinnan Du;Yuan Chen;Yong Wang 0021;Dik Lun Lee;Huamin Qu	Xun Zhao;Yanhong Wu;Weiwei Cui;Xinnan Du;Yuan Chen;Yong Wang;Dik Lun Lee;Huamin Qu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research Asia;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology	10.1109/TVCG.2013.173;10.1109/TVCG.2016.2598432;10.1109/TVCG.2016.2598589;10.1109/TVCG.2015.2468011	Skyline query,skyline visualization,multi-dimensional data,visual analytics,multi-criteria decision making	1	7	3	49	
VAST	2017	EVA: Visual Analytics to Identify Fraudulent Events	10.1109/TVCG.2017.2744758	http://dx.doi.org/10.1109/TVCG.2017.2744758	330	339	J	Financial institutions are interested in ensuring security and quality for their customers. Banks, for instance, need to identify and stop harmful transactions in a timely manner. In order to detect fraudulent operations, data mining techniques and customer profile analysis are commonly used. However, these approaches are not supported by Visual Analytics techniques yet. Visual Analytics techniques have potential to considerably enhance the knowledge discovery process and increase the detection and prediction accuracy of financial fraud detection systems. Thus, we propose EVA, a Visual Analytics approach for supporting fraud investigation, fine-tuning fraud detection algorithms, and thus, reducing false positive alarms.	Roger A. Leite;Theresia Gschwandtner;Silvia Miksch;Simone Kriglstein;Margit Pohl;Erich Gstrein;Johannes Kuntner	Roger A. Leite;Theresia Gschwandtner;Silvia Miksch;Simone Kriglstein;Margit Pohl;Erich Gstrein;Johannes Kuntner	Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Faculty of Computer Science, University of Vienna, Austria;Vienna University of Technology;Erste Group IT International, Austria;Erste Group IT International, Austria	10.1109/VAST.2007.4389009;10.1109/TVCG.2013.126;10.1109/VAST.2015.7347678;10.1109/TVCG.2013.200;10.1109/TVCG.2009.111;10.1109/TVCG.2012.273	Visual Knowledge Discovery,Time Series Data,Business and Finance Visualization,Financial Fraud Detection	0	8	2	36	
VAST	2017	SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance	10.1109/TVCG.2017.2744805	http://dx.doi.org/10.1109/TVCG.2017.2744805	120	130	J	Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself.	Dominik Sacha;Matthias Kraus;Jürgen Bernard;Michael Behrisch 0001;Tobias Schreck;Yuki Asano;Daniel A. Keim	Dominik Sacha;Matthias Kraus;Jürgen Bernard;Michael Behrisch;Tobias Schreck;Yuki Asano;Daniel A. Keim	University of Konstanz, Germany;University of Konstanz, Germany;TU Darmstadt, Germany;University of Konstanz, Germany;Graz University of Technology;University of Tübingen;University of Konstanz, Germany	10.1109/VAST.2009.5332584;10.1109/VAST.2014.7042480;10.1109/TVCG.2013.178;10.1109/TVCG.2011.229;10.1109/TVCG.2011.188;10.1109/TVCG.2016.2598468;10.1109/VAST.2010.5652443;10.1109/VAST.2015.7347625;10.1109/VAST.2007.4389013;10.1109/TVCG.2014.2346260;10.1109/TVCG.2007.70582;10.1109/VAST.2007.4388999;10.1109/TVCG.2014.2346481;10.1109/TVCG.2016.2598495;10.1109/VAST.2011.6102453	Visual Analytics,Interaction,Visual Cluster Analysis,Quality Metrics,Guidance,Self-Organizing Maps,Time Series	0	14	7	58	
VAST	2017	Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study	10.1109/TVCG.2017.2744818	http://dx.doi.org/10.1109/TVCG.2017.2744818	298	308	J	Labeling data instances is an important task in machine learning and visual analytics. Both fields provide a broad set of labeling strategies, whereby machine learning (and in particular active learning) follows a rather model-centered approach and visual analytics employs rather user-centered approaches (visual-interactive labeling). Both approaches have individual strengths and weaknesses. In this work, we conduct an experiment with three parts to assess and compare the performance of these different labeling strategies. In our study, we (1) identify different visual labeling strategies for user-centered labeling, (2) investigate strengths and weaknesses of labeling strategies for different labeling tasks and task complexities, and (3) shed light on the effect of using different visual encodings to guide the visual-interactive labeling process. We further compare labeling of single versus multiple instances at a time, and quantify the impact on efficiency. We systematically compare the performance of visual interactive labeling with that of active learning. Our main findings are that visual-interactive labeling can outperform active learning, given the condition that dimension reduction separates well the class distributions. Moreover, using dimension reduction in combination with additional visual encodings that expose the internal state of the learning model turns out to improve the performance of visual-interactive labeling.	Jürgen Bernard;Marco Hutter 0002;Matthias Zeppelzauer;Dieter W. Fellner;Michael Sedlmair	Jürgen Bernard;Marco Hutter;Matthias Zeppelzauer;Dieter Fellner;Michael Sedlmair	Technische Universität Darmstadt, Darmstadt, Germany;Technische Universität Darmstadt, Darmstadt, Germany;St. Pölten University of Applied Sciences, St. Pölten, Austria;Fraunhofer IGD, Darmstadt, Germany;University of Vienna, Vienna, Austria	10.1109/VAST.2014.7042480;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400492;10.1109/VAST.2010.5652392;10.1109/TVCG.2014.2346482;10.1109/TVCG.2016.2598589;10.1109/TVCG.2016.2598495;10.1109/TVCG.2013.153;10.1109/TVCG.2015.2467717	Labeling,Visual-Interactive Labeling,Information Visualization,Visual Analytics,Active Learning,Machine Learning,Classification,Evaluation,Experiment,Dimensionality Reduction	3	23	8	72	
VAST	2017	Graphiti: Interactive Specification of Attribute-Based Edges for Network Modeling and Visualization	10.1109/TVCG.2017.2744843	http://dx.doi.org/10.1109/TVCG.2017.2744843	226	235	J	Network visualizations, often in the form of node-link diagrams, are an effective means to understand relationships between entities, discover entities with interesting characteristics, and to identify clusters. While several existing tools allow users to visualize pre-defined networks, creating these networks from raw data remains a challenging task, often requiring users to program custom scripts or write complex SQL commands. Some existing tools also allow users to both visualize and model networks. Interaction techniques adopted by these tools often assume users know the exact conditions for defining edges in the resulting networks. This assumption may not always hold true, however. In cases where users do not know much about attributes in the dataset or when there are several attributes to choose from, users may not know which attributes they could use to formulate linking conditions. We propose an alternate interaction technique to model networks that allows users to demonstrate to the system a subset of nodes and links they wish to see in the resulting network. The system, in response, recommends conditions that can be used to model networks based on the specified nodes and links. In this paper, we show how such a demonstration-based interaction technique can be used to model networks by employing it in a prototype tool, Graphiti. Through multiple usage scenarios, we show how Graphiti not only allows users to model networks from a tabular dataset but also facilitates updating a pre-defined network with additional edge types.	Arjun Srinivasan;Hyunwoo Park;Alex Endert;Rahul C. Basole	Arjun Srinivasan;Hyunwoo Park;Alex Endert;Rahul C. Basole	Georgia Institute of Technology;The Ohio State University;Georgia Institute of Technology;Georgia Institute of Technology	10.1109/VAST.2006.261429;10.1109/TVCG.2011.185;10.1109/VAST.2011.6102441;10.1109/VAST.2006.261426;10.1109/TVCG.2009.151;10.1109/TVCG.2006.122;10.1109/TVCG.2016.2598839;10.1109/TVCG.2006.166;10.1109/TVCG.2009.108;10.1109/VAST.2010.5652520	Network modeling,visual analytics,user interaction	1	4	1	49	
VAST	2017	Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow	10.1109/TVCG.2017.2744878	http://dx.doi.org/10.1109/TVCG.2017.2744878	1	12	J	We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model's modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.	Kanit Wongsuphasawat;Daniel Smilkov;James Wexler;Jimbo Wilson;Dan Mané;Doug Fritz;Dilip Krishnan;Fernanda B. Viégas;Martin Wattenberg	Kanit Wongsuphasawat;Daniel Smilkov;James Wexler;Jimbo Wilson;Dandelion Mané;Doug Fritz;Dilip Krishnan;Fernanda B. Viégas;Martin Wattenberg	Paul G. Allen School of Computer Science & EngineeringUniversity of Washington;Google Research;Google Research;Google Research;Google Research;Google Research;Google Research;Google Research;Google Research	10.1109/INFVIS.2005.1532130;10.1109/TVCG.2006.156;10.1109/INFVIS.2004.66;10.1109/TVCG.2015.2467451;10.1109/TVCG.2016.2598831;10.1109/VISUAL.2005.1532820;10.1109/INFVIS.2004.43;10.1109/TVCG.2015.2467251	Neural Network,Graph Visualization,Dataflow Graph,Clustered Graph	14	78	33	57	BP
VAST	2017	VIGOR: Interactive Visual Exploration of Graph Query Results	10.1109/TVCG.2017.2744898	http://dx.doi.org/10.1109/TVCG.2017.2744898	215	225	J	Finding patterns in graphs has become a vital challenge in many domains from biological systems, network security, to finance (e.g., finding money laundering rings of bankers and business owners). While there is significant interest in graph databases and querying techniques, less research has focused on helping analysts make sense of underlying patterns within a group of subgraph results. Visualizing graph query results is challenging, requiring effective summarization of a large number of subgraphs, each having potentially shared node-values, rich node features, and flexible structure across queries. We present VIGOR, a novel interactive visual analytics system, for exploring and making sense of query results. VIGOR uses multiple coordinated views, leveraging different data representations and organizations to streamline analysts sensemaking process. VIGOR contributes: (1) an exemplar-based interaction technique, where an analyst starts with a specific result and relaxes constraints to find other similar results or starts with only the structure (i.e., without node value constraints), and adds constraints to narrow in on specific results; and (2) a novel feature-aware subgraph result summarization. Through a collaboration with Symantec, we demonstrate how VIGOR helps tackle real-world problems through the discovery of security blindspots in a cybersecurity dataset with over 11,000 incidents. We also evaluate VIGOR with a within-subjects study, demonstrating VIGOR's ease of use over a leading graph database management system, and its ability to help analysts understand their results at higher speed and make fewer errors.	Robert Pienta;Fred Hohman;Alex Endert;Acar Tamersoy;Kevin A. Roundy;Christopher Gates 0002;Shamkant B. Navathe;Duen Horng Chau	Robert Pienta;Fred Hohman;Alex Endert;Acar Tamersoy;Kevin Roundy;Chris Gates;Shamkant Navathe;Duen Horng Chau		10.1109/TVCG.2015.2467717;10.1109/TVCG.2015.2468078	graph querying,subgraph results,query result visualization	3	13	3	49	
VAST	2017	Analyzing the Training Processes of Deep Generative Models	10.1109/TVCG.2017.2744938	http://dx.doi.org/10.1109/TVCG.2017.2744938	77	87	J	Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.	Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu 0001;Shixia Liu	Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu;Shixia Liu	Tsinghua UniversityNational Engineering Lab for Big Data Software;Tsinghua University;Tsinghua UniversityNational Engineering Lab for Big Data Software;Tsinghua University;Tsinghua UniversityNational Engineering Lab for Big Data Software	10.1109/TVCG.2016.2598496;10.1109/TVCG.2014.2346594;10.1109/TVCG.2010.131;10.1109/TVCG.2011.239;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598797;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598829;10.1109/VISUAL.2005.1532820;10.1109/VAST.2016.7883511;10.1109/TVCG.2016.2598664	deep learning,deep generative models,blue noise sampling,credit assignment	6	41	21	55	
VAST	2017	Podium: Ranking Data Using Mixed-Initiative Visual Analytics	10.1109/TVCG.2017.2745078	http://dx.doi.org/10.1109/TVCG.2017.2745078	288	297	J	People often rank and order data points as a vital part of making decisions. Multi-attribute ranking systems are a common tool used to make these data-driven decisions. Such systems often take the form of a table-based visualization in which users assign weights to the attributes representing the quantifiable importance of each attribute to a decision, which the system then uses to compute a ranking of the data. However, these systems assume that users are able to quantify their conceptual understanding of how important particular attributes are to a decision. This is not always easy or even possible for users to do. Rather, people often have a more holistic understanding of the data. They form opinions that data point A is better than data point B but do not necessarily know which attributes are important. To address these challenges, we present a visual analytic application to help people rank multi-variate data points. We developed a prototype system, Podium, that allows users to drag rows in the table to rank order data points based on their perception of the relative value of the data. Podium then infers a weighting model using Ranking SVM that satisfies the user's data preferences as closely as possible. Whereas past systems help users understand the relationships between data points based on changes to attribute weights, our approach helps users to understand the attributes that might inform their understanding of the data. We present two usage scenarios to describe some of the potential uses of our proposed technique: (1) understanding which attributes contribute to a user's subjective preferences for data, and (2) deconstructing attributes of importance for existing rankings. Our proposed approach makes powerful machine learning techniques more usable to those who may not have expertise in these areas.	Emily Wall;Subhajit Das;Ravish Chawla;Bharath Kalidindi;Eli T. Brown;Alex Endert	Emily Wall;Subhajit Das;Ravish Chawla;Bharath Kalidindi;Eli T. Brown;Alex Endert	Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;DePaul University, Chicago, IL, USA;Georgia Institute of Technology, Atlanta, GA, USA	10.1109/INFVIS.2005.1532136;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346575;10.1109/VAST.2015.7347625;10.1109/TVCG.2016.2598594;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.173;10.1109/TVCG.2015.2467615;10.1109/TVCG.2016.2598446;10.1109/TVCG.2015.2467551;10.1109/TVCG.2016.2598839;10.1109/TVCG.2012.253;10.1109/VAST.2017.8585669	Mixed-initiative visual analytics,multi-attribute ranking,user interaction	2	15	6	48	
VAST	2017	Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework	10.1109/TVCG.2017.2745080	http://dx.doi.org/10.1109/TVCG.2017.2745080	382	391	J	Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.	Mennatallah El-Assady;Rita Sevastjanova;Fabian Sperrle;Daniel A. Keim;Christopher Collins 0001	Mennatallah El-Assady;Rita Sevastjanova;Fabian Sperrle;Daniel Keim;Christopher Collins	University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Ontario Institute of Technology, Canada	10.1109/TVCG.2015.2467618;10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/VAST.2009.5333443;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346433;10.1109/TVCG.2010.129;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.162;10.1109/TVCG.2013.126;10.1109/TVCG.2014.2346321	Topic Model Configuration,Reinforcement Learning,Feature Detection and Tracking,Iterative Optimization	5	16	10	43	HM
VAST	2017	Sequence Synopsis: Optimize Visual Summary of Temporal Event Data	10.1109/TVCG.2017.2745083	http://dx.doi.org/10.1109/TVCG.2017.2745083	45	55	J	Event sequences analysis plays an important role in many application domains such as customer behavior analysis, electronic health record analysis and vehicle fault diagnosis. Real-world event sequence data is often noisy and complex with high event cardinality, making it a challenging task to construct concise yet comprehensive overviews for such data. In this paper, we propose a novel visualization technique based on the minimum description length (MDL) principle to construct a coarse-level overview of event sequence data while balancing the information loss in it. The method addresses a fundamental trade-off in visualization design: reducing visual clutter vs. increasing the information content in a visualization. The method enables simultaneous sequence clustering and pattern extraction and is highly tolerant to noises such as missing or additional events in the data. Based on this approach we propose a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. We demonstrate the usability and effectiveness of our approach through case studies with two real-world datasets. One dataset showcases a new application domain for event sequence visualization, i.e., fault development path analysis in vehicles for predictive maintenance. We also discuss the strengths and limitations of the proposed method based on user feedback.	Yuanzhe Chen;Panpan Xu;Liu Ren	Yuanzhe Chen;Panpan Xu;Liu Ren	Hong Kong University of Science and Technology;Bosch Research North America, Palo Alto, CA;Bosch Research North America, Palo Alto, CA	10.1109/VAST.2016.7883512;10.1109/TVCG.2013.214;10.1109/TVCG.2014.2346682;10.1109/TVCG.2015.2467622;10.1109/TVCG.2011.179;10.1109/TVCG.2016.2598797;10.1109/TVCG.2015.2467991;10.1109/TVCG.2013.200;10.1109/VAST.2015.7347682;10.1109/INFVIS.2000.885091;10.1109/TVCG.2016.2598591;10.1109/TVCG.2016.2598591;10.1109/TVCG.2009.117;10.1109/TVCG.2009.187;10.1109/VAST.2012.6400494;10.1109/TVCG.2012.225;10.1109/VAST.2009.5332595;10.1109/TVCG.2013.167	Time Series Data,Data Transformation and Representation,Visual Knowledge Representation,Visual Analytics	1	23	15	60	
VAST	2017	Clustervision: Visual Supervision of Unsupervised Clustering	10.1109/TVCG.2017.2745085	http://dx.doi.org/10.1109/TVCG.2017.2745085	142	151	J	Clustering, the process of grouping together similar items into distinct partitions, is a common type of unsupervised machine learning that can be useful for summarizing and aggregating complex multi-dimensional data. However, data can be clustered in many ways, and there exist a large body of algorithms designed to reveal different patterns. While having access to a wide variety of algorithms is helpful, in practice, it is quite difficult for data scientists to choose and parameterize algorithms to get the clustering results relevant for their dataset and analytical tasks. To alleviate this problem, we built Clustervision, a visual analytics tool that helps ensure data scientists find the right clustering among the large amount of techniques and parameters available. Our system clusters data using a variety of clustering techniques and parameters and then ranks clustering results utilizing five quality metrics. In addition, users can guide the system to produce more relevant results by providing task-relevant constraints on the data. Our visual user interface allows users to find high quality clustering results, explore the clusters using several coordinated visualization techniques, and select the cluster result that best suits their task. We demonstrate this novel approach using a case study with a team of researchers in the medical domain and showcase that our system empowers users to choose an effective representation of their complex data.	Bum Chul Kwon;Benjamin Eysenbach;Janu Verma;Kenney Ng;Christopher deFilippi;Walter F. Stewart;Adam Perer	Bum Chul Kwon;Ben Eysenbach;Janu Verma;Kenney Ng;Christopher De Filippi;Walter F. Stewart;Adam Perer	IBM T.J. Watson Research Center, NY, USA;Massachusetts Institute of Technology, Cambridge, MA, USA;IBM T.J. Watson Research Center, NY, USA;IBM T.J. Watson Research Center, NY, USA;Inova Heart and Vascular Institute, Fairfax, VA, USA;Sutter Health Research, Walnut Creek, California, USA;IBM T.J. Watson Research Center, NY, USA	10.1109/TVCG.2011.188;10.1109/TVCG.2014.2346321;10.1109/TVCG.2015.2467717	Unsupervised Clustering,Visual Analytics,Quality Metrics,Interactive Visual Clustering	2	27	11	46	
InfoVis	2017	Open vs. Closed Shapes: New Perceptual Categories?	10.1109/TVCG.2017.2745086	http://dx.doi.org/10.1109/TVCG.2017.2745086	574	583	J	Effective communication using visualization relies in part on the use of viable encoding strategies. For example, a viewer's ability to rapidly and accurately discern between two or more categorical variables in a chart or figure is contingent upon the distinctiveness of the encodings applied to each variable. Research in perception suggests that color is a more salient visual feature when compared to shape and although that finding is supported by visualization studies, characteristics of shape also yield meaningful differences in distinctiveness. We propose that open or closed shapes (that is, whether shapes are composed of line segments that are bounded across a region of space or not) represent a salient characteristic that influences perceptual processing. Three experiments were performed to test the reliability of the open/closed category; the first two from the perspective of attentional allocation, and the third experiment in the context of multi-class scatterplot displays. In the first, a flanker paradigm was used to test whether perceptual load and open/closed feature category would modulate the effect of the flanker on target processing. Results showed an influence of both variables. The second experiment used a Same/Different reaction time task to replicate and extend those findings. Results from both show that responses are faster and more accurate when closed rather than open shapes are processed as targets, and there is more processing interference when two competing shapes come from the same rather than different open or closed feature categories. The third experiment employed three commonly used visual analytic tasks - perception of average value, numerosity, and linear relationships with both single and dual displays of open and closed symbols. Our findings show that for numerosity and trend judgments, in particular, that different symbols from the same open or closed feature category cause more perceptual interference when they are presented together in a plot than symbols from different categories. Moreover, the extent of the interference appears to depend upon whether the participant is focused on processing open or closed symbols.	David Burlinson;Kalpathi R. Subramanian;Paula Goolkasian	David Burlinson;Kalpathi Subramanian;Paula Goolkasian	Department of Computer Science, The University of North Carolina, Charlotte;Department of Computer Science, The University of North Carolina, Charlotte;Department of Psychology, The University of North Carolina, Charlotte	10.1109/TVCG.2014.2346978;10.1109/TVCG.2013.183	scatterplot,visualization design,perceptual category,open shape,closed shape	0	1	0	26	
InfoVis	2017	CasCADe: A Novel 4D Visualization System for Virtual Construction Planning	10.1109/TVCG.2017.2745105	http://dx.doi.org/10.1109/TVCG.2017.2745105	687	697	J	Building Information Modeling (BIM) provides an integrated 3D environment to manage large-scale engineering projects. The Architecture, Engineering and Construction (AEC) industry explores 4D visualizations over these datasets for virtual construction planning. However, existing solutions lack adequate visual mechanisms to inspect the underlying schedule and make inconsistencies readily apparent. The goal of this paper is to apply best practices of information visualization to improve 4D analysis of construction plans. We first present a review of previous work that identifies common use cases and limitations. We then consulted with AEC professionals to specify the main design requirements for such applications. These guided the development of CasCADe, a novel 4D visualization system where task sequencing and spatio-temporal simultaneity are immediately apparent. This unique framework enables the combination of diverse analytical features to create an information-rich analysis environment. We also describe how engineering collaborators used CasCADe to review the real-world construction plans of an Oil &amp;amp; Gas process plant. The system made evident schedule uncertainties, identified work-space conflicts and helped analyze other constructability issues. The results and contributions of this paper suggest new avenues for future research in information visualization for the AEC industry.	Paulo Ivson;Daniel Nascimento;Waldemar Celes Filho;Simone D. J. Barbosa	Paulo Ivson;Daniel Nascimento;Waldemar Celes;Simone DJ Barbosa	Tecgraf InstitutePUC-Rio;Tecgraf InstitutePUC-Rio;Tecgraf InstitutePUC-Rio;Informatics DepartmentPUC-Rio	10.1109/VISUAL.1995.480803;10.1109/TVCG.2006.140;10.1109/TVCG.2007.70574;10.1109/TVCG.2007.70535;10.1109/VISUAL.1997.663876;10.1109/VISUAL.1996.568118;10.1109/TVCG.2007.70539;10.1109/TVCG.2013.126;10.1109/TVCG.2009.152;10.1109/TVCG.2012.213;10.1109/TVCG.2006.115;10.1109/TVCG.2012.265;10.1109/TVCG.2016.2599041;10.1109/TVCG.2007.70570;10.1109/TVCG.2007.70515	Visualization in physical sciences and engineering,design studies,integrating spatial and non-spatial data visualization,task and requirements analysis	4	11	1	119	
VAST	2017	PhenoLines: Phenotype Comparison Visualizations for Disease Subtyping via Topic Models	10.1109/TVCG.2017.2745118	http://dx.doi.org/10.1109/TVCG.2017.2745118	371	381	J	PhenoLines is a visual analysis tool for the interpretation of disease subtypes, derived from the application of topic models to clinical data. Topic models enable one to mine cross-sectional patient comorbidity data (e.g., electronic health records) and construct disease subtypes-each with its own temporally evolving prevalence and co-occurrence of phenotypes-without requiring aligned longitudinal phenotype data for all patients. However, the dimensionality of topic models makes interpretation challenging, and de facto analyses provide little intuition regarding phenotype relevance or phenotype interrelationships. PhenoLines enables one to compare phenotype prevalence within and across disease subtype topics, thus supporting subtype characterization, a task that involves identifying a proposed subtype's dominant phenotypes, ages of effect, and clinical validity. We contribute a data transformation workflow that employs the Human Phenotype Ontology to hierarchically organize phenotypes and aggregate the evolving probabilities produced by topic models. We introduce a novel measure of phenotype relevance that can be used to simplify the resulting topology. The design of PhenoLines was motivated by formative interviews with machine learning and clinical experts. We describe the collaborative design process, distill high-level tasks, and report on initial evaluations with machine learning experts and a medical domain expert. These results suggest that PhenoLines demonstrates promising approaches to support the characterization and optimization of topic models.	Michael Glueck;Mahdi Pakdaman Naeini;Finale Doshi-Velez;Fanny Chevalier;Azam Khan;Daniel J. Wigdor;Michael Brudno	Michael Glueck;Mahdi Pakdaman Naeini;Finale Doshi-Velez;Fanny Chevalier;Azam Khan;Daniel Wigdor;Michael Brudno	Autodesk Research and University, Toronto;Harvard University;Harvard University;Inria;Autodesk Research;University of Toronto;Hospital for Sick ChildrenUniversity of Toronto	10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2009.140;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.162;10.1109/TVCG.2016.2598469;10.1109/TVCG.2015.2467733;10.1109/TVCG.2015.2467622;10.1109/VAST.2014.7042494;10.1109/TVCG.2009.111;10.1109/TVCG.2012.213;10.1109/TVCG.2016.2598591	Developmental disorder,Human Phenotype Ontology (HPO),Phenotypes,Topic models,Topology simplification	2	7	4	57	
InfoVis	2017	Conceptual and Methodological Issues in Evaluating Multidimensional Visualizations for Decision Support	10.1109/TVCG.2017.2745138	http://dx.doi.org/10.1109/TVCG.2017.2745138	749	759	J	We explore how to rigorously evaluate multidimensional visualizations for their ability to support decision making. We first define multi-attribute choice tasks, a type of decision task commonly performed with such visualizations. We then identify which of the existing multidimensional visualizations are compatible with such tasks, and set out to evaluate three elementary visualizations: parallel coordinates, scatterplot matrices and tabular visualizations. Our method consists in first giving participants low-level analytic tasks, in order to ensure that they properly understood the visualizations and their interactions. Participants are then given multi-attribute choice tasks consisting of choosing holiday packages. We assess decision support through multiple objective and subjective metrics, including a decision accuracy metric based on the consistency between the choice made and self-reported preferences for attributes. We found the three visualizations to be comparable on most metrics, with a slight advantage for tabular visualizations. In particular, tabular visualizations allow participants to reach decisions faster. Thus, although decision time is typically not central in assessing decision support, it can be used as a tie-breaker when visualizations achieve similar decision accuracy. Our results also suggest that indirect methods for assessing choice confidence may allow to better distinguish between visualizations than direct ones. We finally discuss the limitations of our methods and directions for future work, such as the need for more sensitive metrics of decision support.	Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic	Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic	Inria, France;Univ. Paris-Sud, CNRS, Inria, Universit&#x00E9; Paris-Saclay, France;Inria, France	10.1109/VAST.2011.6102457;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2004.10;10.1109/TVCG.2015.2467552;10.1109/TVCG.2016.2598594;10.1109/TVCG.2008.153;10.1109/INFVIS.2004.64;10.1109/VISUAL.1999.809866;10.1109/TVCG.2013.173;10.1109/TVCG.2014.2346979;10.1109/TVCG.2006.160;10.1109/TVCG.2013.160;10.1109/TVCG.2015.2466992;10.1109/TVCG.2015.2467671;10.1109/TVCG.2016.2598589;10.1109/TVCG.2014.2346279;10.1109/VAST.2009.5333920;10.1109/TVCG.2015.2468011;10.1109/TVCG.2014.2346320;10.1109/TVCG.2010.205;10.1109/VISUAL.1997.663867;10.1109/INFVIS.2003.1249015	decision making,multidimensional visualization,parallel coordinates,scatterplot matrix,tabular visualization,evaluation	1	11	4	91	
VAST	2017	A Utility-Aware Visual Approach for Anonymizing Multi-Attribute Tabular Data	10.1109/TVCG.2017.2745139	http://dx.doi.org/10.1109/TVCG.2017.2745139	351	360	J	Sharing data for public usage requires sanitization to prevent sensitive information from leaking. Previous studies have presented methods for creating privacy preserving visualizations. However, few of them provide sufficient feedback to users on how much utility is reduced (or preserved) during such a process. To address this, we design a visual interface along with a data manipulation pipeline that allows users to gauge utility loss while interactively and iteratively handling privacy issues in their data. Widely known and discussed types of privacy models, i.e., syntactic anonymity and differential privacy, are integrated and compared under different use case scenarios. Case study results on a variety of examples demonstrate the effectiveness of our approach.	Xu-Meng Wang;Jia-Kai Chou;Wei Chen 0001;Huihua Guan;Wenlong Chen;Tianyi Lao;Kwan-Liu Ma	Xumeng Wang;Jia-Kai Chou;Wei Chen;Huihua Guan;Wenlong Chen;Tianyi Lao;Kwan-Liu Ma	Zhejiang University;University of California, Davis;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;University of California, Davis	10.1109/TVCG.2011.163;10.1109/TVCG.2015.2467671	Privacy preserving visualization,utility aware anonymization,syntactic anonymity,differential privacy	3	8	3	38	
InfoVis	2017	Stable Treemaps via Local Moves	10.1109/TVCG.2017.2745140	http://dx.doi.org/10.1109/TVCG.2017.2745140	729	738	J	Treemaps are a popular tool to visualize hierarchical data: items are represented by nested rectangles and the area of each rectangle corresponds to the data being visualized for this item. The visual quality of a treemap is commonly measured via the aspect ratio of the rectangles. If the data changes, then a second important quality criterion is the stability of the treemap: how much does the treemap change as the data changes. We present a novel stable treemapping algorithm that has very high visual quality. Whereas existing treemapping algorithms generally recompute the treemap every time the input changes, our algorithm changes the layout of the treemap using only local modifications. This approach not only gives us direct control over stability, but it also allows us to use a larger set of possible layouts, thus provably resulting in treemaps of higher visual quality compared to existing algorithms. We further prove that we can reach all possible treemap layouts using only our local modifications. Furthermore, we introduce a new measure for stability that better captures the relative positions of rectangles. We finally show via experiments on real-world data that our algorithm outperforms existing treemapping algorithms also in practice on either visual quality and/or stability. Our algorithm scores high on stability regardless of whether we use an existing stability measure or our new measure.	Max Sondag;Bettina Speckmann;Kevin Verbeek	Max Sondag;Bettina Speckmann;Kevin Verbeek	TU Eindhoven;TU Eindhoven;TU Eindhoven	10.1109/INFVIS.2001.963283;10.1109/TVCG.2007.70529;10.1109/INFVIS.2005.1532145	Treemap,Stability,Local Moves	1	11	5	20	
InfoVis	2017	Visual Exploration of Semantic Relationships in Neural Word Embeddings	10.1109/TVCG.2017.2745141	http://dx.doi.org/10.1109/TVCG.2017.2745141	553	562	J	Constructing distributed representations for words through neural language models and using the resulting vector spaces for analysis has become a crucial component of natural language processing (NLP). However, despite their widespread application, little is known about the structure and properties of these spaces. To gain insights into the relationship between words, the NLP community has begun to adapt high-dimensional visualization techniques. In particular, researchers commonly use t-distributed stochastic neighbor embeddings (t-SNE) and principal component analysis (PCA) to create two-dimensional embeddings for assessing the overall structure and exploring linear relationships (e.g., word analogies), respectively. Unfortunately, these techniques often produce mediocre or even misleading results and cannot address domain-specific visualization challenges that are crucial for understanding semantic relationships in word embeddings. Here, we introduce new embedding techniques for visualizing semantic and syntactic analogies, and the corresponding tests to determine whether the resulting views capture salient structures. Additionally, we introduce two novel views for a comprehensive study of analogy relationships. Finally, we augment t-SNE embeddings to convey uncertainty information in order to allow a reliable interpretation. Combined, the different views address a number of domain-specific tasks difficult to solve with existing tools.	Shusen Liu;Peer-Timo Bremer;Jayaraman J. Thiagarajan;Vivek Srikumar;Bei Wang;Yarden Livnat;Valerio Pascucci	Shusen Liu;Peer-Timo Bremer;Jayaraman J. Thiagarajan;Vivek Srikumar;Bei Wang;Yarden Livnat;Valerio Pascucci	Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;School of ComputingUniversity of Utah;SCI InstituteUniversity of Utah;SCI InstituteUniversity of Utah;SCI InstituteUniversity of Utah	10.1109/TVCG.2011.185;10.1109/VISUAL.1990.146402;10.1109/TVCG.2013.196	Natural Language Processing,Word Embedding,High-Dimensional Data	3	20	8	46	
VAST	2017	TreePOD: Sensitivity-Aware Selection of Pareto-Optimal Decision Trees	10.1109/TVCG.2017.2745158	http://dx.doi.org/10.1109/TVCG.2017.2745158	174	183	J	Balancing accuracy gains with other objectives such as interpretability is a key challenge when building decision trees. However, this process is difficult to automate because it involves know-how about the domain as well as the purpose of the model. This paper presents TreePOD, a new approach for sensitivity-aware model selection along trade-offs. TreePOD is based on exploring a large set of candidate trees generated by sampling the parameters of tree construction algorithms. Based on this set, visualizations of quantitative and qualitative tree aspects provide a comprehensive overview of possible tree characteristics. Along trade-offs between two objectives, TreePOD provides efficient selection guidance by focusing on Pareto-optimal tree candidates. TreePOD also conveys the sensitivities of tree characteristics on variations of selected parameters by extending the tree generation process with a full-factorial sampling. We demonstrate how TreePOD supports a variety of tasks involved in decision tree selection and describe its integration in a holistic workflow for building and selecting decision trees. For evaluation, we illustrate a case study for predicting critical power grid states, and we report qualitative feedback from domain experts in the energy sector. This feedback suggests that TreePOD enables users with and without statistical background a confident and efficient identification of suitable decision trees.	Thomas Mühlbacher;Lorenz Linhardt;Torsten Möller;Harald Piringer	Thomas Mühlbacher;Lorenz Linhardt;Torsten Möller;Harald Piringer	VRVis Research Center;ETH Zurich;University of Vienna;VRVis Research Center	10.1109/VAST.2011.6102457;10.1109/TVCG.2010.190;10.1109/TVCG.2008.145;10.1109/TVCG.2014.2346578;10.1109/TVCG.2016.2598589;10.1109/TVCG.2009.110;10.1109/TVCG.2014.2346321;10.1109/TVCG.2010.130;10.1109/TVCG.2011.248;10.1109/VAST.2011.6102453	Model selection,classification trees,visual parameter search,sensitivity analysis,Pareto optimality	1	8	3	51	
VAST	2017	Visualizing Confidence in Cluster-Based Ensemble Weather Forecast Analyses	10.1109/TVCG.2017.2745178	http://dx.doi.org/10.1109/TVCG.2017.2745178	109	119	J	In meteorology, cluster analysis is frequently used to determine representative trends in ensemble weather predictions in a selected spatio-temporal region, e.g., to reduce a set of ensemble members to simplify and improve their analysis. Identified clusters (i.e., groups of similar members), however, can be very sensitive to small changes of the selected region, so that clustering results can be misleading and bias subsequent analyses. In this article, we - a team of visualization scientists and meteorologists-deliver visual analytics solutions to analyze the sensitivity of clustering results with respect to changes of a selected region. We propose an interactive visual interface that enables simultaneous visualization of a) the variation in composition of identified clusters (i.e., their robustness), b) the variability in cluster membership for individual ensemble members, and c) the uncertainty in the spatial locations of identified trends. We demonstrate that our solution shows meteorologists how representative a clustering result is, and with respect to which changes in the selected region it becomes unstable. Furthermore, our solution helps to identify those ensemble members which stably belong to a given cluster and can thus be considered similar. In a real-world application case we show how our approach is used to analyze the clustering behavior of different regions in a forecast of “Tropical Cyclone Karl”, guiding the user towards the cluster robustness information required for subsequent ensemble analysis.	Alexander Kumpf;Bianca Tost;Marlene Baumgart;Michael Riemer;Rüdiger Westermann;Marc Rautenhaus	Alexander Kumpf;Bianca Tost;Marlene Baumgart;Michael Riemer;Rüdiger Westermann;Marc Rautenhaus	Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany;Institute of Atmospheric Physics, Johannes Gutenberg Universität Mainz, Mainz, Germany;Institute of Atmospheric Physics, Johannes Gutenberg Universität Mainz, Mainz, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany	10.1109/TVCG.2014.2346626;10.1109/TVCG.2010.190;10.1109/TVCG.2006.168;10.1109/TVCG.2015.2467204;10.1109/TVCG.2016.2598868;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2013.141;10.1109/TVCG.2010.138;10.1109/TVCG.2006.170;10.1109/TVCG.2012.207;10.1109/TVCG.2013.177;10.1109/TVCG.2014.2346332;10.1109/TVCG.2013.143	Uncertainty visualization,ensemble visualization,clustering,meteorology	2	17	8	72	
VAST	2017	Beyond Tasks: An Activity Typology for Visual Analytics	10.1109/TVCG.2017.2745180	http://dx.doi.org/10.1109/TVCG.2017.2745180	267	277	J	As Visual Analytics (VA) research grows and diversifies to encompass new systems, techniques, and use contexts, gaining a holistic view of analytic practices is becoming ever more challenging. However, such a view is essential for researchers and practitioners seeking to develop systems for broad audiences that span multiple domains. In this paper, we interpret VA research through the lens of Activity Theory (AT) - a framework for modelling human activities that has been influential in the field of Human-Computer Interaction. We first provide an overview of Activity Theory, showing its potential for thinking beyond tasks, representations, and interactions to the broader systems of activity in which interactive tools are embedded and used. Next, we describe how Activity Theory can be used as an organizing framework in the construction of activity typologies, building and expanding upon the tradition of abstract task taxonomies in the field of Information Visualization. We then apply the resulting process to create an activity typology for Visual Analytics, synthesizing a wide range of systems and activity concepts from the literature. Finally, we use this typology as the foundation of an activity-centered design process, highlighting both tensions and opportunities in the design space of VA systems.	Darren Edge;Nathalie Henry Riche;Jonathan Larson;Christopher White	Darren Edge;Nathalie Henry Riche;Jonathan Larson;Christopher White	Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research	10.1109/INFVIS.2005.1532136;10.1109/VAST.2008.4677362;10.1109/TVCG.2013.124;10.1109/VAST.2006.261439;10.1109/TVCG.2016.2598468;10.1109/INFVIS.2000.885092;10.1109/VAST.2006.261430;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102438;10.1109/VAST.2010.5653598;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677366;10.1109/TVCG.2015.2467551;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.162;10.1109/TVCG.2007.70577;10.1109/TVCG.2016.2598543	Activity theory,visual analytics,activity-centered design,literature review,human-computer interaction	2	2	1	77	
VAST	2017	Bring It to the Pitch: Combining Video and Movement Data to Enhance Team Sport Analysis	10.1109/TVCG.2017.2745181	http://dx.doi.org/10.1109/TVCG.2017.2745181	13	22	J	Analysts in professional team sport regularly perform analysis to gain strategic and tactical insights into player and team behavior. Goals of team sport analysis regularly include identification of weaknesses of opposing teams, or assessing performance and improvement potential of a coached team. Current analysis workflows are typically based on the analysis of team videos. Also, analysts can rely on techniques from Information Visualization, to depict e.g., player or ball trajectories. However, video analysis is typically a time-consuming process, where the analyst needs to memorize and annotate scenes. In contrast, visualization typically relies on an abstract data model, often using abstract visual mappings, and is not directly linked to the observed movement context anymore. We propose a visual analytics system that tightly integrates team sport video recordings with abstract visualization of underlying trajectory data. We apply appropriate computer vision techniques to extract trajectory data from video input. Furthermore, we apply advanced trajectory and movement analysis techniques to derive relevant team sport analytic measures for region, event and player analysis in the case of soccer analysis. Our system seamlessly integrates video and visualization modalities, enabling analysts to draw on the advantages of both analysis forms. Several expert studies conducted with team sport analysts indicate the effectiveness of our integrated approach.	Manuel Stein;Halldór Janetzko;Andreas Lamprecht;Thorsten Breitkreutz;Philipp Zimmermann;Bastian Goldlücke;Tobias Schreck;Gennady L. Andrienko;Michael Grossniklaus;Daniel A. Keim	Manuel Stein;Halldor Janetzko;Andreas Lamprecht;Thorsten Breitkreutz;Philipp Zimmermann;Bastian Goldlücke;Tobias Schreck;Gennady Andrienko;Michael Grossniklaus;Daniel A. Keim	University of Konstanz;University of Zürich;University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;Graz University of Technology;Fraunhofer IAIS, Germany;University of Konstanz;University of Konstanz	10.1109/TVCG.2007.70521;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2013.207;10.1109/TVCG.2012.263;10.1109/TVCG.2014.2346445;10.1109/VAST.2014.7042477	visual analytics,sport analytics,immersive analytics	3	20	9	49	
InfoVis	2017	Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks	10.1109/TVCG.2017.2745219	http://dx.doi.org/10.1109/TVCG.2017.2745219	511	521	J	Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. Only recently have other forms of interaction begun to appear, such as natural language or touch-based interaction, though usually operating only independently. Prior evaluations of natural language interfaces for visualization have indicated potential value in combining direct manipulation and natural language as complementary interaction techniques. We hypothesize that truly multimodal interfaces for visualization, those providing users with freedom of expression via both natural language and touch-based direct manipulation input, may provide an effective and engaging user experience. Unfortunately, however, little work has been done in exploring such multimodal visualization interfaces. To address this gap, we have created an architecture and a prototype visualization system called Orko that facilitates both natural language and direct manipulation input. Specifically, Orko focuses on the domain of network visualization, one that has largely relied on WIMP-based interfaces and direct manipulation interaction, and has little or no prior research exploring natural language interaction. We report results from an initial evaluation study of Orko, and use our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.	Arjun Srinivasan;John T. Stasko	Arjun Srinivasan;John Stasko	Georgia Institute of Technology;Georgia Institute of Technology	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2010.164;10.1109/TVCG.2012.204;10.1109/TVCG.2009.108	Multimodal interaction,network visualization,natural language input,direct manipulation,multitouch input	3	16	8	70	
InfoVis	2017	Data Through Others' Eyes: The Impact of Visualizing Others' Expectations on Visualization Interpretation	10.1109/TVCG.2017.2745240	http://dx.doi.org/10.1109/TVCG.2017.2745240	760	769	J	In addition to visualizing input data, interactive visualizations have the potential to be social artifacts that reveal other people's perspectives on the data. However, how such social information embedded in a visualization impacts a viewer's interpretation of the data remains unknown. Inspired by recent interactive visualizations that display people's expectations of data against the data, we conducted a controlled experiment to evaluate the effect of showing social information in the form of other people's expectations on people's ability to recall the data, the degree to which they adjust their expectations to align with the data, and their trust in the accuracy of the data. We found that social information that exhibits a high degree of consensus lead participants to recall the data more accurately relative to participants who were exposed to the data alone. Additionally, participants trusted the accuracy of the data less and were more likely to maintain their initial expectations when other people's expectations aligned with their own initial expectations but not with the data. We conclude by characterizing the design space for visualizing others' expectations alongside data.	Yea-Seul Kim;Katharina Reinecke;Jessica Hullman	Yea-Seul Kim;Katharina Reinecke;Jessica Hullman	University of Washington;University of Washington;University of Washington	10.1109/VAST.2007.4389011;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2011.255;10.1109/TVCG.2014.2346419;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70589	Social influence,Social visualization,Data interpretation	0	10	4	40	
VAST	2017	Towards a Systematic Combination of Dimension Reduction and Clustering in Visual Analytics	10.1109/TVCG.2017.2745258	http://dx.doi.org/10.1109/TVCG.2017.2745258	131	141	J	Dimension reduction algorithms and clustering algorithms are both frequently used techniques in visual analytics. Both families of algorithms assist analysts in performing related tasks regarding the similarity of observations and finding groups in datasets. Though initially used independently, recent works have incorporated algorithms from each family into the same visualization systems. However, these algorithmic combinations are often ad hoc or disconnected, working independently and in parallel rather than integrating some degree of interdependence. A number of design decisions must be addressed when employing dimension reduction and clustering algorithms concurrently in a visualization system, including the selection of each algorithm, the order in which they are processed, and how to present and interact with the resulting projection. This paper contributes an overview of combining dimension reduction and clustering into a visualization system, discussing the challenges inherent in developing a visualization system that makes use of both families of algorithms.	John E. Wenskovitch;Ian Crandell;Naren Ramakrishnan;Leanna House;Scotland Leman;Chris North	John Wenskovitch;Ian Crandell;Naren Ramakrishnan;Leanna House;Scotland Leman;Chris North	Virginia Tech Department of Computer Science;Virginia Tech Department of Statistics;Virginia Tech Department of Computer Science;Virginia Tech Department of Statistics;Virginia Tech Department of Statistics;Virginia Tech Department of Computer Science	10.1109/TVCG.2006.120;10.1109/TVCG.2011.186;10.1109/INFVIS.2005.1532136;10.1109/VAST.2014.7042492;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346594;10.1109/VAST.2009.5332629;10.1109/TVCG.2013.212;10.1109/TVCG.2009.122;10.1109/TVCG.2006.156;10.1109/VAST.2011.6102449;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2013.188;10.1109/VAST.2012.6400487;10.1109/VAST.2007.4388999;10.1109/TVCG.2014.2346422;10.1109/TVCG.2011.178;10.1109/TVCG.2007.70515	Dimension reduction,clustering,algorithms,visual analytics	4	15	4	94	
InfoVis	2017	Exploring Multivariate Event Sequences Using Rules, Aggregations, and Selections	10.1109/TVCG.2017.2745278	http://dx.doi.org/10.1109/TVCG.2017.2745278	532	541	J	Multivariate event sequences are ubiquitous: travel history, telecommunication conversations, and server logs are some examples. Besides standard properties such as type and timestamp, events often have other associated multivariate data. Current exploration and analysis methods either focus on the temporal analysis of a single attribute or the structural analysis of the multivariate data only. We present an approach where users can explore event sequences at multivariate and sequential level simultaneously by interactively defining a set of rewrite rules using multivariate regular expressions. Users can store resulting patterns as new types of events or attributes to interactively enrich or simplify event sequences for further investigation. In Eventpad we provide a bottom-up glyph-oriented approach for multivariate event sequence analysis by searching, clustering, and aligning them according to newly defined domain specific properties. We illustrate the effectiveness of our approach with real-world data sets including telecommunication traffic and hospital treatments.	Bram C. M. Cappers;Jarke J. van Wijk	Bram C.M. Cappers;Jarke J. van Wijk	Eindhoven University of Technology;Eindhoven University of Technology	10.1109/TVCG.2013.124;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/TVCG.2015.2467622;10.1109/VAST.2007.4389008;10.1109/TVCG.2016.2598797;10.1109/TVCG.2013.200;10.1109/TVCG.2012.225	Event Visualization,Multivariate Events,Regular Expressions,Sequence Alignment,Interaction	0	18	12	50	
VAST	2017	Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs	10.1109/TVCG.2017.2745279	http://dx.doi.org/10.1109/TVCG.2017.2745279	340	350	J	During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst's interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes.	Jian Zhao 0010;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan	Jian Zhao;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan	FX Palo Alto Laboratory;Autodesk Research;Inria;Inria;Autodesk Research	10.1109/VAST.2007.4389009;10.1109/VAST.2011.6102447;10.1109/VAST.2010.5652932;10.1109/VAST.2006.261420;10.1109/VAST.2007.4389011;10.1109/TVCG.2008.137;10.1109/TVCG.2007.70568;10.1109/VAST.2009.5333020;10.1109/VAST.2009.5333878;10.1109/VAST.2011.6102438;10.1109/VAST.2006.261415;10.1109/TVCG.2014.2346573;10.1109/TVCG.2015.2467551;10.1109/VAST.2008.4677358;10.1109/TVCG.2016.2598466;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70589;10.1109/TVCG.2016.2598543	Collaboration,sensemaking,handoff,handover,structured externalizations,interactive visual analysis	4	11	4	55	HM
VAST	2017	Dynamic Influence Networks for Rule-Based Models	10.1109/TVCG.2017.2745280	http://dx.doi.org/10.1109/TVCG.2017.2745280	184	194	J	We introduce the Dynamic Influence Network (DIN), a novel visual analytics technique for representing and analyzing rule-based models of protein-protein interaction networks. Rule-based modeling has proved instrumental in developing biological models that are concise, comprehensible, easily extensible, and that mitigate the combinatorial complexity of multi-state and multi-component biological molecules. Our technique visualizes the dynamics of these rules as they evolve over time. Using the data produced by KaSim, an open source stochastic simulator of rule-based models written in the Kappa language, DINs provide a node-link diagram that represents the influence that each rule has on the other rules. That is, rather than representing individual biological components or types, we instead represent the rules about them (as nodes) and the current influence of these rules (as links). Using our interactive DIN-Viz software tool, researchers are able to query this dynamic network to find meaningful patterns about biological processes, and to identify salient aspects of complex rule-based models. To evaluate the effectiveness of our approach, we investigate a simulation of a circadian clock model that illustrates the oscillatory behavior of the KaiC protein phosphorylation cycle.	Angus G. Forbes;Andrew Thomas Burks;Kristine Lee;Xing Li;Pierre Boutillier;Jean Krivine;Walter Fontana	Angus G. Forbes;Andrew Burks;Kristine Lee;Xing Li;Pierre Boutillier;Jean Krivine;Walter Fontana	University of California, Santa Cruz;University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago;Harvard Medical School;Universit&#x00E9; Paris Diderot;Harvard Medical School	10.1109/TVCG.2011.185;10.1109/TVCG.2010.126;10.1109/TVCG.2013.198;10.1109/TVCG.2007.70528;10.1109/TVCG.2013.154;10.1109/TVCG.2012.189	Dynamic networks,biological data visualization,rule-based modeling,protein-protein interaction networks	2	9	2	67	
InfoVis	2017	TACO: Visualizing Changes in Tables Over Time	10.1109/TVCG.2017.2745298	http://dx.doi.org/10.1109/TVCG.2017.2745298	677	686	J	Multivariate, tabular data is one of the most common data structures used in many different domains. Over time, tables can undergo changes in both structure and content, which results in multiple versions of the same table. A challenging task when working with such derived tables is to understand what exactly has changed between versions in terms of additions/deletions, reorder, merge/split, and content changes. For textual data, a variety of commonplace “diff” tools exist that support the task of investigating changes between revisions of a text. Although there are some comparison tools which assist users in inspecting differences between multiple table instances, the resulting visualizations are often difficult to interpret or do not scale to large tables with thousands of rows and columns. To address these challenges, we developed TACO, an interactive comparison tool that visualizes the differences between multiple tables at various levels of detail. With TACO we show (1) the aggregated differences between multiple table versions over time, (2) the aggregated changes between two selected table versions, and (3) detailed changes between the selected tables. To demonstrate the effectiveness of our approach, we show its application by means of two usage scenarios.	Christina Stoiber;Holger Stitz;Reem Hourieh;Florian Grassinger;Wolfgang Aigner;Marc Streit	Christina Niederer;Holger Stitz;Reem Hourieh;Florian Grassinger;Wolfgang Aigner;Marc Streit	St. Pölten University of Applied Sciences, Austria;Johannes Kepler University, Linz, Austria;Johannes Kepler University, Linz, Austria;St. Pölten University of Applied Sciences, Austria;TU Wien, Austria;Johannes Kepler University, Linz, Austria	10.1109/TVCG.2012.233;10.1109/TVCG.2010.138;10.1109/TVCG.2013.213;10.1109/TVCG.2012.237	Table comparison,matrix,difference visualization	3	8	2	30	
VAST	2017	EventThread: Visual Summarization and Stage Analysis of Event Sequence Data	10.1109/TVCG.2017.2745320	http://dx.doi.org/10.1109/TVCG.2017.2745320	56	65	J	Event sequence data such as electronic health records, a person's academic records, or car service records, are ordered series of events which have occurred over a period of time. Analyzing collections of event sequences can reveal common or semantically important sequential patterns. For example, event sequence analysis might reveal frequently used care plans for treating a disease, typical publishing patterns of professors, and the patterns of service that result in a well-maintained car. It is challenging, however, to visually explore large numbers of event sequences, or sequences with large numbers of event types. Existing methods focus on extracting explicitly matching patterns of events using statistical analysis to create stages of event progression over time. However, these methods fail to capture latent clusters of similar but not identical evolutions of event sequences. In this paper, we introduce a novel visualization system named EventThread which clusters event sequences into threads based on tensor analysis and visualizes the latent stage categories and evolution patterns by interactively grouping the threads by similarity into time-specific clusters. We demonstrate the effectiveness of EventThread through usage scenarios in three different application domains and via interviews with an expert user.	Shunan Guo;Ke Xu;Rongwen Zhao;David Gotz;Hongyuan Zha;Nan Cao	Shunan Guo;Ke Xu;Rongwen Zhao;David Gotz;Hongyuan Zha;Nan Cao	East China Normal University;Hong Kong University of Science and Technology;iDV<sup>x</sup> LabTongji University;University of North Carolina, Chapel Hill;East China Normal University;iDV<sup>x</sup> LabTongji University	10.1109/TVCG.2011.188;10.1109/TVCG.2014.2346682;10.1109/INFVIS.2003.1249017;10.1109/TVCG.2011.179;10.1109/TVCG.2013.200	Visual Knowledge Representation,Visual Knowledge Discovery,Data Clustering,Time Series Data,Illustrative Visualization	0	14	9	39	
InfoVis	2017	EdWordle: Consistency-Preserving Word Cloud Editing	10.1109/TVCG.2017.2745859	http://dx.doi.org/10.1109/TVCG.2017.2745859	647	656	J	We present EdWordle, a method for consistently editing word clouds. At its heart, EdWordle allows users to move and edit words while preserving the neighborhoods of other words. To do so, we combine a constrained rigid body simulation with a neighborhood-aware local Wordle algorithm to update the cloud and to create very compact layouts. The consistent and stable behavior of EdWordle enables users to create new forms of word clouds such as storytelling clouds in which the position of words is carefully edited. We compare our approach with state-of-the-art methods and show that we can improve user performance, user satisfaction, as well as the layout itself.	Yunhai Wang;Xiaowei Chu;Chen Bao;Lifeng Zhu;Oliver Deussen;Baoquan Chen;Michael Sedlmair	Yunhai Wang;Xiaowei Chu;Chen Bao;Lifeng Zhu;Oliver Deussen;Baoquan Chen;Michael Sedlmair	Shandong University;Shandong University;Shandong University;Southeast University;Konstanz University, VCC SIAT, China;Shandong University;University of Vienna, Austria	10.1109/TVCG.2016.2598609;10.1109/TVCG.2011.201;10.1109/VAST.2009.5333443;10.1109/TVCG.2015.2467531;10.1109/TVCG.2014.2346292;10.1109/TVCG.2010.175;10.1109/TVCG.2010.194;10.1109/TVCG.2009.171	Wordle,consistency,text visualization	1	6	3	41	
InfoVis	2017	The Explanatory Visualization Framework: An Active Learning Framework for Teaching Creative Computing Using Explanatory Visualizations	10.1109/TVCG.2017.2745878	http://dx.doi.org/10.1109/TVCG.2017.2745878	791	801	J	Visualizations are nowadays appearing in popular media and are used everyday in the workplace. This democratisation of visualization challenges educators to develop effective learning strategies, in order to train the next generation of creative visualization specialists. There is high demand for skilled individuals who can analyse a problem, consider alternative designs, develop new visualizations, and be creative and innovative. Our three-stage framework, leads the learner through a series of tasks, each designed to develop different skills necessary for coming up with creative, innovative, effective, and purposeful visualizations. For that, we get the learners to create an explanatory visualization of an algorithm of their choice. By making an algorithm choice, and by following an active-learning and project-based strategy, the learners take ownership of a particular visualization challenge. They become enthusiastic to develop good results and learn different creative skills on their learning journey.	Jonathan C. Roberts;Panagiotis D. Ritsos;James R. Jackson;Christopher James Headleand	Jonathan C. Roberts;Panagiotis D. Ritsos;James R. Jackson;Christopher Headleand	Bangor University;Bangor University;Bangor University;University of Lincoln	10.1109/TVCG.2014.2346984;10.1109/TVCG.2016.2599338;10.1109/TVCG.2011.255;10.1109/TVCG.2014.2346331;10.1109/TVCG.2009.111;10.1109/TVCG.2015.2467271;10.1109/TVCG.2012.213;10.1109/TVCG.2010.179	Explanatory visualization,Information Visualization,Teaching visualization,Learning Support	0	3	2	70	
InfoVis	2017	Revisiting Stress Majorization as a Unified Framework for Interactive Constrained Graph Visualization	10.1109/TVCG.2017.2745919	http://dx.doi.org/10.1109/TVCG.2017.2745919	489	499	J	We present an improved stress majorization method that incorporates various constraints, including directional constraints without the necessity of solving a constraint optimization problem. This is achieved by reformulating the stress function to impose constraints on both the edge vectors and lengths instead of just on the edge lengths (node distances). This is a unified framework for both constrained and unconstrained graph visualizations, where we can model most existing layout constraints, as well as develop new ones such as the star shapes and cluster separation constraints within stress majorization. This improvement also allows us to parallelize computation with an efficient GPU conjugant gradient solver, which yields fast and stable solutions, even for large graphs. As a result, we allow the constraint-based exploration of large graphs with 10K nodes - an approach which previous methods cannot support.	Yunhai Wang;Yanyan Wang;Yinqi Sun;Lifeng Zhu;Kecheng Lu;Chi-Wing Fu;Michael Sedlmair;Oliver Deussen;Baoquan Chen	Yunhai Wang;Yanyan Wang;Yinqi Sun;Lifeng Zhu;Kecheng Lu;Chi-Wing Fu;Michael Sedlmair;Oliver Deussen;Baoquan Chen	Shandong University;Shandong University;Shandong University;Southeast University;Shandong University;VRHIT SIATChinese University of Hong Kong;University of Vienna, Austria;Konstanz University, VCC SIAT, China;Shandong University	10.1109/INFVIS.2005.1532130;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/TVCG.2008.130;10.1109/INFVIS.2004.66;10.1109/TVCG.2009.108;10.1109/TVCG.2012.236	Graph visualization,stress majorization,constraints	2	8	4	51	
InfoVis	2017	The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?	10.1109/TVCG.2017.2745941	http://dx.doi.org/10.1109/TVCG.2017.2745941	457	467	J	We report on a controlled user study comparing three visualization environments for common 3D exploration. Our environments differ in how they exploit natural human perception and interaction capabilities. We compare an augmented-reality head-mounted display (Microsoft HoloLens), a handheld tablet, and a desktop setup. The novel head-mounted HoloLens display projects stereoscopic images of virtual content into a user's real world and allows for interaction in-situ at the spatial position of the 3D hologram. The tablet is able to interact with 3D content through touch, spatial positioning, and tangible markers, however, 3D content is still presented on a 2D surface. Our hypothesis is that visualization environments that match human perceptual and interaction capabilities better to the task at hand improve understanding of 3D visualizations. To better understand the space of display and interaction modalities in visualization environments, we first propose a classification based on three dimensions: perception, interaction, and the spatial and cognitive proximity of the two. Each technique in our study is located at a different position along these three dimensions. We asked 15 participants to perform four tasks, each task having different levels of difficulty for both spatial perception and degrees of freedom for interaction. Our results show that each of the tested environments is more effective for certain tasks, but that generally the desktop environment is still fastest and most precise in almost all cases.	Benjamin Bach;Ronell Sicat;Johanna Beyer;Maxime Cordeil;Hanspeter Pfister	Benjamin Bach;Ronell Sicat;Johanna Beyer;Maxime Cordeil;Hanspeter Pfister	Harvard University;Harvard University;Harvard University;Monash University;Harvard University	10.1109/TVCG.2011.234;10.1109/TVCG.2012.216;10.1109/TVCG.2016.2599107;10.1109/TVCG.2008.153;10.1109/TVCG.2013.121;10.1109/TVCG.2013.134;10.1109/TVCG.2015.2467202	Augmented Reality,3D Interaction,User Study,Immersive Displays	9	38	16	67	
InfoVis	2017	Active Reading of Visualizations	10.1109/TVCG.2017.2745958	http://dx.doi.org/10.1109/TVCG.2017.2745958	770	780	J	We investigate whether the notion of active reading for text might be usefully applied to visualizations. Through a qualitative study we explored whether people apply observable active reading techniques when reading paper-based node-link visualizations. Participants used a range of physical actions while reading, and from these we synthesized an initial set of active reading techniques for visualizations. To learn more about the potential impact such techniques may have on visualization reading, we implemented support for one type of physical action from our observations (making freeform marks) in an interactive node-link visualization. Results from our quantitative study of this implementation show that interactive support for active reading techniques can improve the accuracy of performing low-level visualization tasks. Together, our studies suggest that the active reading space is ripe for research exploration within visualization and can lead to new interactions that make for a more flexible and effective visualization reading experience.	Jagoda Walny;Samuel Huron;Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale	Jagoda Walny;Samuel Huron;Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale	University of Calgary;University of Calgary;University of Calgary;University of Calgary;University of Calgary;University of Calgary	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.185;10.1109/TVCG.2015.2467201;10.1109/TVCG.2014.2346984;10.1109/TVCG.2016.2598594;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346435;10.1109/TVCG.2010.164;10.1109/TVCG.2008.141;10.1109/TVCG.2015.2467452;10.1109/TVCG.2015.2467671;10.1109/TVCG.2015.2467195;10.1109/TVCG.2014.2346573;10.1109/TVCG.2015.2467811;10.1109/TVCG.2014.2346422;10.1109/TVCG.2010.179;10.1109/TVCG.2013.164;10.1109/TVCG.2012.189	active reading of visualizations,active reading,information visualization,spectrum of physical engagement	2	10	9	74	
InfoVis	2017	HiPiler: Visual Exploration of Large Genome Interaction Matrices with Interactive Small Multiples	10.1109/TVCG.2017.2745978	http://dx.doi.org/10.1109/TVCG.2017.2745978	522	531	J	This paper presents an interactive visualization interface-HiPiler-for the exploration and visualization of regions-of-interest in large genome interaction matrices. Genome interaction matrices approximate the physical distance of pairs of regions on the genome to each other and can contain up to 3 million rows and columns with many sparse regions. Regions of interest (ROIs) can be defined, e.g., by sets of adjacent rows and columns, or by specific visual patterns in the matrix. However, traditional matrix aggregation or pan-and-zoom interfaces fail in supporting search, inspection, and comparison of ROIs in such large matrices. In HiPiler, ROIs are first-class objects, represented as thumbnail-like “snippets”. Snippets can be interactively explored and grouped or laid out automatically in scatterplots, or through dimension reduction methods. Snippets are linked to the entire navigable genome interaction matrix through brushing and linking. The design of HiPiler is based on a series of semi-structured interviews with 10 domain experts involved in the analysis and interpretation of genome interaction matrices. We describe six exploration tasks that are crucial for analysis of interaction matrices and demonstrate how HiPiler supports these tasks. We report on a user study with a series of data exploration sessions with domain experts to assess the usability of HiPiler as well as to demonstrate respective findings in the data.	Fritz Lekschas;Benjamin Bach;Peter Kerpedjiev;Nils Gehlenborg;Hanspeter Pfister	Fritz Lekschas;Benjamin Bach;Peter Kerpedjiev;Nils Gehlenborg;Hanspeter Pfister	Harvard University;Harvard University;Harvard Medical School;Harvard Medical School;Harvard University	10.1109/TVCG.2015.2467851;10.1109/TVCG.2016.2598467;10.1109/TVCG.2012.208;10.1109/TVCG.2007.70582;10.1109/VAST.2009.5333893	Interactive Small Multiples,Matrix Comparison,Biomedical Visualization,Genomics	4	14	3	45	
InfoVis	2017	Taking Word Clouds Apart: An Empirical Investigation of the Design Space for Keyword Summaries	10.1109/TVCG.2017.2746018	http://dx.doi.org/10.1109/TVCG.2017.2746018	657	666	J	In this paper we present a set of four user studies aimed at exploring the visual design space of what we call keyword summaries: lists of words with associated quantitative values used to help people derive an intuition of what information a given document collection (or part of it) may contain. We seek to systematically study how different visual representations may affect people's performance in extracting information out of keyword summaries. To this purpose, we first create a design space of possible visual representations and compare the possible solutions in this design space through a variety of representative tasks and performance metrics. Other researchers have, in the past, studied some aspects of effectiveness with word clouds, however, the existing literature is somewhat scattered and do not seem to address the problem in a sufficiently systematic and holistic manner. The results of our studies showed a strong dependency on the tasks users are performing. In this paper we present details of our methodology, the results, as well as, guidelines on how to design effective keyword summaries based in our discoveries.	Cristian Felix;Steven Franconeri;Enrico Bertini	Cristian Felix;Steven Franconeri;Enrico Bertini	New York University;Northwestern University;New York University	10.1109/VAST.2009.5333443;10.1109/TVCG.2016.2598447;10.1109/TVCG.2011.176;10.1109/TVCG.2010.194;10.1109/TVCG.2009.165;10.1109/TVCG.2009.171	Word Clouds,Tag Clouds,Text Visualization,Keyword Summaries	3	13	6	27	
VAST	2017	CRICTO: Supporting Sensemaking through Crowdsourced Information Schematization	10.1109/VAST.2017.8585484	http://dx.doi.org/10.1109/VAST.2017.8585484	139	150	C	We present CRICTO, a new crowdsourcing visual analytics environment for making sense of and analyzing text data, whereby multiple crowdworkers are able to parallelize the simple information schematization tasks of relating and connecting entities across documents. The diverse links from these schematization tasks are then automatically combined and the system visualizes them based on the semantic types of the linkages. CRICTO also includes several tools that allow analysts to interactively explore and refine crowdworkers' results to better support their own sensemaking processes. We evaluated CRICTO's techniques and analysis workflow with deployments of CRICTO using Amazon Mechanical Turk and a user study that assess the effect of crowdsourced schematization in sensemaking tasks. The results of our evaluation show that CRICTO's crowdsourcing approaches and workflow help analysts explore diverse aspects of datasets, and uncover more accurate hidden stories embedded in the text datasets.	Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews	Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews	University of Alabama in Huntsville;University of Alabama in Huntsville;University of Alabama in Huntsville;Middlebury College	10.1109/VAST.2007.4389006;10.1109/TVCG.2013.164;10.1109/TVCG.2007.70577;10.1109/VAST.2009.5333878;10.1109/VAST.2008.4677362;10.1109/TVCG.2014.2346573;10.1109/VAST.2006.261439;10.1109/VAST.2010.5652932;10.1109/VAST.2007.4389011	Visual text analytics,sensemaking,crowdsourcing		3	1	51	
VAST	2017	The y of it Matters, Even for Storyline Visualization	10.1109/VAST.2017.8585487	http://dx.doi.org/10.1109/VAST.2017.8585487	81	91	C	Storylines are adept at communicating complex change by encoding time on the x-axis and using the proximity of lines in the y direction to represent interaction between entities. The original definition of a storyline visualization requires data defined in terms of explicit interaction groups. Relaxing this definition allows storyline visualization to be applied more generally, but this creates questions about how the y-coordinate should encode interactions when this is tied to a particular place or state. To answer this question, we conducted a design study where we considered two layout algorithm design alternatives within a geo-temporal analysis tool written to solve part of the VAST Challenge 2014. We measured the performance of users at overview and detail oriented tasks between two storyline layout algorithms. To the best of our knowledge, this paper is the first work to question the design principles for storyline visualization, and what we found surprised us. For overview tasks with the alternative layout, which has a consistent encoding for the y-coordinate, users performed moderately better (p &lt;; .05) than the storyline layout based on existing design constraints and aesthetic criteria. Our empirical findings were also supported by first-hand accounts taken from interviews with multiple expert analysts, who suggested that the inconsistent meaning of the y-axis was misleading. These findings led us to design a new storyline layout algorithm that is a “best of both” where the y-axis has a consistent meaning but aesthetic criteria (e.g., line crossings) are considered.	Dustin Arendt;Meg Pirrung	Dustin Arendt;Meg Pirrung	Pacific Northwest National Laboratory;Pacific Northwest National Laboratory	10.1109/VAST.2009.5332593;10.1109/TVCG.2014.2346433;10.1109/TVCG.2013.196;10.1109/TVCG.2013.221;10.1109/TVCG.2012.212;10.1109/TVCG.2015.2468151	Storyline visualization,layout algorithms,interaction context,geospatial analysis,VAST Challenge		1	0	38	
VAST	2017	The Role of Explicit Knowledge: A Conceptual Model of Knowledge-Assisted Visual Analytics	10.1109/VAST.2017.8585498	http://dx.doi.org/10.1109/VAST.2017.8585498	92	103	C	Visual Analytics (VA) aims to combine the strengths of humans and computers for effective data analysis. In this endeavor, humans' tacit knowledge from prior experience is an important asset that can be leveraged by both human and computer to improve the analytic process. While VA environments are starting to include features to formalize, store, and utilize such knowledge, the mechanisms and degree in which these environments integrate explicit knowledge varies widely. Additionally, this important class of VA environments has never been elaborated on by existing work on VA theory. This paper proposes a conceptual model of Knowledge-assisted VA conceptually grounded on the visualization model by van Wijk. We apply the model to describe various examples of knowledge-assisted VA from the literature and elaborate on three of them in finer detail. Moreover, we illustrate the utilization of the model to compare different design alternatives and to evaluate existing approaches with respect to their use of knowledge. Finally, the model can inspire designers to generate novel VA environments using explicit knowledge effectively.	Paolo Federico 0001;Markus Wagner 0008;Alexander Rind;Albert Amor-Amoros;Silvia Miksch;Wolfgang Aigner	Paolo Federico;Markus Wagner;Alexander Rind;Albert Amor-Amorós;Silvia Miksch;Wolfgang Aigner	TU Wien, Austria;St. Poelten University of Applied Sciences, Austria and TU Wien, Austria;St. Poelten University of Applied Sciences, Austria and TU Wien, Austria;TU Wien, Austria;TU Wien, Austria;TU Wien, Austria	10.1109/TVCG.2013.146;10.1109/TVCG.2014.2346575;10.1109/INFVIS.1997.636792;10.1109/TVCG.2016.2598468;10.1109/INFVIS.2000.885092;10.1109/INFVIS.1998.729560;10.1109/TVCG.2016.2598460;10.1109/TVCG.2016.2598471;10.1109/VAST.2008.4677352;10.1109/TVCG.2008.109;10.1109/VAST.2012.6400555;10.1109/VAST.2010.5654451;10.1109/TVCG.2014.2346481;10.1109/TVCG.2016.2598839;10.1109/VAST.2007.4389021;10.1109/TVCG.2014.2346574;10.1109/TVCG.2016.2598829;10.1109/VISUAL.2005.1532781	Automated analysis,tacit knowledge,explicit knowledge,visual analytics,information visualization,theory and model		7	3	81	
VAST	2017	Interactive Visual Alignment of Medieval Text Versions	10.1109/VAST.2017.8585505	http://dx.doi.org/10.1109/VAST.2017.8585505	127	138	C	Textual criticism consists of the identification and analysis of variant readings among different versions of a text. Being a relatively simple task for modern languages, the collation of medieval text traditions ranges from the complex to the virtually impossible depending on the degree of instability of textual transmission. We present a visual analytics environment that supports computationally aligning such complex textual differences typical of orally inflected medieval poetry. For the purpose of analyzing alignment, we provide interactive visualizations for different text hierarchy levels, specifically, a meso reading view to support investigating repetition and variance at the line level across text segments. In addition to outlining important aspects of our interdisciplinary collaboration, we emphasize the utility of the proposed system by various usage scenarios in medieval French literature.	Stefan Jänicke;David Joseph Wrisley	Stefan Jänicke;David Joseph Wrisley	Image and Signal Processing Group, Institute for Computer Science, Leipzig University, Germany;Digital Humanities, New York University Abu Dhabi, United Arab Emirates	10.1109/VAST.2014.7042493;10.1109/TVCG.2014.2346431;10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389004;10.1109/VAST.2009.5333564;10.1109/VAST.2009.5333248			2	4	63	
VAST	2017	Visualizing Real-Time Strategy Games: The Example of StarCraft II	10.1109/VAST.2017.8585594	http://dx.doi.org/10.1109/VAST.2017.8585594	71	80	C	We present a visualization system for users to examine real-time strategy games, which have become very popular globally in recent years. Unlike previous systems that focus on showing statistics and build order, our system can depict the most important part - battles in the games. Specifically, we visualize detailed movements of armies belonging to respective nations on a map and enable users to examine battles from a global view to a local view. In the global view, battles are depicted by curved arrows revealing how the armies enter and escape from the battlefield. By observing the arrows and the height map, users can make sense of offensive and defensive strategies easily. In the local view, units of each type are rendered on the map, and their movements are represented by animation. We also render an attack line between a pair of units if one of them can attack the other to help users analyze the advantages and disadvantages of a particular formation. Accordingly, users can utilize our system to discover statistics, build order, and battles, and learn strategies from games played by professionals.	Yen-Ting Kuan;Yu-Shuen Wang;Jung-Hong Chuang	Yen-Ting Kuan;Yu-Shuen Wang;Jung-Hong Chuang	National Chiao Tung University;National Chiao Tung University;National Chiao Tung University	10.1109/INFVIS.2000.885098	real-time strategy games,StarCraft,game visualization,trajectories		2	1	23	
VAST	2017	Pattern Trails: Visual Analysis of Pattern Transitions in Subspaces	10.1109/VAST.2017.8585613	http://dx.doi.org/10.1109/VAST.2017.8585613	1	12	C	Subspace analysis methods have gained interest for identifying patterns in subspaces of high-dimensional data. Existing techniques allow to visualize and compare patterns in subspaces. However, many subspace analysis methods produce an abundant amount of patterns, which often remain redundant and are difficult to relate. Creating effective layouts for comparison of subspace patterns remains challenging. We introduce Pattern Trails, a novel approach for visually ordering and comparing subspace patterns. Central to our approach is the notion of pattern transitions as an interpretable structure imposed to order and compare patterns between subspaces. The basic idea is to visualize projections of subspaces side-by-side, and indicate changes between adjacent patterns in the subspaces by a linked representation, hence introducing pattern transitions. Our contributions comprise a systematization for how pairs of subspace patterns can be compared, and how changes can be interpreted in terms of pattern transitions. We also contribute a technique for visual subspace analysis based on a data-driven similarity measure between subspace representations. This measure is useful to order the patterns, and interactively group subspaces to reduce redundancy. We demonstrate the usefulness of our approach by application to several use cases, indicating that data can be meaningfully ordered and interpreted in terms of pattern transitions.	Dominik Jäckle;Michael Blumenschein;Michael Behrisch 0001;Daniel A. Keim;Tobias Schreck	Dominik Jäckle;Michael Hund;Michael Behrisch;Daniel A. Keim;Tobias Schreck	University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;TU Graz	10.1109/VAST.2012.6400490;10.1109/TVCG.2011.188;10.1109/TVCG.2015.2467552;10.1109/TVCG.2010.184;10.1109/INFVIS.2005.1532141;10.1109/TVCG.2013.173;10.1109/VAST.2010.5652392;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1995.485140;10.1109/TVCG.2014.2346482;10.1109/TVCG.2015.2467132;10.1109/TVCG.2014.2346481;10.1109/TVCG.2016.2598495;10.1109/TVCG.2013.153;10.1109/TVCG.2015.2467717;10.1109/VAST.2012.6400488;10.1109/TVCG.2011.178;10.1109/VISUAL.1995.485139;10.1109/TVCG.2009.179;10.1109/TVCG.2013.150		0	2	0	58	
VAST	2017	E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media	10.1109/VAST.2017.8585638	http://dx.doi.org/10.1109/VAST.2017.8585638	36	47	C	Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.	Siming Chen;Shuai Chen 0001;Lijing Lin;Xiaoru Yuan;Jie Liang 0004;Xiaolong Zhang 0001	Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang;Xiaolong Zhang	Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia;College of Information Sciences and Technology, Pennsylvania State University, USA	10.1109/VAST.2008.4677356;10.1109/TVCG.2013.186;10.1109/TVCG.2011.185;10.1109/TVCG.2012.291;10.1109/VAST.2012.6400557;10.1109/VAST.2016.7883510;10.1109/TVCG.2015.2467619;10.1109/TVCG.2014.2346433;10.1109/TVCG.2010.129;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70582;10.1109/TVCG.2016.2598590;10.1109/TVCG.2015.2467554;10.1109/VAST.2015.7347632;10.1109/TVCG.2013.196;10.1109/VAST.2011.6102456;10.1109/TVCG.2016.2598919;10.1109/TVCG.2009.171;10.1109/VAST.2016.7883511;10.1109/TVCG.2015.2467691;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346922;10.1109/VAST.2014.7042496	Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics		4	6	63	
VAST	2017	A Visual Analytics System for Optimizing Communications in Massively Parallel Applications	10.1109/VAST.2017.8585646	http://dx.doi.org/10.1109/VAST.2017.8585646	59	70	C	Current and future supercomputers have tens of thousands of compute nodes interconnected with high-dimensional networks and complex network topologies for improved performance. Application developers are required to write scalable parallel programs in order to achieve high throughput on these machines. Application performance is largely determined by efficient inter-process communication. A common way to analyze and optimize performance is through profiling parallel codes to identify communication bottlenecks. However, understanding gigabytes of profiled at a is not a trivial task. In this paper, we present a visual analytics system for identifying the scalability bottlenecks and improving the communication efficiency of massively parallel applications. Visualization methods used in this system are designed to comprehend large-scale and varied communication patterns on thousands of nodes in complex networks such as the 5D torus and the dragonfly. We also present efficient rerouting and remapping algorithms that can be coupled with our interactive visual analytics design for performance optimization. We demonstrate the utility of our system with several case studies using three benchmark applications on two leading supercomputers. The mapping suggestion from our system led to 38% improvement in hop-bytes for Mini AMR application on 4,096 MPI processes.	Takanori Fujiwara;Preeti Malakar;Khairi Reda;Venkatram Vishwanath;Michael E. Papka;Kwan-Liu Ma	Takanori Fujiwara;Preeti Malakar;Khairi Reda;Venkatram Vishwanath;Michael E. Papka;Kwan-Liu Ma	University of California, Davis;Argonne National Laboratory;Indiana University-Purdue University Indianapolis;Argonne National Laboratory;Argonne National Laboratory, Northern Illinois University;University of California, Davis	10.1109/INFVIS.2004.1;10.1109/TVCG.2012.286;10.1109/TVCG.2014.2346441	Supercomputing,parallel communications,performance analysis,visual analytics,communication visualization		4	0	83	
VAST	2017	Visual Causality Analysis Made Practical	10.1109/VAST.2017.8585647	http://dx.doi.org/10.1109/VAST.2017.8585647	151	161	C	Deriving the exact casual model that governs the relations between variables in a multidimensional dataset is difficult in practice. It is because causal inference algorithms by themselves typically cannot encode an adequate amount of domain knowledge to break all ties. Visual analytic approaches are considered a feasible alternative to fully automated methods. However, their application in real-world scenarios can be tedious. This paper focuses on these practical aspects of visual causality analysis. The most imperative of these aspects is posed by Simpson' Paradox. It implies the existence of multiple causal models differing in both structure and parameter depending on how the data is subdivided. We propose a comprehensive interface that engages human experts in identifying these subdivisions and allowing them to establish the corresponding causal models via a rich set of interactive facilities. Other features of our interface include: (1) a new causal network visualization that emphasizes the flow of causal dependencies, (2) a model scoring mechanism with visual hints for interactive model refinement, and (3) flexible approaches for handling heterogeneous data. Various real-world data examples are given.	Jun Wang;Klaus Mueller	Jun Wang;Klaus Mueller	Visual Analytics and Imaging Lab, Stony Brook University;Visual Analytics and Imaging Lab, Stony Brook University	10.1109/TVCG.2015.2467931;10.1109/TVCG.2012.225;10.1109/TVCG.2013.200;10.1109/TVCG.2016.2598797;10.1109/TVCG.2016.2598919;10.1109/TVCG.2016.2598543;10.1109/TVCG.2015.2467691	Visual knowledge discovery,Causality,Hypothesis testing,Visual evidence,High-dimensional data		1	1	49	
VAST	2017	CrystalBall: A Visual Analytic System for Future Event Discovery and Analysis from Social Media Data	10.1109/VAST.2017.8585658	http://dx.doi.org/10.1109/VAST.2017.8585658	25	35	C	Social media data bear valuable insights regarding events that occur around the world. Events are inherently temporal and spatial. Existing visual text analysis systems have focused on detecting and analyzing past and ongoing events. Few have leveraged social media information to look for events that may occur in the future. In this paper, we present an interactive visual analytic system, CrystalBall, that automatically identifies and ranks future events from Twitter streams. CrystalBall integrates new methods to discover events with interactive visualizations that permit sensemaking of the identified future events. Our computational methods integrate seven different measures to identify and characterize future events, leveraging information regarding time, location, social networks, and the informativeness of the messages. A visual interface is tightly coupled with the computational methods to present a concise summary of the possible future events. A novel connection graph and glyphs are designed to visualize the characteristics of the future events. To demonstrate the efficacy of CrystalBall in identifying future events and supporting interactive analysis, we present multiple case studies and validation studies on analyzing events derived from Twitter data.	Isaac Cho;Ryan Wesslen;Svitlana Volkova;William Ribarsky;Wenwen Dou	Isaac Cho;Ryan Wesslen;Svitlana Volkova;William Ribarsky;Wenwen Dou	University of North Carolina at Charlotte;University of North Carolina at Charlotte;Pacific Northwest National Laboratory;University of North Carolina at Charlotte;University of North Carolina at Charlotte	10.1109/VAST.2012.6400485	Social media analysis,Event detection and analysis,visual analytics		6	1	35	
VAST	2017	The Anchoring Effect in Decision-Making with Visual Analytics	10.1109/VAST.2017.8585665	http://dx.doi.org/10.1109/VAST.2017.8585665	116	126	C	Anchoring effect is the tendency to focus too heavily on one piece of information when making decisions. In this paper, we present a novel, systematic study and resulting analyses that investigate the effects of anchoring effect on human decision-making using visual analytic systems. Visual analytics interfaces typically contain multiple views that present various aspects of information such as spatial, temporal, and categorical. These views are designed to present complex, heterogeneous data in accessible forms that aid decision-making. However, human decision-making is often hindered by the use of heuristics, or cognitive biases, such as anchoring effect. Anchoring effect can be triggered by the order in which information is presented or the magnitude of information presented. Through carefully designed laboratory experiments, we present evidence of anchoring effect in analysis with visual analytics interfaces when users are primed by representation of different pieces of information. We also describe detailed analyses of users' interaction logs which reveal the impact of anchoring bias on the visual representation preferred and paths of analysis. We discuss implications for future research to possibly detect and alleviate anchoring bias.	Isaac Cho;Ryan Wesslen;Alireza Karduni;Sashank Santhanam;Samira Shaikh;Wenwen Dou	Isaac Cho;Ryan Wesslen;Alireza Karduni;Sashank Santhanam;Samira Shaikh;Wenwen Dou	University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte	10.1109/TVCG.2015.2467971;10.1109/VAST.2017.8585658;10.1109/TVCG.2016.2598594;10.1109/VAST.2011.6102491;10.1109/TVCG.2009.152;10.1109/TVCG.2015.2467591	Visual Analytics,Anchoring Effect,Sense Making,Cognitive Bias,Interaction Log Analysis		10	4	46	
VAST	2017	Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics	10.1109/VAST.2017.8585669	http://dx.doi.org/10.1109/VAST.2017.8585669	104	115	C	Visual analytic tools combine the complementary strengths of humans and machines in human-in-the-loop systems. Humans provide invaluable domain expertise and sensemaking capabilities to this discourse with analytic models; however, little consideration has yet been given to the ways inherent human biases might shape the visual analytic process. In this paper, we establish a conceptual framework for considering bias assessment through human-in-the-loop systems and lay the theoretical foundations for bias measurement. We propose six preliminary metrics to systematically detect and quantify bias from user interactions and demonstrate how the metrics might be implemented in an existing visual analytic system, InterAxis. We discuss how our proposed metrics could be used by visual analytic systems to mitigate the negative effects of cognitive biases by making users aware of biased processes throughout their analyses.	Emily Wall;Leslie M. Blaha;Lyndsey Franklin;Alex Endert	Emily Wall;Leslie M. Blaha;Lyndsey Franklin;Alex Endert	Georgia Tech;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Georgia Tech	10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346575;10.1109/VAST.2015.7347625;10.1109/TVCG.2016.2598594;10.1109/VAST.2011.6102449;10.1109/TVCG.2016.2599058;10.1109/VAST.2008.4677365;10.1109/VAST.2008.4677361;10.1109/VISUAL.2000.885678;10.1109/TVCG.2015.2467615;10.1109/TVCG.2016.2598446;10.1109/TVCG.2012.273;10.1109/TVCG.2015.2467551;10.1109/TVCG.2015.2467591;10.1109/TVCG.2014.2346481;10.1109/TVCG.2016.2598466;10.1109/TVCG.2017.2745078;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70515	cognitive bias,visual analytics,human-in-the-loop,mixed initiative,user interaction,H.5.0 [Information Systems]: Human-Computer Interaction-General		23	8	80	
VAST	2017	A Workflow for Visual Diagnostics of Binary Classifiers using Instance-Level Explanations	10.1109/VAST.2017.8585720	http://dx.doi.org/10.1109/VAST.2017.8585720	162	172	C	Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages “instance-level explanations”, measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved.	Josua Krause;Aritra Dasgupta;Jordan Swartz;Yindalon Aphinyanagphongs;Enrico Bertini	Josua Krause;Aritra Dasgupta;Jordan Swartz;Yindalon Aphinyanaphongs;Enrico Bertini	NYU Tandon School of Engineering;Pacific Northwest National Laboratory;NYU School of Medicine;NYU School of Medicine;NYU Tandon School of Engineering	10.1109/TVCG.2014.2346660;10.1109/TVCG.2016.2598544;10.1109/TVCG.2014.2346482;10.1109/TVCG.2016.2598828;10.1109/TVCG.2016.2598829	Machine Learning,Interpretation,Visual Analytics	3	14	4	33	
VAST	2017	Understanding Hidden Memories of Recurrent Neural Networks	10.1109/VAST.2017.8585721	http://dx.doi.org/10.1109/VAST.2017.8585721	13	24	C	Recurrent neural networks (RNNs) have been successfully applied to various natural language processing (NLP) tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs' hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN's hidden state at the sentence-level. The usability and effectiveness of our method are demonstrated through case studies and reviews from domain experts.	Yao Ming;Shaozu Cao;Ruixiang Zhang;Zhen Li;Yuanzhe Chen;Yangqiu Song;Huamin Qu	Yao Ming;Shaozu Cao;Ruixiang Zhang;Zhen Li;Yuanzhe Chen;Yangqiu Song;Huamin Qu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology	10.1109/VAST.2015.7347637;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.252;10.1109/TVCG.2016.2598831;10.1109/TVCG.2011.212;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/TVCG.2016.2598465;10.1109/TVCG.2014.2346665	recurrent neural networks,visual analytics,understanding neural model,co-clustering	9	20	17	52	
VAST	2017	QSAnglyzer: Visual Analytics for Prismatic Analysis of Question Answering System Evaluations	10.1109/VAST.2017.8585733	http://dx.doi.org/10.1109/VAST.2017.8585733	48	58	C	Developing sophisticated artificial intelligence (AI) systems requires AI researchers to experiment with different designs and analyze results from evaluations (we refer this task as evaluation analysis). In this paper, we tackle the challenges of evaluation analysis in the domain of question-answering (QA) systems. Through in-depth studies with QA researchers, we identify tasks and goals of evaluation analysis and derive a set of design rationales, based on which we propose a novel approach termed prismatic analysis. Prismatic analysis examines data through multiple ways of categorization (referred as angles). Categories in each angle are measured by aggregate metrics to enable diverse comparison scenarios. To facilitate prismatic analysis of QA evaluations, we design and implement the Question Space Anglyzer (QSAnglyzer), a visual analytics (VA) tool. In QSAnglyzer, the high-dimensional space formed by questions is divided into categories based on several angles (e.g., topic and question type). Each category is aggregated by accuracy, the number of questions, and accuracy variance across evaluations. QSAnglyzer visualizes these angles so that QA researchers can examine and compare evaluations from various aspects both individually and collectively. Furthermore, QA researchers filter questions based on any angle by clicking to construct complex queries. We validate QSAnglyzer through controlled experiments and by expert reviews. The results indicate that when using QSAnglyzer, users perform analysis tasks faster (p &lt;; 0.01) and more accurately (p &lt;; 0.05), and are quick to gain new insight. We discuss how prismatic analysis and QSAnglyzer scaffold evaluation analysis, and provide directions for future research.	Nan-Chen Chen;Been Kim	Nan-Chen Chen;Been Kim	University of Washington;Allen Institute for Artificial Intelligence	10.1109/VAST.2015.7347637;10.1109/INFVIS.2000.885091;10.1109/VAST.2012.6400488	visual analytics,visualization,interactive visualization,question answering,multi-experiment analysis,visual comparison,visual exploration,prismatic analysis,H.5.2 [Information Interfaces and Presentation]: User Interfaces—		0	0	34	
SciVis	2018	Persistence Atlas for Critical Point Variability in Ensembles	10.1109/TVCG.2018.2864432	http://dx.doi.org/10.1109/TVCG.2018.2864432	1152	1162	J	This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes.	Guillaume Favelier;Noura Faraj;Brian Summa;Julien Tierny	Guillaume Favelier;Noura Faraj;Brian Summa;Julien Tierny	Sorbonne UniversitéCNRS (LIP6);Tulane University;Tulane University;Sorbonne UniversitéCNRS (LIP6)	10.1109/TVCG.2013.208;10.1109/TVCG.2015.2467958;10.1109/TVCG.2015.2467204;10.1109/TVCG.2014.2346403;10.1109/TVCG.2008.110;10.1109/TVCG.2015.2467432;10.1109/TVCG.2013.141;10.1109/TVCG.2011.249;10.1109/TVCG.2006.186;10.1109/TVCG.2014.2346455;10.1109/TVCG.2015.2467754;10.1109/TVCG.2010.181;10.1109/VISUAL.1999.809897;10.1109/TVCG.2012.249;10.1109/TVCG.2014.2346332;10.1109/TVCG.2013.143	Topological data analysis,scalar data,ensemble data	0	0	2	87	
VAST	2018	iForest: Interpreting Random Forests via Visual Analytics	10.1109/TVCG.2018.2864475	http://dx.doi.org/10.1109/TVCG.2018.2864475	407	416	J	As an ensemble model that consists of many independent decision trees, random forests generate predictions by feeding the input to internal trees and summarizing their outputs. The ensemble nature of the model helps random forests outperform any individual decision tree. However, it also leads to a poor model interpretability, which significantly hinders the model from being used in fields that require transparent and explainable predictions, such as medical diagnosis and financial fraud detection. The interpretation challenges stem from the variety and complexity of the contained decision trees. Each decision tree has its unique structure and properties, such as the features used in the tree and the feature threshold in each tree node. Thus, a data input may lead to a variety of decision paths. To understand how a final prediction is achieved, it is desired to understand and compare all decision paths in the context of all tree structures, which is a huge challenge for any users. In this paper, we propose a visual analytic system aiming at interpreting random forest models and predictions. In addition to providing users with all the tree information, we summarize the decision paths in random forests, which eventually reflects the working mechanism of the model and reduces users' mental burden of interpretation. To demonstrate the effectiveness of our system, two usage scenarios and a qualitative user study are conducted.	Xun Zhao;Yanhong Wu;Dik Lun Lee;Weiwei Cui	Xun Zhao;Yanhong Wu;Dik Lun Lee;Weiwei Cui	Hong Kong University of Science and Technology;Visa Research;Hong Kong University of Science and Technology;Microsoft Research Asia	10.1109/TVCG.2017.2744378;10.1109/TVCG.2017.2745158;10.1109/VAST.2011.6102453	Interpretable Machine Learning,Random Forests,Random Forest Visualization,Visual Analytics		5	3	60	
VAST	2018	Clustrophile 2: Guided Visual Clustering Analysis	10.1109/TVCG.2018.2864477	http://dx.doi.org/10.1109/TVCG.2018.2864477	267	276	J	Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson's disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.	Marco Cavallo;Çagatay Demiralp	Marco Cavallo;Çağatay Demiralp	IBM Research;MIT CSAIL & Fitnescity Labs	10.1109/TVCG.2011.188;10.1109/TVCG.2013.119;10.1109/TVCG.2012.219;10.1109/TVCG.2017.2745085;10.1109/TVCG.2010.138;10.1109/VAST.2007.4388999;10.1109/TVCG.2012.207;10.1109/TVCG.2017.2744805;10.1109/VAST.2008.4677350;10.1109/INFVIS.2004.3;10.1109/TVCG.2015.2467191	Clustering tour,Guided data analysis,Unsupervised learning,Exploratory data analysis,Interactive clustering analysis,Interpretability,Explainability,Visual data exploration recommendation,Dimensionality reduction,What-if analysis,Clustrophile	0	11	3	46	
SciVis	2018	Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments	10.1109/TVCG.2018.2864491	http://dx.doi.org/10.1109/TVCG.2018.2864491	977	986	J	Labeling is intrinsically important for exploring and understanding complex environments and models in a variety of domains. We present a method for interactive labeling of crowded 3D scenes containing very many instances of objects spanning multiple scales in size. In contrast to previous labeling methods, we target cases where many instances of dozens of types are present and where the hierarchical structure of the objects in the scene presents an opportunity to choose the most suitable level for each placed label. Our solution builds on and goes beyond labeling techniques in medical 3D visualization, cartography, and biological illustrations from books and prints. In contrast to these techniques, the main characteristics of our new technique are: 1) a novel way of labeling objects as part of a bigger structure when appropriate, 2) visual clutter reduction by labeling only representative instances for each type of an object, and a strategy of selecting those. The appropriate level of label is chosen by analyzing the scene's depth buffer and the scene objects' hierarchy tree. We address the topic of communicating the parent-children relationship between labels by employing visual hierarchy concepts adapted from graphic design. Selecting representative instances considers several criteria tailored to the character of the data and is combined with a greedy optimization approach. We demonstrate the usage of our method with models from mesoscale biology where these two characteristics-multi-scale and multi-instance-are abundant, along with the fact that these scenes are extraordinarily dense.	David Kouril;Ladislav Cmolík;Barbora Kozlíková;Hsiang-Yun Wu;Graham Johnson;David S. Goodsell;Arthur J. Olson;M. Eduard Gröller;Ivan Viola	David Kouřil;Ladislav Čmolík;Barbora Kozlíková;Hslanc-Yun Wu;Graham Johnson;David S. Goodsell;Arthur Olson;M. Eduard Gröller;Ivan Viola	TU Wien;Faculty of Electrical Engineering, Czech Technical University, Prague;Masaryk University;TU Wien;Allen Institute for Cell Science;The Scripps Research Institute;The Scripps Research Institute;TU Wien;TU Wien	10.1109/TVCG.2006.136;10.1109/TVCG.2008.168;10.1109/TVCG.2017.2744518	labeling,multi-scale data,multi-instance data		5	0	54	HM
SciVis	2018	Deadeye: A Novel Preattentive Visualization Technique Based on Dichoptic Presentation	10.1109/TVCG.2018.2864498	http://dx.doi.org/10.1109/TVCG.2018.2864498	936	945	J	Preattentive visual features such as hue or flickering can effectively draw attention to an object of interest - for instance, an important feature in a scientific visualization. These features appear to pop out and can be recognized by our visual system, independently from the number of distractors. Most cues do not take advantage of the fact that most humans have two eyes. In cases where binocular vision is applied, it is almost exclusively used to convey depth by exposing stereo pairs. We present Deadeye, a novel preattentive visualization technique based on presenting different stimuli to each eye. The target object is rendered for one eye only and is instantly detected by our visual system. In contrast to existing cues, Deadeye does not modify any visual properties of the target and, thus, is particularly suited for visualization applications. Our evaluation confirms that Deadeye is indeed perceived preattentively. We also explore a conjunction search based on our technique and show that, in contrast to 3D depth, the task cannot be processed in parallel.	Andrey Krekhov;Jens H. Krüger	Andrey Krekhov;Jens Krüger	Center of Visual Data Analysis and Computer Graphics (COVIDAG)University of Duisburg-Essen;Center of Visual Data Analysis and Computer Graphics (COVIDAG)University of Duisburg-Essen	10.1109/TVCG.2011.234;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2014.2346352	Popout,preattentive vision,comparative visualization,dichoptic presentation	0	2	1	62	BP
VAST	2018	Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models	10.1109/TVCG.2018.2864499	http://dx.doi.org/10.1109/TVCG.2018.2864499	364	373	J	Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models' outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.	Jiawei Zhang;Yang Wang;Piero Molino;Lezhi Li;David S. Ebert	Jiawei Zhang;Yang Wang;Piero Molino;Lezhi Li;David S. Ebert	Purdue University;Uber Technologies, Inc;Uber AI Labs;Uber Technologies, Inc;Purdue University	10.1109/TVCG.2014.2346660;10.1109/VAST.2015.7347637;10.1109/TVCG.2014.2346594;10.1109/TVCG.2013.212;10.1109/TVCG.2017.2744718;10.1109/TVCG.2017.2744938;10.1109/TVCG.2017.2744378;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346578;10.1109/TVCG.2009.111;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/INFVIS.2000.885086;10.1109/TVCG.2017.2744158;10.1109/TVCG.2016.2598829;10.1109/TVCG.2017.2744878	Interactive machine learning,performance analysis,model comparison,model debugging	0	14	9	43	
VAST	2018	GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation	10.1109/TVCG.2018.2864500	http://dx.doi.org/10.1109/TVCG.2018.2864500	310	320	J	Recent success in deep learning has generated immense interest among practitioners and students, inspiring many to learn about this new technology. While visual and interactive approaches have been successfully developed to help people more easily learn deep learning, most existing tools focus on simpler models. In this work, we present GAN Lab, the first interactive visualization tool designed for non-experts to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, users can interactively train generative models and visualize the dynamic training process's intermediate results. GAN Lab tightly integrates an model overview graph that summarizes GAN's structure, and a layered distributions view that helps users interpret the interplay between submodels. GAN Lab introduces new interactive experimentation features for learning complex deep learning models, such as step-by-step training at multiple levels of abstraction for understanding intricate training dynamics. Implemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web browsers, without the need for installation or specialized hardware, overcoming a major practical challenge in deploying interactive tools for deep learning.	Minsuk Kahng;Nikhil Thorat;Duen Horng Chau;Fernanda B. Viégas;Martin Wattenberg	Minsuk Kahng;Nikhil Thorat;Duen Horng (Polo) Chau;Fernanda B. Viégas;Martin Wattenberg	Georgia Institute of Technology;Google Brain;Georgia Institute of Technology;Google Brain;Google Brain	10.1109/TVCG.2008.119;10.1109/TVCG.2017.2744683;10.1109/TVCG.2017.2744718;10.1109/TVCG.2017.2744938;10.1109/TVCG.2016.2598831;10.1109/TVCG.2010.177;10.1109/VAST.2017.8585721;10.1109/TVCG.2017.2744358;10.1109/TVCG.2017.2744158;10.1109/TVCG.2017.2744878	Deep learning,information visualization,visual analytics,generative adversarial networks,machine learning,interactive experimentation,explorable explanations	1	16	6	44	
VAST	2018	Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data	10.1109/TVCG.2018.2864503	http://dx.doi.org/10.1109/TVCG.2018.2864503	43	53	J	A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows.	Zhiguang Zhou;Linhao Meng;Cheng Tang;Ying Zhao 0001;Zhiyong Guo;Miaoxin Hu;Wei Chen 0001	Zhiguang Zhou;Linhao Meng;Cheng Tang;Ying Zhao;Zhiyong Guo;Miaoxin Hu;Wei Chen	School of InformationZhejiang University of Finance and Economics;State Key Lab of CAD & CGZhejiang University;Information SchoolZhejiang Sci-tech University;Central South University;School of InformationZhejiang University of Finance and Economics;School of InformationZhejiang University of Finance and Economics;State Key Lab of CAD & CGZhejiang University	10.1109/TVCG.2017.2744322;10.1109/TVCG.2016.2598667;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346594;10.1109/TVCG.2008.135;10.1109/TVCG.2011.233;10.1109/TVCG.2013.226;10.1109/TVCG.2009.143;10.1109/TVCG.2014.2346271;10.1109/TVCG.2016.2598432;10.1109/TVCG.2013.196;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2015.2467691;10.1109/TVCG.2014.2346746;10.1109/TVCG.2016.2598885	Visual abstraction,human mobility,origin-destination,flow map,representation learning	0	12	12	51	
VAST	2018	DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks	10.1109/TVCG.2018.2864504	http://dx.doi.org/10.1109/TVCG.2018.2864504	288	298	J	Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent's experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.	Junpeng Wang;Liang Gou;Han-Wei Shen;Hao Yang	Junpeng Wang;Liang Gou;Han-Wei Shen;Hao Yang	The Ohio State University;Visa Research;The Ohio State University;Visa Research	10.1109/TVCG.2017.2744683;10.1109/TVCG.2014.2346682;10.1109/TVCG.2017.2745320;10.1109/TVCG.2017.2744718;10.1109/TVCG.2011.179;10.1109/TVCG.2017.2744938;10.1109/TVCG.2016.2598831;10.1109/VAST.2017.8585721;10.1109/TVCG.2013.200;10.1109/TVCG.2017.2744358;10.1109/TVCG.2017.2744158	Deep Q-Network (DQN),reinforcement learning,model interpretation,visual analytics	0	11	8	55	HM
SciVis	2018	Probabilistic Asymptotic Decider for Topological Ambiguity Resolution in Level-Set Extraction for Uncertain 2D Data	10.1109/TVCG.2018.2864505	http://dx.doi.org/10.1109/TVCG.2018.2864505	1163	1172	J	We present a framework for the analysis of uncertainty in isocontour extraction. The marching squares (MS) algorithm for isocontour reconstruction generates a linear topology that is consistent with hyperbolic curves of a piecewise bilinear interpolation. The saddle points of the bilinear interpolant cause topological ambiguity in isocontour extraction. The midpoint decider and the asymptotic decider are well-known mathematical techniques for resolving topological ambiguities. The latter technique investigates the data values at the cell saddle points for ambiguity resolution. The uncertainty in data, however, leads to uncertainty in underlying bilinear interpolation functions for the MS algorithm, and hence, their saddle points. In our work, we study the behavior of the asymptotic decider when data at grid vertices is uncertain. First, we derive closed-form distributions characterizing variations in the saddle point values for uncertain bilinear interpolants. The derivation assumes uniform and nonparametric noise models, and it exploits the concept of ratio distribution for analytic formulations. Next, the probabilistic asymptotic decider is devised for ambiguity resolution in uncertain data using distributions of the saddle point values derived in the first step. Finally, the confidence in probabilistic topological decisions is visualized using a colormapping technique. We demonstrate the higher accuracy and stability of the probabilistic asymptotic decider in uncertain data with regard to existing decision frameworks, such as deciders in the mean field and the probabilistic midpoint decider, through the isocontour visualization of synthetic and real datasets.	Tushar M. Athawale;Christopher R. Johnson 0001	Tushar Athawale;Chris R. Johnson	Scientific Computing & Imaging (SCI) InstituteUniversity of Utah;Scientific Computing & Imaging (SCI) InstituteUniversity of Utah	10.1109/TVCG.2013.208;10.1109/TVCG.2015.2467958;10.1109/VISUAL.2002.1183769;10.1109/TVCG.2017.2744099;10.1109/TVCG.2011.203;10.1109/TVCG.2007.70518;10.1109/VISUAL.1991.175782;10.1109/TVCG.2013.143	Isocontour visualization,topological uncertainty,marching squares,asymptotic decider,bilinear interpolation,probabilistic computation		2	1	40	
SciVis	2018	Visualization of Bubble Formation in Porous Media	10.1109/TVCG.2018.2864506	http://dx.doi.org/10.1109/TVCG.2018.2864506	1060	1069	J	We present a visualization approach for the analysis of CO<sub>2</sub>bubble-induced attenuation in porous rock formations. As a basis for this, we introduce customized techniques to extract CO<sub>2</sub>bubbles and their surrounding porous structure from X-ray computed tomography data (XCT) measurements. To understand how the structure of porous media influences the occurrence and the shape of formed bubbles, we automatically classify and relate them in terms of morphology and geometric features, and further directly support searching for promising porous structures. To allow for the meaningful direct visual comparison of bubbles and their structures, we propose a customized registration technique considering the bubble shape as well as its points of contact with the porous media surface. With our quantitative extraction of geometric bubble features, we further support the analysis as well as the creation of a physical model. We demonstrate that our approach was successfully used to answer several research questions in the domain, and discuss its high practical relevance to identify critical seismic characteristics of fluid-saturated rock that govern its capability to store CO<sub>2</sub>.	Hui Zhang 0027;Steffen Frey;Holger Steeb;David Uribe;Thomas Ertl;Wenping Wang	Hui Zhang;Steffen Frey;Holger Steeb;David Uribe;Thomas Ertl;Wenping Wang	Department of Computer ScienceThe University of Hong Kong;Visualization Research CenterUniversity of Stuttgart;Institute of Applied MechanicsUniversity of Stuttgart;Institute of Applied MechanicsUniversity of Stuttgart;Visualization Research CenterUniversity of Stuttgart;Department of Computer ScienceThe University of Hong Kong	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.124;10.1109/TVCG.2014.2346351;10.1109/TVCG.2013.177;10.1109/TVCG.2012.200;10.1109/VISUAL.2004.48	3D volume rendering,bubble visualization,porous media	0	0	0	43	
SciVis	2018	Interactive Visualization of RNA and DNA Structures	10.1109/TVCG.2018.2864507	http://dx.doi.org/10.1109/TVCG.2018.2864507	967	976	J	The analysis and visualization of nucleic acids (RNA and DNA) is playing an increasingly important role due to their fundamental importance for all forms of life and the growing number of known 3D structures of such molecules. The great complexity of these structures, in particular, those of RNA, demands interactive visualization to get deeper insights into the relationship between the 2D secondary structure motifs and their 3D tertiary structures. Over the last decades, a lot of research in molecular visualization has focused on the visual exploration of protein structures while nucleic acids have only been marginally addressed. In contrast to proteins, which are composed of amino acids, the ingredients of nucleic acids are nucleotides. They form structuring patterns that differ from those of proteins and, hence, also require different visualization and exploration techniques. In order to support interactive exploration of nucleic acids, the computation of secondary structure motifs as well as their visualization in 2D and 3D must be fast. Therefore, in this paper, we focus on the performance of both the computation and visualization of nucleic acid structure. We present a ray casting-based visualization of RNA and DNA secondary and tertiary structures, which enables for the first time real-time visualization of even large molecular dynamics trajectories. Furthermore, we provide a detailed description of all important aspects to visualize nucleic acid secondary and tertiary structures. With this, we close an important gap in molecular visualization.	Norbert Lindow;Daniel Baum;Morgan Leborgne;Hans-Christian Hege	Norbert Lindow;Daniel Baum;Morgan Leborgne;Hans-Christian Hege	Zuse Institute, Berlin;Zuse Institute, Berlin;Zuse Institute, Berlin;Zuse Institute, Berlin		Ribonucleic acids,DNA,RNA,secondary & tertiary structures,interactive rendering,ray casting,brushing & linking	0	5	1	48	
SciVis	2018	Gaia Sky: Navigating the Gaia Catalog	10.1109/TVCG.2018.2864508	http://dx.doi.org/10.1109/TVCG.2018.2864508	1070	1079	J	In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA's Gaia mission. Gaia's data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.	Antoni Sagristà;Stefan Jordan;Thomas Müller 0005;Filip Sadlo	Antoni Sagristà;Stefan Jordan;Thomas Müller;Filip Sadlo	Heidelberg University;Heidelberg University;Max Planck Institute for Astronomy;Heidelberg University	10.1109/TVCG.2006.176	Astronomy visualization,3D Universe software,star catalog rendering,Gaia mission	0	2	3	31	
SciVis	2018	Visual Analysis of Aneurysm Data using Statistical Graphics	10.1109/TVCG.2018.2864509	http://dx.doi.org/10.1109/TVCG.2018.2864509	997	1007	J	This paper presents a framework to explore multi-field data of aneurysms occurring at intracranial and cardiac arteries by using statistical graphics. The rupture of an aneurysm is often a fatal scenario, whereas during treatment serious complications for the patient can occur. Whether an aneurysm ruptures or whether a treatment is successful depends on the interaction of different morphological such as wall deformation and thickness, and hemodynamic attributes like wall shear stress and pressure. Therefore, medical researchers are very interested in better understanding these relationships. However, the required analysis is a time-consuming process, where suspicious wall regions are difficult to detect due to the time-dependent behavior of the data. Our proposed visualization framework enables medical researchers to efficiently assess aneurysm risk and treatment options. This comprises a powerful set of views including 2D and 3D depictions of the aneurysm morphology as well as statistical plots of different scalar fields. Brushing and linking aids the user to identify interesting wall regions and to understand the influence of different attributes on the aneurysm's state. Moreover, a visual comparison of pre- and post-treatment as well as different treatment options is provided. Our analysis techniques are designed in collaboration with domain experts, e.g., physicians, and we provide details about the evaluation.	Monique Meuschke;Tobias Günther;Philipp Berg;Ralph Wickenhöfer;Bernhard Preim;Kai Lawonn	Monique Meuschke;Tobias Günther;Philipp Berg;Ralph Wickenhöfer;Bernhard Preim;Kai Lawonn	University of Magdeburg, Germany;ETH Zürich, Switzerland;University of Magdeburg, Germany;Heart of Jesus Hospital, Germany;University of Magdeburg, Germany;University of Koblenz-Landau, Germany	10.1109/TVCG.2011.235;10.1109/TVCG.2014.2346406;10.1109/VISUAL.2000.885739;10.1109/TVCG.2013.139;10.1109/TVCG.2016.2598795;10.1109/TVCG.2016.2598866;10.1109/TVCG.2010.153	Medical visualizations,aneurysms,blood flow,parametrization	0	0	1	53	
SciVis	2018	Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves	10.1109/TVCG.2018.2864510	http://dx.doi.org/10.1109/TVCG.2018.2864510	1040	1049	J	The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes.	Johannes Weissenböck;Bernhard Fröhler;M. Eduard Gröller;Johann Kastner;Christoph Heinzl	Johannes Weissenböck;Bernhard Fröhler;Eduard Gröller;Johann Kastner;Christoph Heinzl	University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria;TU Wien, Vienna, Austria;University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria	10.1109/TVCG.2014.2346448;10.1109/VAST.2015.7347634;10.1109/TVCG.2009.155;10.1109/TVCG.2014.2346455;10.1109/VISUAL.2005.1532847;10.1109/TVCG.2013.213;10.1109/VAST.2014.7042491;10.1109/TVCG.2014.2346321;10.1109/VAST.2016.7883516;10.1109/TVCG.2013.143	Ensemble data,comparative visualization,visual analysis,Hilbert curve,nonlinear scaling,X-ray computed tomography		2	1	43	
VAST	2018	Duet: Helping Data Analysis Novices Conduct Pairwise Comparisons by Minimal Specification	10.1109/TVCG.2018.2864526	http://dx.doi.org/10.1109/TVCG.2018.2864526	427	437	J	Data analysis novices often encounter barriers in executing low-level operations for pairwise comparisons. They may also run into barriers in interpreting the artifacts (e.g., visualizations) created as a result of the operations. We developed Duet, a visual analysis system designed to help data analysis novices conduct pairwise comparisons by addressing execution and interpretation barriers. To reduce the barriers in executing low-level operations during pairwise comparison, Duet employs minimal specification: when one object group (i.e. a group of records in a data table) is specified, Duet recommends object groups that are similar to or different from the specified one; when two object groups are specified, Duet recommends similar and different attributes between them. To lower the barriers in interpreting its recommendations, Duet explains the recommended groups and attributes using both visualizations and textual descriptions. We conducted a qualitative evaluation with eight participants to understand the effectiveness of Duet. The results suggest that minimal specification is easy to use and Duet's explanations are helpful for interpreting the recommendations despite some usability issues.	Po-Ming Law;Rahul C. Basole;Yanhong Wu	Po-Ming Law;Rahul C. Basole;Yanhong Wu	Georgia Institute of Technology;Georgia Institute of Technology;Visa Research	10.1109/TVCG.2011.188;10.1109/TVCG.2016.2598468;10.1109/VAST.2011.6102435;10.1109/TVCG.2017.2744199;10.1109/TVCG.2010.164;10.1109/TVCG.2017.2744684;10.1109/TVCG.2008.109;10.1109/TVCG.2015.2467195;10.1109/TVCG.2017.2745219;10.1109/TVCG.2015.2467191	Pairwise comparison,novices,data analysis,automatic insight generation		4	2	51	
SciVis	2018	Firefly: Virtual Illumination Drones for Interactive Visualization	10.1109/TVCG.2018.2864656	http://dx.doi.org/10.1109/TVCG.2018.2864656	1204	1213	J	Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples.	Sergej Stoppel;Magnus Paulson Erga;Stefan Bruckner	Sergej Stoppel;Magnus Paulson Erga;Stefan Bruckner	University of Bergen, Norway;University of Bergen, Norway;University of Bergen, Norway	10.1109/TVCG.2012.203;10.1109/TVCG.2013.156;10.1109/VISUAL.2002.1183785;10.1109/VISUAL.2003.1250395;10.1109/VISUAL.2004.62;10.1109/TVCG.2011.173;10.1109/TVCG.2013.172	Dynamic lighting design,lighting drones	0	1	1	47	HM
SciVis	2018	Interactive obstruction-free lensing for volumetric data visualization	10.1109/TVCG.2018.2864690	http://dx.doi.org/10.1109/TVCG.2018.2864690	1029	1039	J	Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects' vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration.	Michael Traoré;Christophe Hurter;Alexandru Telea	Michael Traoré;Christophe Hurter;Alexandru Telea	ENACFrench Civil Aviation University;ENACFrench Civil Aviation University;Institute Johan BernoulliUniversity of Groningen	10.1109/TVCG.2006.140;10.1109/TVCG.2006.144;10.1109/TVCG.2007.70565;10.1109/TVCG.2010.127;10.1109/TVCG.2009.138;10.1109/VISUAL.2004.32;10.1109/TVCG.2011.223;10.1109/TVCG.2010.193;10.1109/TVCG.2006.124;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.1999.809865;10.1109/TVCG.2012.265;10.1109/TVCG.2016.2599049;10.1109/VISUAL.2005.1532818	Interaction techniques,focus + context,volume visualization,volume rendering,raycasting	0	2	1	51	
SciVis	2018	Robust and Fast Extraction of 3D Symmetric Tensor Field Topology	10.1109/TVCG.2018.2864768	http://dx.doi.org/10.1109/TVCG.2018.2864768	1102	1111	J	3D symmetric tensor fields appear in many science and engineering fields, and topology-driven analysis is important in many of these application domains, such as solid mechanics and fluid dynamics. Degenerate curves and neutral surfaces are important topological features in 3D symmetric tensor fields. Existing methods to extract degenerate curves and neutral surfaces often miss parts of the curves and surfaces, respectively. Moreover, these methods are computationally expensive due to the lack of knowledge of structures of degenerate curves and neutral surfaces.&lt;;/p&gt; &lt;;p&gt;In this paper, we provide theoretical analysis on the geometric and topological structures of degenerate curves and neutral surfaces of 3D linear tensor fields. These structures lead to parameterizations for degenerate curves and neutral surfaces that can not only provide more robust extraction of these features but also incur less computational cost.&lt;;/p&gt; &lt;;p&gt;We demonstrate the benefits of our approach by applying our degenerate curve and neutral surface detection techniques to solid mechanics simulation data sets.	Lawrence Roy;Prashant Kumar;Yue Zhang 0009;Eugene Zhang	Lawrence Roy;Prashant Kumar;Yue Zhang;Eugene Zhang	Oregon State University;Oregon State University;Oregon State University;Oregon State University	10.1109/TVCG.2009.184;10.1109/VISUAL.1994.346326;10.1109/TVCG.2008.148;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2004.105;10.1109/VISUAL.2005.1532841	Tensor field visualization,3D symmetric tensor fields,tensor field topology,traceless tensors,degenerate curve extraction,neutral surface extraction	0	1	1	24	
VAST	2018	Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution	10.1109/TVCG.2018.2864769	http://dx.doi.org/10.1109/TVCG.2018.2864769	374	384	J	To effectively assess the potential consequences of human interventions in model-driven analytics systems, we establish the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms. This paper presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decision-making process. Our approach visualizes the model-space of our novel incremental hierarchical topic modeling algorithm, unveiling its inner-workings. We support the active incorporation of the user's domain knowledge in every step through explicit model manipulation interactions. In addition, users can initialize the model with expected topic seeds, the backbone priors. For a more targeted optimization, the modeling process automatically triggers a speculative execution of various optimization strategies, and requests feedback whenever the measured model quality deteriorates. Users compare the proposed optimizations to the current model state and preview their effect on the next model iterations, before applying one of them. This supervised human-in-the-Ioop process targets maximum improvement for minimum feedback and has proven to be effective in three independent studies that confirm topic model quality improvements.	Mennatallah El-Assady;Fabian Sperrle;Oliver Deussen;Daniel A. Keim;Christopher Collins 0001	Mennatallah El-Assady;Fabian Sperrle;Oliver Deussen;Daniel Keim;Christopher Collins	University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Ontario Institute of Technology, Canada	10.1109/VAST.2014.7042493;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.162;10.1109/TVCG.2017.2745080;10.1109/TVCG.2017.2744199;10.1109/TVCG.2017.2743959;10.1109/TVCG.2013.231;10.1109/TVCG.2013.212;10.1109/TVCG.2016.2598445;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.232	User-Steerable Topic Modeling,Speculative Execution,Mixed-Initiative Visual Analytics,Explainable Machine Learning	0	8	4	69	
SciVis	2018	CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data	10.1109/TVCG.2018.2864801	http://dx.doi.org/10.1109/TVCG.2018.2864801	1214	1224	J	CoDDA (Copula-based Distribution Driven Analysis) is a flexible framework for large-scale multivariate datasets. A common strategy to deal with large-scale scientific simulation data is to partition the simulation domain and create statistical data summaries. Instead of storing the high-resolution raw data from the simulation, storing the compact statistical data summaries results in reduced storage overhead and alleviated I/O bottleneck. Such summaries, often represented in the form of statistical probability distributions, can serve various post-hoc analysis and visualization tasks. However, for multivariate simulation data using standard multivariate distributions for creating data summaries is not feasible. They are either storage inefficient or are computationally expensive to be estimated in simulation time (in situ) for large number of variables. In this work, using copula functions, we propose a flexible multivariate distribution-based data modeling and analysis framework that offers significant data reduction and can be used in an in situ environment. The framework also facilitates in storing the associated spatial information along with the multivariate distributions in an efficient representation. Using the proposed multivariate data summaries, we perform various multivariate post-hoc analyses like query-driven visualization and sampling-based visualization. We evaluate our proposed method on multiple real-world multivariate scientific datasets. To demonstrate the efficacy of our framework in an in situ environment, we apply it on a large-scale flow simulation.	Subhashis Hazarika;Soumya Dutta;Han-Wei Shen;Jen-Ping Chen	Subhashis Hazarika;Soumya Dutta;Han-Wei Shen;Jen-Ping Chen	The Department of Computer Science and EngineeringGRAVITY research groupThe Ohio State University;The Department of Computer Science and EngineeringGRAVITY research groupThe Ohio State University;The Department of Computer Science and EngineeringGRAVITY research groupThe Ohio State University;The Department of Mechanical and Aerospace EngineeringThe Ohio State University	10.1109/TVCG.2015.2467958;10.1109/TVCG.2007.70519;10.1109/TVCG.2015.2467952;10.1109/TVCG.2016.2598604;10.1109/TVCG.2015.2467436;10.1109/TVCG.2015.2467204;10.1109/TVCG.2017.2744099;10.1109/TVCG.2007.70615;10.1109/VAST.2015.7347634;10.1109/TVCG.2006.165;10.1109/TVCG.2015.2467411	In situ processing,Distribution-based,Multivariate,Query-driven,Copula	0	3	1	64	
SciVis	2018	Interactive 3D Visual Analysis of Atmospheric Fronts	10.1109/TVCG.2018.2864806	http://dx.doi.org/10.1109/TVCG.2018.2864806	1080	1090	J	Atmospheric fronts play a central role in meteorology, as the boundaries between different air masses and as fundamental features of extra-tropical cyclones. They appear in numerous conceptual model depictions of extra-tropical weather systems. Conceptually, fronts are three-dimensional surfaces in space possessing an innate structural complexity, yet in meteorology, both manual and objective identification and depiction have historically focused on the structure in two dimensions. In this work, we -a team of visualization scientists and meteorologists-propose a novel visualization approach to analyze the three-dimensional structure of atmospheric fronts and related physical and dynamical processes. We build upon existing approaches to objectively identify fronts as lines in two dimensions and extend these to obtain frontal surfaces in three dimensions, using the magnitude of temperature change along the gradient of a moist potential temperature field as the primary identifying factor. We introduce the use of normal curves in the temperature gradient field to visualize a frontal zone (i.e., the transitional zone between the air masses) and the distribution of atmospheric variables in such zones. To enable for the first time a statistical analysis of frontal zones, we present a new approach to obtain the volume enclosed by a zone, by classifying grid boxes that intersect with normal curves emanating from a selected front. We introduce our method by means of an idealized numerical simulation and demonstrate its use with two real-world cases using numerical weather prediction data.	Michael Kern;Tim Hewson;Andreas Schäfler;Rüdiger Westermann;Marc Rautenhaus	Michael Kern;Tim Hewson;Andreas Schätler;Rüdiger Westermann;Marc Rautenhaus	Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany;European Centre for Medium-Range Weather Forecasts, Reading, UK;Deutsches Zentrum für Luft- und Raumfahrt (DLR), Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany	10.1109/TVCG.2017.2743989;10.1109/TVCG.2007.70554	Meteorology,Atmospheric Fronts,Feature Detection	0	1	0	56	
SciVis	2018	Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps	10.1109/TVCG.2018.2864808	http://dx.doi.org/10.1109/TVCG.2018.2864808	1236	1245	J	We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.	Jun Tao;Martin Imre;Chaoli Wang;Nitesh V. Chawla;Hanqi Guo;Gokhan Sever;Seung Hyun Kim	Jun Tao;Martin Imre;Chaoli Wang;Nitesh V. Chawla;Hanqi Guo;Gökhan Sever;Seung Hyun Kim	University of Notre Dame;University of Notre Dame;University of Notre Dame;University of Notre Dame;Argonne National Laboratory;Argonne National Laboratory;The Ohio State University	10.1109/TVCG.2013.133;10.1109/TVCG.2012.284;10.1109/TVCG.2008.184;10.1109/TVCG.2011.246;10.1109/TVCG.2011.258;10.1109/TVCG.2008.116;10.1109/VISUAL.2005.1532857;10.1109/TVCG.2009.136;10.1109/TVCG.2015.2467431;10.1109/TVCG.2006.165;10.1109/TVCG.2013.213;10.1109/TVCG.2008.143;10.1109/VISUAL.1999.809910;10.1109/VISUAL.2005.1532792;10.1109/TVCG.2008.140;10.1109/TVCG.2006.164;10.1109/VISUAL.2003.1250402	Time-varying multivariate data visualization,isosurface,similarity map,visual interface,path recommendation	0	1	1	41	
VAST	2018	Analysis of Flight Variability: a Systematic Approach	10.1109/TVCG.2018.2864811	http://dx.doi.org/10.1109/TVCG.2018.2864811	54	64	J	In movement data analysis, there exists a problem of comparing multiple trajectories of moving objects to common or distinct reference trajectories. We introduce a general conceptual framework for comparative analysis of trajectories and an analytical procedure, which consists of (1) finding corresponding points in pairs of trajectories, (2) computation of pairwise difference measures, and (3) interactive visual analysis of the distributions of the differences with respect to space, time, set of moving objects, trajectory structures, and spatio-temporal context. We propose a combination of visualisation, interaction, and data transformation techniques supporting the analysis and demonstrate the use of our approach for solving a challenging problem from the aviation domain.	Natalia V. Andrienko;Gennady L. Andrienko;Jose Manuel Cordero Garcia;David Scarlatti	Natalia Andrienko;Gennady Andrienko;Jose Manuel Cordero Garcia;David Scarlatti	Fraunhofer IAISCity, University of London;Fraunhofer IAISCity, University of London;CRIDA (Reference Center for Research, Development and Innovation in ATM);Boeing Research & Development Europe	10.1109/VAST.2008.4677356;10.1109/VAST.2010.5653580;10.1109/TVCG.2017.2744322;10.1109/TVCG.2013.193;10.1109/TVCG.2015.2467851;10.1109/TVCG.2011.233;10.1109/TVCG.2012.265;10.1109/TVCG.2015.2468078	Visual analytics,movement data,flight trajectories	0	5	2	55	
VAST	2018	RuleMatrix: Visualizing and Understanding Classifiers with Rules	10.1109/TVCG.2018.2864812	http://dx.doi.org/10.1109/TVCG.2018.2864812	342	352	J	With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.	Yao Ming;Huamin Qu;Enrico Bertini	Yao Ming;Huamin Qu;Enrico Bertini	University of Science and Technology;University of Science and Technology;New York University	10.1109/TVCG.2017.2744683;10.1109/TVCG.2017.2744718;10.1109/VAST.2017.8585720;10.1109/TVCG.2016.2598831;10.1109/VAST.2017.8585721;10.1109/TVCG.2017.2744358;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/TVCG.2017.2744158;10.1109/VISUAL.2005.1532820;10.1109/VAST.2011.6102453;10.1109/TVCG.2017.2744878	explainable machine learning,rule visualization,visual analytics	0	1	7	48	
SciVis	2018	Recirculation Surfaces for Flow Visualization	10.1109/TVCG.2018.2864813	http://dx.doi.org/10.1109/TVCG.2018.2864813	946	955	J	We present a formal approach to the visual analysis of recirculation in flows by introducing recirculation surfaces for 3D unsteady flow fields. Recirculation surfaces are the loci where massless particle integration returns to its starting point after some variable, finite integration. We give a rigorous definition of recirculation surfaces as 2-manifolds embedded in 5D space and study their properties. Based on this we construct an algorithm for their extraction, which searches for intersections of a recirculation surface with lines defined in 3D. This reduces the problem to a repeated search for critical points in 3D vector fields. We provide a uniform sampling of the search space paired with a surface reconstruction and visualize results. This way, we present the first algorithm for a comprehensive feature extraction in the 5D flow map of a 3D flow. The problem of finding isolated closed orbits in steady vector fields occurs as a special case of recirculation surfaces. This includes isolated closed orbits with saddle behavior. We show recirculation surfaces for a number of artificial and real flow data sets.	Thomas Wilde;Christian Rossi;Holger Theisel	Thomas Wilde;Christian Rössi;Holger Theisel	Visual Computing groupUniversity of Magdeburg;Visual Computing groupUniversity of Magdeburg;Visual Computing groupUniversity of Magdeburg	10.1109/VISUAL.2004.107;10.1109/TVCG.2009.177;10.1109/VISUAL.2004.59;10.1109/VISUAL.2002.1183786;10.1109/TVCG.2008.163	Flow visualization,recirculation,unsteady flow	0	2	1	41	
VAST	2018	BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence	10.1109/TVCG.2018.2864814	http://dx.doi.org/10.1109/TVCG.2018.2864814	162	171	J	The emerging prosperity of cryptocurrencies, such as Bitcoin, has come into the spotlight during the past few years. Cryptocurrency exchanges, which act as the gateway to this world, now play a dominant role in the circulation of Bitcoin. Thus, delving into the analysis of the transaction patterns of exchanges can shed light on the evolution and trends in the Bitcoin market, and participants can gain hints for identifying credible exchanges as well. Not only Bitcoin practitioners but also researchers in the financial domains are interested in the business intelligence behind the curtain. However, the task of multiple exchanges exploration and comparisons has been limited owing to the lack of efficient tools. Previous methods of visualizing Bitcoin data have mainly concentrated on tracking suspicious transaction logs, but it is cumbersome to analyze exchanges and their relationships with existing tools and methods. In this paper, we present BitExTract, an interactive visual analytics system, which, to the best of our knowledge, is the first attempt to explore the evolutionary transaction patterns of Bitcoin exchanges from two perspectives, namely, exchange versus exchange and exchange versus client. In particular, BitExTract summarizes the evolution of the Bitcoin market by observing the transactions between exchanges over time via a massive sequence view. A node-link diagram with ego-centered views depicts the trading network of exchanges and their temporal transaction distribution. Moreover, BitExTract embeds multiple parallel bars on a timeline to examine and compare the evolution patterns of transactions between different exchanges. Three case studies with novel insights demonstrate the effectiveness and usability of our system.	Xuanwu Yue;Xinhuan Shu;Xinyu Zhu;Xinnan Du;Zheqing Yu;Dimitrios Papadopoulos;Siyuan Liu	Xuanwu Yue;Xinhuan Shu;Xinyu Zhu;Xinnan Du;Zheqing Yu;Dimitrios Papadopoulos;Siyuan Liu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Penn State University	10.1109/TVCG.2008.117;10.1109/TVCG.2011.169;10.1109/VAST.2007.4389009;10.1109/TVCG.2009.180;10.1109/TVCG.2014.2346913	Bitcoin exchange,transaction data,comparative analysis,visual analytics,FinTech		3	2	50	
SciVis	2018	An Interactive Framework for Visualization of Weather Forecast Ensembles	10.1109/TVCG.2018.2864815	http://dx.doi.org/10.1109/TVCG.2018.2864815	1091	1101	J	Numerical Weather Prediction (NWP) ensembles are commonly used to assess the uncertainty and confidence in weather forecasts. Spaghetti plots are conventional tools for meteorologists to directly examine the uncertainty exhibited by ensembles, where they simultaneously visualize isocontours of all ensemble members. To avoid visual clutter in practical usages, one needs to select a small number of informative isovalues for visual analysis. Moreover, due to the complex topology and variation of ensemble isocontours, it is often a challenging task to interpret the spaghetti plot for even a single isovalue in large ensembles. In this paper, we propose an interactive framework for uncertainty visualization of weather forecast ensembles that significantly improves and expands the utility of spaghetti plots in ensemble analysis. Complementary to state-of-the-art methods, our approach provides a complete framework for visual exploration of ensemble isocontours, including isovalue selection, interactive isocontour variability exploration, and interactive sub-region selection and re-analysis. Our framework is built upon the high-density clustering paradigm, where the mode structure of the density function is represented as a hierarchy of nested subsets of the data. We generalize the high-density clustering for isocontours and propose a bandwidth selection method for estimating the density function of ensemble isocontours. We present novel visualizations based on high-density clustering results, called the mode plot and the simplified spaghetti plot. The proposed mode plot visually encodes the structure provided by the high-density clustering result and summarizes the distribution of ensemble isocontours. It also enables the selection of subsets of interesting isocontours, which are interactively highlighted in a linked spaghetti plot for providing spatial context. To provide an interpretable overview of the positional variability of isocontours, our system allows for selection of informative isovalues from the simplified spaghetti plot. Due to the spatial variability of ensemble isocontours, the system allows for interactive selection and focus on sub-regions for local uncertainty and clustering re-analysis. We examine a number of ensemble datasets to establish the utility of our approach and discuss its advantages over state-of-the-art visual analysis tools for ensemble data.	Bo Ma 0002;Alireza Entezari	Bo Ma;Alireza Entezari	University of Florida;University of Florida	10.1109/TVCG.2013.208;10.1109/TVCG.2015.2467958;10.1109/TVCG.2016.2598869;10.1109/TVCG.2014.2346448;10.1109/TVCG.2015.2467204;10.1109/TVCG.2016.2598868;10.1109/TVCG.2015.2468093;10.1109/TVCG.2017.2745178;10.1109/TVCG.2015.2467754;10.1109/TVCG.2010.181;10.1109/TVCG.2014.2346332;10.1109/TVCG.2016.2598830;10.1109/TVCG.2013.143	Spaghetti plots,ensemble visualization,uncertainty visualization,high-density clustering,ensemble forecasting	0	2	0	56	
SciVis	2018	Interactive Visualization of 3D Histopathology in Native Resolution	10.1109/TVCG.2018.2864816	http://dx.doi.org/10.1109/TVCG.2018.2864816	1008	1017	J	We present a visualization application that enables effective interactive visual analysis of large-scale 3D histopathology, that is, high-resolution 3D microscopy data of human tissue. Clinical work flows and research based on pathology have, until now, largely been dominated by 2D imaging. As we will show in the paper, studying volumetric histology data will open up novel and useful opportunities for both research and clinical practice. Our starting point is the current lack of appropriate visualization tools in histopathology, which has been a limiting factor in the uptake of digital pathology. Visualization of 3D histology data does pose difficult challenges in several aspects. The full-color datasets are dense and large in scale, on the order of 100,000 × 100,000 × 100 voxels. This entails serious demands on both rendering performance and user experience design. Despite this, our developed application supports interactive study of 3D histology datasets at native resolution. Our application is based on tailoring and tuning of existing methods, system integration work, as well as a careful study of domain specific demands emanating from a close participatory design process with domain experts as team members. Results from a user evaluation employing the tool demonstrate a strong agreement among the 14 participating pathologists that 3D histopathology will be a valuable and enabling tool for their work.	Martin Falk;Anders Ynnerman;Darren Treanor;Claes Lundström	Martin Falk;Anders Ynnerman;Darren Treanor;Claes Lundström	Department of Science and Technology, Linköping University, Sweden;Department of Science and Technology, Linköping University, Sweden;Leeds Teaching Hospitals NHS Trust, United Kingdom;The Center for Medical Image Science and Visualization (CMIV), Linköping University, Sweden	10.1109/TVCG.2009.150;10.1109/VISUAL.2002.1183757;10.1109/TVCG.2012.240	Histology,Pathology,Volume Rendering,Expert Evaluation		1	0	35	
SciVis	2018	Visual Analysis of Spatia-temporal Relations of Pairwise Attributes in Unsteady Flow	10.1109/TVCG.2018.2864817	http://dx.doi.org/10.1109/TVCG.2018.2864817	1246	1256	J	Despite significant advances in the analysis and visualization of unsteady flow, the interpretation of it's behavior still remains a challenge. In this work, we focus on the linear correlation and non-linear dependency of different physical attributes of unsteady flows to aid their study from a new perspective. Specifically, we extend the existing spatial correlation quantification, i.e. the Local Correlation Coefficient (LCC), to the spatio-temporal domain to study the correlation of attribute-pairs from both the Eulerian and Lagrangian views. To study the dependency among attributes, which need not be linear, we extend and compute the mutual information (MI) among attributes over time. To help visualize and interpret the derived correlation and dependency among attributes associated with a particle, we encode the correlation and dependency values on individual pathlines. Finally, to utilize the correlation and MI computation results to identify regions with interesting flow behavior, we propose a segmentation strategy of the flow domain based on the ranking of the strength of the attributes relations. We have applied our correlation and dependency metrics to a number of 2D and 3D unsteady flows with varying spatio-temporal kernel sizes to demonstrate and assess their effectiveness.	Marzieh Berenjkoub;Rodolfo Ostilla Monico;Robert S. Laramee;Guoning Chen	Marzieh Berenjkoub;Rodolfo Ostilla Monico;Robert S. Laramee;Guoning Chen	University of Houston;University of Houston;Swansea University;University of Houston	10.1109/TVCG.2010.131;10.1109/VISUAL.2004.99;10.1109/TVCG.2010.198;10.1109/TVCG.2015.2467200;10.1109/TVCG.2009.200;10.1109/TVCG.2010.131;10.1109/TVCG.2013.133;10.1109/TVCG.2011.249	Unsteady flow,correlation study,mutual information	0	1	2	63	
VAST	2018	EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data	10.1109/TVCG.2018.2864825	http://dx.doi.org/10.1109/TVCG.2018.2864825	109	119	J	The results of anomaly detection are sensitive to the choice of detection algorithms as they are specialized for different properties of data, especially for multidimensional data. Thus, it is vital to select the algorithm appropriately. To systematically select the algorithms, ensemble analysis techniques have been developed to support the assembly and comparison of heterogeneous algorithms. However, challenges remain due to the absence of the ground truth, interpretation, or evaluation of these anomaly detectors. In this paper, we present a visual analytics system named EnsembleLens that evaluates anomaly detection algorithms based on the ensemble analysis process. The system visualizes the ensemble processes and results by a set of novel visual designs and multiple coordinated contextual views to meet the requirements of correlation analysis, assessment and reasoning of anomaly detection algorithms. We also introduce an interactive analysis workflow that dynamically produces contextualized and interpretable data summaries that allow further refinements of exploration results based on user feedback. We demonstrate the effectiveness of EnsembleLens through a quantitative evaluation, three case studies with real-world data and interviews with two domain experts.	Ke Xu;Meng Xia;Xing Mu;Yun Wang 0012;Nan Cao	Ke Xu;Meng Xia;Xing Mu;Yun Wang;Nan Cao	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;iDVxLabTongji University	10.1109/SciVis.2015.7429487;10.1109/TVCG.2017.2744419;10.1109/TVCG.2014.2346448;10.1109/TVCG.2015.2468093;10.1109/VISUAL.1990.146402;10.1109/TVCG.2017.2745178;10.1109/TVCG.2010.181;10.1109/TVCG.2016.2598830;10.1109/TVCG.2014.2346922	Algorithm Evaluation,Ensemble Analysis,Anomaly Detection,Visual Analysis,Multidimensional Data		3	0	80	
VAST	2018	VIBR: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle	10.1109/TVCG.2018.2864826	http://dx.doi.org/10.1109/TVCG.2018.2864826	321	330	J	Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people's affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.	Gromit Yeuk-Yin Chan;Panpan Xu;Zeng Dai;Liu Ren	Gromit Yeuk-Yin Chan;Panpan Xu;Zeng Dai;Liu Ren	New York University;Bosch Research North America, Sunnyvale;Bosch Research North America, Sunnyvale;Bosch Research North America, Sunnyvale	10.1109/TVCG.2010.154;10.1109/TVCG.2012.252;10.1109/TVCG.2013.223;10.1109/INFVIS.2004.1;10.1109/TVCG.2016.2598831;10.1109/TVCG.2009.111;10.1109/TVCG.2014.2346279;10.1109/TVCG.2006.166;10.1109/VAST.2007.4389006;10.1109/TVCG.2015.2467813;10.1109/TVCG.2014.2346665;10.1109/TVCG.2016.2598591	Bipartite Graph,Visual Summarization,Minimum Description Length,Information Theory	0	3	4	47	
SciVis	2018	Hexahedral Mesh Structure Visualization and Evaluation	10.1109/TVCG.2018.2864827	http://dx.doi.org/10.1109/TVCG.2018.2864827	1173	1182	J	Understanding hexahedral (hex-) mesh structures is important for a number of hex-mesh generation and optimization tasks. However, due to various configurations of the singularities in a valid pure hex-mesh, the structure (or base complex) of the mesh can be arbitrarily complex. In this work, we present a first and effective method to help meshing practitioners understand the possible configurations in a valid 3D base complex for the characterization of their complexity. In particular, we propose a strategy to decompose the complex hex-mesh structure into multi-level sub-structures so that they can be studied separately, from which we identify a small set of the sub-structures that can most efficiently represent the whole mesh structure. Furthermore, from this set of sub-structures, we attempt to define the first metric for the quantification of the complexity of hex-mesh structure. To aid the exploration of the extracted multi-level structure information, we devise a visual exploration system coupled with a matrix view to help alleviate the common challenge of 3D data exploration (e.g., clutter and occlusion). We have applied our tool and metric to a large number of hex-meshes generated with different approaches to reveal different characteristics of these methods in terms of the mesh structures they can produce. We also use our metric to assess the existing structure simplification techniques in terms of their effectiveness.	Kaoji Xu;Guoning Chen	Kaoji Xu;Guoning Chen	University of Houston;University of Houston		hexahedral mesh,base complex,sheet decomposition,complexity analysis	0	1	0	42	
SciVis	2018	Objective Vortex Corelines of Finite-sized Objects in Fluid Flows	10.1109/TVCG.2018.2864828	http://dx.doi.org/10.1109/TVCG.2018.2864828	956	966	J	Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.	Tobias Günther;Holger Theisel	Tobias Günther;Holger Theisel	Computer Graphics LaboratoryETH Zürich;Visual Computing GroupUniversity of Magdeburg	10.1109/VISUAL.1991.175773;10.1109/TVCG.2015.2467200;10.1109/TVCG.2014.2346415;10.1109/TVCG.2016.2599016;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296;10.1109/TVCG.2016.2599018;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545	Vortex extraction,inertial particles,objectivity,vortex coreline		3	0	81	
InfoVis	2018	Design Exposition with Literate Visualization	10.1109/TVCG.2018.2864836	http://dx.doi.org/10.1109/TVCG.2018.2864836	759	768	J	We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuth's idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: `notebook' documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.	Jo Wood;Alexander Kachkaev;Jason Dykes	Jo Wood;Alexander Kachkaev;Jason Dykes	giCentreCity University of London;giCentreCity University of London;giCentreCity University of London	10.1109/TVCG.2013.145;10.1109/TVCG.2014.2346325;10.1109/TVCG.2017.2744319;10.1109/TVCG.2011.209;10.1109/TVCG.2014.2346331;10.1109/TVCG.2016.2598542;10.1109/TVCG.2009.111;10.1109/TVCG.2015.2467271;10.1109/TVCG.2016.2599030;10.1109/TVCG.2012.213;10.1109/TVCG.2014.2346323	storytelling,design,literate programming,theory	0	4	4	41	HM
VAST	2018	VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning	10.1109/TVCG.2018.2864838	http://dx.doi.org/10.1109/TVCG.2018.2864838	385	395	J	While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely “VA-assisted ML”. The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workflows by systematically examining the potential benefits that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reflect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly.	Dominik Sacha;Matthias Kraus;Daniel A. Keim;Min Chen 0001	Dominik Sacha;Matthias Kraus;Daniel A. Keim;Min Chen	University of Konstanz;University of Konstanz;University of Konstanz;University of Oxford	10.1109/TVCG.2017.2744683;10.1109/VISUAL.2004.10;10.1109/VAST.2008.4677361;10.1109/TVCG.2017.2744718;10.1109/TVCG.2017.2745178;10.1109/TVCG.2017.2745085;10.1109/TVCG.2017.2744938;10.1109/TVCG.2016.2598831;10.1109/TVCG.2017.2744378;10.1109/TVCG.2017.2745158;10.1109/TVCG.2017.2744358;10.1109/TVCG.2016.2598838;10.1109/TVCG.2016.2598828;10.1109/TVCG.2017.2744805;10.1109/TVCG.2014.2346481;10.1109/TVCG.2016.2598495;10.1109/TVCG.2017.2744158;10.1109/TVCG.2016.2598829;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2016.2598830;10.1109/TVCG.2017.2744878	Visual Analytics,Visualization,Machine Learning,Human-Computer Interaction,Ontology,VIS4ML	0	12	5	71	
SciVis	2018	Time-Dependent Flow seen through Approximate Observer Killing Fields	10.1109/TVCG.2018.2864839	http://dx.doi.org/10.1109/TVCG.2018.2864839	1257	1266	J	Flow fields are usually visualized relative to a global observer, i.e., a single frame of reference. However, often no global frame can depict all flow features equally well. Likewise, objective criteria for detecting features such as vortices often use either a global reference frame, or compute a separate frame for each point in space and time. We propose the first general framework that enables choosing a smooth trade-off between these two extremes. Using global optimization to minimize specific differential geometric properties, we compute a time-dependent observer velocity field that describes the motion of a continuous field of observers adapted to the input flow. This requires developing the novel notion of an observed time derivative. While individual observers are restricted to rigid motions, overall we compute an approximate Killing field, corresponding to almost-rigid motion. This enables continuous transitions between different observers. Instead of focusing only on flow features, we furthermore develop a novel general notion of visualizing how all observers jointly perceive the input field. This in fact requires introducing the concept of an observation time, with respect to which a visualization is computed. We develop the corresponding notions of observed stream, path, streak, and time lines. For efficiency, these characteristic curves can be computed using standard approaches, by first transforming the input field accordingly. Finally, we prove that the input flow perceived by the observer field is objective. This makes derived flow features, such as vortices, objective as well.	Markus Hadwiger;Matej Mlejnek;Thomas Theußl;Peter Rautek	Markus Hadwiger;Matej Mlejnek;Thomas Theußl;Peter Rautek	King Abdullah University of Science and Technology (KAUST), Visual Computing Center, Saudi Arabia;King Abdullah University of Science and Technology (KAUST), Visual Computing Center, Saudi Arabia;King Abdullah University of Science and Technology (KAUST), Core Labs, Saudi Arabia;King Abdullah University of Science and Technology (KAUST), Visual Computing Center, Saudi Arabia	10.1109/TVCG.2015.2467200;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1997.663898;10.1109/TVCG.2008.163;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198;10.1109/TVCG.2007.70557	Flow visualization,observer frames of reference,Killing vector fields,infinitesimal isometries,Lie derivatives,objectivity	0	1	1	52	
SciVis	2018	A Declarative Grammar of Flexible Volume Visualization Pipelines	10.1109/TVCG.2018.2864841	http://dx.doi.org/10.1109/TVCG.2018.2864841	1050	1059	J	This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations.	Min Shih;Charles Rozhon;Kwan-Liu Ma	Min Shih;Charles Rozhon;Kwan-Liu Ma	University of California, Davis;University of California, Davis;University of California, Davis	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70555;10.1109/TVCG.2014.2346322;10.1109/TVCG.2009.189;10.1109/TVCG.2015.2467449;10.1109/VISUAL.1992.235219;10.1109/VISUAL.2004.95;10.1109/TVCG.2007.70534;10.1109/TVCG.2014.2346318;10.1109/TVCG.2016.2599030;10.1109/TVCG.2015.2467091;10.1109/SciVis.2015.7429514;10.1109/TVCG.2016.2599041	Volume visualization,direct volume rendering,declarative specification,multivariate/multimodal volume data,animation	0	1	0	41	
VAST	2018	An Interactive Method to Improve Crowdsourced Annotations	10.1109/TVCG.2018.2864843	http://dx.doi.org/10.1109/TVCG.2018.2864843	235	245	J	In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.	Shixia Liu;Changjian Chen;Yafeng Lu;Fang-Xin Ou-Yang;Bin Wang	Shixia Liu;Changjian Chen;Yafeng Lu;Fangxin Ouyang;Bin Wang	School of SoftwareTsinghua University;School of SoftwareTsinghua University;Arizona State University;School of SoftwareTsinghua University;School of SoftwareTsinghua University	10.1109/TVCG.2016.2598592;10.1109/VAST.2014.7042480;10.1109/TVCG.2017.2744818;10.1109/VAST.2016.7883520;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346594;10.1109/TVCG.2013.212;10.1109/TVCG.2011.239;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400492;10.1109/TVCG.2016.2598445;10.1109/TVCG.2015.2467622;10.1109/TVCG.2015.2467554;10.1109/TVCG.2017.2744938;10.1109/TVCG.2016.2598831;10.1109/TVCG.2017.2744378;10.1109/VAST.2016.7883508;10.1109/TVCG.2009.139;10.1109/TVCG.2016.2598829;10.1109/TVCG.2017.2745078;10.1109/VAST.2014.7042494;10.1109/TVCG.2017.2744685;10.1109/TVCG.2013.164;10.1109/VAST.2016.7883514	Crowdsourcing,learning-from-crowds,interactive visualization,focus + context		4	2	65	
VAST	2018	A Visual Analytics Framework for Spatiotemporal Trade Network Analysis	10.1109/TVCG.2018.2864844	http://dx.doi.org/10.1109/TVCG.2018.2864844	331	341	J	Economic globalization is increasing connectedness among regions of the world, creating complex interdependencies within various supply chains. Recent studies have indicated that changes and disruptions within such networks can serve as indicators for increased risks of violence and armed conflicts. This is especially true of countries that may not be able to compete for scarce commodities during supply shocks. Thus, network-induced vulnerability to supply disruption is typically exported from wealthier populations to disadvantaged populations. As such, researchers and stakeholders concerned with supply chains, political science, environmental studies, etc. need tools to explore the complex dynamics within global trade networks and how the structure of these networks relates to regional instability. However, the multivariate, spatiotemporal nature of the network structure creates a bottleneck in the extraction and analysis of correlations and anomalies for exploratory data analysis and hypothesis generation. Working closely with experts in political science and sustainability, we have developed a highly coordinated, multi-view framework that utilizes anomaly detection, network analytics, and spatiotemporal visualization methods for exploring the relationship between global trade networks and regional instability. Requirements for analysis and initial research questions to be investigated are elicited from domain experts, and a variety of visual encoding techniques for rapid assessment of analysis and correlations between trade goods, network patterns, and time series signatures are explored. We demonstrate the application of our framework through case studies focusing on armed conflicts in Africa, regional instability measures, and their relationship to international global trade.	Hong Wang;Yafeng Lu;Shade T. Shutters;Michael Steptoe;Feng Wang 0012;Steven Landis;Ross Maciejewski	Hong Wang;Yafeng Lu;Shade T. Shutters;Michael Steptoe;Feng Wang;Steven Landis;Ross Maciejewski	Arizona State University;Arizona State University;Arizona State University;Arizona State University;GE Global Research;University of Nevada;Arizona State University	10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400557;10.1109/TVCG.2008.135;10.1109/VAST.2012.6400485;10.1109/TVCG.2014.2346682;10.1109/TVCG.2009.143;10.1109/TVCG.2014.2346271;10.1109/TVCG.2015.2467991;10.1109/VAST.2012.6400491;10.1109/INFVIS.1996.559226;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2016.2598885	Global trade network,anomaly detection,visual analytics	0	1	1	82	
SciVis	2018	DT-MRI Streamsurfaces Revisited	10.1109/TVCG.2018.2864845	http://dx.doi.org/10.1109/TVCG.2018.2864845	1112	1121	J	DT-MRI streamsurfaces, defined as surfaces that are everywhere tangential to the major and medium eigenvector fields, have been proposed as a tool for visualizing regions of predominantly planar behavior in diffusion tensor MRI. Even though it has long been known that their construction assumes that the involved eigenvector fields satisfy an integrability condition, it has never been tested systematically whether this condition is met in real-world data. We introduce a suitable and efficiently computable test to the visualization literature, demonstrate that it can be used to distinguish integrable from nonintegrable configurations in simulations, and apply it to whole-brain datasets of 15 healthy subjects. We conclude that streamsurface integrability is approximately satisfied in a substantial part of the brain, but not everywhere, including some regions of planarity. As a consequence, algorithms for streamsurface extraction should explicitly test local integrability. Finally, we propose a novel patch-based approach to streamsurface visualization that reduces visual artifacts, and is shown to more fully sample the extent of streamsurfaces.	Michael Ankele;Thomas Schultz 0001	Michael Ankele;Thomas Schultz	University of Bonn;University of Bonn	10.1109/TVCG.2007.70551;10.1109/VISUAL.1992.235211;10.1109/TVCG.2007.70554;10.1109/TVCG.2007.70602;10.1109/TVCG.2008.148	Diffusion Tensor MRI,streamsurfaces,Frobenius theorem,Lie bracket	0	1	0	36	
SciVis	2018	Tensor Field Visualization using Fiber Surfaces of Invariant Space	10.1109/TVCG.2018.2864846	http://dx.doi.org/10.1109/TVCG.2018.2864846	1122	1131	J	Scientific visualization developed successful methods for scalar and vector fields. For tensor fields, however, effective, interactive visualizations are still missing despite progress over the last decades. We present a general approach for the generation of separating surfaces in symmetric, second-order, three-dimensional tensor fields. These surfaces are defined as fiber surfaces of the invariant space, i.e. as pre-images of surfaces in the range of a complete set of invariants. This approach leads to a generalization of the fiber surface algorithm by Klacansky et al. [16] to three dimensions in the range. This is due to the fact that the invariant space is three-dimensional for symmetric second-order tensors over a spatial domain. We present an algorithm for surface construction for simplicial grids in the domain and simplicial surfaces in the invariant space. We demonstrate our approach by applying it to stress fields from component design in mechanical engineering.	Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann	Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann	Institute of Computer Science, Leipzig University, Leipzig, Germany;Institute of Computer Science, Leipzig University, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Institute of Computer Science, Leipzig University, Leipzig, Germany	10.1109/VISUAL.1994.346326	visualization,tensor field,invariants,fiber surface,interaction	0	2	1	36	
SciVis	2018	Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach	10.1109/TVCG.2018.2864847	http://dx.doi.org/10.1109/TVCG.2018.2864847	1132	1141	J	With the rapid increase in raw volume data sizes, such as terabyte-sized microscopy volumes, the corresponding segmentation label volumes have become extremely large as well. We focus on integer label data, whose efficient representation in memory, as well as fast random data access, pose an even greater challenge than the raw image data. Often, it is crucial to be able to rapidly identify which segments are located where, whether for empty space skipping for fast rendering, or for spatial proximity queries. We refer to this process as<i>culling</i>. In order to enable efficient culling of millions of labeled segments, we present a novel hybrid approach that combines deterministic and probabilistic representations of label data in a data-adaptive hierarchical data structure that we call the label list tree. In each node, we adaptively encode label data using either a probabilistic constant-time access representation for fast conservative culling, or a deterministic logarithmic-time access representation for exact queries. We choose the best data structures for representing the labels of each spatial region while building the label list tree. At run time, we further employ a novel<i>query-adaptive</i>culling strategy. While filtering a query down the tree, we prune it successively, and in each node adaptively select the representation that is best suited for evaluating the pruned query, depending on its size. We show an analysis of the efficiency of our approach with several large data sets from connectomics, including a brain scan with more than 13 million labeled segments, and compare our method to conventional culling approaches. Our approach achieves significant reductions in storage size as well as faster query times.	Johanna Beyer;Haneen Mohammed;Marco Agus;Ali K. Al-Awami;Hanspeter Pfister;Markus Hadwiger	Johanna Beyer;Haneen Mohammed;Marco Agus;Ali K. Al-Awami;Hanspeter Pfister;Markus Hadwiger	Harvard University, Cambridge, MA, USA;Harvard UniversityKAUST;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;KAUST, Saudi Aramco, Dhahran, Saudi Arabia;Harvard University, Cambridge, MA, USA;King Abdullah University of Science and Technology (KAUST), Saudi Arabia	10.1109/VISUAL.1992.235231;10.1109/TVCG.2013.142;10.1109/TVCG.2009.121;10.1109/VISUAL.2003.1250386;10.1109/TVCG.2012.240;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1999.809908;10.1109/VISUAL.1995.480792;10.1109/VISUAL.2005.1532792;10.1109/VISUAL.1990.146377;10.1109/VISUAL.2001.964521	Hierarchical Culling,Segmented Volume Data,Bloom Filter,Volume Rendering,Spatial Queries	0	0	1	42	
SciVis	2018	Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy	10.1109/TVCG.2018.2864848	http://dx.doi.org/10.1109/TVCG.2018.2864848	1183	1192	J	Topological techniques have proven to be a powerful tool in the analysis and visualization of large-scale scientific data. In particular, the Morse-Smale complex and its various components provide a rich framework for robust feature definition and computation. Consequently, there now exist a number of approaches to compute Morse-Smale complexes for large-scale data in parallel. However, existing techniques are based on discrete concepts which produce the correct topological structure but are known to introduce grid artifacts in the resulting geometry. Here, we present a new approach that combines parallel streamline computation with combinatorial methods to construct a high-quality discrete Morse-Smale complex. In addition to being invariant to the orientation of the underlying grid, this algorithm allows users to selectively build a subset of features using high-quality geometry. In particular, a user may specifically select which ascending/descending manifolds are reconstructed with improved accuracy, focusing computational effort where it matters for subsequent analysis. This approach computes Morse-Smale complexes for larger data than previously feasible with significant speedups. We demonstrate and validate our approach using several examples from a variety of different scientific domains, and evaluate the performance of our method.	Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci	Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci	SCI InstituteUniversity of Utah;Lawrence Livermore National Lab;SCI InstituteUniversity of Utah	10.1109/TVCG.2012.209;10.1109/TVCG.2008.110;10.1109/TVCG.2007.70603;10.1109/TVCG.2014.2346434;10.1109/TVCG.2015.2467432;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2011.249;10.1109/TVCG.2015.2467449;10.1109/TVCG.2006.186	Morse complex,Parallel Computation,Topology,Accurate Geometry		3	2	36	
SciVis	2018	Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations	10.1109/TVCG.2018.2864849	http://dx.doi.org/10.1109/TVCG.2018.2864849	1225	1235	J	Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: “Overview first, zoom and filter, then details on demand”. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.	Timothy Luciani;Andrew Thomas Burks;Cassiano Sugiyama;Jonathan Komperda;G. Elisabeta Marai	Timothy Luciani;Andrew Burks;Cassiano Sugiyama;Jonathan Komperda;G. Elisabeta Marai	Electronic Visualization Laboratory, University of Illinois, Chicago;Electronic Visualization Laboratory, University of Illinois, Chicago;Favo Urban Agriculture, Brazil;Department of Mechanical & Industrial Engineering, University of Illinois, Chicago;Electronic Visualization Laboratory, University of Illinois, Chicago	10.1109/TVCG.2007.70599;10.1109/TVCG.2014.2346448;10.1109/TVCG.2015.2466838;10.1109/TVCG.2015.2468093;10.1109/TVCG.2009.141;10.1109/TVCG.2011.209;10.1109/TVCG.2017.2744459;10.1109/TVCG.2013.161;10.1109/TVCG.2014.2346744;10.1109/VAST.2006.261451;10.1109/TVCG.2009.111;10.1109/TVCG.2012.213;10.1109/TVCG.2009.108;10.1109/TVCG.2008.140	theory,visualization design,details-first model,discourse paper,computational fluid dynamics		4	1	72	
SciVis	2018	CPU Isosurface Ray Tracing of Adaptive Mesh Refinement Data	10.1109/TVCG.2018.2864850	http://dx.doi.org/10.1109/TVCG.2018.2864850	1142	1151	J	Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy-the octant method-which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets.	Feng Wang;Ingo Wald;Qi Wu;William Usher;Christopher R. Johnson 0001	Feng Wang;Ingo Wald;Qi Wu;Will Usher;Chris R. Johnson	Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT;Intel Corporation;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT	10.1109/TVCG.2008.157;10.1109/TVCG.2009.149;10.1109/TVCG.2011.252;10.1109/VISUAL.2002.1183820;10.1109/VISUAL.1998.745713;10.1109/TVCG.2007.70566;10.1109/TVCG.2016.2599041	AMR,Isosurface,Ray tracing,Reconstruction strategy,OSPRay	0	1	1	46	
SciVis	2018	Visualization of Large Molecular Trajectories	10.1109/TVCG.2018.2864851	http://dx.doi.org/10.1109/TVCG.2018.2864851	987	996	J	The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback.	David Duran;Pedro Hermosilla;Timo Ropinski;Barbora Kozlíková;Alvar Vinacua;Pere-Pau Vázquez	David Duran;Pedro Hermosilla;Timo Ropinski;Barbora Kozlíková;Álvar Vinacua;Pere-Pau Vázquez	ViRVIG Group, UPC, Barcelona;Visual Computing GroupU. Ulm.;Visual Computing GroupU. Ulm.;Masaryk University;ViRVIG Group, UPC, Barcelona;ViRVIG Group, UPC, Barcelona	10.1109/TVCG.2015.2467434;10.1109/VISUAL.2005.1532792;10.1109/TVCG.2016.2598825;10.1109/TVCG.2016.2598797;10.1109/TVCG.2014.2346574;10.1109/TVCG.2012.225	Molecular visualization,simulation inspection,long trajectories	0	4	1	43	
SciVis	2018	Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images	10.1109/TVCG.2018.2864852	http://dx.doi.org/10.1109/TVCG.2018.2864852	1018	1028	J	Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.	Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie E. Kaufman	Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie Kaufman	Department of Computer ScienceStony Brook University;Department of Computer ScienceStony Brook University;Department of Neurobiology & behaviorStony Brook University;Department of Neurobiology & behaviorStony Brook University;Department of Neurobiology & behaviorStony Brook University;Department of Computer ScienceStony Brook University	10.1109/TVCG.2014.2346312;10.1109/TVCG.2013.142;10.1109/TVCG.2012.203;10.1109/TVCG.2017.2744079;10.1109/TVCG.2009.118;10.1109/TVCG.2016.2598472	Wide-field microscopy,volume visualization,neuron visualization,neuroscience		2	0	58	
SciVis	2018	A Study of the Trade-off Between Reducing Precision and Reducing Resolution for Data Analysis and Visualization	10.1109/TVCG.2018.2864853	http://dx.doi.org/10.1109/TVCG.2018.2864853	1193	1203	J	There currently exist two dominant strategies to reduce data sizes in analysis and visualization: reducing the precision of the data, e.g., through quantization, or reducing its resolution, e.g., by subsampling. Both have advantages and disadvantages and both face fundamental limits at which the reduced information ceases to be useful. The paper explores the additional gains that could be achieved by combining both strategies. In particular, we present a common framework that allows us to study the trade-off in reducing precision and/or resolution in a principled manner. We represent data reduction schemes as progressive streams of bits and study how various bit orderings such as by resolution, by precision, etc., impact the resulting approximation error across a variety of data sets as well as analysis tasks. Furthermore, we compute streams that are optimized for different tasks to serve as lower bounds on the achievable error. Scientific data management systems can use the results presented in this paper as guidance on how to store and stream data to make efficient use of the limited storage and bandwidth in practice.	Duong Hoang;Pavol Klacansky;Harsh Bhatia;Peer-Timo Bremer;Peter Lindstrom;Valerio Pascucci	Duong Hoang;Pavol Klacansky;Harsh Bhatia;Peer-Timo Bremer;Peter Lindstrom;Valerio Pascucci	SCI Institute, University of Utah, USA;SCI Institute, University of Utah, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;SCI Institute, University of Utah, USA	10.1109/TVCG.2009.194;10.1109/TVCG.2007.70516;10.1109/VISUAL.2002.1183757;10.1109/TVCG.2012.240;10.1109/VISUAL.1999.809908;10.1109/TVCG.2014.2346458;10.1109/TVCG.2006.143;10.1109/VISUAL.2004.51;10.1109/VISUAL.2003.1250385;10.1109/TVCG.2011.214;10.1109/TVCG.2012.274;10.1109/TVCG.2015.2467412	data compression,bit ordering,multi-resolution,data analysis		1	0	70	
InfoVis	2018	Face to Face: Evaluating Visual Comparison	10.1109/TVCG.2018.2864884	http://dx.doi.org/10.1109/TVCG.2018.2864884	861	871	J	Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs.	Brian D. Ondov;Nicole Jardine;Niklas Elmqvist;Steven Franconeri	Brian Ondov;Nicole Jardine;Niklas Elmqvist;Steven Franconeri	National Institutes of Health, MD, USA;Northwestern University, Evanston, IL, USA;University of Maryland, College Park, MD, USA;Northwestern University, Evanston, IL, USA	10.1109/TVCG.2017.2744359;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.185;10.1109/TVCG.2015.2466971;10.1109/TVCG.2014.2346424;10.1109/TVCG.2017.2744199;10.1109/TVCG.2014.2346979;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.162;10.1109/TVCG.2017.2744198;10.1109/TVCG.2008.125;10.1109/TVCG.2017.2745140;10.1109/INFVIS.2000.885091	Graphical perception,visual perception,visual comparison,crowdsourced evaluation	0	4	4	70	
VAST	2018	Visual Progression Analysis of Event Sequence Data	10.1109/TVCG.2018.2864885	http://dx.doi.org/10.1109/TVCG.2018.2864885	417	426	J	Event sequence data is common to a broad range of application domains, from security to health care to scholarly communication. This form of data captures information about the progression of events for an individual entity (e.g., a computer network device; a patient; an author) in the form of a series of time-stamped observations. Moreover, each event is associated with an event type (e.g., a computer login attempt, or a hospital discharge). Analyses of event sequence data have been shown to help reveal important temporal patterns, such as clinical paths resulting in improved outcomes, or an understanding of common career trajectories for scholars. Moreover, recent research has demonstrated a variety of techniques designed to overcome methodological challenges such as large volumes of data and high dimensionality. However, the effective identification and analysis of latent stages of progression, which can allow for variation within different but similarly evolving event sequences, remain a significant challenge with important real-world motivations. In this paper, we propose an unsupervised stage analysis algorithm to identify semantically meaningful progression stages as well as the critical events which help define those stages. The algorithm follows three key steps: (1) event representation estimation, (2) event sequence warping and alignment, and (3) sequence segmentation. We also present a novel visualization system, ET<sup>2</sup>, which interactively illustrates the results of the stage analysis algorithm to help reveal evolution patterns across stages. Finally, we report three forms of evaluation for ET<sup>2</sup>: (1) case studies with two real-world datasets, (2) interviews with domain expert users, and (3) a performance evaluation on the progression analysis algorithm and the visualization design.	Shunan Guo;Zhuochen Jin;David Gotz;Fan Du;Hongyuan Zha;Nan Cao	Shunan Guo;Zhuochen Jin;David Gotz;Fan Du;Hongyuan Zha;Nan Cao	East China Normal University;iDVX labTongji University;University of North Carolina, Chapel Hill;University of Maryland;East China Normal University;iDVX labTongji University	10.1109/TVCG.2011.188;10.1109/TVCG.2017.2745278;10.1109/TVCG.2017.2745083;10.1109/VAST.2016.7883512;10.1109/TVCG.2014.2346682;10.1109/TVCG.2017.2745320;10.1109/TVCG.2014.2346574;10.1109/TVCG.2009.187;10.1109/TVCG.2014.2346913	Progression Analysis,Visual Analysis,Event Sequence Data		3	3	49	
VAST	2018	MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration	10.1109/TVCG.2018.2864886	http://dx.doi.org/10.1109/TVCG.2018.2864886	396	406	J	Exploring event sequences by defining queries alone or by using mining algorithms alone is often not sufficient to support analysis. Analysts often interweave querying and mining in a recursive manner during event sequence analysis: sequences extracted as query results are used for mining patterns, patterns generated are incorporated into a new query for segmenting the sequences, and the resulting segments are mined or queried again. To support flexible analysis, we propose a framework that describes the process of interwoven querying and mining. Based on this framework, we developed MAQUI, a Mining And Querying User Interface that enables recursive event sequence exploration. To understand the efficacy of MAQUI, we conducted two case studies with domain experts. The findings suggest that the capability of interweaving querying and mining helps the participants articulate their questions and gain novel insights from their data.	Po-Ming Law;Zhicheng Liu;Sana Malik;Rahul C. Basole	Po-Ming Law;Zhicheng Liu;Sana Malik;Rahul C. Basole	Georgia Institute of Technology;Adobe Research;Adobe Research;Georgia Institute of Technology	10.1109/TVCG.2017.2745278;10.1109/TVCG.2017.2745083;10.1109/VAST.2016.7883512;10.1109/VAST.2006.261421;10.1109/TVCG.2017.2744199;10.1109/TVCG.2014.2346682;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346452;10.1109/TVCG.2016.2598797;10.1109/TVCG.2013.200;10.1109/VAST.2015.7347682;10.1109/TVCG.2014.2346574;10.1109/TVCG.2009.117;10.1109/VAST.2009.5332595	Sequential pattern mining,temporal query,event sequence exploration		5	3	46	
VAST	2018	InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming	10.1109/TVCG.2018.2864887	http://dx.doi.org/10.1109/TVCG.2018.2864887	277	287	J	Prewriting is the process of generating and organizing ideas before drafting a document. Although often overlooked by novice writers and writing tool developers, prewriting is a critical process that improves the quality of a final document. To better understand current prewriting practices, we first conducted interviews with writing learners and experts. Based on the learners' needs and experts' recommendations, we then designed and developed InkPlanner, a novel pen and touch visualization tool that allows writers to utilize visual diagramming for ideation during prewriting. InkPlanner further allows writers to sort their ideas into a logical and sequential narrative by using a novel widget- NarrativeLine. Using a NarrativeLine, InkPlanner can automatically generate a document outline to guide later drafting exercises. Inkplanner is powered by machine-generated semantic and structural suggestions that are curated from various texts. To qualitatively review the tool and understand how writers use InkPlanner for prewriting, two writing experts were interviewed and a user study was conducted with university students. The results demonstrated that InkPlanner encouraged writers to generate more diverse ideas and also enabled them to think more strategically about how to organize their ideas for later drafting.	Zhicong Lu;Mingming Fan 0001;Yun Wang;Jian Zhao 0010;Michelle Annett;Daniel J. Wigdor	Zhicong Lu;Mingming Fan;Yun Wang;Jian Zhao;Michelle Annett;Daniel Wigdor	University of Toronto;University of Toronto;Hong Kong University of Science and Technology;FX Palo Alto Laboratory;MishMashMakers;University of Toronto	10.1109/TVCG.2013.191	Writing,prewriting,diagraming,content and structure recommendation,pen and touch interfaces	0	2	2	60	
InfoVis	2018	In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation	10.1109/TVCG.2018.2864889	http://dx.doi.org/10.1109/TVCG.2018.2864889	903	913	J	Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.	Jessica Hullman;Xiaoli Qiao;Michael Correll;Alex Kale;Matthew Kay	Jessica Hullman;Xiaoli Qiao;Michael Correll;Alex Kale;Matthew Kay	Northwestern University;University of Washington;Tableau Software;University of Washington;University of Michigan	10.1109/TVCG.2015.2467752;10.1109/TVCG.2017.2743898;10.1109/TVCG.2013.126;10.1109/TVCG.2007.70530;10.1109/TVCG.2007.70518;10.1109/TVCG.2009.111	Uncertainty visualization,user study,subjective confidence,probability distribution	0	6	2	94	
InfoVis	2018	iStoryline: Effective Convergence to Hand-drawn Storylines	10.1109/TVCG.2018.2864899	http://dx.doi.org/10.1109/TVCG.2018.2864899	769	778	J	Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes (1) how artists utilize narrative elements and (2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations.	Tan Tang;Sadia Rubab;Jiewen Lai;Weiwei Cui;Lingyun Yu;Yingcai Wu	Tan Tang;Sadia Rubab;Jiewen Lai;Weiwei Cui;Lingyun Yu;Yingcai Wu	State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies;State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies;State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies;Microsoft Research;Bernoulli Institute, University of Groningen, Netherlands;State Key Lab of CAD&CGZhejiang UniversityAlibaba-Zhejiang UniversityJoint Institute of Frontier Technologies	10.1109/TVCG.2016.2598647;10.1109/VAST.2017.8585487;10.1109/TVCG.2017.2743990;10.1109/TVCG.2009.109;10.1109/TVCG.2015.2467531;10.1109/TVCG.2015.2467451;10.1109/TVCG.2016.2598620;10.1109/TVCG.2013.191;10.1109/TVCG.2016.2598831;10.1109/TVCG.2013.196;10.1109/TVCG.2014.2346291;10.1109/TVCG.2017.2745878;10.1109/TVCG.2012.212;10.1109/TVCG.2014.2346913	Hand-drawn illustrations,automatic layout,design space,interactions,optimization	0	0	0	44	
VAST	2018	Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities	10.1109/TVCG.2018.2864901	http://dx.doi.org/10.1109/TVCG.2018.2864901	98	108	J	Ensemble sensitivity analysis (ESA) has been established in the atmospheric sciences as a correlation-based approach to determine the sensitivity of a scalar forecast quantity computed by a numerical weather prediction model to changes in another model variable at a different model state. Its applications include determining the origin of forecast errors and placing targeted observations to improve future forecasts. We - a team of visualization scientists and meteorologists - present a visual analysis framework to improve upon current practice of ESA. We support the user in selecting regions to compute a meaningful target forecast quantity by embedding correlation-based grid-point clustering to obtain statistically coherent regions. The evolution of sensitivity features computed via ESA are then traced through time, by integrating a quantitative measure of feature matching into optical-flow-based feature assignment, and displayed by means of a swipe-path showing the geo-spatial evolution of the sensitivities. Visualization of the internal correlation structure of computed features guides the user towards those features robustly predicting a certain weather event. We demonstrate the use of our method by application to real-world 2D and 3D cases that occurred during the 2016 NAWDEX field campaign, showing the interactive generation of hypothesis chains to explore how atmospheric processes sensitive to each other are interrelated.	Alexander Kumpf;Marc Rautenhaus;Michael Riemer;Rüdiger Westermann	Alexander Kumpf;Marc Rautenhaus;Michael Riemer;Rüdiger Westermann	Computer Graphics & Visualization Group, Technische Universitiit München, Garching, Germany;Computer Graphics & Visualization Group, Technische Universitiit München, Garching, Germany;Universität Hamburg, Regional Computing Center, Hamburg, Germany;Computer Graphics & Visualization Group, Technische Universitiit München, Garching, Germany	10.1109/TVCG.2013.131;10.1109/VISUAL.2004.46;10.1109/TVCG.2017.2743989;10.1109/TVCG.2017.2745178;10.1109/TVCG.2006.165	Correlation,clustering,tracking,ensemble visualization	0	4	0	47	
InfoVis	2018	What Do We Talk About When We Talk About Dashboards?	10.1109/TVCG.2018.2864903	http://dx.doi.org/10.1109/TVCG.2018.2864903	682	692	J	Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation and use.	Alper Sarikaya;Michael Correll;Lyn Bartram;Melanie Tory;Danyel Fisher	Alper Sarikaya;Michael Correll;Lyn Bartram;Melanie Tory;Danyel Fisher	Microsoft Corporation;Tableau Research;Simon Fraser University;Tableau Research;Honeycomb.io	10.1109/TVCG.2013.124;10.1109/TVCG.2017.2744198;10.1109/TVCG.2013.120	Dashboards,literature review,survey,design space,open coding	0	17	1	66	
VAST	2018	Doccurate: A Curation-Based Approach for Clinical Text Visualization	10.1109/TVCG.2018.2864905	http://dx.doi.org/10.1109/TVCG.2018.2864905	142	151	J	Before seeing a patient, physicians seek to obtain an overview of the patient's medical history. Text plays a major role in this activity since it represents the bulk of the clinical documentation, but reviewing it quickly becomes onerous when patient charts grow too large. Text visualization methods have been widely explored to manage this large scale through visual summaries that rely on information retrieval algorithms to structure text and make it amenable to visualization. However, the integration with such automated approaches comes with a number of limitations, including significant error rates and the need for healthcare providers to fine-tune algorithms without expert knowledge of their inner mechanics. In addition, several of these approaches obscure or substitute the original clinical text and therefore fail to leverage qualitative and rhetorical flavours of the clinical notes. These drawbacks have limited the adoption of text visualization and other summarization technologies in clinical practice. In this work we present Doccurate, a novel system embodying a curation-based approach for the visualization of large clinical text datasets. Our approach offers automation auditing and customizability to physicians while also preserving and extensively linking to the original text. We discuss findings of a formal qualitative evaluation conducted with 6 domain experts, shedding light onto physicians' information needs, perceived strengths and limitations of automated tools, and the importance of customization while balancing efficiency. We also present use case scenarios to showcase Doccurate's envisioned usage in practice.	Nicole Sultanum;Devin Singh;Michael Brudno;Fanny Chevalier	Nicole Sultanum;Devin Singh;Michael Brudno;Fanny Chevalier	Hospital for Sick Children;Hospital for Sick Children;University of Toronto;University of Toronto	10.1109/VAST.2012.6400485;10.1109/TVCG.2015.2467531;10.1109/TVCG.2017.2745118;10.1109/INFVIS.2000.885098;10.1109/TVCG.2017.2744478;10.1109/TVCG.2015.2467591	Visual Curation,Clinical Text,Text Visualization,Medical Narrative		3	2	40	
InfoVis	2018	Looks Good To Me: Visualizations As Sanity Checks	10.1109/TVCG.2018.2864907	http://dx.doi.org/10.1109/TVCG.2018.2864907	830	839	J	Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.	Michael Correll;Mingwei Li;Gordon L. Kindlmann;Carlos Scheidegger	Michael Correll;Mingwei Li;Gordon Kindlmann;Carlos Scheidegger	Tableau Research;University of Arizona;University of Chicago;University of Arizona	10.1109/TVCG.2016.2598862;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346298;10.1109/VAST.2016.7883519;10.1109/TVCG.2016.2598618;10.1109/TVCG.2014.2346978;10.1109/TVCG.2014.2346979;10.1109/TVCG.2012.230;10.1109/TVCG.2014.2346325;10.1109/TVCG.2016.2599030;10.1109/TVCG.2017.2744359;10.1109/TVCG.2015.2469125;10.1109/TVCG.2010.161;10.1109/TVCG.2015.2467191	Graphical perception,data quality,univariate visualizations	0	2	2	51	
InfoVis	2018	Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data	10.1109/TVCG.2018.2864909	http://dx.doi.org/10.1109/TVCG.2018.2864909	892	902	J	Animated representations of outcomes drawn from distributions (hypothetical outcome plots, or HOPs) are used in the media and other public venues to communicate uncertainty. HOPs greatly improve multivariate probability estimation over conventional static uncertainty visualizations and leverage the ability of the visual system to quickly, accurately, and automatically process the summary statistical properties of ensembles. However, it is unclear how well HOPs support applied tasks resembling real world judgments posed in uncertainty communication. We identify and motivate an appropriate task to investigate realistic judgments of uncertainty in the public domain through a qualitative analysis of uncertainty visualizations in the news. We contribute two crowdsourced experiments comparing the effectiveness of HOPs, error bars, and line ensembles for supporting perceptual decision-making from visualized uncertainty. Participants infer which of two possible underlying trends is more likely to have produced a sample of time series data by referencing uncertainty visualizations which depict the two trends with variability due to sampling error. By modeling each participant's accuracy as a function of the level of evidence presented over many repeated judgments, we find that observers are able to correctly infer the underlying trend in samples conveying a lower level of evidence when using HOPs rather than static aggregate uncertainty visualizations as a decision aid. Modeling approaches like ours contribute theoretically grounded and richly descriptive accounts of user perceptions to visualization evaluation.	Alex Kale;Francis Nguyen;Matthew Kay;Jessica Hullman	Alex Kale;Francis Nguyen;Matthew Kay;Jessica Hullman	University of Washington;University of Washington;University of Michigan;Northwestern University	10.1109/TVCG.2017.2743898;10.1109/TVCG.2007.70518;10.1109/TVCG.2017.2744359	uncertainty visualization,hypothetical outcome plots,psychometric functions	0	7	2	66	
InfoVis	2018	Structure-aware Fisheye Views for Efficient Large Graph Exploration	10.1109/TVCG.2018.2864911	http://dx.doi.org/10.1109/TVCG.2018.2864911	566	575	J	Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for structure-aware fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance.	Yunhai Wang;Yanyan Wang;Haifeng Zhang;Yinqi Sun;Chi-Wing Fu;Michael Sedlmair;Baoquan Chen;Oliver Deussen	Yunhai Wang;Yanyan Wang;Haifeng Zhang;Yinqi Sun;Chi-Wing Fu;Michael Sedlmair;Baoquan Chen;Oliver Deussen	Shandong University;Shandong University;Shandong University;Shandong University;Chinese University of Hong Kong;VISUSUniversity of Stuttgart;Peking University;Konstanz University, Germany	10.1109/TVCG.2015.2467035;10.1109/INFVIS.2005.1532130;10.1109/TVCG.2006.156;10.1109/TVCG.2008.130;10.1109/INFVIS.2004.66;10.1109/TVCG.2011.223;10.1109/TVCG.2009.108;10.1109/TVCG.2007.70577;10.1109/TVCG.2017.2745919;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2012.189	Graph Visualization,Focus-Context Technique,Structure-aware Zoom,Graph Layout Technique	0	2	2	56	
InfoVis	2018	Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots	10.1109/TVCG.2018.2864912	http://dx.doi.org/10.1109/TVCG.2018.2864912	820	829	J	Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top K suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods.	Yunhai Wang;Xin Chen;Tong Ge;Chen Bao;Michael Sedlmair;Chi-Wing Fu;Oliver Deussen;Baoquan Chen	Yunhai Wang;Xin Chen;Tong Ge;Chen Bao;Michael Sedlmair;Chi-Wing Fu;Oliver Deussen;Baoquan Chen	Shandong University;Shandong University;Shandong University;Shandong University;VISUS, University of Stuttgart, Germany;Chinese University, Hong Kong;Konstanz University, Germany;Peking University	10.1109/VISUAL.1995.480803;10.1109/TVCG.2016.2599214;10.1109/TVCG.2013.183;10.1109/TVCG.2016.2598918;10.1109/VISUAL.1996.568118;10.1109/TVCG.2017.2744184;10.1109/TVCG.2013.153;10.1109/TVCG.2015.2467471;10.1109/TVCG.2017.2744359;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.118	Color perception,visual design,scatterplots	0	1	5	50	
InfoVis	2018	A Framework for Externalizing Implicit Error Using Visualization	10.1109/TVCG.2018.2864913	http://dx.doi.org/10.1109/TVCG.2018.2864913	925	935	J	This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isn't explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.	Nina McCurdy;Julie Gerdes;Miriah D. Meyer	Nina Mccurdy;Julie Gerdes;Miriah Meyer	University of UtahSchool of Computing;Texas Tech UniversityCollege of Arts … Sciences;University of UtahSchool of Computing	10.1109/VAST.2011.6102457;10.1109/VAST.2010.5652885;10.1109/TVCG.2017.2743898;10.1109/TVCG.2017.2745240;10.1109/INFVIS.2005.1532134;10.1109/TVCG.2015.2467551;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2007.70577;10.1109/TVCG.2013.132;10.1109/TVCG.2007.70589;10.1109/TVCG.2016.2598543	implicit error,knowledge externalization,design study	0	4	5	75	
InfoVis	2018	Where's My Data? Evaluating Visualizations with Missing Data	10.1109/TVCG.2018.2864914	http://dx.doi.org/10.1109/TVCG.2018.2864914	914	924	J	Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.	Hayeong Song;Danielle Albers Szafir	Hayeong Song;Danielle Albers Szafir	University of Colorado;University of Colorado	10.1109/TVCG.2016.2598592;10.1109/VAST.2015.7347672;10.1109/TVCG.2011.185;10.1109/TVCG.2012.220;10.1109/TVCG.2014.2346298;10.1109/VISUAL.1999.809916;10.1109/TVCG.2013.183;10.1109/TVCG.2015.2467752;10.1109/TVCG.2015.2467951;10.1109/TVCG.2012.279;10.1109/TVCG.2015.2467591;10.1109/TVCG.2012.256;10.1109/VISUAL.1994.346317;10.1109/TVCG.2012.262;10.1109/VAST.2006.261424	Information Visualization,Graphical Perception,Time Series Data,Data Wrangling,Imputation		6	1	57	
VAST	2018	TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis	10.1109/TVCG.2018.2865018	http://dx.doi.org/10.1109/TVCG.2018.2865018	1	11	J	Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype.	Dongyu Liu;Panpan Xu;Liu Ren	Dongyu Liu;Panpan Xu;Liu Ren	Hong Kong University of Science and Technology;Bosch Research North America, Sunnyvale, CA;Bosch Research North America, Sunnyvale, CA	10.1109/TVCG.2016.2598862;10.1109/TVCG.2017.2744419;10.1109/TVCG.2006.161;10.1109/TVCG.2014.2346449;10.1109/TVCG.2013.226;10.1109/TVCG.2013.179;10.1109/TVCG.2016.2598432;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598624;10.1109/TVCG.2017.2744805;10.1109/TVCG.2015.2467112;10.1109/TVCG.2014.2346574;10.1109/INFVIS.2003.1249018;10.1109/INFVIS.1999.801851;10.1109/TVCG.2015.2468111;10.1109/TVCG.2018.2865126;10.1109/TVCG.2007.70515	Spatio-temporal data,tensor decomposition,interactive exploration,automatic pattern discoveries	0	13	2	67	BP
VAST	2018	Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters	10.1109/TVCG.2018.2865020	http://dx.doi.org/10.1109/TVCG.2018.2865020	12	21	J	Fuzzy clustering assigns a probability of membership for a datum to a cluster, which veritably reflects real-world clustering scenarios but significantly increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that visualization techniques for multi-dimensional data are beneficial to understand fuzzy clusters. However, no empirical evidence exists on the effectiveness and efficiency of these visualization techniques in solving analytical tasks featured by fuzzy clusters. In this paper, we conduct a controlled experiment to evaluate the ability of fuzzy clusters analysis to use four multi-dimensional visualization techniques, namely, parallel coordinate plot, scatterplot matrix, principal component analysis, and Radviz. First, we define the analytical tasks and their representative questions specific to fuzzy clusters analysis. Then, we design objective questionnaires to compare the accuracy, time, and satisfaction in using the four techniques to solve the questions. We also design subjective questionnaires to collect the experience of the volunteers with the four techniques in terms of ease of use, informativeness, and helpfulness. With a complete experiment process and a detailed result analysis, we test against four hypotheses that are formulated on the basis of our experience, and provide instructive guidance for analysts in selecting appropriate and efficient visualization techniques to analyze fuzzy clusters.	Ying Zhao 0001;Feng Luo;Minghui Chen;Yingchao Wang;Jiazhi Xia;Fangfang Zhou;Yunhai Wang;Yi Chen 0007;Wei Chen 0001	Ying Zhao;Feng Luo;Minghui Chen;Yingchao Wang;Jiazhi Xia;Fangfang Zhou;Yunhai Wang;Yi Chen;Wei Chen	Central South University;Central South University;Central South University;Central South University;Central South University;Central South University;Shandong University;Beijing TechnologyBusiness University;State Key Lab of CAD & CGZhejiang University	10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729559;10.1109/TVCG.2017.2745138;10.1109/VAST.2010.5652450;10.1109/VISUAL.1997.663916;10.1109/TVCG.2009.153;10.1109/TVCG.2016.2598831;10.1109/INFVIS.2004.15;10.1109/TVCG.2017.2744198;10.1109/TVCG.2015.2467324;10.1109/TVCG.2013.153;10.1109/TVCG.2008.173;10.1109/VISUAL.1990.146375;10.1109/TVCG.2017.2744098;10.1109/TVCG.2016.2598479;10.1109/INFVIS.2003.1249015	Evaluation,multi-dimensional visualization,fuzzy clustering,parallel coordinate plot,scatterplot matrix,principal component analysis,radviz	0	16	6	63	
VAST	2018	GraphProtector: A Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms	10.1109/TVCG.2018.2865021	http://dx.doi.org/10.1109/TVCG.2018.2865021	193	203	J	Analyzing social networks reveals the relationships between individuals and groups in the data. However, such analysis can also lead to privacy exposure (whether intentionally or inadvertently): leaking the real-world identity of ostensibly anonymous individuals. Most sanitization strategies modify the graph's structure based on hypothesized tactics that an adversary would employ. While combining multiple anonymization schemes provides a more comprehensive privacy protection, deciding the appropriate set of techniques-along with evaluating how applying the strategies will affect the utility of the anonymized results-remains a significant challenge. To address this problem, we introduce GraphProtector, a visual interface that guides a user through a privacy preservation pipeline. GraphProtector enables multiple privacy protection schemes which can be simultaneously combined together as a hybrid approach. To demonstrate the effectiveness of GraphPro tector, we report several case studies and feedback collected from interviews with expert users in various scenarios.	Xu-Meng Wang;Wei Chen 0001;Jia-Kai Chou;Chris Bryan;Huihua Guan;Wenlong Chen;Rusheng Pan;Kwan-Liu Ma	Xumeng Wang;Wei Chen;Jia-Kai Chou;Chris Bryan;Huihua Guan;Wenlong Chen;Rusheng Pan;Kwan-Liu Ma	Zhejiang University;Zhejiang University;University of California, Davis;University of California, Davis;Zhejiang UniversityAlibaba Group;Zhejiang University;Zhejiang University;University of California, Davis	10.1109/TVCG.2011.163;10.1109/TVCG.2017.2745139;10.1109/TVCG.2014.2346920	Graph privacy,k-anonymity,structural features,privacy preservation	0	3	1	57	
VAST	2018	VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization	10.1109/TVCG.2018.2865022	http://dx.doi.org/10.1109/TVCG.2018.2865022	152	161	J	Publication records and collaboration networks are important for assessing the expertise and experience of researchers. Existing digital libraries show the raw publication lists in author profiles, whereas visualization techniques focus on specific subproblems. Instead, we look at publication records from various perspectives mixing low-level publication data with high-level abstractions and background information. This work presents VIS Author Profiles, a novel approach to generate integrated textual and visual descriptions to highlight patterns in publication records. We leverage template-based natural language generation to summarize notable publication statistics, evolution of research topics, and collaboration relationships. Seamlessly integrated visualizations augment the textual description and are interactively connected with each other and the text. The underlying publication data and detailed explanations of the analysis are available on demand. We compare our approach to existing systems by taking into account information needs of users and demonstrate its usefulness in two realistic application examples.	Shahid Latif;Fabian Beck 0001	Shahid Latif;Fabian Beck	Paluno, University of Duisburg, Essen, Germany;Paluno, University of Duisburg, Essen, Germany	10.1109/TVCG.2015.2467757;10.1109/TVCG.2012.252;10.1109/TVCG.2014.2346435;10.1109/TVCG.2007.70582;10.1109/VAST.2015.7347632;10.1109/TVCG.2015.2468151;10.1109/TVCG.2013.167	Natural language generation,document visualization,interactive documents,sparklines,digital libraries		4	2	36	
VAST	2018	Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities	10.1109/TVCG.2018.2865023	http://dx.doi.org/10.1109/TVCG.2018.2865023	225	234	J	The forensic investigation of communication datasets which contain unstructured text, social network information, and metadata is a complex task that is becoming more important due to the immense amount of data being collected. Currently there are limited approaches that allow an investigator to explore the network, text and metadata in a unified manner. We developed Beagle as a forensic tool for email datasets that allows investigators to flexibly form complex queries in order to discover important information in email data. Beagle was successfully deployed at a security firm which had a large email dataset that was difficult to properly investigate. We discuss our experience developing Beagle as well as the lessons we learned applying visual analytic techniques to a difficult real-world problem.	Jay Koven;Cristian Felix;Hossein Siadati;Markus Jakobsson;Enrico Bertini	Jay Koven;Cristian Felix;Hossein Siadati;Markus Jakobsson;Enrico Bertini	NYU Tandon School of Engineering;NYU Tandon School of Engineering;NYU Tandon School of Engineering;Amber Solutions Inc.;NYU Tandon School of Engineering	10.1109/VAST.2007.4389011;10.1109/VAST.2010.5652968;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2009.111;10.1109/TVCG.2014.2346481;10.1109/TVCG.2012.213	Visual Analytics,Email Investigation,Email Forensics	0	1	0	26	
VAST	2018	KnowledgePearls: Provenance-Based Visualization Retrieval	10.1109/TVCG.2018.2865024	http://dx.doi.org/10.1109/TVCG.2018.2865024	120	130	J	Storing analytical provenance generates a knowledge base with a large potential for recalling previous results and guiding users in future analyses. However, without extensive manual creation of meta information and annotations by the users, search and retrieval of analysis states can become tedious. We present KnowledgePearls, a solution for efficient retrieval of analysis states that are structured as provenance graphs containing automatically recorded user interactions and visualizations. As a core component, we describe a visual interface for querying and exploring analysis states based on their similarity to a partial definition of a requested analysis state. Depending on the use case, this definition may be provided explicitly by the user by formulating a search query or inferred from given reference states. We explain our approach using the example of efficient retrieval of demographic analyses by Hans Rosling and discuss our implementation for a fast look-up of previous states. Our approach is independent of the underlying visualization framework. We discuss the applicability for visualizations which are based on the declarative grammar Vega and we use a Vega-based implementation of Gapminder as guiding example. We additionally present a biomedical case study to illustrate how KnowledgePearls facilitates the exploration process by recalling states from earlier analyses.	Holger Stitz;Samuel Gratzl;Harald Piringer;Thomas Zichner;Marc Streit	Holger Stitz;Samuel Gratzl;Harald Piringer;Thomas Zichner;Marc Streit	Johannes Kepler University, Linz, Austria;Johannes Kepler University, Linz, Austria;VRVis Research Center, Austria;Boehringer Ingelheim RCV GmbH & Co KG, Austria;Johannes Kepler University, Linz, Austria	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.229;10.1109/TVCG.2013.155;10.1109/TVCG.2009.176;10.1109/VAST.2008.4677365;10.1109/INFVIS.2004.2;10.1109/TVCG.2012.271;10.1109/TVCG.2016.2598589;10.1109/TVCG.2017.2744320;10.1109/TVCG.2015.2467551;10.1109/TVCG.2016.2599030;10.1109/TVCG.2015.2467091;10.1109/TVCG.2006.142;10.1109/TVCG.2017.2745219;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2005.1532142	Visualization provenance,interaction provenance,retrieval	0	2	2	47	
VAST	2018	An Information-Theoretic Approach to the Cost-benefit Analysis of Visualization in Virtual Environments	10.1109/TVCG.2018.2865025	http://dx.doi.org/10.1109/TVCG.2018.2865025	32	42	J	Visualization and virtual environments (VEs) have been two interconnected parallel strands in visual computing for decades. Some VEs have been purposely developed for visualization applications, while many visualization applications are exemplary showcases in general-purpose VEs. Because of the development and operation costs of VEs, the majority of visualization applications in practice have yet to benefit from the capacity of VEs. In this paper, we examine this status quo from an information-theoretic perspective. Our objectives are to conduct cost-benefit analysis on typical VE systems (including augmented and mixed reality, theater-based systems, and large powerwalls), to explain why some visualization applications benefit more from VEs than others, and to sketch out pathways for the future development of visualization applications in VEs. We support our theoretical propositions and analysis using theories and discoveries in the literature of cognitive sciences and the practical evidence reported in the literatures of visualization and VEs.	Min Chen 0001;Kelly P. Gaither;Nigel W. John;Brian McCann	Min Chen;Kelly Gaither;Nigel W. John;Brian Mccann	University of Oxford, UK;University of Texas, Austin, USA;University of Chester, UK;University of Texas, Austin, USA	10.1109/TVCG.2010.131;10.1109/TVCG.2008.142;10.1109/TVCG.2011.231;10.1109/TVCG.2014.2346325;10.1109/TVCG.2013.127;10.1109/TVCG.2016.2598829;10.1109/INFVIS.2004.59;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2010.131;10.1109/TVCG.2006.184	Theory of visualization,virtual environments,four levels of visualization,virtual reality,augmented reality,mixed reality,cost-benefit analysis,information theory,cognitive sciences,visualization applications,immersive analytics	0	2	1	119	
VAST	2018	A Visual Analytics Framework for the Detection of Anomalous Call Stack Trees in High Performance Computing Applications	10.1109/TVCG.2018.2865026	http://dx.doi.org/10.1109/TVCG.2018.2865026	215	224	J	Anomalous runtime behavior detection is one of the most important tasks for performance diagnosis in High Performance Computing (HPC). Most of the existing methods find anomalous executions based on the properties of individual functions, such as execution time. However, it is insufficient to identify abnormal behavior without taking into account the context of the executions, such as the invocations of children functions and the communications with other HPC nodes. We improve upon the existing anomaly detection approaches by utilizing the call stack structures of the executions, which record rich temporal and contextual information. With our call stack tree (CSTree) representation of the executions, we formulate the anomaly detection problem as finding anomalous tree structures in a call stack forest. The CSTrees are converted to vector representations using our proposed stack2vec embedding. Structural and temporal visualizations of CSTrees are provided to support users in the identification and verification of the anomalies during an active anomaly detection process. Three case studies of real-world HPC applications demonstrate the capabilities of our approach.	Cong Xie;Wei Xu;Klaus Mueller	Cong Xie;Wei Xu;Klaus Mueller	Department of Computer ScienceStony Brook University;Computational Science InitiativeBrookhaven National Laboratory;Department of Computer ScienceStony Brook University	10.1109/TVCG.2015.2467552;10.1109/TVCG.2012.277;10.1109/VAST.2016.7883514;10.1109/TVCG.2016.2598664	Call Stack,Performance Visualization,Representation Learning,Active Learning,Anomaly Detection	0	6	5	55	HM
VAST	2018	RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records	10.1109/TVCG.2018.2865027	http://dx.doi.org/10.1109/TVCG.2018.2865027	299	309	J	We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.	Bum Chul Kwon;Min-Je Choi;Joanne Taery Kim;Edward Choi;Young Bin Kim;Soonwook Kwon;Jimeng Sun;Jaegul Choo	Bum Chul Kwon;Min-Je Choi;Joanne Taery Kim;Edward Choi;Young Bin Kim;Soonwook Kwon;Jimeng Sun;Jaegul Choo	IBM T.J. Watson Research CenterKorea University;Georgia Institute of Technology;Georgia Institute of Technology;Chung-Ang University;IBM T.J. Watson Research CenterKorea University;Catholic University, Daegu;IBM T.J. Watson Research CenterKorea University;Georgia Institute of Technology	10.1109/TVCG.2013.212;10.1109/TVCG.2017.2745080;10.1109/TVCG.2012.277;10.1109/TVCG.2017.2744718;10.1109/TVCG.2017.2745085;10.1109/TVCG.2016.2598446;10.1109/TVCG.2015.2467555;10.1109/TVCG.2016.2598831;10.1109/VAST.2017.8585721;10.1109/TVCG.2017.2744358;10.1109/TVCG.2016.2598838;10.1109/TVCG.2012.213;10.1109/TVCG.2017.2744158;10.1109/TVCG.2017.2744878	Interactive Artificial Intelligence,XAI (Explainable Artificial Intelligence),Interpretable Deep Learning,Healthcare	0	18	6	85	
VAST	2018	Vulnus: Visual Vulnerability Analysis for Network Security	10.1109/TVCG.2018.2865028	http://dx.doi.org/10.1109/TVCG.2018.2865028	183	192	J	Vulnerabilities represent one of the main weaknesses of IT systems and the availability of consolidated official data, like CVE (Common Vulnerabilities and Exposures), allows for using them to compute the paths an attacker is likely to follow. However, even if patches are available, business constraints or lack of resources create obstacles to their straightforward application. As a consequence, the security manager of a network needs to deal with a large number of vulnerabilities, making decisions on how to cope with them. This paper presents VULNUS (VULNerabilities visUal aSsessment), a visual analytics solution for dynamically inspecting the vulnerabilities spread on networks, allowing for a quick understanding of the network status and visually classifying nodes according to their vulnerabilities. Moreover, VULNUS computes the approximated optimal sequence of patches able to eliminate all the attack paths and allows for exploring sub-optimal patching strategies, simulating the effect of removing one or more vulnerabilities. VULNUS has been evaluated by domain experts using a lab-test experiment, investigating the effectiveness and efficiency of the proposed solution.	Marco Angelini;Graziano Blasilli;Tiziana Catarci;Simone Lenti;Giuseppe Santucci	Marco Angelini;Graziano Blasilli;Tiziana Catarci;Simone Lenti;Giuseppe Santucci	University of Rome “La Sapienza”;University of Rome “La Sapienza”;University of Rome “La Sapienza”;University of Rome “La Sapienza”;University of Rome “La Sapienza”	10.1109/TVCG.2007.70540;10.1109/TVCG.2007.70522;10.1109/INFVIS.2001.963283	Visual Analytics,Network security,Vulnerability analysis,CVE,CVSS,Attack Graph,Vulnerability triage and management	0	3	3	46	
VAST	2018	Situ: Identifying and Explaining Suspicious Behavior in Networks	10.1109/TVCG.2018.2865029	http://dx.doi.org/10.1109/TVCG.2018.2865029	204	214	J	Despite the best efforts of cyber security analysts, networked computing assets are routinely compromised, resulting in the loss of intellectual property, the disclosure of state secrets, and major financial damages. Anomaly detection methods are beneficial for detecting new types of attacks and abnormal network activity, but such algorithms can be difficult to understand and trust. Network operators and cyber analysts need fast and scalable tools to help identify suspicious behavior that bypasses automated security systems, but operators do not want another automated tool with algorithms they do not trust. Experts need tools to augment their own domain expertise and to provide a contextual understanding of suspicious behavior to help them make decisions. In this paper we present Situ, a visual analytics system for discovering suspicious behavior in streaming network data. Situ provides a scalable solution that combines anomaly detection with information visualization. The system's visualizations enable operators to identify and investigate the most anomalous events and IP addresses, and the tool provides context to help operators understand why they are anomalous. Finally, operators need tools that can be integrated into their workflow and with their existing tools. This paper describes the Situ platform and its deployment in an operational network setting. We discuss how operators are currently using the tool in a large organization's security operations center and present the results of expert reviews with professionals.	John R. Goodall;Eric D. Ragan;Chad A. Steed;Joel W. Reed;G. David Richardson;Kelly M. T. Huffer;Robert A. Bridges;Jason A. Laska	John R. Goodall;Eric D. Ragan;Chad A. Steed;Joel W. Reed;G. David Richardson;Kelly M.T. Huffer;Robert A. Bridges;Jason A. Laska	Oak Ridge National Laboratory;University of Florida;Oak Ridge National Laboratory;Oak Ridge National Laboratory;Oak Ridge National Laboratory;Oak Ridge National Laboratory;Oak Ridge National Laboratory;Oak Ridge National Laboratory	10.1109/TVCG.2007.70589	Network security,situational awareness,privacy and security,streaming data,machine learning,visualization	0	3	3	55	
VAST	2018	Enhancing Web-based Analytics Applications through Provenance	10.1109/TVCG.2018.2865039	http://dx.doi.org/10.1109/TVCG.2018.2865039	131	141	J	Visual analytics systems continue to integrate new technologies and leverage modern environments for exploration and collaboration, making tools and techniques available to a wide audience through web browsers. Many of these systems have been developed with rich interactions, offering users the opportunity to examine details and explore hypotheses that have not been directly encoded by a designer. Understanding is enhanced when users can replay and revisit the steps in the sensemaking process, and in collaborative settings, it is especially important to be able to review not only the current state but also what decisions were made along the way. Unfortunately, many web-based systems lack the ability to capture such reasoning, and the path to a result is transient, forgotten when a user moves to a new view. This paper explores the requirements to augment existing client-side web applications with support for capturing, reviewing, sharing, and reusing steps in the reasoning process. Furthermore, it considers situations where decisions are made with streaming data, and the insights gained from revisiting those choices when more data is available. It presents a proof of concept, the Shareable Interactive Manipulation Provenance framework (SIMProv.js), that addresses these requirements in a modern, client-side JavaScript library, and describes how it can be integrated with existing frameworks.	Akhilesh Camisetty;Chaitanya Chandurkar;Maoyuan Sun;David Koop	Akhilesh Camisetty;Chaitanya Chandurkar;Maoyuan Sun;David Koop	UMass Dartmouth;UMass Dartmouth;UMass Dartmouth;UMass Dartmouth	10.1109/VISUAL.1993.398857;10.1109/VAST.2011.6102447;10.1109/VAST.2010.5652932;10.1109/TVCG.2016.2598471;10.1109/TVCG.2016.2599058;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.197;10.1109/VAST.2007.4389011;10.1109/VISUAL.1999.809871;10.1109/TVCG.2014.2346573;10.1109/TVCG.2015.2467551;10.1109/TVCG.2015.2467191;10.1109/TVCG.2017.2745279	Collaboration,provenance,streaming data,history,web	0	1	0	60	
VAST	2018	Futzing and Moseying: Interviews with Professional Data Analysts on Exploration Practices	10.1109/TVCG.2018.2865040	http://dx.doi.org/10.1109/TVCG.2018.2865040	22	31	J	We report the results of interviewing thirty professional data analysts working in a range of industrial, academic, and regulatory environments. This study focuses on participants' descriptions of exploratory activities and tool usage in these activities. Highlights of the findings include: distinctions between exploration as a precursor to more directed analysis versus truly open-ended exploration; confirmation that some analysts see “finding something interesting” as a valid goal of data exploration while others explicitly disavow this goal; conflicting views about the role of intelligent tools in data exploration; and pervasive use of visualization for exploration, but with only a subset using direct manipulation interfaces. These findings provide guidelines for future tool development, as well as a better understanding of the meaning of the term “data exploration” based on the words of practitioners “in the wild”.	Sara Alspaugh;Nava Zokaei;Andrea Liu;Cindy Jin;Marti A. Hearst	Sara Alspaugh;Nava Zokaei;Andrea Liu;Cindy Jin;Marti A. Hearst	UC, Berkeley;UC, Berkeley;UC, Berkeley;UC, Berkeley;UC, Berkeley	10.1109/VAST.2008.4677365;10.1109/INFVIS.1997.636793;10.1109/TVCG.2012.219;10.1109/VAST.2011.6102438;10.1109/TVCG.2006.122;10.1109/TVCG.2015.2467191	EDA,exploratory data analysis,interview study,visual analytics tools		7	3	26	
VAST	2018	ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer	10.1109/TVCG.2018.2865041	http://dx.doi.org/10.1109/TVCG.2018.2865041	65	75	J	Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.	Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang;Shoubin Cheng;Wei Chen 0001	Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang;Shoubin Cheng;Wei Chen	State Key Lab of CAD&CGZhejiang University;State Key Lab of CAD&CGZhejiang University;State Key Lab of CAD&CGZhejiang University;State Key Lab of CAD&CGZhejiang University;State Key Lab of CAD&CGZhejiang University;Department of Sport ScienceZhejiang University;Department of Sport ScienceZhejiang University;State Key Lab of CAD&CGZhejiang University	10.1109/VAST.2008.4677356;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346433;10.1109/VAST.2014.7042477;10.1109/TVCG.2018.2865018;10.1109/TVCG.2016.2598831;10.1109/TVCG.2013.192;10.1109/TVCG.2014.2346445;10.1109/TVCG.2017.2745181;10.1109/TVCG.2017.2744218	Soccer data,formation analysis,spatio-temporal visualization	0	11	5	48	
VAST	2018	Identification of Temporally Varying Areas of Interest in Long-Duration Eye-Tracking Data Sets	10.1109/TVCG.2018.2865042	http://dx.doi.org/10.1109/TVCG.2018.2865042	87	97	J	Eye-tracking has become an invaluable tool for the analysis of working practices in many technological fields of activity. Typically studies focus on short tasks and use static expected areas of interest (AoI) in the display to explore subjects' behaviour, making the analyst's task quite straightforward. In long-duration studies, where the observations may last several hours over a complete work session, the AoIs may change over time in response to altering workload, emergencies or other variables making the analysis more difficult. This work puts forward a novel method to automatically identify spatial AoIs changing over time through a combination of clustering and cluster merging in the temporal domain. A visual analysis system based on the proposed methods is also presented. Finally, we illustrate our approach within the domain of air traffic control, a complex task sensitive to prevailing conditions over long durations, though it is applicable to other domains such as monitoring of complex systems.	Prithiviraj K. Muthumanickam;Katerina Vrotsou;Aida Nordman;Jimmy Johansson;Matthew D. Cooper	Prithiviraj K. Muthumanickam;Katerina Vrotsou;Aida Nordman;Jimmy Johansson;Matthew Cooper	Linköping University;Linköping University;Linköping University;Linköping University;Linköping University	10.1109/TVCG.2012.276;10.1109/TVCG.2015.2468091;10.1109/TVCG.2016.2598695;10.1109/TVCG.2013.194;10.1109/TVCG.2017.2743939;10.1109/TVCG.2009.117	Eye-tracking data,areas of interest,clustering,minimum spanning tree,temporal data,spatio-temporal data	0	4	2	49	
VAST	2018	RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis	10.1109/TVCG.2018.2865043	http://dx.doi.org/10.1109/TVCG.2018.2865043	246	255	J	We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.	Dennis Dingen;Marcel van 't Veer;Patrick Houthuizen;Eveline H. J. Mestrom;Hendrikus H. M. Korsten;Arthur R. A. Bouwman;Jarke J. van Wijk	Dennis Dingen;Marcel van't Veer;Patrick Houthuizen;Eveline H. J. Mestrom;Erik H.H.M. Korsten;Arthur R.A. Bouwman;Jarke van Wijk	Eindhoven University of Technology;Catharina Hospital Eindhoven;Catharina Hospital Eindhoven;Catharina Hospital Eindhoven;Catharina Hospital Eindhoven;Catharina Hospital Eindhoven;University of Technology	10.1109/VAST.2017.8585720;10.1109/TVCG.2015.2467325;10.1109/TVCG.2013.125;10.1109/VAST.2011.6102453;10.1109/TVCG.2015.2467931	Visual analytics,Predictive visual analytics,Exploratory data analysis,Multivariate statistics,Regression analysis,Variable selection,Subgroup analysis		2	1	32	
VAST	2018	Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models	10.1109/TVCG.2018.2865044	http://dx.doi.org/10.1109/TVCG.2018.2865044	353	363	J	Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and “what if”-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.	Hendrik Strobelt;Sebastian Gehrmann;Michael Behrisch 0001;Adam Perer;Hanspeter Pfister;Alexander M. Rush	Hendrik Strobelt;Sebastian Gehrmann;Michael Behrisch;Adam Perer;Hanspeter Pfister;Alexander M. Rush	IBM ReseatchMIT-IBM Watson AI Lab.;Harvard NLP group;Hatvatd Visual Computing group;IBM ReseatchMIT-IBM Watson AI Lab.;Hatvatd Visual Computing group;Harvard NLP group	10.1109/TVCG.2017.2744718;10.1109/TVCG.2017.2744478;10.1109/TVCG.2017.2744158	Explainable AI,Visual Debugging,Visual Analytics,Machine Learning,Deep Learning,NLP	1	8	12	55	HM
VAST	2018	SIRIUS: Dual, Symmetric, Interactive Dimension Reductions	10.1109/TVCG.2018.2865047	http://dx.doi.org/10.1109/TVCG.2018.2865047	172	182	J	Much research has been done regarding how to visualize and interact with observations and attributes of high-dimensional data for exploratory data analysis. From the analyst's perceptual and cognitive perspective, current visualization approaches typically treat the observations of the high-dimensional dataset very differently from the attributes. Often, the attributes are treated as inputs (e.g., sliders), and observations as outputs (e.g., projection plots), thus emphasizing investigation of the observations. However, there are many cases in which analysts wish to investigate both the observations and the attributes of the dataset, suggesting a symmetry between how analysts think about attributes and observations. To address this, we define SIRIUS (Symmetric Interactive Representations In a Unified System), a symmetric, dual projection technique to support exploratory data analysis of high-dimensional data. We provide an example implementation of SIRIUS and demonstrate how this symmetry affords additional insights.	Michelle Dowling;John E. Wenskovitch;J. T. Fry;Scotland Leman;Leanna House;Chris North	Michelle Dowling;John Wenskovitch;J.T. Fry;Scotland Leman;Leanna House;Chris North	Virginia Tech Department of Computer Science;Virginia Tech Department of Computer Science;Virginia Tech Department of Statistics;Virginia Tech Department of Statistics;Virginia Tech Department of Statistics;Virginia Tech Department of Computer Science	10.1109/VAST.2012.6400493;10.1109/INFVIS.2005.1532136;10.1109/VAST.2014.7042492;10.1109/VAST.2012.6400486;10.1109/TVCG.2015.2467552;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.260;10.1109/VAST.2011.6102449;10.1109/TVCG.2011.220;10.1109/TVCG.2016.2598445;10.1109/TVCG.2016.2598446;10.1109/INFVIS.2003.1249020;10.1109/TVCG.2008.173;10.1109/TVCG.2011.178;10.1109/TVCG.2012.256;10.1109/TVCG.2016.2598479;10.1109/TVCG.2013.150	Dimension reduction,semantic interaction,exploratory data analysis,observation projection,attribute projection	0	3	1	59	
VAST	2018	MotionRugs: Visualizing Collective Trends in Space and Time	10.1109/TVCG.2018.2865049	http://dx.doi.org/10.1109/TVCG.2018.2865049	76	86	J	Understanding the movement patterns of collectives, such as flocks of birds or fish swarms, is an interesting open research question. The collectives are driven by mutual objectives or react to individual direction changes and external influence factors and stimuli. The challenge in visualizing collective movement data is to show space and time of hundreds of movements at the same time to enable the detection of spatiotemporal patterns. In this paper, we propose MotionRugs, a novel space efficient technique for visualizing moving groups of entities. Building upon established space-partitioning strategies, our approach reduces the spatial dimensions in each time step to a one-dimensional ordered representation of the individual entities. By design, MotionRugs provides an overlap-free, compact overview of the development of group movements over time and thus, enables analysts to visually identify and explore group-specific temporal patterns. We demonstrate the usefulness of our approach in the field of fish swarm analysis and report on initial feedback of domain experts from the field of collective behavior.	Juri Buchmüller;Dominik Jäckle;Eren Cakmak;Ulrik Brandes;Daniel A. Keim	Juri Buchmüller;Dominik Jäckle;Eren Cakmak;Ulrik Brandes;Daniel A. Keim	University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;ETH Zurich, Switzerland;University of Konstanz, Germany	10.1109/TVCG.2013.193;10.1109/TVCG.2011.226;10.1109/VAST.2009.5332593;10.1109/TVCG.2009.145;10.1109/VAST.2014.7042477;10.1109/TVCG.2006.193;10.1109/TVCG.2013.192;10.1109/TVCG.2008.125;10.1109/TVCG.2012.265	Spatio-Temporal Visualization,Spatial Abstraction,Spatial Index Structures,Collective Movement	0	5	4	54	
VAST	2018	Drag and Track: A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space	10.1109/TVCG.2018.2865051	http://dx.doi.org/10.1109/TVCG.2018.2865051	256	266	J	We present a direct manipulation technique that allows material scientists to interactively highlight relevant parameterized simulation instances located in dimensionally reduced spaces, enabling a user-defined understanding of a continuous parameter space. Our goals are two-fold: first, to build a user-directed intuition of dimensionally reduced data, and second, to provide a mechanism for creatively exploring parameter relationships in parameterized simulation sets, called ensembles. We start by visualizing ensemble data instances in dimensionally reduced scatter plots. To understand these abstract views, we employ user-defined virtual data instances that, through direct manipulation, search an ensemble for similar instances. Users can create multiple of these direct manipulation queries to visually annotate the spaces with sets of highlighted ensemble data instances. User-defined goals are therefore translated into custom illustrations that are projected onto the dimensionally reduced spaces. Combined forward and inverse searches of the parameter space follow naturally allowing for continuous parameter space prediction and visual query comparison in the context of an ensemble. The potential for this visualization technique is confirmed via expert user feedback for a shock physics application and synthetic model analysis.	Daniel Orban;Daniel F. Keefe;Ayan Biswas;James P. Ahrens;David H. Rogers	Daniel Orban;Daniel F. Keefe;Ayan Biswas;James Ahrens;David Rogers	University of Minnesota, USA;University of Minnesota, USA;Los Alamos National Labs;Los Alamos National Labs;Los Alamos National Labs	10.1109/TVCG.2013.133;10.1109/TVCG.2016.2598869;10.1109/VAST.2012.6400486;10.1109/TVCG.2010.190;10.1109/TVCG.2013.147;10.1109/VAST.2012.6400489;10.1109/TVCG.2015.2467436;10.1109/TVCG.2012.260;10.1109/VAST.2011.6102449;10.1109/TVCG.2015.2467204;10.1109/TVCG.2013.141;10.1109/TVCG.2017.2745178;10.1109/TVCG.2014.2346455;10.1109/TVCG.2016.2598589;10.1109/TVCG.2016.2598495;10.1109/TVCG.2016.2598839;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2016.2598830	Visual Parameter Space Analysis,Ensemble Visualization,Semantic Interaction,Direct Manipulation,Shock Physics	0	5	3	56	
InfoVis	2018	Embedded Merge & Split: Visual Adjustment of Data Grouping	10.1109/TVCG.2018.2865075	http://dx.doi.org/10.1109/TVCG.2018.2865075	800	809	J	Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge &amp; Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.	Ali Sarvghad;Bahador Saket;Alex Endert;Nadir Weibel	Ali Sarvghad;Bahador Saket;Alex Endert;Nadir Weibel	University of California, San Diego;Georgia Institute of Technology;Georgia Institute of Technology;University of California, San Diego	10.1109/VAST.2012.6400486;10.1109/TVCG.2015.2467615;10.1109/TVCG.2008.109;10.1109/TVCG.2016.2598839	Data Visualization,Direct Manipulation,Embedded Merge & Split,Data Grouping,Embedded Interaction	0	3	2	48	
InfoVis	2018	IDMVis: Temporal Event Sequence Visualization for Type 1 Diabetes Treatment Decision Support	10.1109/TVCG.2018.2865076	http://dx.doi.org/10.1109/TVCG.2018.2865076	512	522	J	Type 1 diabetes is a chronic, incurable autoimmune disease affecting millions of Americans in which the body stops producing insulin and blood glucose levels rise. The goal of intensive diabetes management is to lower average blood glucose through frequent adjustments to insulin protocol, diet, and behavior. Manual logs and medical device data are collected by patients, but these multiple sources are presented in disparate visualization designs to the clinician-making temporal inference difficult. We conducted a design study over 18 months with clinicians performing intensive diabetes management. We present a data abstraction and novel hierarchical task abstraction for this domain. We also contribute IDMVis: a visualization tool for temporal event sequences with multidimensional, interrelated data. IDMVis includes a novel technique for folding and aligning records by dual sentinel events and scaling the intermediate timeline. We validate our design decisions based on our domain abstractions, best practices, and through a qualitative evaluation with six clinicians. The results of this study indicate that IDMVis accurately reflects the workflow of clinicians. Using IDMVis, clinicians are able to identify issues of data quality such as missing or conflicting data, reconstruct patient records when data is missing, differentiate between days with different patterns, and promote educational interventions after identifying discrepancies.	Yixuan Zhang;Kartik Chanana;Cody Dunne	Yixuan Zhang;Kartik Chanana;Cody Dunne	Northeastern University;Northeastern University;Northeastern University	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2013.124;10.1109/TVCG.2017.2744319;10.1109/TVCG.2009.111;10.1109/TVCG.2012.213;10.1109/VISUAL.1992.235203	Design study,task analysis,event sequence visualization,time series data,qualitative evaluation,health applications	0	6	6	60	
InfoVis	2018	Comparing Similarity Perception in Time Series Visualizations	10.1109/TVCG.2018.2865077	http://dx.doi.org/10.1109/TVCG.2018.2865077	523	533	J	A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.	Anna Gogolou;Theophanis Tsandilas;Themis Palpanas;Anastasia Bezerianos	Anna Gogolou;Theophanis Tsandilas;Themis Palpanas;Anastasia Bezerianos	Inria, Univ. Paris-Sud, Univ. Paris-Saclay, France;Inria, Univ. Paris-Sud, CNRS, Univ. Paris-Saclay, France;Univ. Paris-Descartes, France;Inria, Univ. Paris-Sud, CNRS, Univ. Paris-Saclay, France	10.1109/TVCG.2011.232;10.1109/VAST.2007.4389007;10.1109/TVCG.2008.166;10.1109/VAST.2016.7883519;10.1109/TVCG.2010.162;10.1109/VAST.2016.7883518;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2012.196;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.195	Time series,similarity perception,automatic similarity search,line charts,horizon graphs,colorfields,evaluation	0	6	7	70	
InfoVis	2018	Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web	10.1109/TVCG.2018.2865117	http://dx.doi.org/10.1109/TVCG.2018.2865117	501	511	J	The diverse and vibrant ecosystem of interactive visualizations on the web presents an opportunity for researchers and practitioners to observe and analyze how everyday people interact with data visualizations. However, existing metrics of visualization interaction behavior used in research do not fully reveal the breadth of peoples' open-ended explorations with visualizations. One possible way to address this challenge is to determine high-level goals for visualization interaction metrics, and infer corresponding features from user interaction data that characterize different aspects of peoples' explorations of visualizations. In this paper, we identify needs for visualization behavior measurement, and develop corresponding candidate features that can be inferred from users' interaction data. We then propose metrics that capture novel aspects of peoples' open-ended explorations, including exploration uniqueness and exploration pacing. We evaluate these metrics along with four other metrics recently proposed in visualization literature by applying them to interaction data from prior visualization studies. The results of these evaluations suggest that these new metrics 1) reveal new characteristics of peoples' use of visualizations, 2) can be used to evaluate statistical differences between visualization designs, and 3) are statistically independent of prior metrics used in visualization research. We discuss implications of these results for future studies, including the potential for applying these metrics in visualization interaction analysis, as well as emerging challenges in developing and selecting metrics depicting visualization explorations.	Mi Feng;Evan M. Peck;Lane Harrison	Mi Feng;Evan Peck;Lane Harrison	Worcester Polytechnic Institute;Bucknell University;Worcester Polytechnic Institute	10.1109/TVCG.2011.229;10.1109/TVCG.2015.2467871;10.1109/TVCG.2015.2467201;10.1109/TVCG.2014.2346575;10.1109/VAST.2007.4389009;10.1109/TVCG.2016.2599058;10.1109/TVCG.2015.2467613;10.1109/TVCG.2008.137;10.1109/VAST.2007.4389008;10.1109/TVCG.2014.2346452;10.1109/TVCG.2016.2598797;10.1109/TVCG.2013.200;10.1109/TVCG.2016.2598466;10.1109/VAST.2017.8585669;10.1109/TVCG.2017.2745958;10.1109/TVCG.2007.70515	Interaction,Visualization,Quantitative Evaluation	0	0	2	46	
InfoVis	2018	Shape-preserving Star Coordinates	10.1109/TVCG.2018.2865118	http://dx.doi.org/10.1109/TVCG.2018.2865118	449	458	J	Dimensionality reduction is commonly applied to multidimensional data to reduce the complexity of their analysis. In visual analysis systems, projections embed multidimensional data into 2D or 3D spaces for graphical representation. To facilitate a robust and accurate analysis, essential characteristics of the multidimensional data shall be preserved when projecting. Orthographic star coordinates is a state-of-the-art linear projection method that avoids distortion of multidimensional clusters by restricting interactive exploration to orthographic projections. However, existing numerical methods for computing orthographic star coordinates have a number of limitations when putting them into practice. We overcome these limitations by proposing the novel concept of shape-preserving star coordinates where shape preservation is assured using a superset of orthographic projections. Our scheme is explicit, exact, simple, fast, parameter-free, and stable. To maintain a valid shape-preserving star-coordinates configuration during user interaction with one of the star-coordinates axes, we derive an algorithm that only requires us to modify the configuration of one additional compensatory axis. Different design goals can be targeted by using different strategies for selecting the compensatory axis. We propose and discuss four strategies including a strategy that approximates orthographic star coordinates very well and a data-driven strategy. We further present shape-preserving morphing strategies between two shape-preserving configurations, which can be adapted for the generation of data tours. We apply our concept to multiple data analysis scenarios to document its applicability and validate its desired properties.	Vladimir Molchanov;Lars Linsen	Vladimir Molchanov;Lars Linsen	Westfälische Wilhelms-Universität Münster, Germany;Westfälische Wilhelms-Universität Münster, Germany	10.1109/TVCG.2010.209;10.1109/TVCG.2013.182;10.1109/TVCG.2015.2467132;10.1109/TVCG.2015.2467324;10.1109/TVCG.2014.2346258	Star coordinates,multidimensional data projection,multivariate data visualization	0	1	0	30	
InfoVis	2018	Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading	10.1109/TVCG.2018.2865119	http://dx.doi.org/10.1109/TVCG.2018.2865119	661	671	J	Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, figures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.	Sriram Karthik Badam;Zhicheng Liu;Niklas Elmqvist	Sriram Karthik Badam;Zhicheng Liu;Niklas Elmqvist	University of Maryland, College Park, MD, USA;Adobe Research, Seattle, WA, USA;University of Maryland, College Park, MD, USA	10.1109/TVCG.2011.185;10.1109/TVCG.2016.2598594;10.1109/TVCG.2014.2346435;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70594;10.1109/TVCG.2014.2346279;10.1109/INFVIS.2000.885091;10.1109/TVCG.2009.139;10.1109/TVCG.2009.165;10.1109/TVCG.2009.171	Document reading,contextual visualizations,visual aids,comprehension,summarization		2	0	66	
InfoVis	2018	SRVis: Towards Better Spatial Integration in Ranking Visualization	10.1109/TVCG.2018.2865126	http://dx.doi.org/10.1109/TVCG.2018.2865126	459	469	J	Interactive ranking techniques have substantially promoted analysts' ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankings' visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.	Di Weng;Ran Chen;Zikun Deng;Feiran Wu;Jingmin Chen;Yingcai Wu	Di Weng;Ran Chen;Zikun Deng;Feiran Wu;Jingmin Chen;Yingcai Wu	State Key Lab of CAD & CGZhejiang UniversityAlibaba-Zhejiang University JointInstitute of Frontier Technologies;State Key Lab of CAD & CGZhejiang UniversityAlibaba-Zhejiang University JointInstitute of Frontier Technologies;State Key Lab of CAD & CGZhejiang UniversityAlibaba-Zhejiang University JointInstitute of Frontier Technologies;Alibaba Group, Hangzhou, China;Alibaba Group, Hangzhou, China;State Key Lab of CAD & CGZhejiang UniversityAlibaba-Zhejiang University JointInstitute of Frontier Technologies	10.1109/TVCG.2016.2598416;10.1109/TVCG.2013.193;10.1109/TVCG.2011.185;10.1109/TVCG.2008.166;10.1109/TVCG.2014.2346594;10.1109/TVCG.2013.173;10.1109/TVCG.2015.2467771;10.1109/TVCG.2008.181;10.1109/TVCG.2016.2598432;10.1109/TVCG.2018.2865018;10.1109/VAST.2011.6102455;10.1109/TVCG.2016.2598831;10.1109/TVCG.2016.2598585;10.1109/TVCG.2009.111;10.1109/TVCG.2015.2467112;10.1109/TVCG.2012.253;10.1109/TVCG.2015.2467717;10.1109/TVCG.2017.2745078;10.1109/TVCG.2014.2346913	Spatial ranking,visualization	0	2	4	60	
InfoVis	2018	Evaluating ‘Graphical Perception’ with CNNs	10.1109/TVCG.2018.2865138	http://dx.doi.org/10.1109/TVCG.2018.2865138	641	650	J	Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGill's seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations.	Daniel Haehn;James Tompkin;Hanspeter Pfister	Daniel Haehn;James Tompkin;Hanspeter Pfister	Harvard University;Brown University;Harvard University	10.1109/TVCG.2014.2346979;10.1109/TVCG.2014.2346320	Machine Perception,Graphical Perception,Deep Learning,Convolutional Neural Networks	0	2	1	50	
InfoVis	2018	Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks	10.1109/TVCG.2018.2865139	http://dx.doi.org/10.1109/TVCG.2018.2865139	555	565	J	When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.	Wei Chen 0001;Fangzhou Guo;Dongming Han;Jacheng Pan;Xiaotao Nie;Jiazhi Xia;Xiaolong Zhang	Wei Chen;Fangzhou Guo;Dongming Han;Jacheng Pan;Xiaotao Nie;Jiazhi Xia;Xiaolong Zhang	State Key Lab of CAD and CGZhejiang University;State Key Lab of CAD and CGZhejiang University;State Key Lab of CAD and CGZhejiang University;State Key Lab of CAD and CGZhejiang University;State Key Lab of CAD and CGZhejiang University;Central South University;Pennsylvania State University	10.1109/TVCG.2006.120;10.1109/TVCG.2016.2598958;10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.147;10.1109/TVCG.2008.151;10.1109/TVCG.2017.2743858;10.1109/VAST.2014.7042485;10.1109/TVCG.2017.2744938;10.1109/TVCG.2016.2598831;10.1109/TVCG.2017.2744898;10.1109/TVCG.2017.2745219;10.1109/TVCG.2015.2468078;10.1109/TVCG.2009.108;10.1109/VAST.2009.5333893;10.1109/TVCG.2013.167	Large Network Exploration,Structure-Based Exploration,Suggestive Exploration	0	5	2	80	
InfoVis	2018	A Declarative Rendering Model for Multiclass Density Maps	10.1109/TVCG.2018.2865141	http://dx.doi.org/10.1109/TVCG.2018.2865141	470	480	J	Multiclass maps are scatterplots, multidimensional projections, or thematic geographic maps where data points have a categorical attribute in addition to two quantitative attributes. This categorical attribute is often rendered using shape or color, which does not scale when overplotting occurs. When the number of data points increases, multiclass maps must resort to data aggregation to remain readable. We present multiclass density maps: multiple 2D histograms computed for each of the category values. Multiclass density maps are meant as a building block to improve the expressiveness and scalability of multiclass map visualization. In this article, we first present a short survey of aggregated multiclass maps, mainly from cartography. We then introduce a declarative model-a simple yet expressive JSON grammar associated with visual semantics-that specifies a wide design space of visualizations for multiclass density maps. Our declarative model is expressive and can be efficiently implemented in visualization front-ends such as modern web browsers. Furthermore, it can be reconfigured dynamically to support data exploration tasks without recomputing the raw data. Finally, we demonstrate how our model can be used to reproduce examples from the past and support exploring data at scale.	Jaemin Jo;Frédéric Vernier;Pierre Dragicevic;Jean-Daniel Fekete	Jaemin Jo;Frédéric Vernier;Pierre Dragicevic;Jean-Daniel Fekete	Seoul National University, Republic of Korea;LIMSICNRSUniv. Paris-SudUniversité Paris-Saclay;Inria;Inria	10.1109/TVCG.2011.185;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2017.2744199;10.1109/TVCG.2007.70623;10.1109/TVCG.2013.179;10.1109/TVCG.2013.130;10.1109/TVCG.2017.2744184;10.1109/TVCG.2016.2599030;10.1109/TVCG.2011.197;10.1109/VISUAL.1993.398863;10.1109/TVCG.2009.175	Scalability,multiclass scatterplots,density maps,aggregation,declarative specification,visualization grammar		5	5	54	
InfoVis	2018	Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches	10.1109/TVCG.2018.2865142	http://dx.doi.org/10.1109/TVCG.2018.2865142	630	640	J	We present the results of two perception studies to assess how quickly people can perform a simple data comparison task for small-scale visualizations on a smartwatch. The main goal of these studies is to extend our understanding of design constraints for smartwatch visualizations. Previous work has shown that a vast majority of smartwatch interactions last under 5 s. It is still unknown what people can actually perceive from visualizations during such short glances, in particular with such a limited display space of smartwatches. To shed light on this question, we conducted two perception studies that assessed the lower bounds of task time for a simple data comparison task. We tested three chart types common on smartwatches: bar charts, donut charts, and radial bar charts with three different data sizes: 7, 12, and 24 data values. In our first study, we controlled the differences of the two target bars to be compared, while the second study varied the difference randomly. For both studies, we found that participants performed the task on average in &lt;;300 ms for the bar chart, &lt;;220 ms for the donut chart, and in &lt;; 1780 ms for the radial bar chart. Thresholds in the second study per chart type were on average 1.14-1.35× higher than in the first study. Our results show that bar and donut charts should be preferred on smartwatch displays when quick data comparisons are necessary.	Tanja Blascheck;Lonni Besançon;Anastasia Bezerianos;Bongshin Lee;Petra Isenberg	Tanja Blascheck;Lonni Besançon;Anastasia Bezerianos;Bongshin Lee;Petra Isenberg	Inria;Université Paris Saclay;Université Paris SudInriaCNRSUniversité Paris Saclay;Microsoft Research;Inria	10.1109/TVCG.2014.2346435;10.1109/TVCG.2012.233;10.1109/TVCG.2010.162;10.1109/TVCG.2013.192;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2012.196;10.1109/TVCG.2014.2346320;10.1109/TVCG.2007.70589	Glanceable visualization,smartwatch,perception,quantitative evaluation,data comparison	0	7	3	52	
InfoVis	2018	Vistrates: A Component Model for Ubiquitous Analytics	10.1109/TVCG.2018.2865144	http://dx.doi.org/10.1109/TVCG.2018.2865144	586	596	J	Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components-the building blocks of this model-can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce Vistrates, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic “anytime” and “anywhere” motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices..	Sriram Karthik Badam;Andreas Mathisen;Roman Rädle;Clemens Nylandsted Klokmose;Niklas Elmqvist	Sriram Karthik Badam;Andreas Mathisen;Roman Rädle;Clemens N. Klokmose;Niklas Elmqvist	University of Maryland, College Park, MD, USA;Aarhus University, Aarhus, Denmark;Aarhus University, Aarhus, Denmark;Aarhus University, Aarhus, Denmark;University of Maryland, College Park, MD, USA	10.1109/TVCG.2016.2598647;10.1109/TVCG.2017.2743990;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2017.2745278;10.1109/INFVIS.2000.885092;10.1109/TVCG.2013.197;10.1109/VAST.2007.4389011;10.1109/TVCG.2008.137;10.1109/TVCG.2017.2744019;10.1109/TVCG.2012.204;10.1109/TVCG.2013.191;10.1109/TVCG.2014.2346573;10.1109/TVCG.2013.200;10.1109/TVCG.2014.2346291;10.1109/TVCG.2016.2599030;10.1109/TVCG.2014.2346574;10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.162;10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70589	Components,literate computing,development,exploration,dissemination,collaboration,heterogeneous devices	0	3	2	80	
InfoVis	2018	Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication	10.1109/TVCG.2018.2865145	http://dx.doi.org/10.1109/TVCG.2018.2865145	672	681	J	Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type, data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voder's design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.	Arjun Srinivasan;Steven Mark Drucker;Alex Endert;John T. Stasko	Arjun Srinivasan;Steven M. Drucker;Alex Endert;John Stasko	Georgia Institute of Technology;Microsoft Research;Georgia Institute of Technology;Georgia Institute of Technology	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2013.124;10.1109/TVCG.2010.164;10.1109/TVCG.2013.119;10.1109/TVCG.2012.229;10.1109/TVCG.2007.70594;10.1109/VISUAL.1992.235203;10.1109/TVCG.2017.2744843;10.1109/TVCG.2017.2745219;10.1109/VISUAL.1990.146375;10.1109/TVCG.2015.2467191	Natural Language Generation,Mixed-initiative Interaction,Visualization Recommendation,Data-driven Communication	0	10	5	50	
InfoVis	2018	A Heuristic Approach to Value-Driven Evaluation of Visualizations	10.1109/TVCG.2018.2865146	http://dx.doi.org/10.1109/TVCG.2018.2865146	491	500	J	Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however, providing no actionable method of assessing a visualization's value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.	Emily Wall;Meeshu Agnihotri;Laura E. Matzen;Kristin Divis;Michael J. Haass;Alex Endert;John T. Stasko	Emily Wall;Meeshu Agnihotri;Laura Matzen;Kristin Divis;Michael Haass;Alex Endert;John Stasko	Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA	10.1109/INFVIS.2001.963289;10.1109/VISUAL.2003.1250401	Visualization evaluation,heuristics,value of visualization	0	2	2	35	
InfoVis	2018	Mapping Color to Meaning in Colormap Data Visualizations	10.1109/TVCG.2018.2865147	http://dx.doi.org/10.1109/TVCG.2018.2865147	810	819	J	To interpret data visualizations, people must determine how visual features map onto concepts. For example, to interpret colormaps, people must determine how dimensions of color (e.g., lightness, hue) map onto quantities of a given measure (e.g., brain activity, correlation magnitude). This process is easier when the encoded mappings in the visualization match people's predictions of how visual features will map onto concepts, their inferred mappings. To harness this principle in visualization design, it is necessary to understand what factors determine people's inferred mappings. In this study, we investigated how inferred color-quantity mappings for colormap data visualizations were influenced by the background color. Prior literature presents seemingly conflicting accounts of how the background color affects inferred color-quantity mappings. The present results help resolve those conflicts, demonstrating that sometimes the background has an effect and sometimes it does not, depending on whether the colormap appears to vary in opacity. When there is no apparent variation in opacity, participants infer that darker colors map to larger quantities (dark-is-more bias). As apparent variation in opacity increases, participants become biased toward inferring that more opaque colors map to larger quantities (opaque-is-more bias). These biases work together on light backgrounds and conflict on dark backgrounds. Under such conflicts, the opaque-is-more bias can negate, or even supersede the dark-is-more bias. The results suggest that if a design goal is to produce colormaps that match people's inferred mappings and are robust to changes in background color, it is beneficial to use colormaps that will not appear to vary in opacity on any background color, and to encode larger quantities in darker colors.	Karen B. Schloss;Connor Gramazio;Allison T. Silverman;Madeline L. Parker;Audrey S. Wang	Karen B. Schloss;Connor C. Gramazio;Allison T. Silverman;Madeline L. Parker;Audrey S. Wang	Department of Psychology and Wisconsin Institute for DiscoveryUniversity of Wisconsin-Madison;Department of Computer ScienceBrown University;School of Public HealthBrown University;Department of Psychology and Wisconsin Institute for DiscoveryUniversity of Wisconsin-Madison;Department of Applied and Computational MathematicsCalifornia Institute of Technology	10.1109/TVCG.2017.2743978;10.1109/TVCG.2016.2598918;10.1109/TVCG.2010.162;10.1109/TVCG.2007.70583;10.1109/TVCG.2017.2744359	Visual Reasoning,Visual Communication,Colormaps,Color Perception,Visual Encoding,Visual Design	0	9	2	49	HM
InfoVis	2018	Juniper: A Tree+Table Approach to Multivariate Graph Visualization	10.1109/TVCG.2018.2865149	http://dx.doi.org/10.1109/TVCG.2018.2865149	544	554	J	Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree-table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.	Carolina Nobre;Marc Streit;Alexander Lex	Carolina Nobre;Marc Streit;Alexander Lex	University of Utah;Johannes Kepler University, Linz;University of Utah	10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.147;10.1109/INFVIS.2003.1249009;10.1109/VISUAL.1991.175815;10.1109/TVCG.2014.2346248;10.1109/TVCG.2017.2744898;10.1109/INFVIS.2000.885091;10.1109/TVCG.2015.2468078;10.1109/TVCG.2014.2346441;10.1109/TVCG.2009.108;10.1109/TVCG.2016.2598885;10.1109/INFVIS.2001.963279	Multivariate graphs,networks,tree-based graph visualization,adjacency matrix,spanning trees,visualization	0	4	4	52	
InfoVis	2018	Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach	10.1109/TVCG.2018.2865151	http://dx.doi.org/10.1109/TVCG.2018.2865151	576	585	J	Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.	Timothy Major;Rahul C. Basole	Timothy Major;Rahul C. Basole	Georgia Institute of Technology;Georgia Institute of Technology	10.1109/TVCG.2012.252;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70539;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346292;10.1109/TVCG.2013.227;10.1109/TVCG.2006.166;10.1109/TVCG.2014.2346441;10.1109/TVCG.2009.108;10.1109/INFVIS.2003.1249004;10.1109/TVCG.2010.205;10.1109/TVCG.2007.70589;10.1109/VAST.2009.5333880;10.1109/TVCG.2013.167	Unit visualization,network visualization,context	0	1	1	46	
InfoVis	2018	DXR: A Toolkit for Building Immersive Data Visualizations	10.1109/TVCG.2018.2865152	http://dx.doi.org/10.1109/TVCG.2018.2865152	715	725	J	This paper presents DXR, a toolkit for building immersive data visualizations based on the Unity development platform. Over the past years, immersive data visualizations in augmented and virtual reality (AR, VR) have been emerging as a promising medium for data sense-making beyond the desktop. However, creating immersive visualizations remains challenging, and often require complex low-level programming and tedious manual encoding of data attributes to geometric and visual properties. These can hinder the iterative idea-to-prototype process, especially for developers without experience in 3D graphics, AR, and VR programming. With DXR, developers can efficiently specify visualization designs using a concise declarative visualization grammar inspired by Vega-Lite. DXR further provides a GUI for easy and quick edits and previews of visualization designs in-situ, i.e., while immersed in the virtual world. DXR also provides reusable templates and customizable graphical marks, enabling unique and engaging visualizations. We demonstrate the flexibility of DXR through several examples spanning a wide range of applications.	Ronell Sicat;Jiabao Li;Junyoung Choi;Maxime Cordeil;Won-Ki Jeong;Benjamin Bach;Hanspeter Pfister	Ronell Sicat;Jiabao Li;Junyoung Choi;Maxime Cordeil;Won-Ki Jeong;Benjamin Bach;Hanspeter Pfister	Harvard Visual Computing Group;Harvard Graduate School of Design;Ulsan National Institute of Science and Technology;Immersive Analytics LabMonash University;Ulsan National Institute of Science and Technology;School of InformaticsEdinburgh University;Harvard Visual Computing Group	10.1109/TVCG.2017.2745941;10.1109/TVCG.2016.2598609;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346322;10.1109/TVCG.2016.2599107;10.1109/INFVIS.2004.64;10.1109/TVCG.2010.144;10.1109/TVCG.2016.2598620;10.1109/TVCG.2015.2467449;10.1109/TVCG.2014.2346318;10.1109/TVCG.2016.2599030;10.1109/TVCG.2015.2467091;10.1109/TVCG.2017.2744079;10.1109/TVCG.2016.2598608	Augmented Reality,Virtual Reality,Immersive Visualization,Immersive Analytics,Visualization Toolkit	0	8	2	72	
InfoVis	2018	Charticulator: Interactive Construction of Bespoke Chart Layouts	10.1109/TVCG.2018.2865158	http://dx.doi.org/10.1109/TVCG.2018.2865158	789	799	J	We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulator's conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com.	Donghao Ren;Bongshin Lee;Matthew Brehmer	Donghao Ren;Bongshin Lee;Matthew Brehmer	University of California, Santa Barbara;Microsoft Research;Microsoft Research	10.1109/TVCG.2016.2598609;10.1109/TVCG.2015.2467732;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2006.147;10.1109/TVCG.2016.2598620;10.1109/TVCG.2014.2346291;10.1109/TVCG.2016.2599030;10.1109/TVCG.2015.2467091;10.1109/INFVIS.2000.885086;10.1109/TVCG.2015.2467191	Interactive visualization authoring,Chart layout design,Glyph design,Constraint-based design,Reusable chart layout	0	8	5	68	HM
InfoVis	2018	Dynamic Composite Data Physicalization Using Wheeled Micro-Robots	10.1109/TVCG.2018.2865159	http://dx.doi.org/10.1109/TVCG.2018.2865159	737	747	J	This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work.	Mathieu Le Goc;Charles Perin;Sean Follmer;Jean-Daniel Fekete;Pierre Dragicevic	Mathieu Le Goc;Charles Perin;Sean Follmer;Jean-Daniel Fekete;Pierre Dragicevic	Stanford University, USA;University of Victoria, Canada;Stanford University, USA;INRIA, Saclay, France;INRIA, Saclay, France	10.1109/TVCG.2014.2346984;10.1109/TVCG.2014.2346424;10.1109/TVCG.2008.153;10.1109/TVCG.2007.70539;10.1109/TVCG.2014.2346292;10.1109/TVCG.2013.227;10.1109/TVCG.2013.134;10.1109/TVCG.2014.2346250;10.1109/TVCG.2017.2743859;10.1109/TVCG.2016.2598920;10.1109/TVCG.2012.199;10.1109/TVCG.2014.2346279;10.1109/TVCG.2007.70541;10.1109/TVCG.2016.2598498	information visualization,data physicalization,tangible user interfaces	1	2	1	92	
InfoVis	2018	FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights	10.1109/TVCG.2018.2865191	http://dx.doi.org/10.1109/TVCG.2018.2865191	704	714	J	Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology.	Christophe Hurter;Nathalie Henry Riche;Steven Mark Drucker;Maxime Cordeil;Richard Alligier;Romain Vuillemot	Christophe Hurter;Nathalie Henry Riche;Steven M. Drucker;Maxime Cordeil;Richard Alligier;Romain Vuillemot	ENAC, The French Civil Aviation University, Toulouse University, France;Microsoft Research;Microsoft Research;Monash University;ENAC, The French Civil Aviation University, Toulouse University, France;Univ Lyon, École Centrale de Lyon, CNRS UMR52 05, LIRIS, France	10.1109/TVCG.2016.2599217;10.1109/TVCG.2011.192;10.1109/VISUAL.1991.175794;10.1109/TVCG.2008.153;10.1109/TVCG.2011.233;10.1109/TVCG.2013.226;10.1109/TVCG.2017.2744338;10.1109/TVCG.2009.145;10.1109/INFVIS.2004.27;10.1109/TVCG.2011.224;10.1109/TVCG.2015.2467112;10.1109/TVCG.2013.153;10.1109/TVCG.2012.265;10.1109/TVCG.2017.2744079;10.1109/TVCG.2012.217	Immersive Analytics,3D Visualization,Dynamic Queries,Bimanual Interaction,Multidimensional Data	0	7	4	58	
InfoVis	2018	Origin-Destination Flow Maps in Immersive Environments	10.1109/TVCG.2018.2865192	http://dx.doi.org/10.1109/TVCG.2018.2865192	693	703	J	Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call<i>MapsLink</i>, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that<i>careful</i>use of the third spatial dimension can resolve visual clutter in complex flow maps.	Yalong Yang 0001;Tim Dwyer;Bernhard Jenny;Kim Marriott;Maxime Cordeil;Haohui Chen	Yalong Yang;Tim Dwyer;Bernhard Jenny;Kim Marriott;Maxime Cordeil;Haohui Chen	Monash University;Monash University;Monash University;Monash University;Monash University;Data61, CSIRO, Australia	10.1109/TVCG.2016.2598958;10.1109/TVCG.2011.202;10.1109/TVCG.2007.70521;10.1109/INFVIS.1995.528697;10.1109/INFVIS.1996.559226;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2011.181;10.1109/TVCG.2014.2346441;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2016.2598885	Origin-destination,Flow Map,Virtual Reality,Cartographic Information Visualisation,Immersive Analytics	0	8	2	67	
InfoVis	2018	Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks	10.1109/TVCG.2018.2865193	http://dx.doi.org/10.1109/TVCG.2018.2865193	882	891	J	A common approach to sampling the space of a prediction is the generation of an ensemble of potential outcomes, where the ensemble's distribution reveals the statistical structure of the prediction space. For example, the US National Hurricane Center generates multiple day predictions for a storm's path, size, and wind speed, and then uses a Monte Carlo approach to sample this prediction into a large ensemble of potential storm outcomes. Various forms of summary visualizations are generated from such an ensemble, often using spatial spread to indicate its statistical characteristics. However, studies have shown that changes in the size of such summary glyphs, representing changes in the uncertainty of the prediction, are frequently confounded with other attributes of the phenomenon, such as its size or strength. In addition, simulation ensembles typically encode multivariate information, which can be difficult or confusing to include in a summary display. This problem can be overcome by directly displaying the ensemble as a set of annotated trajectories, however this solution will not be effective if ensembles are densely overdrawn or structurally disorganized. We propose to overcome these difficulties by selectively sampling the original ensemble, constructing a smaller representative and spatially well organized ensemble. This can be drawn directly as a set of paths that implicitly reveals the underlying spatial uncertainty distribution of the prediction. Since this approach does not use a visual channel to encode uncertainty, additional information can more easily be encoded in the display without leading to visual confusion. To demonstrate our argument, we describe the development of a visualization for ensembles of tropical cyclone forecast tracks, explaining how their spatial and temporal predictions, as well as other crucial storm characteristics such as size and intensity, can be clearly revealed. We verify the effectiveness of this visualization approach through a cognitive study exploring how storm damage estimates are affected by the density of tracks drawn, and by the presence or absence of annotating information on storm size and intensity.	Le Liu;Lace M. K. Padilla;Sarah H. Creem-Regehr;Donald H. House	Le Liu;Lace Padilla;Sarah H. Creem-Regehr;Donald H. House	Magic Weaver Inc., Santa Clara, CA;Department of Psychology, Northwestern University, Evanston, IL;Department of Psychology, University of Utah, Salt Lake City, UT;School of Computing, Clemson University, Clemson, SC	10.1109/TVCG.2017.2743898;10.1109/TVCG.2010.181	uncertainty visualization,hurricane forecasts,ensemble visualization,ensemble sampling,implicit uncertainty		4	1	32	
InfoVis	2018	DimReader: Axis lines that explain non-linear projections	10.1109/TVCG.2018.2865194	http://dx.doi.org/10.1109/TVCG.2018.2865194	481	490	J	Non-linear dimensionality reduction (NDR) methods such as LLE and t-SNE are popular with visualization researchers and experienced data analysts, but present serious problems of interpretation. In this paper, we present DimReader, a technique that recovers readable axes from such techniques. DimReader is based on analyzing infinitesimal perturbations of the dataset with respect to variables of interest. The perturbations define exactly how we want to change each point in the original dataset and we measure the effect that these changes have on the projection. The recovered axes are in direct analogy with the axis lines (grid lines) of traditional scatterplots. We also present methods for discovering perturbations on the input data that change the projection the most. The calculation of the perturbations is efficient and easily integrated into programs written in modern programming languages. We present results of DimReader on a variety of NDR methods and datasets both synthetic and real-life, and show how it can be used to compare different NDR methods. Finally, we discuss limitations of our proposal and situations where further research is needed.	Rebecca Faust;David Glickenstein;Carlos Scheidegger	Rebecca Faust;David Glickenstein;Carlos Scheidegger	University of Arizona;University of Arizona;University of Arizona	10.1109/TVCG.2014.2346984;10.1109/TVCG.2014.2346431;10.1109/TVCG.2013.124;10.1109/VISUAL.1996.567787;10.1109/VAST.2010.5652460;10.1109/TVCG.2015.2467552;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.157;10.1109/TVCG.2011.220;10.1109/TVCG.2014.2346325;10.1109/INFVIS.2002.1173161;10.1109/TVCG.2016.2598495;10.1109/TVCG.2013.153;10.1109/TVCG.2015.2467717	Non-linear dimensionality reduction,auto-differentiation	0	0	1	52	
InfoVis	2018	NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models	10.1109/TVCG.2018.2865230	http://dx.doi.org/10.1109/TVCG.2018.2865230	651	660	J	With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.	Shusen Liu;Zhimin Li;Tao Li;Vivek Srikumar;Valerio Pascucci;Peer-Timo Bremer	Shusen Liu;Zhimin Li;Tao Li;Vivek Srikumar;Valerio Pascucci;Peer-Timo Bremer	Lawrence Livermore National Laboratory;SCI InstituteUniversity of Utah;School of ComputingUniversity of Utah;School of ComputingUniversity of Utah;SCI InstituteUniversity of Utah;Lawrence Livermore National Laboratory	10.1109/TVCG.2017.2744683;10.1109/TVCG.2017.2744718;10.1109/TVCG.2017.2744938;10.1109/TVCG.2016.2598831;10.1109/TVCG.2017.2745141;10.1109/TVCG.2017.2744358;10.1109/TVCG.2017.2744158;10.1109/VISUAL.2005.1532820;10.1109/TVCG.2017.2744878	Natural Language Processing,Interpretable Machine Learning,Natural Language Inference,Attention Visualization	0	4	5	40	
InfoVis	2018	SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays	10.1109/TVCG.2018.2865231	http://dx.doi.org/10.1109/TVCG.2018.2865231	597	607	J	Details-on-demand is a crucial feature in the visual information-seeking process but is often only implemented in highly constrained settings. The most common solution, hover queries (i.e., tooltips), are fast and expressive but are usually limited to single mark (e.g., a bar in a bar chart). `Queries' to retrieve details for more complex sets of objects (e.g., comparisons between pairs of elements, averages across multiple items, trend lines, etc.) are difficult for end-users to invoke explicitly. Further, the output of these queries require complex annotations and overlays which need to be displayed and dismissed on demand to avoid clutter. In this work we introduce SmartCues, a library to support details-on-demand through dynamically computed overlays. For end-users, SmartCues provides multitouch interactions to construct complex queries for a variety of details. For designers, SmartCues offers an interaction library that can be used out-of-the-box, and can be extended for new charts and detail types. We demonstrate how SmartCues can be implemented across a wide array of visualization types and, through a lab study, show that end users can effectively use SmartCues.	Hariharan Subramonyam;Eytan Adar	Hariharan Subramonyam;Eytan Adar	School of InformationUniversity of Michigan;School of InformationUniversity of Michigan	10.1109/INFVIS.1995.528688;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2013.124;10.1109/TVCG.2006.187;10.1109/VAST.2010.5652885;10.1109/TVCG.2013.119;10.1109/VAST.2012.6400487;10.1109/TVCG.2014.2346250;10.1109/TVCG.2012.229;10.1109/TVCG.2008.109;10.1109/TVCG.2012.204;10.1109/TVCG.2010.179;10.1109/TVCG.2017.2745958;10.1109/TVCG.2007.70515	Graphical overlays,details-on-demand,graph comprehension	0	1	0	73	
InfoVis	2018	Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs	10.1109/TVCG.2018.2865232	http://dx.doi.org/10.1109/TVCG.2018.2865232	779	788	J	Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. The teachers craft an introduction slideshow through first organizing these components, and then explaining them sequentially. A series of templates are provided for adding annotations and animations to improve efficiency during the authoring process. We evaluate Narvis through a qualitative analysis of the authoring experience, and a preliminary evaluation of the generated slideshows.	Qianwen Wang;Zhen Li;Siwei Fu;Weiwei Cui;Huamin Qu	Qianwen Wang;Zhen Li;Siwei Fu;Weiwei Cui;Huamin Qu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research Asia;Hong Kong University of Science and Technology	10.1109/TVCG.2016.2598647;10.1109/TVCG.2009.174;10.1109/TVCG.2016.2598876;10.1109/TVCG.2015.2467196;10.1109/TVCG.2011.239;10.1109/VAST.2007.4388992;10.1109/TVCG.2015.2467531;10.1109/TVCG.2007.70539;10.1109/TVCG.2013.119;10.1109/TVCG.2013.191;10.1109/TVCG.2010.183	Education,Narrative Visualization,Authoring Tools	0	0	0	42	
InfoVis	2018	Mitigating the Attraction Effect with Visualizations	10.1109/TVCG.2018.2865233	http://dx.doi.org/10.1109/TVCG.2018.2865233	850	860	J	Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias - the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.	Evanthia Dimara;Gilles Bailly;Anastasia Bezerianos;Steven Franconeri	Evanthia Dimara;Gilles Bailly;Anastasia Bezerianos;Steven Franconeri	ISIR;ISIR;Univ. Paris-Sud & CNRS (LRI)Inria;Northwestern Univ.	10.1109/INFVIS.2005.1532136;10.1109/VAST.2017.8585665;10.1109/INFVIS.1996.559213;10.1109/TVCG.2016.2598594;10.1109/TVCG.2017.2745138;10.1109/TVCG.2013.173;10.1109/VAST.2010.5652880;10.1109/TVCG.2012.199;10.1109/TVCG.2015.2467758;10.1109/TVCG.2016.2598589;10.1109/VISUAL.1992.235203;10.1109/TVCG.2017.2744138;10.1109/VAST.2017.8585669;10.1109/VISUAL.1990.146375;10.1109/TVCG.2010.161;10.1109/TVCG.2007.70515	Decision making,cognitive bias,bias alleviation,bias mitigation,debiasing,information visualization,attraction effect	0	4	4	98	
InfoVis	2018	Visualizing Ranges over Time on Mobile Phones: A Task-Based Crowdsourced Evaluation	10.1109/TVCG.2018.2865234	http://dx.doi.org/10.1109/TVCG.2018.2865234	619	629	J	In the first crowdsourced visualization experiment conducted exclusively on mobile phones, we compare approaches to visualizing ranges over time on small displays. People routinely consume such data via a mobile phone, from temperatures in weather forecasting apps to sleep and blood pressure readings in personal health apps. However, we lack guidance on how to effectively visualize ranges on small displays in the context of different value retrieval and comparison tasks, or with respect to different data characteristics such as periodicity, seasonality, or the cardinality of ranges. Central to our experiment is a comparison between two ways to lay out ranges: a more conventional linear layout strikes a balance between quantitative and chronological scale resolution, while a less conventional radial layout emphasizes the cyclicality of time and may prioritize discrimination between values at its periphery. With results from 87 crowd workers, we found that while participants completed tasks more quickly with linear layouts than with radial ones, there were few differences in terms of error rate between layout conditions. We also found that participants performed similarly with both layouts in tasks that involved comparing superimposed observed and average ranges.	Matthew Brehmer;Bongshin Lee;Petra Isenberg;Eun Kyoung Choe	Matthew Brehmer;Bongshin Lee;Petra Isenberg;Eun Kyoung Choe	Microsoft Research;Microsoft Research;Inria;The University of Maryland, College Park	10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2010.209;10.1109/TVCG.2010.162;10.1109/VAST.2007.4388994	Evaluation,graphical perception,mobile phones,range visualization,crowdsourcing	0	4	3	54	
InfoVis	2018	Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances	10.1109/TVCG.2018.2865235	http://dx.doi.org/10.1109/TVCG.2018.2865235	608	618	J	Interactive wall-sized displays benefit data visualization. Due to their sheer display size, they make it possible to show large amounts of data in multiple coordinated views (MCV) and facilitate collaborative data analysis. In this work, we propose a set of important design considerations and contribute a fundamental input vocabulary and interaction mapping for MCV functionality. We also developed a fully functional application with more than 45 coordinated views visualizing a real-world, multivariate data set of crime activities, which we used in a comprehensive qualitative user study investigating how pairs of users behave. Most importantly, we found that flexible movement is essential and-depending on user goals-is connected to collaboration, perception, and interaction. Therefore, we argue that for future systems interaction from the distance is required and needs good support. We show that our consistent design for both direct touch at the large display and distant interaction using mobile phones enables the seamless exploration of large-scale MCV at wall-sized displays. Our MCV application builds on design aspects such as simplicity, flexibility, and visual consistency and, therefore, supports realistic workflows. We believe that in the future, many visual data analysis scenarios will benefit from wall-sized displays presenting numerous coordinated visualizations, for which our findings provide a valuable foundation.	Ricardo Langner;Ulrike Kister;Raimund Dachselt	Ricardo Langner;Ulrike Kister;Raimund Dachselt	Interactive Media Lab, Technische Universität Dresden, Germany;Interactive Media Lab, Technische Universität Dresden, Germany;Interactive Media Lab, Technische Universität Dresden, Germany	10.1109/VAST.2016.7883506;10.1109/TVCG.2012.251;10.1109/VAST.2010.5652880;10.1109/TVCG.2013.166;10.1109/TVCG.2013.134;10.1109/TVCG.2017.2743859;10.1109/TVCG.2017.2744019;10.1109/TVCG.2012.204;10.1109/TVCG.2017.2744198;10.1109/TVCG.2017.2745219;10.1109/TVCG.2009.162;10.1109/TVCG.2012.237;10.1109/TVCG.2012.275;10.1109/INFVIS.1996.559216;10.1109/TVCG.2006.184	Multiple coordinated views,wall-sized displays,mobile devices,distant interaction,physical navigation,user behavior,user movements,multi-user,collaborative data analysis	0	3	2	79	
InfoVis	2018	Information Olfactation: Harnessing Scent to Convey Data	10.1109/TVCG.2018.2865237	http://dx.doi.org/10.1109/TVCG.2018.2865237	726	736	J	Olfactory feedback for analytical tasks is a virtually unexplored area in spite of the advantages it offers for information recall, feature identification, and location detection. Here we introduce the concept of information olfactation as the fragrant sibling of information visualization, and discuss how scent can be used to convey data. Building on a review of the human olfactory system and mirroring common visualization practice, we propose olfactory marks, the substrate in which they exist, and their olfactory channels that are available to designers. To exemplify this idea, we present viScent: A six-scent stereo olfactory display capable of conveying olfactory glyphs of varying temperature and direction, as well as a corresponding software system that integrates the display with a traditional visualization display. Finally, we present three applications that make use of the viScent system: A 2D graph visualization, a 2D line and point chart, and an immersive analytics graph visualization in 3D virtual reality. We close the paper with a review of possible extensions of viScent and applications of information olfactation for general visualization beyond the examples in this paper.	Biswaksen Patnaik;Andrea Batch;Niklas Elmqvist	Biswaksen Patnaik;Andrea Batch;Niklas Elmqvist	University of Maryland, College Park, MD, USA;University of Maryland, College Park, MD, USA;University of Maryland, College Park, MD, USA	10.1109/TVCG.2016.2599107	Olfaction,smell,scent,olfactory display,immersive analytics,immersion	0	2	1	104	
InfoVis	2018	Formalizing Visualization Design Knowledge as Constraints: Actionable and Extensible Models in Draco	10.1109/TVCG.2018.2865240	http://dx.doi.org/10.1109/TVCG.2018.2865240	438	448	J	There exists a gap between visualization design guidelines and their application in visualization tools. While empirical studies can provide design guidance, we lack a formal framework for representing design knowledge, integrating results across studies, and applying this knowledge in automated design tools that promote effective encodings and facilitate visual exploration. We propose modeling visualization design knowledge as a collection of constraints, in conjunction with a method to learn weights for soft constraints from experimental data. Using constraints, we can take theoretical design knowledge and express it in a concrete, extensible, and testable form: the resulting models can recommend visualization designs and can easily be augmented with additional constraints or updated weights. We implement our approach in Draco, a constraint-based system based on Answer Set Programming (ASP). We demonstrate how to construct increasingly sophisticated automated visualization design systems, including systems based on weights learned directly from the results of graphical perception experiments.	Dominik Moritz;Chenglong Wang;Greg L. Nelson;Halden Lin;Adam M. Smith;Bill Howe;Jeffrey Heer	Dominik Moritz;Chenglong Wang;Greg L. Nelson;Halden Lin;Adam M. Smith;Bill Howe;Jeffrey Heer	University of Washington;University of Washington;University of Washington;University of Washington;University of California Santa Cruz;University of Washington;University of Washington	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2014.2346984;10.1109/TVCG.2013.183;10.1109/TVCG.2014.2346979;10.1109/TVCG.2007.70594;10.1109/TVCG.2017.2744320;10.1109/TVCG.2017.2744198;10.1109/TVCG.2017.2744198;10.1109/TVCG.2016.2599030;10.1109/TVCG.2017.2744359;10.1109/TVCG.2015.2467191	Automated Visualization Design,Perceptual Effectiveness,Constraints,Knowledge Bases,Answer Set Programming	1	30	4	67	BP
InfoVis	2018	A Framework for Creative Visualization-Opportunities Workshops	10.1109/TVCG.2018.2865241	http://dx.doi.org/10.1109/TVCG.2018.2865241	748	758	J	Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience.	Ethan Kerzner;Sarah Goodwin;Jason Dykes;Sara Jones 0001;Miriah D. Meyer	Ethan Kerzner;Sarah Goodwin;Jason Dykes;Sara Jones;Miriah Meyer	University of Utah;Royal Melbourne Institute of TechnologyMonash University;City, University of London;City, University of London;University of Utah	10.1109/TVCG.2010.191;10.1109/TVCG.2013.145;10.1109/TVCG.2016.2598545;10.1109/TVCG.2016.2599338;10.1109/TVCG.2011.209;10.1109/TVCG.2017.2744459;10.1109/TVCG.2014.2346331;10.1109/TVCG.2009.111;10.1109/TVCG.2015.2467271;10.1109/TVCG.2016.2599030;10.1109/TVCG.2012.213;10.1109/TVCG.2013.132;10.1109/TVCG.2015.2467191	User-centered visualization design,design studies,creativity workshops,critically reflective practice	0	5	3	90	
InfoVis	2018	At a Glance: Pixel Approximate Entropy as a Measure of Line Chart Complexity	10.1109/TVCG.2018.2865264	http://dx.doi.org/10.1109/TVCG.2018.2865264	872	881	J	When inspecting information visualizations under time critical settings, such as emergency response or monitoring the heart rate in a surgery room, the user only has a small amount of time to view the visualization “at a glance”. In these settings, it is important to provide a quantitative measure of the visualization to understand whether or not the visualization is too “complex” to accurately judge at a glance. This paper proposes Pixel Approximate Entropy (PAE), which adapts the approximate entropy statistical measure commonly used to quantify regularity and unpredictability in time-series data, as a measure of visual complexity for line charts. We show that PAE is correlated with user-perceived chart complexity, and that increased chart PAE correlates with reduced judgement accuracy. `We also find that the correlation between PAE values and participants' judgment increases when the user has less time to examine the line charts.	Gabriel Ryan;Abigail Mosca;Remco Chang;Eugene Wu 0002	Gabriel Ryan;Abigail Mosca;Remco Chang;Eugene Wu	Columbia University;Tufts University;Tufts University;Columbia University	10.1109/TVCG.2011.229;10.1109/TVCG.2013.133;10.1109/TVCG.2010.131;10.1109/TVCG.2010.184;10.1109/VAST.2010.5653598;10.1109/TVCG.2007.70594;10.1109/INFVIS.2004.15;10.1109/VAST.2006.261423;10.1109/TVCG.2008.140;10.1109/TVCG.2010.161;10.1109/INFVIS.2005.1532142	Visualization,Graphical Perception,Entropy,At-a-glance		4	1	69	
InfoVis	2018	Temporal Treemaps: Static Visualization of Evolving Trees	10.1109/TVCG.2018.2865265	http://dx.doi.org/10.1109/TVCG.2018.2865265	534	543	J	We consider temporally evolving trees with changing topology and data: tree nodes may persist for a time range, merge or split, and the associated data may change. Essentially, one can think of this as a time series of trees with a node correspondence per hierarchy level between consecutive time steps. Existing visualization approaches for such data include animated 2D treemaps, where the dynamically changing layout makes it difficult to observe the data in its entirety. We present a method to visualize this dynamic data in a static, nested, and space-filling visualization. This is based on two major contributions: First, the layout constitutes a graph drawing problem. We approach it for the entire time span at once using a combination of a heuristic and simulated annealing. Second, we propose a rendering that emphasizes the hierarchy through an adaption of the classic cushion treemaps. We showcase the wide range of applicability using data from feature tracking in time-dependent scalar fields, evolution of file system hierarchies, and world population.	Wiebke Köpp;Tino Weinkauf	Wiebke Köpp;Tino Weinkauf	KTH Royal Institute of Technology, Stockholm, Sweden;KTH Royal Institute of Technology, Stockholm, Sweden	10.1109/INFVIS.2005.1532128;10.1109/TVCG.2011.226;10.1109/TVCG.2008.166;10.1109/TVCG.2014.2346433;10.1109/TVCG.2017.2743959;10.1109/VISUAL.1991.175815;10.1109/TVCG.2013.196;10.1109/INFVIS.2001.963283;10.1109/TVCG.2017.2745140;10.1109/TVCG.2007.70529;10.1109/INFVIS.1999.801860;10.1109/TVCG.2008.163	Treemaps,Temporal trees		4	3	40	
InfoVis	2018	Image-Based Aspect Ratio Selection	10.1109/TVCG.2018.2865266	http://dx.doi.org/10.1109/TVCG.2018.2865266	840	849	J	Selecting a good aspect ratio is crucial for effective 2D diagrams. There are several aspect ratio selection methods for function plots and line charts, but only few can handle general, discrete diagrams such as 2D scatter plots. However, these methods either lack a perceptual foundation or heavily rely on intermediate isoline representations, which depend on choosing the right isovalues and are time-consuming to compute. This paper introduces a general image-based approach for selecting aspect ratios for a wide variety of 2D diagrams, ranging from scatter plots and density function plots to line charts. Our approach is derived from Federer's co-area formula and a line integral representation that enable us to directly construct image-based versions of existing selection methods using density fields. In contrast to previous methods, our approach bypasses isoline computation, so it is faster to compute, while following the perceptual foundation to select aspect ratios. Furthermore, this approach is complemented by an anisotropic kernel density estimation to construct density fields, allowing us to more faithfully characterize data patterns, such as the subgroups in scatterplots or dense regions in time series. We demonstrate the effectiveness of our approach by quantitatively comparing to previous methods and revisiting a prior user study. Finally, we present extensions for ROI banking, multi-scale banking, and the application to image data.	Yunhai Wang;Zeyu Wang 0005;Chi-Wing Fu;Hansjörg Schmauder;Oliver Deussen;Daniel Weiskopf	Yunhai Wang;Zeyu Wang;Chi-Wing Fu;Hansjörq Schmauder;Oliver Deussen;Daniel Weiskopf	Shandong University;SIAT, Shenzhen VisuCA Key Lab, China;Chinese University of Hong Kong;VISUS, University of Stuttgart, Germany;Konstanz University, Germany;VISUS, University of Stuttgart, Germany	10.1109/TVCG.2008.119;10.1109/TVCG.2006.168;10.1109/TVCG.2013.187;10.1109/TVCG.2009.131;10.1109/TVCG.2010.146;10.1109/TVCG.2017.2744184;10.1109/TVCG.2006.168;10.1109/TVCG.2011.167;10.1109/TVCG.2012.196;10.1109/VAST.2009.5332628;10.1109/INFVIS.2005.1532142	Aspect ratio,image-based method,Federer's co-area formula,density field,anisotropic kernel density estimation	0	1	1	42	
VAST	2018	VUSphere: Visual Analysis of Video Utilization in Online Distance Education	10.1109/VAST.2018.8802383	http://dx.doi.org/10.1109/VAST.2018.8802383	25	35	C	Online Distance Education (ODE) provides massive course videos of various specialties for students across the country to learn professional knowledge anytime and anywhere. Analyzing the utilization of these videos from user log data can help academics better understand the learning process of students, evaluate the quality of service provided by regional learning centers, and improve the quality of program curriculum in the future. However, due to the lack of comparable indicators, it is a great challenge to discover the utilization patterns of massive videos and analyze the learning process of large-scale student population from learning log data. In this paper, we introduce a visual analytics system, called VUSphere, to explore the video utilization from multiple perspectives with two proposed indicators. This system offers three coordinated views: a spherical layout overview to depict the overall utilization distribution of videos, courses, and students; a detailed statistics view with four panels to present video utilization statistics of each element from multiple perspectives; and a comparison view to examine the differences in individual elements. Based on the real dataset from our ODE school, several patterns related to video utilization and enrollment are found in the case study with our domain experts.	Huan He;Qinghua Zheng;Bo Dong	Huan He;Oinghua Zheng;Bo Dong	Key Laboratory of Intelligent Networks and Network Security, Ministry of Education, Xi’an Jiaotong University;Key Laboratory of Intelligent Networks and Network Security, Ministry of Education, Xi’an Jiaotong University;School of Continuing Education, Xi’an Jiaotong University	10.1109/TVCG.2016.2598444;10.1109/VAST.2016.7883517;10.1109/TVCG.2015.2467322	Video utilization pattern,online distance education,visual analytics		0		0	
VAST	2018	Segue: Overviewing Evolution Patterns of Egocentric Networks by Interactive Construction of Spatial Layouts	10.1109/VAST.2018.8802415	http://dx.doi.org/10.1109/VAST.2018.8802415	72	83	C	Getting the overall picture of how a large number of ego-networks evolve is a common yet challenging task. Existing techniques often require analysts to inspect the evolution patterns of ego-networks one after another. In this study, we explore an approach that allows analysts to interactively create spatial layouts in which each dot is a dynamic ego-network. These spatial layouts provide overviews of the evolution patterns of ego-networks, thereby revealing different global patterns such as trends, clusters and outliers in evolution patterns. To let analysts interactively construct interpretable spatial layouts, we propose a data transformation pipeline, with which analysts can adjust the spatial layouts and convert dynamic ego-networks into event sequences to aid interpretations of the spatial positions. Based on this transformation pipeline, we develop Segue, a visual analysis system that supports thorough exploration of the evolution patterns of ego-networks. Through two usage scenarios, we demonstrate how analysts can gain insights into the overall evolution patterns of a large collection of ego-networks by interactively creating different spatial layouts.	Po-Ming Law;Yanhong Wu;Rahul C. Basole	Po-Ming Law;Yanhong Wu;Rahul C. Basole	Georgia Institute of Technology;Visa Research;Georgia Institute of Technology	10.1109/TVCG.2015.2467851;10.1109/VAST.2012.6400486;10.1109/TVCG.2011.226;10.1109/TVCG.2011.188;10.1109/VAST.2016.7883512;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.198;10.1109/TVCG.2015.2467615;10.1109/TVCG.2016.2598446;10.1109/VAST.2015.7347632;10.1109/TVCG.2016.2598797;10.1109/TVCG.2013.200;10.1109/TVCG.2017.2744198;10.1109/TVCG.2015.2468078;10.1109/VAST.2009.5332595;10.1109/TVCG.2015.2468151	Human-centered computing,Visualization,Visualization techniques,Graph drawings		0	27	0	
VAST	2018	The Effect of Semantic Interaction on Foraging in Text Analysis	10.1109/VAST.2018.8802424	http://dx.doi.org/10.1109/VAST.2018.8802424	13	24	C	Completing text analysis tasks is a continuous sensemaking loop of foraging for information and incrementally synthesizing it into hypotheses. Past research has shown the advantages of using spatial workspaces as a means for synthesizing information through externalizing hypotheses and creating spatial schemas. However, spatializing the entirety of datasets becomes prohibitive as the number of documents available to the analysts grows, particularly when only a small subset are relevant to the task at hand. StarSPIRE is a visual analytics tool designed to explore collections of documents, leveraging users' semantic interactions to steer (1) a synthesis model that aids in document layout, and (2) a foraging model to automatically retrieve new relevant information. In contrast to traditional keyword search foraging (KSF), “semantic interaction foraging” (SIF) occurs as a result of the user's synthesis actions. To quantify the value of semantic interaction foraging, we use StarSPIRE to evaluate its utility for an intelligence analysis sensemaking task. Semantic interaction foraging accounted for 26% of useful documents found, and it also resulted in increased synthesis interactions and improved sensemaking task performance by users in comparison to only using keyword search.	John E. Wenskovitch;Lauren Bradel;Michelle Dowling;Leanna House;Chris North	John Wenskovitch;Lauren Bradel;Michelle Dowling;Leanna House;Chris North	Virginia Tech Computer Science;Department of Defense;Virginia Tech Computer Science;Virginia Tech Statistics;Virginia Tech Computer Science	10.1109/TVCG.2006.120;10.1109/VAST.2012.6400559;10.1109/TVCG.2013.205;10.1109/VAST.2008.4677362;10.1109/VAST.2014.7042492;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.260;10.1109/VAST.2011.6102449;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2004.37	Human-centered computing,Visualization,Empirical studies in visualization,Human-centered computing,Visualization,Visual analytics		1	29	0	
VAST	2018	The Effect of Proximity in Social Data Charts on Perceived Unity	10.1109/VAST.2018.8802449	http://dx.doi.org/10.1109/VAST.2018.8802449	1	12	C	Social data charts - visual presentations of quantitative data about peer behaviors - may offer new means to motivate individuals to participate in group goals. However, to do so these charts need to create a semantic response of `unity' among the chart viewers in order to overcome the problems of social loafing where people act selfishly and undervalue the group's goal. In this paper, we focus on two properties of social data charts that may affect a viewer's perceptions of unity: (1) The skewness in the data structure - the statistical distribution of the social data, and (2) the proximity in the visual structure of the chart - the spatial organization of the data points. We performed a controlled perceptual experiment to examine the effect of proximity and skewness on four different semantic facets of perceived group unity: similarity, entitativity, rapport, and centrality. We exposed 179 participants on Amazon Mechanical Turk to different group charts using a 2 x 2 factorial design, varying both proximity and skewness. Our two-way ANCOVA analyses reveal three important findings: (1) Across all conditions, proximity has a strong positive effect on perceived group unity and conveys a social meaning of group entitativity, as well as, member similarity and rapport; (2) Skewness and proximity interact in a non-linear way, suggesting that skewness creates a negative force that modifies the semantic responses to high proximity; and (3) The perceptual responses to proximity have different semantic facets that are either stable or sensitive to skewness. These findings contribute to perceptual as well as social InfoVis literature.	Marlen Promann;Sabine Brunswicker	Marlen Promann;Sabine Brunswicker	Purdue University;Purdue University	10.1109/TVCG.2017.2746018;10.1109/TVCG.2008.171;10.1109/TVCG.2014.2346419;10.1109/TVCG.2007.70541;10.1109/TVCG.2013.234;10.1109/TVCG.2010.174;10.1109/TVCG.2012.221;10.1109/TVCG.2017.2745240	Social visualization,information visualization,Human-centered computing,Empirical studies in HCI,Displays and imagers,Social engineering (social sciences),Visualization theory, concepts and paradigms,Gestalt theory,controlled experiment,data density,data spread,perception,group identity,unity,priming		0	27	0	
VAST	2018	EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection	10.1109/VAST.2018.8802454	http://dx.doi.org/10.1109/VAST.2018.8802454	48	59	C	Constructing latent vector representation for nodes in a network through embedding models has shown its practicality in many graph analysis applications, such as node classification, clustering, and link prediction. However, despite the high efficiency and accuracy of learning an embedding model, people have little clue of what information about the original network is preserved in the embedding vectors. The abstractness of low-dimensional vector representation, stochastic nature of the construction process, and non-transparent hyper-parameters all obscure understanding of network embedding results. Visualization techniques have been introduced to facilitate embedding vector inspection, usually by projecting the embedding space to a two-dimensional display. Although the existing visualization methods allow simple examination of the structure of embedding space, they cannot support in-depth exploration of the embedding vectors. In this paper, we design an exploratory visual analytics system that supports the comparative visual interpretation of embedding vectors at the cluster, instance, and structural levels. To be more specific, it facilitates comparison of what and how node metrics are preserved across different embedding models and investigation of relationships between node metrics and selected embedding vectors. Several case studies confirm the efficacy of our system. Experts' feedback suggests that our approach indeed helps them better embrace the understanding of network embedding models.	Quan Li;Kristanto Sean Njotoprawiro;Hammad Haleem;Qiaoan Chen;Chris Yi;Xiaojuan Ma	Quan Li;Kristanto Sean Njotoprawiro;Hammad Haleem;Qiaoan Chen;Chris Yi;Xiaojuan Ma	Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;WeChat, Tencent Technology (Shenzhen) Co., Ltd., Shenzhen, China;WeChat, Tencent Technology (Shenzhen) Co., Ltd., Shenzhen, China;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong	10.1109/TVCG.2007.70521;10.1109/TVCG.2013.173;10.1109/VISUAL.1990.146402;10.1109/TVCG.2016.2598415;10.1109/TVCG.2017.2745141;10.1109/TVCG.2016.2598838;10.1109/TVCG.2015.2468151	Human-centered computing,Visualization,Visualization application domains,Visual analytics,Human-centered computing,Visualization,Visualization design and evaluation methods	0	3	3	0	
VAST	2018	SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach	10.1109/VAST.2018.8802486	http://dx.doi.org/10.1109/VAST.2018.8802486	36	47	C	We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.	Michael Blumenschein;Michael Behrisch 0001;Stefanie Schmid;Simon Butscher;Deborah Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim	Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah R. Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim	University of Konstanz, Germany;Harvard University, USA;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany	10.1109/INFVIS.2004.46;10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/TVCG.2017.2743978;10.1109/TVCG.2011.188;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.184;10.1109/TVCG.2014.2346260;10.1109/TVCG.2013.173;10.1109/TVCG.2015.2467553;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.138;10.1109/INFVIS.2004.15;10.1109/TVCG.2014.2346279;10.1109/INFVIS.2003.1249016;10.1109/VAST.2009.5332628;10.1109/TVCG.2015.2468078;10.1109/TVCG.2017.2745078;10.1109/TVCG.2017.2744098;10.1109/TVCG.2013.150	High-dimensional data,visual exploration,pattern-driven analysis,tabular visualization,subspace,aggregation		0	7	0	
VAST	2018	Analyzing the Noise Robustness of Deep Neural Networks	10.1109/VAST.2018.8802509	http://dx.doi.org/10.1109/VAST.2018.8802509	60	71	C	Deep neural networks (DNNs) are vulnerable to maliciously generated adversarial examples. These examples are intentionally designed by making imperceptible perturbations and often mislead a DNN into making an incorrect prediction. This phenomenon means that there is significant risk in applying DNNs to safety-critical applications, such as driverless cars. To address this issue, we present a visual analytics approach to explain the primary cause of the wrong predictions introduced by adversarial examples. The key is to analyze the datapaths of the adversarial examples and compare them with those of the normal examples. A datapath is a group of critical neurons and their connections. To this end, we formulate the datapath extraction as a subset selection problem and approximately solve it based on back-propagation. A multi-level visualization consisting of a segmented DAG (layer level), an Euler diagram (feature map level), and a heat map (neuron level), has been designed to help experts investigate datapaths from the high-level layers to the detailed neuron activations. Two case studies are conducted that demonstrate the promise of our approach in support of explaining the working mechanism of adversarial examples.	Mengchen Liu;Shixia Liu;Hang Su;Kelei Cao;Jun Zhu 0001	Mengchen Liu;Shixia Liu;Hang Su;Kelei Cao;Jun Zhu	School of Software, Tsinghua University;School of Software, Tsinghua University;Dept.of Comp.Sci.Tech., Tsinghua University;School of Software, Tsinghua University;Dept.of Comp.Sci.Tech., Tsinghua University	10.1109/TVCG.2015.2467618;10.1109/TVCG.2011.186;10.1109/TVCG.2016.2598496;10.1109/TVCG.2017.2744683;10.1109/TVCG.2014.2346431;10.1109/TVCG.2014.2346433;10.1109/TVCG.2017.2744199;10.1109/TVCG.2017.2744718;10.1109/TVCG.2017.2744938;10.1109/TVCG.2016.2598831;10.1109/TVCG.2013.196;10.1109/TVCG.2011.209;10.1109/TVCG.2017.2744358;10.1109/TVCG.2016.2598838;10.1109/TVCG.2010.210;10.1109/TVCG.2017.2744018;10.1109/TVCG.2011.183;10.1109/TVCG.2017.2744158;10.1109/VISUAL.2005.1532820;10.1109/VAST.2014.7042494;10.1109/TVCG.2017.2744878;10.1109/TVCG.2018.2865041	Deep neural networks,robustness,adversarial examples,back propagation,multi-level visualization.	0	3	0	0	